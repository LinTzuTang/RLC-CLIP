{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f2b5ff6-4344-474e-b82f-0732175481ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIPModel(\n",
      "  (matrix_encoder): MatrixEncoder(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): ReLU()\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "      (7): Linear(in_features=2048, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (vector_encoder): VectorEncoder(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoderWithPair(\n",
      "    (emb_layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
      "    (final_layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
      "    (final_head_layer_norm): LayerNorm(torch.Size([4]), eps=1e-05, elementwise_affine=True)\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): SelfMultiheadAttention(\n",
      "          (in_proj): Linear(in_features=128, out_features=384, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=128, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=128, bias=True)\n",
      "        (final_layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Batch 1/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.0231,  0.1238, -0.0356,  ...,  0.0303,  0.0344,  0.0904],\n",
      "        [-0.0033, -0.0321,  0.0869,  ..., -0.0313, -0.0444,  0.1082],\n",
      "        [ 0.0081,  0.1524, -0.0623,  ...,  0.1088, -0.0165, -0.0927],\n",
      "        ...,\n",
      "        [-0.0654,  0.1687, -0.0810,  ...,  0.0013,  0.0748,  0.0224],\n",
      "        [-0.0196,  0.1336, -0.0454,  ...,  0.1031,  0.0218, -0.0670],\n",
      "        [ 0.0418,  0.0449, -0.1536,  ...,  0.1084,  0.0431, -0.0548]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0313,  0.1227,  0.0125,  ...,  0.0328,  0.0386, -0.0757],\n",
      "        [ 0.0596,  0.1447,  0.0141,  ...,  0.1419,  0.0134,  0.0507],\n",
      "        [ 0.0748,  0.0566,  0.0774,  ..., -0.0323, -0.1134, -0.0412],\n",
      "        ...,\n",
      "        [ 0.0405,  0.0655,  0.0376,  ..., -0.0751,  0.0620, -0.0217],\n",
      "        [ 0.0374,  0.1619,  0.0226,  ...,  0.0727,  0.0028,  0.0910],\n",
      "        [ 0.1026,  0.1213, -0.0248,  ...,  0.0552, -0.0595, -0.0106]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 2.6616,  3.3749,  4.0074,  0.7183,  1.7424,  2.4592,  1.3046,  2.2689,\n",
      "          3.7876,  2.3829,  4.3623,  1.1962,  2.5635,  2.3002,  5.9606,  3.1116],\n",
      "        [ 1.5336,  3.8702,  2.7173,  0.2586,  3.2985,  2.6473,  2.3743,  2.2405,\n",
      "          2.1649,  1.3089,  2.5769,  1.7624,  2.6798,  1.0186,  3.5369,  1.7433],\n",
      "        [ 1.6842,  2.3045,  5.1457,  0.2719,  2.8039,  1.6701,  2.7876,  3.1981,\n",
      "          2.4127,  3.9365,  3.5252,  2.7722,  2.5467,  2.4230,  5.1660,  2.7084],\n",
      "        [ 2.1044,  3.2332,  3.5053,  1.8399,  2.0908,  3.2865,  2.4133,  2.5598,\n",
      "          2.2207,  2.9178,  3.8407,  2.3004,  2.0031,  1.0775,  5.9124,  4.4914],\n",
      "        [ 0.4666,  2.5884,  1.1222,  1.3165,  2.6630,  3.5261,  1.6949,  3.5352,\n",
      "          2.5508,  1.9782,  2.9693,  0.4766,  1.9507,  0.8473,  2.5713,  1.3670],\n",
      "        [ 2.4424,  3.0532,  3.2022,  1.3549,  1.7665,  3.9052,  1.6845,  3.4063,\n",
      "          3.8385,  3.3391,  4.6826,  1.1660,  2.5207,  0.1647,  6.2027,  3.0668],\n",
      "        [-0.3776,  3.8981,  2.2419, -0.2844,  3.1184,  2.8853,  2.9489,  1.9712,\n",
      "          2.1951,  2.2275,  2.2092,  0.5975,  2.9412,  0.6942,  4.0973,  3.1078],\n",
      "        [ 2.8164,  2.1604,  4.2725,  0.9740,  2.4455,  3.8363,  2.8406,  5.5191,\n",
      "          3.3584,  4.5766,  5.2803,  2.1571,  2.9230,  0.7323,  5.9629,  3.0090],\n",
      "        [ 2.6625,  2.5159,  4.1059,  1.2146,  0.3010,  2.8662,  1.1037,  2.2961,\n",
      "          5.7633,  2.2607,  2.8489,  1.5392,  2.3893,  1.9492,  5.5565,  3.7109],\n",
      "        [ 0.5556,  3.8087,  4.2429, -0.5433,  3.8625,  2.3389,  3.6558,  3.6753,\n",
      "          2.8330,  3.9821,  3.0138,  1.8344,  2.4483,  1.7401,  4.8136,  1.9682],\n",
      "        [ 0.5155,  2.7220,  2.5733, -1.0359,  1.0969,  2.2236,  0.7180,  2.5860,\n",
      "          1.3042,  2.0677,  4.5921,  0.8946,  1.3199, -0.7449,  4.5675,  1.6423],\n",
      "        [ 2.0850,  3.7545,  5.1486, -0.0881,  2.2903,  2.1027,  2.8300,  3.6095,\n",
      "          2.2371,  3.0379,  3.4029,  3.3464,  2.2489,  1.8810,  5.9299,  3.3435],\n",
      "        [ 1.3625,  3.4229,  3.8294,  0.3144,  1.6333,  3.5179,  2.9832,  2.6752,\n",
      "          3.4082,  2.3142,  4.6765,  2.3508,  5.5547,  1.8587,  4.4853,  4.0472],\n",
      "        [ 2.0909,  2.6322,  3.4210,  1.3002,  2.3668,  3.2641,  1.8034,  2.7514,\n",
      "          4.3405,  3.4526,  3.8447,  1.7003,  1.8658,  1.6664,  5.0042,  2.4144],\n",
      "        [ 2.7768,  2.3739,  3.5357,  2.9423,  1.7011,  2.1409,  2.9298,  3.1557,\n",
      "          4.1908,  3.0914,  3.2038,  1.0343,  2.8442,  1.0197,  7.3986,  5.7685],\n",
      "        [ 3.0625,  2.0754,  3.2122,  1.7411,  0.7508,  2.2536,  1.5387,  1.7286,\n",
      "          1.6902,  2.3225,  3.4126,  1.6716,  1.4248,  0.1372,  5.0091,  4.1751]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([2.6616, 3.8702, 5.1457, 1.8399, 2.6630, 3.9052, 2.9489, 5.5191, 5.7633,\n",
      "        3.9821, 4.5921, 3.3464, 5.5547, 1.6664, 7.3986, 4.1751],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(2.2399, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 3.3749,  4.0074,  0.7183,  1.7424,  2.4592,  1.3046,  2.2689,  3.7876,\n",
      "          2.3829,  4.3623,  1.1962,  2.5635,  2.3002,  5.9606,  3.1116],\n",
      "        [ 1.5336,  2.7173,  0.2586,  3.2985,  2.6473,  2.3743,  2.2405,  2.1649,\n",
      "          1.3089,  2.5769,  1.7624,  2.6798,  1.0186,  3.5369,  1.7433],\n",
      "        [ 1.6842,  2.3045,  0.2719,  2.8039,  1.6701,  2.7876,  3.1981,  2.4127,\n",
      "          3.9365,  3.5252,  2.7722,  2.5467,  2.4230,  5.1660,  2.7084],\n",
      "        [ 2.1044,  3.2332,  3.5053,  2.0908,  3.2865,  2.4133,  2.5598,  2.2207,\n",
      "          2.9178,  3.8407,  2.3004,  2.0031,  1.0775,  5.9124,  4.4914],\n",
      "        [ 0.4666,  2.5884,  1.1222,  1.3165,  3.5261,  1.6949,  3.5352,  2.5508,\n",
      "          1.9782,  2.9693,  0.4766,  1.9507,  0.8473,  2.5713,  1.3670],\n",
      "        [ 2.4424,  3.0532,  3.2022,  1.3549,  1.7665,  1.6845,  3.4063,  3.8385,\n",
      "          3.3391,  4.6826,  1.1660,  2.5207,  0.1647,  6.2027,  3.0668],\n",
      "        [-0.3776,  3.8981,  2.2419, -0.2844,  3.1184,  2.8853,  1.9712,  2.1951,\n",
      "          2.2275,  2.2092,  0.5975,  2.9412,  0.6942,  4.0973,  3.1078],\n",
      "        [ 2.8164,  2.1604,  4.2725,  0.9740,  2.4455,  3.8363,  2.8406,  3.3584,\n",
      "          4.5766,  5.2803,  2.1571,  2.9230,  0.7323,  5.9629,  3.0090],\n",
      "        [ 2.6625,  2.5159,  4.1059,  1.2146,  0.3010,  2.8662,  1.1037,  2.2961,\n",
      "          2.2607,  2.8489,  1.5392,  2.3893,  1.9492,  5.5565,  3.7109],\n",
      "        [ 0.5556,  3.8087,  4.2429, -0.5433,  3.8625,  2.3389,  3.6558,  3.6753,\n",
      "          2.8330,  3.0138,  1.8344,  2.4483,  1.7401,  4.8136,  1.9682],\n",
      "        [ 0.5155,  2.7220,  2.5733, -1.0359,  1.0969,  2.2236,  0.7180,  2.5860,\n",
      "          1.3042,  2.0677,  0.8946,  1.3199, -0.7449,  4.5675,  1.6423],\n",
      "        [ 2.0850,  3.7545,  5.1486, -0.0881,  2.2903,  2.1027,  2.8300,  3.6095,\n",
      "          2.2371,  3.0379,  3.4029,  2.2489,  1.8810,  5.9299,  3.3435],\n",
      "        [ 1.3625,  3.4229,  3.8294,  0.3144,  1.6333,  3.5179,  2.9832,  2.6752,\n",
      "          3.4082,  2.3142,  4.6765,  2.3508,  1.8587,  4.4853,  4.0472],\n",
      "        [ 2.0909,  2.6322,  3.4210,  1.3002,  2.3668,  3.2641,  1.8034,  2.7514,\n",
      "          4.3405,  3.4526,  3.8447,  1.7003,  1.8658,  5.0042,  2.4144],\n",
      "        [ 2.7768,  2.3739,  3.5357,  2.9423,  1.7011,  2.1409,  2.9298,  3.1557,\n",
      "          4.1908,  3.0914,  3.2038,  1.0343,  2.8442,  1.0197,  5.7685],\n",
      "        [ 3.0625,  2.0754,  3.2122,  1.7411,  0.7508,  2.2536,  1.5387,  1.7286,\n",
      "          1.6902,  2.3225,  3.4126,  1.6716,  1.4248,  0.1372,  5.0091]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0611, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(1.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 1: 1.1504970788955688\n",
      "Batch 2/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0339, -0.0583, -0.0686,  ...,  0.0467, -0.1006, -0.1655],\n",
      "        [ 0.0139, -0.0136, -0.1082,  ...,  0.0867, -0.0747, -0.1162],\n",
      "        [ 0.0292, -0.0672, -0.1365,  ...,  0.0467, -0.0673, -0.0403],\n",
      "        ...,\n",
      "        [ 0.0489, -0.0341, -0.0944,  ...,  0.0579, -0.0502, -0.1293],\n",
      "        [ 0.0510, -0.0366, -0.0704,  ...,  0.0142, -0.1269, -0.0906],\n",
      "        [ 0.0307, -0.0217, -0.0575,  ...,  0.0580, -0.0928, -0.1397]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1513,  0.1050, -0.0545,  ...,  0.1491, -0.1477, -0.0570],\n",
      "        [ 0.0289,  0.1230, -0.1049,  ...,  0.1431, -0.0972, -0.0190],\n",
      "        [ 0.0841,  0.0038, -0.0288,  ...,  0.0437, -0.1332, -0.1331],\n",
      "        ...,\n",
      "        [ 0.0743,  0.0274, -0.1118,  ...,  0.1420, -0.1026, -0.0850],\n",
      "        [ 0.1722, -0.0418, -0.0909,  ...,  0.0829, -0.1364, -0.0060],\n",
      "        [ 0.0087,  0.0591, -0.0573,  ..., -0.0415, -0.0931, -0.0083]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 8.1290,  8.1290,  7.5820,  7.7197,  7.1801,  8.2449, 10.5970,  8.7810,\n",
      "         -1.6642,  6.8349,  7.9282,  8.5810,  9.7512, 10.5103,  6.0253,  8.4811],\n",
      "        [ 7.4753,  8.5666,  6.9286,  7.2320,  7.1110,  7.3970,  9.9887,  8.3019,\n",
      "         -2.4781,  5.7573,  7.5937,  8.3981,  9.6666, 10.4695,  5.7996,  8.2499],\n",
      "        [ 7.3958,  8.3759,  7.7906,  7.8311,  7.5723,  8.3065, 10.2521,  8.2400,\n",
      "         -0.9186,  6.8498,  8.0776,  7.8973,  9.7234, 10.7276,  6.9388,  8.6353],\n",
      "        [ 7.8276,  8.1455,  7.4438,  8.3286,  7.5788,  8.1905, 10.6575,  8.8825,\n",
      "         -1.6852,  6.4707,  8.1424,  8.1727, 10.0648, 10.6877,  6.9380,  8.8590],\n",
      "        [ 7.7252,  8.0739,  6.6464,  7.3858,  7.8162,  7.5457, 10.3489,  8.7605,\n",
      "         -2.6175,  6.5056,  7.4966,  8.4076,  9.7198, 10.3527,  6.1096,  8.1336],\n",
      "        [ 7.7883,  8.2339,  7.2082,  7.4870,  7.5258,  8.4584, 10.7798,  8.8180,\n",
      "         -1.1982,  6.8804,  7.6718,  8.4645,  9.5941, 10.4500,  6.8127,  8.7224],\n",
      "        [ 7.8534,  8.8807,  7.9439,  8.1442,  7.2751,  8.3415, 11.1209,  8.8310,\n",
      "         -1.4128,  6.7796,  8.4343,  8.7146, 10.1021, 10.8282,  7.2022,  8.8200],\n",
      "        [ 6.8742,  7.4902,  6.9957,  7.2120,  6.2481,  7.1327, 10.4405,  9.3536,\n",
      "         -2.4444,  6.2971,  7.6815,  8.2797,  9.3438, 10.0394,  6.4778,  8.4809],\n",
      "        [ 7.3807,  8.4007,  7.2734,  7.0347,  7.1880,  7.6684, 10.3122,  8.8521,\n",
      "         -0.7787,  6.1037,  7.8068,  8.2593,  9.3722, 10.1818,  6.4612,  8.3986],\n",
      "        [ 7.3314,  7.6710,  7.4973,  7.4868,  6.9981,  7.8494, 10.4624,  8.6304,\n",
      "         -1.8654,  7.2727,  7.8457,  7.8095,  9.5646, 10.3839,  6.5558,  8.2493],\n",
      "        [ 8.0985,  8.2279,  7.0423,  7.3525,  7.2049,  7.8801, 10.5223,  8.9539,\n",
      "         -2.4240,  6.6219,  8.3023,  8.5294,  9.8236, 10.6414,  6.2442,  8.3081],\n",
      "        [ 8.0003,  8.3197,  7.3314,  7.7071,  7.2830,  8.0334, 11.1222,  9.2581,\n",
      "         -2.1392,  6.7452,  8.3906,  9.1527,  9.9594, 10.6314,  6.9770,  8.9497],\n",
      "        [ 7.9779,  8.3587,  7.6323,  7.6508,  7.3220,  8.3402, 10.8054,  8.8998,\n",
      "         -1.6487,  6.3401,  8.2623,  8.4713, 10.0155, 10.7072,  6.7747,  8.8850],\n",
      "        [ 7.5806,  8.4699,  7.0999,  7.2530,  7.1151,  7.8810, 10.5198,  8.8139,\n",
      "         -2.3924,  6.7700,  8.2518,  8.1164, 10.2813, 11.0612,  6.5198,  8.6967],\n",
      "        [ 7.2094,  8.1152,  6.9222,  7.3018,  6.8814,  7.4321, 10.2082,  9.0802,\n",
      "         -2.2141,  6.2815,  7.9110,  8.3515,  9.6490, 10.3746,  7.2621,  8.4202],\n",
      "        [ 7.9060,  8.4483,  6.9941,  7.9559,  7.5927,  8.0199, 10.6865,  8.9226,\n",
      "         -2.0764,  6.3990,  7.9656,  8.7652,  9.9776, 10.6466,  6.8939,  9.0923]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([ 8.1290,  8.5666,  7.7906,  8.3286,  7.8162,  8.4584, 11.1209,  9.3536,\n",
      "        -0.7787,  7.2727,  8.3023,  9.1527, 10.0155, 11.0612,  7.2621,  9.0923],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(3.5976, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 8.1290,  7.5820,  7.7197,  7.1801,  8.2449, 10.5970,  8.7810, -1.6642,\n",
      "          6.8349,  7.9282,  8.5810,  9.7512, 10.5103,  6.0253,  8.4811],\n",
      "        [ 7.4753,  6.9286,  7.2320,  7.1110,  7.3970,  9.9887,  8.3019, -2.4781,\n",
      "          5.7573,  7.5937,  8.3981,  9.6666, 10.4695,  5.7996,  8.2499],\n",
      "        [ 7.3958,  8.3759,  7.8311,  7.5723,  8.3065, 10.2521,  8.2400, -0.9186,\n",
      "          6.8498,  8.0776,  7.8973,  9.7234, 10.7276,  6.9388,  8.6353],\n",
      "        [ 7.8276,  8.1455,  7.4438,  7.5788,  8.1905, 10.6575,  8.8825, -1.6852,\n",
      "          6.4707,  8.1424,  8.1727, 10.0648, 10.6877,  6.9380,  8.8590],\n",
      "        [ 7.7252,  8.0739,  6.6464,  7.3858,  7.5457, 10.3489,  8.7605, -2.6175,\n",
      "          6.5056,  7.4966,  8.4076,  9.7198, 10.3527,  6.1096,  8.1336],\n",
      "        [ 7.7883,  8.2339,  7.2082,  7.4870,  7.5258, 10.7798,  8.8180, -1.1982,\n",
      "          6.8804,  7.6718,  8.4645,  9.5941, 10.4500,  6.8127,  8.7224],\n",
      "        [ 7.8534,  8.8807,  7.9439,  8.1442,  7.2751,  8.3415,  8.8310, -1.4128,\n",
      "          6.7796,  8.4343,  8.7146, 10.1021, 10.8282,  7.2022,  8.8200],\n",
      "        [ 6.8742,  7.4902,  6.9957,  7.2120,  6.2481,  7.1327, 10.4405, -2.4444,\n",
      "          6.2971,  7.6815,  8.2797,  9.3438, 10.0394,  6.4778,  8.4809],\n",
      "        [ 7.3807,  8.4007,  7.2734,  7.0347,  7.1880,  7.6684, 10.3122,  8.8521,\n",
      "          6.1037,  7.8068,  8.2593,  9.3722, 10.1818,  6.4612,  8.3986],\n",
      "        [ 7.3314,  7.6710,  7.4973,  7.4868,  6.9981,  7.8494, 10.4624,  8.6304,\n",
      "         -1.8654,  7.8457,  7.8095,  9.5646, 10.3839,  6.5558,  8.2493],\n",
      "        [ 8.0985,  8.2279,  7.0423,  7.3525,  7.2049,  7.8801, 10.5223,  8.9539,\n",
      "         -2.4240,  6.6219,  8.5294,  9.8236, 10.6414,  6.2442,  8.3081],\n",
      "        [ 8.0003,  8.3197,  7.3314,  7.7071,  7.2830,  8.0334, 11.1222,  9.2581,\n",
      "         -2.1392,  6.7452,  8.3906,  9.9594, 10.6314,  6.9770,  8.9497],\n",
      "        [ 7.9779,  8.3587,  7.6323,  7.6508,  7.3220,  8.3402, 10.8054,  8.8998,\n",
      "         -1.6487,  6.3401,  8.2623,  8.4713, 10.7072,  6.7747,  8.8850],\n",
      "        [ 7.5806,  8.4699,  7.0999,  7.2530,  7.1151,  7.8810, 10.5198,  8.8139,\n",
      "         -2.3924,  6.7700,  8.2518,  8.1164, 10.2813,  6.5198,  8.6967],\n",
      "        [ 7.2094,  8.1152,  6.9222,  7.3018,  6.8814,  7.4321, 10.2082,  9.0802,\n",
      "         -2.2141,  6.2815,  7.9110,  8.3515,  9.6490, 10.3746,  8.4202],\n",
      "        [ 7.9060,  8.4483,  6.9941,  7.9559,  7.5927,  8.0199, 10.6865,  8.9226,\n",
      "         -2.0764,  6.3990,  7.9656,  8.7652,  9.9776, 10.6466,  6.8939]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0687, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(1.8332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 2: 1.8331776857376099\n",
      "Batch 3/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1079, -0.0032, -0.0705,  ...,  0.1022, -0.1012, -0.1485],\n",
      "        [ 0.1115,  0.0115, -0.0444,  ...,  0.1322, -0.0943, -0.1411],\n",
      "        [ 0.0963,  0.0052, -0.1032,  ...,  0.0974, -0.0950, -0.1141],\n",
      "        ...,\n",
      "        [ 0.1059, -0.0042, -0.0916,  ...,  0.1298, -0.0517, -0.1686],\n",
      "        [ 0.1205, -0.0096, -0.1286,  ...,  0.0947, -0.1039, -0.1241],\n",
      "        [ 0.1154, -0.0039, -0.0801,  ...,  0.1301, -0.0972, -0.1366]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0884,  0.0367, -0.1149,  ...,  0.1516, -0.1440, -0.1363],\n",
      "        [ 0.0326,  0.0394, -0.0729,  ...,  0.0773, -0.0353, -0.0907],\n",
      "        [ 0.1074,  0.0233, -0.1113,  ...,  0.1653, -0.1163, -0.0732],\n",
      "        ...,\n",
      "        [ 0.1038,  0.0383, -0.0326,  ...,  0.1393, -0.0973, -0.1473],\n",
      "        [ 0.1716,  0.0186, -0.1019,  ...,  0.0924, -0.1394, -0.0995],\n",
      "        [ 0.1128, -0.0046, -0.0639,  ...,  0.0941, -0.0956, -0.0604]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[12.5978, 12.9356, 12.5279, 12.5798, 12.6617, 12.8123, 12.5409, 12.7835,\n",
      "         12.9269, 12.6843, 12.2204, 12.4814, 12.7644, 12.9486, 13.1213, 12.0701],\n",
      "        [12.5702, 13.1453, 12.6771, 12.8460, 12.7600, 12.7799, 12.7170, 12.7450,\n",
      "         12.9062, 12.9015, 12.3242, 12.5351, 12.7536, 12.9849, 13.0112, 12.1420],\n",
      "        [12.4597, 13.0282, 12.9817, 12.5293, 12.5556, 12.7385, 12.5476, 12.7970,\n",
      "         13.1400, 12.8632, 12.4620, 12.6117, 12.9632, 12.8799, 13.2325, 12.4482],\n",
      "        [12.7946, 13.1711, 12.7450, 13.0020, 12.9204, 12.8950, 12.8391, 13.0415,\n",
      "         12.9563, 12.9952, 12.5151, 12.7739, 12.9263, 12.9803, 13.2547, 12.2517],\n",
      "        [12.4987, 12.9803, 12.6062, 12.8116, 12.7558, 12.7492, 12.6778, 12.6311,\n",
      "         12.8770, 12.7544, 12.2917, 12.5108, 12.8964, 12.7760, 13.1902, 12.0220],\n",
      "        [12.3442, 12.7781, 12.5435, 12.5267, 12.4115, 12.7733, 12.4477, 12.5823,\n",
      "         12.9577, 12.6855, 12.1062, 12.2452, 12.8751, 12.7327, 13.0844, 12.0516],\n",
      "        [12.3560, 12.9836, 12.7351, 12.6541, 12.5502, 12.8471, 12.5244, 12.5900,\n",
      "         13.1126, 12.8097, 12.3837, 12.3794, 12.7754, 12.8719, 13.0686, 12.1424],\n",
      "        [12.7899, 13.2451, 12.8822, 12.9603, 12.7642, 12.9162, 12.8399, 13.0747,\n",
      "         13.0226, 13.1042, 12.5266, 12.7966, 12.9543, 12.9605, 13.2486, 12.3518],\n",
      "        [12.3632, 12.9244, 12.8196, 12.5892, 12.4922, 12.8282, 12.4485, 12.6401,\n",
      "         13.2637, 12.9406, 12.4616, 12.5574, 13.0278, 12.8243, 13.1034, 12.5697],\n",
      "        [12.6865, 13.1060, 12.8411, 12.8306, 12.8299, 13.0008, 12.7163, 13.0677,\n",
      "         13.1338, 13.2304, 12.5914, 12.8736, 12.8597, 12.9715, 13.2824, 12.4217],\n",
      "        [12.6049, 13.2122, 12.9703, 12.7839, 12.8668, 12.9826, 12.6994, 12.7617,\n",
      "         13.1005, 13.0851, 12.7008, 12.8068, 12.8302, 13.0803, 13.0813, 12.3945],\n",
      "        [12.6843, 13.1333, 12.7147, 12.8434, 12.8034, 12.8934, 12.7989, 13.0246,\n",
      "         13.0085, 12.9829, 12.4722, 12.8586, 12.8433, 12.9415, 13.2557, 12.2540],\n",
      "        [12.3216, 12.8018, 12.6064, 12.6150, 12.4202, 12.7662, 12.4506, 12.7028,\n",
      "         13.1681, 12.7809, 12.1557, 12.2860, 13.0931, 12.6578, 13.2059, 12.1993],\n",
      "        [12.4320, 12.9896, 12.5446, 12.5982, 12.6844, 12.5450, 12.4390, 12.6404,\n",
      "         12.8008, 12.6860, 12.2328, 12.6282, 12.6449, 12.8967, 12.9131, 11.9985],\n",
      "        [12.6970, 13.0594, 12.7948, 12.7969, 12.7459, 12.8291, 12.6281, 13.0375,\n",
      "         12.9944, 12.9819, 12.5511, 12.9202, 12.9868, 13.0462, 13.3657, 12.5306],\n",
      "        [12.3766, 12.8597, 12.7381, 12.4982, 12.3737, 12.8396, 12.5317, 12.3464,\n",
      "         13.1307, 12.7893, 12.3347, 12.4220, 12.8914, 12.7913, 13.1367, 12.4515]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([12.5978, 13.1453, 12.9817, 13.0020, 12.7558, 12.7733, 12.5244, 13.0747,\n",
      "        13.2637, 13.2304, 12.7008, 12.8586, 13.0931, 12.8967, 13.3657, 12.4515],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(2.6351, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[12.9356, 12.5279, 12.5798, 12.6617, 12.8123, 12.5409, 12.7835, 12.9269,\n",
      "         12.6843, 12.2204, 12.4814, 12.7644, 12.9486, 13.1213, 12.0701],\n",
      "        [12.5702, 12.6771, 12.8460, 12.7600, 12.7799, 12.7170, 12.7450, 12.9062,\n",
      "         12.9015, 12.3242, 12.5351, 12.7536, 12.9849, 13.0112, 12.1420],\n",
      "        [12.4597, 13.0282, 12.5293, 12.5556, 12.7385, 12.5476, 12.7970, 13.1400,\n",
      "         12.8632, 12.4620, 12.6117, 12.9632, 12.8799, 13.2325, 12.4482],\n",
      "        [12.7946, 13.1711, 12.7450, 12.9204, 12.8950, 12.8391, 13.0415, 12.9563,\n",
      "         12.9952, 12.5151, 12.7739, 12.9263, 12.9803, 13.2547, 12.2517],\n",
      "        [12.4987, 12.9803, 12.6062, 12.8116, 12.7492, 12.6778, 12.6311, 12.8770,\n",
      "         12.7544, 12.2917, 12.5108, 12.8964, 12.7760, 13.1902, 12.0220],\n",
      "        [12.3442, 12.7781, 12.5435, 12.5267, 12.4115, 12.4477, 12.5823, 12.9577,\n",
      "         12.6855, 12.1062, 12.2452, 12.8751, 12.7327, 13.0844, 12.0516],\n",
      "        [12.3560, 12.9836, 12.7351, 12.6541, 12.5502, 12.8471, 12.5900, 13.1126,\n",
      "         12.8097, 12.3837, 12.3794, 12.7754, 12.8719, 13.0686, 12.1424],\n",
      "        [12.7899, 13.2451, 12.8822, 12.9603, 12.7642, 12.9162, 12.8399, 13.0226,\n",
      "         13.1042, 12.5266, 12.7966, 12.9543, 12.9605, 13.2486, 12.3518],\n",
      "        [12.3632, 12.9244, 12.8196, 12.5892, 12.4922, 12.8282, 12.4485, 12.6401,\n",
      "         12.9406, 12.4616, 12.5574, 13.0278, 12.8243, 13.1034, 12.5697],\n",
      "        [12.6865, 13.1060, 12.8411, 12.8306, 12.8299, 13.0008, 12.7163, 13.0677,\n",
      "         13.1338, 12.5914, 12.8736, 12.8597, 12.9715, 13.2824, 12.4217],\n",
      "        [12.6049, 13.2122, 12.9703, 12.7839, 12.8668, 12.9826, 12.6994, 12.7617,\n",
      "         13.1005, 13.0851, 12.8068, 12.8302, 13.0803, 13.0813, 12.3945],\n",
      "        [12.6843, 13.1333, 12.7147, 12.8434, 12.8034, 12.8934, 12.7989, 13.0246,\n",
      "         13.0085, 12.9829, 12.4722, 12.8433, 12.9415, 13.2557, 12.2540],\n",
      "        [12.3216, 12.8018, 12.6064, 12.6150, 12.4202, 12.7662, 12.4506, 12.7028,\n",
      "         13.1681, 12.7809, 12.1557, 12.2860, 12.6578, 13.2059, 12.1993],\n",
      "        [12.4320, 12.9896, 12.5446, 12.5982, 12.6844, 12.5450, 12.4390, 12.6404,\n",
      "         12.8008, 12.6860, 12.2328, 12.6282, 12.6449, 12.9131, 11.9985],\n",
      "        [12.6970, 13.0594, 12.7948, 12.7969, 12.7459, 12.8291, 12.6281, 13.0375,\n",
      "         12.9944, 12.9819, 12.5511, 12.9202, 12.9868, 13.0462, 12.5306],\n",
      "        [12.3766, 12.8597, 12.7381, 12.4982, 12.3737, 12.8396, 12.5317, 12.3464,\n",
      "         13.1307, 12.7893, 12.3347, 12.4220, 12.8914, 12.7913, 13.1367]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0639, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(1.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 3: 1.3494642972946167\n",
      "Batch 4/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1336,  0.0074, -0.1035,  ...,  0.0928, -0.0808, -0.1361],\n",
      "        [ 0.1210,  0.0065, -0.0827,  ...,  0.0939, -0.0761, -0.1221],\n",
      "        [ 0.1082,  0.0182, -0.1009,  ...,  0.1165, -0.1152, -0.1217],\n",
      "        ...,\n",
      "        [ 0.0830,  0.0236, -0.1091,  ...,  0.1261, -0.0725, -0.0934],\n",
      "        [ 0.1115,  0.0135, -0.1131,  ...,  0.1185, -0.1107, -0.1128],\n",
      "        [ 0.1215,  0.0276, -0.0607,  ...,  0.1222, -0.0834, -0.1155]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1298,  0.0378, -0.0932,  ...,  0.1134, -0.0897, -0.0871],\n",
      "        [ 0.1092,  0.0310, -0.0855,  ...,  0.1295, -0.0840, -0.1088],\n",
      "        [ 0.0674,  0.0174, -0.0974,  ...,  0.1592, -0.1411, -0.0750],\n",
      "        ...,\n",
      "        [ 0.0941,  0.0425, -0.0810,  ...,  0.0856, -0.1110, -0.0856],\n",
      "        [ 0.1077,  0.0421, -0.1195,  ...,  0.1165, -0.1486, -0.0493],\n",
      "        [ 0.0812,  0.1037, -0.0703,  ...,  0.1004, -0.1379, -0.1013]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.6387, 12.9642, 13.1967, 12.6943, 13.1824, 12.9224, 13.4354, 13.3053,\n",
      "         13.1716, 13.1729, 13.1487, 13.5359, 13.4424, 13.3724, 13.1274, 12.6435],\n",
      "        [13.6473, 13.2995, 13.2640, 13.1020, 13.3311, 13.0209, 13.3514, 13.4684,\n",
      "         13.2855, 13.4274, 13.4645, 13.4450, 13.3590, 13.6180, 13.2692, 12.8809],\n",
      "        [13.5975, 13.0992, 13.4882, 12.8169, 13.1706, 12.9290, 13.3680, 13.4008,\n",
      "         13.2499, 13.3250, 13.2663, 13.4490, 13.4898, 13.4931, 13.1701, 12.8911],\n",
      "        [13.6517, 13.3299, 13.3514, 13.1418, 13.3172, 12.9225, 13.3835, 13.4998,\n",
      "         13.3030, 13.4710, 13.5603, 13.4160, 13.3022, 13.6054, 13.2726, 13.0374],\n",
      "        [13.6187, 13.1948, 13.3540, 12.8931, 13.3143, 12.8888, 13.4381, 13.3156,\n",
      "         13.2760, 13.3232, 13.2417, 13.4492, 13.4262, 13.4741, 13.1263, 12.7165],\n",
      "        [13.6691, 13.1397, 13.2259, 13.0613, 13.2571, 13.1977, 13.2954, 13.3742,\n",
      "         13.2201, 13.3825, 13.4913, 13.4822, 13.4192, 13.6468, 13.4062, 12.8845],\n",
      "        [13.5071, 13.1153, 13.3681, 12.6590, 13.1888, 12.7170, 13.3920, 13.3087,\n",
      "         13.2662, 13.2130, 13.1180, 13.3314, 13.3965, 13.4307, 13.1013, 12.6747],\n",
      "        [13.4387, 13.0055, 13.3207, 12.7262, 12.9922, 12.7060, 13.3227, 13.2829,\n",
      "         13.1351, 13.1928, 13.1953, 13.3208, 13.3817, 13.4144, 13.0170, 12.7372],\n",
      "        [13.6646, 13.0587, 13.6435, 12.9363, 13.2546, 12.9542, 13.4888, 13.4680,\n",
      "         13.5222, 13.4335, 13.3113, 13.4915, 13.4806, 13.5500, 13.0499, 12.9457],\n",
      "        [13.6917, 13.2501, 13.3398, 13.0593, 13.2538, 12.8908, 13.3690, 13.4637,\n",
      "         13.3164, 13.4057, 13.3646, 13.2924, 13.4096, 13.5578, 13.1513, 13.0816],\n",
      "        [13.6290, 13.1813, 13.3078, 13.0692, 13.1782, 13.0479, 13.3083, 13.5739,\n",
      "         13.3156, 13.4569, 13.4465, 13.4150, 13.2943, 13.5704, 13.3353, 13.1723],\n",
      "        [13.6154, 12.9860, 13.2282, 12.7387, 13.2064, 12.8776, 13.3595, 13.3363,\n",
      "         13.2821, 13.2001, 13.3261, 13.4920, 13.4473, 13.3548, 13.1137, 12.7099],\n",
      "        [13.6743, 13.2281, 13.4254, 13.0654, 13.1750, 13.0485, 13.3416, 13.4118,\n",
      "         13.3146, 13.3905, 13.4684, 13.5205, 13.4712, 13.5254, 13.2341, 13.0202],\n",
      "        [13.5776, 13.2333, 13.3740, 12.8870, 13.2147, 12.7986, 13.3593, 13.3398,\n",
      "         13.2220, 13.2503, 13.3709, 13.3366, 13.3396, 13.5903, 13.1617, 12.8732],\n",
      "        [13.7139, 13.2503, 13.3514, 13.1334, 13.3053, 13.2668, 13.2778, 13.3986,\n",
      "         13.2362, 13.4251, 13.5263, 13.5826, 13.4683, 13.6598, 13.5017, 12.9736],\n",
      "        [13.6201, 13.2072, 13.2753, 13.2301, 13.1876, 13.0566, 13.1833, 13.4805,\n",
      "         13.2944, 13.4830, 13.6755, 13.3286, 13.2463, 13.5937, 13.3156, 13.3026]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6387, 13.2995, 13.4882, 13.1418, 13.3143, 13.1977, 13.3920, 13.2829,\n",
      "        13.5222, 13.4057, 13.4465, 13.4920, 13.4712, 13.5903, 13.5017, 13.3026],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(2.6699, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[12.9642, 13.1967, 12.6943, 13.1824, 12.9224, 13.4354, 13.3053, 13.1716,\n",
      "         13.1729, 13.1487, 13.5359, 13.4424, 13.3724, 13.1274, 12.6435],\n",
      "        [13.6473, 13.2640, 13.1020, 13.3311, 13.0209, 13.3514, 13.4684, 13.2855,\n",
      "         13.4274, 13.4645, 13.4450, 13.3590, 13.6180, 13.2692, 12.8809],\n",
      "        [13.5975, 13.0992, 12.8169, 13.1706, 12.9290, 13.3680, 13.4008, 13.2499,\n",
      "         13.3250, 13.2663, 13.4490, 13.4898, 13.4931, 13.1701, 12.8911],\n",
      "        [13.6517, 13.3299, 13.3514, 13.3172, 12.9225, 13.3835, 13.4998, 13.3030,\n",
      "         13.4710, 13.5603, 13.4160, 13.3022, 13.6054, 13.2726, 13.0374],\n",
      "        [13.6187, 13.1948, 13.3540, 12.8931, 12.8888, 13.4381, 13.3156, 13.2760,\n",
      "         13.3232, 13.2417, 13.4492, 13.4262, 13.4741, 13.1263, 12.7165],\n",
      "        [13.6691, 13.1397, 13.2259, 13.0613, 13.2571, 13.2954, 13.3742, 13.2201,\n",
      "         13.3825, 13.4913, 13.4822, 13.4192, 13.6468, 13.4062, 12.8845],\n",
      "        [13.5071, 13.1153, 13.3681, 12.6590, 13.1888, 12.7170, 13.3087, 13.2662,\n",
      "         13.2130, 13.1180, 13.3314, 13.3965, 13.4307, 13.1013, 12.6747],\n",
      "        [13.4387, 13.0055, 13.3207, 12.7262, 12.9922, 12.7060, 13.3227, 13.1351,\n",
      "         13.1928, 13.1953, 13.3208, 13.3817, 13.4144, 13.0170, 12.7372],\n",
      "        [13.6646, 13.0587, 13.6435, 12.9363, 13.2546, 12.9542, 13.4888, 13.4680,\n",
      "         13.4335, 13.3113, 13.4915, 13.4806, 13.5500, 13.0499, 12.9457],\n",
      "        [13.6917, 13.2501, 13.3398, 13.0593, 13.2538, 12.8908, 13.3690, 13.4637,\n",
      "         13.3164, 13.3646, 13.2924, 13.4096, 13.5578, 13.1513, 13.0816],\n",
      "        [13.6290, 13.1813, 13.3078, 13.0692, 13.1782, 13.0479, 13.3083, 13.5739,\n",
      "         13.3156, 13.4569, 13.4150, 13.2943, 13.5704, 13.3353, 13.1723],\n",
      "        [13.6154, 12.9860, 13.2282, 12.7387, 13.2064, 12.8776, 13.3595, 13.3363,\n",
      "         13.2821, 13.2001, 13.3261, 13.4473, 13.3548, 13.1137, 12.7099],\n",
      "        [13.6743, 13.2281, 13.4254, 13.0654, 13.1750, 13.0485, 13.3416, 13.4118,\n",
      "         13.3146, 13.3905, 13.4684, 13.5205, 13.5254, 13.2341, 13.0202],\n",
      "        [13.5776, 13.2333, 13.3740, 12.8870, 13.2147, 12.7986, 13.3593, 13.3398,\n",
      "         13.2220, 13.2503, 13.3709, 13.3366, 13.3396, 13.1617, 12.8732],\n",
      "        [13.7139, 13.2503, 13.3514, 13.1334, 13.3053, 13.2668, 13.2778, 13.3986,\n",
      "         13.2362, 13.4251, 13.5263, 13.5826, 13.4683, 13.6598, 12.9736],\n",
      "        [13.6201, 13.2072, 13.2753, 13.2301, 13.1876, 13.0566, 13.1833, 13.4805,\n",
      "         13.2944, 13.4830, 13.6755, 13.3286, 13.2463, 13.5937, 13.3156]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0641, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(1.3670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 4: 1.3669828176498413\n",
      "Batch 5/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1202,  0.0331, -0.0608,  ...,  0.1454, -0.1170, -0.1091],\n",
      "        [ 0.1381, -0.0008, -0.1079,  ...,  0.1067, -0.1044, -0.1351],\n",
      "        [ 0.1186,  0.0237, -0.0775,  ...,  0.1269, -0.1068, -0.0957],\n",
      "        ...,\n",
      "        [ 0.1401,  0.0079, -0.0940,  ...,  0.1260, -0.0973, -0.1176],\n",
      "        [ 0.1117,  0.0340, -0.0786,  ...,  0.1365, -0.0996, -0.0995],\n",
      "        [ 0.1063,  0.0387, -0.1022,  ...,  0.1304, -0.0911, -0.1131]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0677,  0.0172, -0.0749,  ...,  0.1465, -0.1479, -0.0713],\n",
      "        [ 0.1221,  0.0229, -0.1217,  ...,  0.1426, -0.1130, -0.1379],\n",
      "        [ 0.1381,  0.0598, -0.0755,  ...,  0.1658, -0.1349, -0.0965],\n",
      "        ...,\n",
      "        [ 0.1180,  0.0083, -0.1124,  ...,  0.1141, -0.0858, -0.0993],\n",
      "        [ 0.1224,  0.0657, -0.1140,  ...,  0.1363, -0.1082, -0.1037],\n",
      "        [ 0.1170,  0.0329, -0.0729,  ...,  0.1479, -0.1371, -0.0915]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.5488, 13.2967, 13.4623, 13.4225, 13.3219, 13.3296, 13.4939, 13.5018,\n",
      "         13.4451, 13.3899, 13.5221, 13.3433, 13.4573, 13.2903, 13.4327, 13.6137],\n",
      "        [13.3732, 13.3963, 13.4338, 13.3048, 13.3373, 13.1355, 13.4256, 13.4278,\n",
      "         13.4656, 13.4113, 13.4703, 13.4317, 13.4649, 13.3389, 13.4475, 13.5103],\n",
      "        [13.3613, 13.0785, 13.5094, 13.3284, 13.4189, 13.3240, 13.3764, 13.3464,\n",
      "         13.4295, 13.3738, 13.5977, 13.4023, 13.5823, 13.5137, 13.4132, 13.5148],\n",
      "        [13.4973, 13.2886, 13.5634, 13.5327, 13.4908, 13.3687, 13.5970, 13.6429,\n",
      "         13.6077, 13.5405, 13.6895, 13.4350, 13.5791, 13.4056, 13.5136, 13.6086],\n",
      "        [13.2468, 13.2703, 13.3152, 13.2471, 13.4169, 13.1752, 13.3522, 13.4318,\n",
      "         13.5408, 13.3929, 13.3986, 13.2653, 13.4285, 13.3211, 13.3681, 13.4974],\n",
      "        [13.3116, 13.1129, 13.4760, 13.2060, 13.2915, 13.2791, 13.4051, 13.3658,\n",
      "         13.2929, 13.2953, 13.4564, 13.2058, 13.5483, 13.4400, 13.2931, 13.4470],\n",
      "        [13.4353, 13.2574, 13.4465, 13.3367, 13.4786, 13.2010, 13.6213, 13.4935,\n",
      "         13.4962, 13.4109, 13.4642, 13.3538, 13.6007, 13.3727, 13.4314, 13.5798],\n",
      "        [13.2174, 13.1267, 13.3290, 13.1601, 13.3332, 13.0832, 13.3309, 13.4127,\n",
      "         13.4364, 13.2864, 13.3219, 13.2089, 13.3746, 13.2486, 13.2842, 13.4276],\n",
      "        [13.3714, 13.3381, 13.4839, 13.4379, 13.5316, 13.2712, 13.4424, 13.5045,\n",
      "         13.6352, 13.5346, 13.6223, 13.4795, 13.5572, 13.4435, 13.5024, 13.6024],\n",
      "        [13.4820, 13.2902, 13.4943, 13.3839, 13.4580, 13.2950, 13.4765, 13.5468,\n",
      "         13.5791, 13.5508, 13.6262, 13.4771, 13.5200, 13.3775, 13.3771, 13.5023],\n",
      "        [13.3485, 13.0415, 13.4129, 13.1283, 13.3697, 13.1386, 13.4175, 13.3735,\n",
      "         13.5018, 13.3158, 13.4802, 13.3375, 13.4899, 13.3167, 13.2455, 13.4498],\n",
      "        [13.4482, 13.3159, 13.4284, 13.4261, 13.3915, 13.3343, 13.5024, 13.4785,\n",
      "         13.5151, 13.4629, 13.5333, 13.4039, 13.5753, 13.4549, 13.4508, 13.5568],\n",
      "        [13.2761, 13.2004, 13.5244, 13.3766, 13.4760, 13.2397, 13.4226, 13.4917,\n",
      "         13.5306, 13.4606, 13.4918, 13.2741, 13.5616, 13.4522, 13.3370, 13.5314],\n",
      "        [13.2432, 13.1288, 13.4429, 13.2534, 13.3179, 13.1395, 13.4659, 13.3181,\n",
      "         13.4061, 13.3458, 13.5802, 13.2455, 13.5325, 13.3240, 13.2260, 13.4635],\n",
      "        [13.5325, 13.3798, 13.7400, 13.5541, 13.5281, 13.5313, 13.6224, 13.7027,\n",
      "         13.6065, 13.5270, 13.5715, 13.4674, 13.7143, 13.5177, 13.6149, 13.7032],\n",
      "        [13.5256, 13.2948, 13.5310, 13.3962, 13.4982, 13.3345, 13.6268, 13.5631,\n",
      "         13.5082, 13.4412, 13.5379, 13.4167, 13.6712, 13.4277, 13.5026, 13.6738]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.5488, 13.3963, 13.5094, 13.5327, 13.4169, 13.2791, 13.6213, 13.4127,\n",
      "        13.6352, 13.5508, 13.4802, 13.4039, 13.5616, 13.3240, 13.6149, 13.6738],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(2.7024, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[13.2967, 13.4623, 13.4225, 13.3219, 13.3296, 13.4939, 13.5018, 13.4451,\n",
      "         13.3899, 13.5221, 13.3433, 13.4573, 13.2903, 13.4327, 13.6137],\n",
      "        [13.3732, 13.4338, 13.3048, 13.3373, 13.1355, 13.4256, 13.4278, 13.4656,\n",
      "         13.4113, 13.4703, 13.4317, 13.4649, 13.3389, 13.4475, 13.5103],\n",
      "        [13.3613, 13.0785, 13.3284, 13.4189, 13.3240, 13.3764, 13.3464, 13.4295,\n",
      "         13.3738, 13.5977, 13.4023, 13.5823, 13.5137, 13.4132, 13.5148],\n",
      "        [13.4973, 13.2886, 13.5634, 13.4908, 13.3687, 13.5970, 13.6429, 13.6077,\n",
      "         13.5405, 13.6895, 13.4350, 13.5791, 13.4056, 13.5136, 13.6086],\n",
      "        [13.2468, 13.2703, 13.3152, 13.2471, 13.1752, 13.3522, 13.4318, 13.5408,\n",
      "         13.3929, 13.3986, 13.2653, 13.4285, 13.3211, 13.3681, 13.4974],\n",
      "        [13.3116, 13.1129, 13.4760, 13.2060, 13.2915, 13.4051, 13.3658, 13.2929,\n",
      "         13.2953, 13.4564, 13.2058, 13.5483, 13.4400, 13.2931, 13.4470],\n",
      "        [13.4353, 13.2574, 13.4465, 13.3367, 13.4786, 13.2010, 13.4935, 13.4962,\n",
      "         13.4109, 13.4642, 13.3538, 13.6007, 13.3727, 13.4314, 13.5798],\n",
      "        [13.2174, 13.1267, 13.3290, 13.1601, 13.3332, 13.0832, 13.3309, 13.4364,\n",
      "         13.2864, 13.3219, 13.2089, 13.3746, 13.2486, 13.2842, 13.4276],\n",
      "        [13.3714, 13.3381, 13.4839, 13.4379, 13.5316, 13.2712, 13.4424, 13.5045,\n",
      "         13.5346, 13.6223, 13.4795, 13.5572, 13.4435, 13.5024, 13.6024],\n",
      "        [13.4820, 13.2902, 13.4943, 13.3839, 13.4580, 13.2950, 13.4765, 13.5468,\n",
      "         13.5791, 13.6262, 13.4771, 13.5200, 13.3775, 13.3771, 13.5023],\n",
      "        [13.3485, 13.0415, 13.4129, 13.1283, 13.3697, 13.1386, 13.4175, 13.3735,\n",
      "         13.5018, 13.3158, 13.3375, 13.4899, 13.3167, 13.2455, 13.4498],\n",
      "        [13.4482, 13.3159, 13.4284, 13.4261, 13.3915, 13.3343, 13.5024, 13.4785,\n",
      "         13.5151, 13.4629, 13.5333, 13.5753, 13.4549, 13.4508, 13.5568],\n",
      "        [13.2761, 13.2004, 13.5244, 13.3766, 13.4760, 13.2397, 13.4226, 13.4917,\n",
      "         13.5306, 13.4606, 13.4918, 13.2741, 13.4522, 13.3370, 13.5314],\n",
      "        [13.2432, 13.1288, 13.4429, 13.2534, 13.3179, 13.1395, 13.4659, 13.3181,\n",
      "         13.4061, 13.3458, 13.5802, 13.2455, 13.5325, 13.2260, 13.4635],\n",
      "        [13.5325, 13.3798, 13.7400, 13.5541, 13.5281, 13.5313, 13.6224, 13.7027,\n",
      "         13.6065, 13.5270, 13.5715, 13.4674, 13.7143, 13.5177, 13.7032],\n",
      "        [13.5256, 13.2948, 13.5310, 13.3962, 13.4982, 13.3345, 13.6268, 13.5631,\n",
      "         13.5082, 13.4412, 13.5379, 13.4167, 13.6712, 13.4277, 13.5026]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0642, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(1.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 5: 1.3832885026931763\n",
      "Batch 6/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1114,  0.0230, -0.1280,  ...,  0.0778, -0.0985, -0.1124],\n",
      "        [ 0.1064,  0.0131, -0.0721,  ...,  0.1394, -0.1064, -0.1129],\n",
      "        [ 0.1258,  0.0370, -0.0901,  ...,  0.0962, -0.1031, -0.1188],\n",
      "        ...,\n",
      "        [ 0.1382,  0.0163, -0.1117,  ...,  0.1088, -0.1049, -0.1200],\n",
      "        [ 0.1260,  0.0325, -0.1021,  ...,  0.1114, -0.1134, -0.0571],\n",
      "        [ 0.1144,  0.0171, -0.1066,  ...,  0.1163, -0.1058, -0.0950]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0914,  0.0350, -0.1000,  ...,  0.1169, -0.0648, -0.1080],\n",
      "        [ 0.1440,  0.0311, -0.1262,  ...,  0.1523, -0.1194, -0.0637],\n",
      "        [ 0.1117,  0.0802, -0.0883,  ...,  0.1255, -0.1199, -0.0953],\n",
      "        ...,\n",
      "        [ 0.1176,  0.0054, -0.1258,  ...,  0.1342, -0.1147, -0.0557],\n",
      "        [ 0.1267,  0.0575, -0.1063,  ...,  0.1238, -0.1232, -0.0908],\n",
      "        [ 0.1611,  0.0409, -0.0983,  ...,  0.0933, -0.1154, -0.0946]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.6375, 13.3377, 13.3078, 13.4897, 13.4275, 13.5315, 13.5101, 13.3915,\n",
      "         13.3737, 13.3588, 13.7576, 13.7229, 13.6069, 13.7197, 13.5077, 13.3429],\n",
      "        [13.5642, 13.3507, 13.2291, 13.3690, 13.3796, 13.4315, 13.2861, 13.4275,\n",
      "         13.3208, 13.3522, 13.6096, 13.5910, 13.5809, 13.7349, 13.3834, 13.1972],\n",
      "        [13.5887, 13.2888, 13.3481, 13.5001, 13.4165, 13.5402, 13.4562, 13.3493,\n",
      "         13.3902, 13.3646, 13.6157, 13.6493, 13.5929, 13.6083, 13.5139, 13.3178],\n",
      "        [13.5973, 13.4727, 13.3110, 13.6113, 13.5738, 13.5691, 13.4609, 13.4952,\n",
      "         13.4962, 13.5563, 13.6641, 13.6748, 13.6069, 13.7275, 13.4486, 13.2700],\n",
      "        [13.3952, 13.0116, 12.9219, 13.4388, 13.5246, 13.5129, 13.1807, 13.3036,\n",
      "         13.2156, 13.4062, 13.4624, 13.5449, 13.4347, 13.5841, 13.3281, 12.9857],\n",
      "        [13.4764, 13.1659, 13.0599, 13.3470, 13.4952, 13.6995, 13.2838, 13.2344,\n",
      "         13.3403, 13.3190, 13.4438, 13.6864, 13.4987, 13.5845, 13.4016, 13.0051],\n",
      "        [13.5520, 13.3253, 13.2151, 13.5114, 13.4543, 13.4617, 13.4973, 13.2616,\n",
      "         13.4443, 13.3302, 13.6976, 13.6626, 13.5199, 13.6551, 13.4608, 13.2256],\n",
      "        [13.4814, 13.2078, 13.2224, 13.3847, 13.3467, 13.4144, 13.3253, 13.3126,\n",
      "         13.3365, 13.4397, 13.6236, 13.7079, 13.5444, 13.6709, 13.3818, 13.1566],\n",
      "        [13.6766, 13.5015, 13.3827, 13.6338, 13.5956, 13.5774, 13.6442, 13.4494,\n",
      "         13.6437, 13.5804, 13.7310, 13.7833, 13.7009, 13.7565, 13.4991, 13.4684],\n",
      "        [13.0536, 12.6891, 12.6201, 13.0748, 13.3657, 13.5213, 12.9344, 12.9823,\n",
      "         13.0065, 13.4354, 13.2346, 13.4336, 13.4273, 13.4255, 13.0140, 12.6809],\n",
      "        [13.6076, 13.2755, 13.1061, 13.4352, 13.4792, 13.4364, 13.3009, 13.3894,\n",
      "         13.3499, 13.5260, 13.6840, 13.5760, 13.5779, 13.7052, 13.3766, 13.2453],\n",
      "        [13.5286, 13.2981, 13.2187, 13.5497, 13.5951, 13.6617, 13.4500, 13.4378,\n",
      "         13.4673, 13.5869, 13.6757, 13.7701, 13.6827, 13.7759, 13.4454, 13.2658],\n",
      "        [13.4560, 13.1325, 12.9892, 13.3827, 13.3911, 13.4674, 13.1697, 13.1789,\n",
      "         13.2779, 13.4612, 13.5293, 13.6873, 13.6038, 13.6044, 13.2761, 13.0003],\n",
      "        [13.5300, 13.2683, 13.1502, 13.3979, 13.4965, 13.5895, 13.3292, 13.4583,\n",
      "         13.3215, 13.5640, 13.6877, 13.6145, 13.6030, 13.7191, 13.3997, 13.1881],\n",
      "        [13.5720, 13.3974, 13.3345, 13.4608, 13.4596, 13.5439, 13.5113, 13.3780,\n",
      "         13.3787, 13.3665, 13.6895, 13.6551, 13.5972, 13.7524, 13.4696, 13.3209],\n",
      "        [13.6412, 13.4402, 13.3231, 13.4770, 13.4706, 13.4877, 13.4556, 13.4274,\n",
      "         13.4777, 13.4826, 13.7391, 13.7235, 13.6484, 13.7577, 13.4866, 13.3689]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6375, 13.3507, 13.3481, 13.6113, 13.5246, 13.6995, 13.4973, 13.3126,\n",
      "        13.6437, 13.4354, 13.6840, 13.7701, 13.6038, 13.7191, 13.4696, 13.3689],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(2.6826, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[13.3377, 13.3078, 13.4897, 13.4275, 13.5315, 13.5101, 13.3915, 13.3737,\n",
      "         13.3588, 13.7576, 13.7229, 13.6069, 13.7197, 13.5077, 13.3429],\n",
      "        [13.5642, 13.2291, 13.3690, 13.3796, 13.4315, 13.2861, 13.4275, 13.3208,\n",
      "         13.3522, 13.6096, 13.5910, 13.5809, 13.7349, 13.3834, 13.1972],\n",
      "        [13.5887, 13.2888, 13.5001, 13.4165, 13.5402, 13.4562, 13.3493, 13.3902,\n",
      "         13.3646, 13.6157, 13.6493, 13.5929, 13.6083, 13.5139, 13.3178],\n",
      "        [13.5973, 13.4727, 13.3110, 13.5738, 13.5691, 13.4609, 13.4952, 13.4962,\n",
      "         13.5563, 13.6641, 13.6748, 13.6069, 13.7275, 13.4486, 13.2700],\n",
      "        [13.3952, 13.0116, 12.9219, 13.4388, 13.5129, 13.1807, 13.3036, 13.2156,\n",
      "         13.4062, 13.4624, 13.5449, 13.4347, 13.5841, 13.3281, 12.9857],\n",
      "        [13.4764, 13.1659, 13.0599, 13.3470, 13.4952, 13.2838, 13.2344, 13.3403,\n",
      "         13.3190, 13.4438, 13.6864, 13.4987, 13.5845, 13.4016, 13.0051],\n",
      "        [13.5520, 13.3253, 13.2151, 13.5114, 13.4543, 13.4617, 13.2616, 13.4443,\n",
      "         13.3302, 13.6976, 13.6626, 13.5199, 13.6551, 13.4608, 13.2256],\n",
      "        [13.4814, 13.2078, 13.2224, 13.3847, 13.3467, 13.4144, 13.3253, 13.3365,\n",
      "         13.4397, 13.6236, 13.7079, 13.5444, 13.6709, 13.3818, 13.1566],\n",
      "        [13.6766, 13.5015, 13.3827, 13.6338, 13.5956, 13.5774, 13.6442, 13.4494,\n",
      "         13.5804, 13.7310, 13.7833, 13.7009, 13.7565, 13.4991, 13.4684],\n",
      "        [13.0536, 12.6891, 12.6201, 13.0748, 13.3657, 13.5213, 12.9344, 12.9823,\n",
      "         13.0065, 13.2346, 13.4336, 13.4273, 13.4255, 13.0140, 12.6809],\n",
      "        [13.6076, 13.2755, 13.1061, 13.4352, 13.4792, 13.4364, 13.3009, 13.3894,\n",
      "         13.3499, 13.5260, 13.5760, 13.5779, 13.7052, 13.3766, 13.2453],\n",
      "        [13.5286, 13.2981, 13.2187, 13.5497, 13.5951, 13.6617, 13.4500, 13.4378,\n",
      "         13.4673, 13.5869, 13.6757, 13.6827, 13.7759, 13.4454, 13.2658],\n",
      "        [13.4560, 13.1325, 12.9892, 13.3827, 13.3911, 13.4674, 13.1697, 13.1789,\n",
      "         13.2779, 13.4612, 13.5293, 13.6873, 13.6044, 13.2761, 13.0003],\n",
      "        [13.5300, 13.2683, 13.1502, 13.3979, 13.4965, 13.5895, 13.3292, 13.4583,\n",
      "         13.3215, 13.5640, 13.6877, 13.6145, 13.6030, 13.3997, 13.1881],\n",
      "        [13.5720, 13.3974, 13.3345, 13.4608, 13.4596, 13.5439, 13.5113, 13.3780,\n",
      "         13.3787, 13.3665, 13.6895, 13.6551, 13.5972, 13.7524, 13.3209],\n",
      "        [13.6412, 13.4402, 13.3231, 13.4770, 13.4706, 13.4877, 13.4556, 13.4274,\n",
      "         13.4777, 13.4826, 13.7391, 13.7235, 13.6484, 13.7577, 13.4866]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0641, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(1.3734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 6: 1.3733805418014526\n",
      "Batch 7/7: Matrix features: torch.Size([4, 128]), Vector features: torch.Size([4, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 1.0107e-01,  3.2037e-02, -1.0393e-01, -1.8554e-01,  5.9266e-02,\n",
      "         -2.6920e-02,  1.1764e-01,  1.4573e-01, -1.5642e-01, -1.0050e-01,\n",
      "          8.3036e-02, -1.4265e-01, -1.5791e-01, -2.6984e-02,  1.2567e-01,\n",
      "          3.3044e-02, -1.3156e-02,  5.6002e-02, -7.5408e-02, -6.3250e-02,\n",
      "         -7.3032e-02,  1.3196e-01,  3.4059e-02, -4.1626e-02, -1.9678e-02,\n",
      "         -1.5092e-01,  7.7922e-02, -1.2721e-01,  1.3898e-01, -1.2384e-01,\n",
      "          8.3558e-02, -6.1406e-02, -6.6623e-02,  1.0511e-01,  6.9833e-02,\n",
      "          5.2079e-02,  1.1035e-01, -4.1580e-02, -5.4632e-02,  2.3887e-02,\n",
      "         -9.5736e-02, -3.3969e-02, -6.2757e-03, -4.0577e-02,  4.3505e-02,\n",
      "         -6.3673e-02, -7.0242e-02, -1.8912e-03,  1.3654e-01, -1.4110e-01,\n",
      "          3.0178e-02,  1.9716e-01,  3.0020e-02,  2.9508e-02, -1.5941e-01,\n",
      "          2.9319e-02,  4.1337e-02, -1.3030e-01, -1.4367e-01,  2.2634e-02,\n",
      "          1.5380e-01, -7.7541e-02, -3.0652e-02,  6.9977e-02, -1.8757e-03,\n",
      "          2.9807e-02,  8.8724e-02,  7.6263e-02, -2.0445e-02,  6.8131e-02,\n",
      "          1.2822e-01,  8.0523e-02,  9.5413e-02,  3.2810e-02,  9.7091e-02,\n",
      "         -6.6802e-02, -4.0838e-02,  9.6116e-02, -9.7736e-02, -3.7958e-02,\n",
      "         -5.2716e-02,  3.4647e-02,  5.9876e-02, -1.5258e-01,  2.3348e-02,\n",
      "         -3.0531e-04, -9.6235e-02,  4.9497e-02, -1.0215e-01,  5.4923e-02,\n",
      "          3.4392e-02,  4.8182e-02,  3.4661e-02, -5.7749e-02,  4.2379e-02,\n",
      "          1.4079e-01, -1.2072e-01, -3.4693e-02,  5.3643e-02,  1.5360e-01,\n",
      "          1.0860e-01,  2.0967e-02,  8.7943e-02, -1.0558e-01, -8.4995e-02,\n",
      "         -2.6258e-02, -2.4272e-02, -1.3474e-01,  1.2981e-01,  1.4592e-02,\n",
      "          1.4462e-01, -9.9679e-02,  5.9214e-02, -1.5723e-01, -1.3676e-02,\n",
      "          1.3140e-02,  9.5242e-02, -3.0210e-02,  7.5550e-05,  5.2815e-02,\n",
      "         -2.6815e-03, -3.0828e-02, -9.1043e-03, -1.0898e-01, -5.1431e-02,\n",
      "          1.5421e-01, -8.8501e-02, -1.1843e-01],\n",
      "        [ 1.1733e-01,  3.0199e-02, -9.6743e-02, -2.0422e-01,  3.5240e-02,\n",
      "         -3.8529e-02,  9.6503e-02,  1.4754e-01, -1.2470e-01, -9.9098e-02,\n",
      "          9.4527e-02, -1.2268e-01, -1.4331e-01, -4.6636e-02,  1.0054e-01,\n",
      "          4.6113e-02, -1.6587e-02,  6.2608e-02, -6.8702e-02, -7.2787e-02,\n",
      "         -1.0355e-01,  1.1387e-01,  3.4701e-02, -4.5342e-02, -1.9465e-02,\n",
      "         -1.7708e-01,  7.9689e-02, -1.5938e-01,  1.5507e-01, -1.0475e-01,\n",
      "          1.1332e-01, -9.3875e-02, -7.3578e-02,  1.1481e-01,  4.1567e-02,\n",
      "          5.9509e-02,  1.0850e-01, -1.6091e-02, -6.3282e-02,  8.7831e-03,\n",
      "         -9.6291e-02, -6.5208e-02, -8.3761e-03, -2.1579e-02,  2.4092e-02,\n",
      "         -3.2772e-02, -6.2231e-02,  1.4843e-02,  1.3182e-01, -1.0113e-01,\n",
      "          1.7536e-02,  2.2024e-01,  5.8698e-02,  1.2119e-02, -1.5816e-01,\n",
      "          2.6591e-02,  2.9293e-02, -8.3710e-02, -1.5368e-01,  2.2663e-02,\n",
      "          1.5273e-01, -8.2127e-02, -3.6888e-02,  5.2424e-02, -1.7237e-02,\n",
      "          4.1843e-02,  8.3154e-02,  8.7477e-02, -2.8323e-02,  4.8285e-02,\n",
      "          1.1580e-01,  9.7158e-02,  9.1683e-02,  7.2361e-03,  9.3715e-02,\n",
      "         -6.1447e-02, -6.3895e-02,  9.6927e-02, -1.0677e-01, -2.5675e-02,\n",
      "         -6.9118e-02,  3.1053e-02,  6.9050e-02, -1.7186e-01,  9.1721e-02,\n",
      "         -3.4154e-02, -7.6306e-02,  2.2529e-02, -8.0107e-02,  2.1596e-02,\n",
      "          4.2054e-02,  8.5818e-02,  5.3478e-02, -5.3019e-02,  4.1221e-02,\n",
      "          1.2790e-01, -1.1035e-01, -4.6621e-02,  5.2331e-02,  1.6677e-01,\n",
      "          1.1990e-01,  2.4547e-02,  8.6484e-02, -1.1910e-01, -1.1073e-01,\n",
      "         -1.0603e-02, -2.1538e-02, -1.4507e-01,  1.0287e-01,  3.3296e-02,\n",
      "          1.4067e-01, -9.3288e-02,  6.6266e-02, -1.5296e-01, -4.7805e-03,\n",
      "          3.5457e-02,  9.7094e-02, -5.0414e-02,  3.5756e-02,  5.0594e-02,\n",
      "          1.9274e-02, -2.9832e-02, -2.9279e-03, -9.6774e-02, -6.2110e-02,\n",
      "          9.0249e-02, -1.1121e-01, -5.2887e-02],\n",
      "        [ 1.2710e-01,  2.2212e-02, -9.9036e-02, -2.0263e-01,  3.5258e-02,\n",
      "         -4.3884e-02,  1.2970e-01,  1.4205e-01, -1.5419e-01, -7.5838e-02,\n",
      "          6.0932e-02, -1.1408e-01, -1.4816e-01, -5.2420e-02,  1.0695e-01,\n",
      "          2.8362e-02, -8.9860e-03,  6.8140e-02, -6.0505e-02, -6.6974e-02,\n",
      "         -8.7240e-02,  1.2517e-01,  4.5994e-02, -3.4148e-02, -2.9159e-02,\n",
      "         -1.2570e-01,  7.8703e-02, -1.2800e-01,  1.6011e-01, -1.1491e-01,\n",
      "          1.0273e-01, -9.2564e-02, -8.6487e-02,  9.0683e-02,  6.5942e-02,\n",
      "          5.4968e-02,  1.1766e-01, -4.8493e-02, -5.8597e-02,  2.4767e-02,\n",
      "         -6.0172e-02, -7.6037e-02, -3.0277e-03, -1.8537e-02,  3.3906e-02,\n",
      "         -6.8171e-02, -7.6118e-02,  8.8409e-03,  1.3139e-01, -1.2549e-01,\n",
      "          1.4356e-02,  1.6823e-01,  5.6005e-02,  2.5196e-02, -1.2895e-01,\n",
      "          1.2172e-02,  2.1045e-02, -1.3441e-01, -1.4389e-01,  4.0904e-02,\n",
      "          1.2862e-01, -7.8164e-02, -4.9747e-02,  8.1027e-02, -3.9797e-02,\n",
      "          2.1380e-02,  1.0403e-01,  1.1089e-01, -3.6808e-02,  5.4848e-02,\n",
      "          1.4221e-01,  7.7010e-02,  1.2410e-01,  1.4225e-03,  1.2349e-01,\n",
      "         -8.2809e-02, -6.5637e-02,  1.1037e-01, -1.2348e-01, -4.0335e-02,\n",
      "         -8.1218e-02,  1.9926e-02,  6.6842e-02, -2.0805e-01,  6.2627e-02,\n",
      "         -2.4125e-02, -7.7507e-02,  4.4738e-02, -9.4122e-02,  5.3835e-02,\n",
      "          3.1406e-02,  6.0373e-02,  3.6675e-02, -4.9203e-02,  3.6363e-02,\n",
      "          1.1491e-01, -1.2469e-01, -4.6034e-02,  3.8035e-02,  1.3137e-01,\n",
      "          1.2449e-01,  2.0365e-02,  1.1715e-01, -1.0836e-01, -9.4622e-02,\n",
      "          4.1428e-03, -1.5138e-03, -1.1860e-01,  1.1866e-01,  1.4601e-02,\n",
      "          1.1327e-01, -1.0264e-01,  7.9262e-02, -1.4713e-01, -1.2002e-02,\n",
      "          4.4666e-02,  1.0345e-01, -3.4268e-02,  8.6199e-03,  5.5600e-02,\n",
      "          1.0128e-02, -4.0888e-02, -3.2358e-02, -7.0669e-02, -2.4413e-02,\n",
      "          1.3945e-01, -9.1078e-02, -7.0153e-02],\n",
      "        [ 1.0607e-01,  1.3222e-02, -9.0768e-02, -1.8436e-01,  2.3884e-02,\n",
      "         -1.2701e-02,  1.3747e-01,  1.4983e-01, -1.5947e-01, -7.6862e-02,\n",
      "          5.7228e-02, -1.5640e-01, -1.4801e-01, -5.3696e-02,  1.0616e-01,\n",
      "          3.6572e-02, -1.6334e-02,  5.9396e-02, -5.9164e-02, -8.5617e-02,\n",
      "         -9.4834e-02,  1.5547e-01, -1.1977e-03, -2.7026e-02, -1.1694e-02,\n",
      "         -9.8955e-02,  6.0895e-02, -1.4356e-01,  1.2811e-01, -1.2091e-01,\n",
      "          1.0736e-01, -8.9755e-02, -7.0698e-02,  1.1238e-01,  7.3466e-02,\n",
      "          6.1083e-02,  1.0441e-01, -6.4975e-02, -5.7323e-02,  2.4849e-02,\n",
      "         -7.7317e-02, -5.5881e-02,  7.9160e-03, -1.8100e-02,  4.6675e-02,\n",
      "         -5.9386e-02, -8.1204e-02,  8.6323e-03,  1.4473e-01, -1.0576e-01,\n",
      "          3.8123e-02,  1.8738e-01,  2.5630e-02,  2.0818e-02, -1.4287e-01,\n",
      "          1.9697e-02,  3.0032e-02, -1.1456e-01, -1.7345e-01,  2.6978e-02,\n",
      "          1.4905e-01, -7.0054e-02, -4.0870e-02,  5.5755e-02,  7.6321e-03,\n",
      "          5.0343e-02,  1.0255e-01,  1.0119e-01, -2.1884e-02,  7.8347e-02,\n",
      "          1.4977e-01,  9.2204e-02,  7.9287e-02,  2.8884e-02,  1.2319e-01,\n",
      "         -8.3203e-02, -4.2669e-02,  9.0098e-02, -1.3343e-01, -4.9887e-02,\n",
      "         -6.1946e-02,  3.0218e-02,  7.5648e-02, -1.9047e-01,  8.0285e-02,\n",
      "          5.7230e-03, -7.5933e-02,  1.9430e-02, -6.9871e-02,  6.3439e-02,\n",
      "          2.5200e-02,  3.9249e-02,  3.0053e-02, -4.8600e-02,  3.7248e-02,\n",
      "          8.2784e-02, -1.2442e-01, -4.5985e-02,  6.5342e-02,  1.3845e-01,\n",
      "          1.0559e-01,  1.6280e-02,  1.1038e-01, -6.6753e-02, -1.0782e-01,\n",
      "          4.9775e-03, -2.9306e-02, -1.5871e-01,  1.3363e-01,  2.8686e-02,\n",
      "          1.0294e-01, -1.0713e-01,  6.8930e-02, -1.6281e-01, -1.6475e-02,\n",
      "          4.7636e-02,  8.2470e-02, -3.7048e-02,  1.4459e-02,  3.2660e-02,\n",
      "          1.6183e-02, -4.1854e-02, -2.6840e-02, -8.7273e-02, -4.0777e-02,\n",
      "          1.3136e-01, -8.6288e-02, -9.8139e-02]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 1.0902e-01,  2.3103e-02, -1.2502e-01, -1.6521e-01,  7.5808e-03,\n",
      "         -5.4448e-03,  1.0227e-01,  1.4742e-01, -1.5523e-01, -9.1645e-02,\n",
      "          6.8493e-02, -7.7929e-02, -1.9844e-01, -4.3480e-02,  1.1303e-01,\n",
      "         -2.5110e-04,  6.1563e-03,  6.6553e-02, -8.9137e-02, -9.0788e-02,\n",
      "         -4.5409e-02,  1.7122e-01,  1.8861e-02, -6.2543e-02, -3.6578e-04,\n",
      "         -9.6730e-02,  3.0413e-02, -1.8054e-01,  1.0778e-01, -1.2690e-01,\n",
      "          1.2435e-01, -9.1143e-02, -7.6186e-02,  1.5067e-01,  7.3105e-02,\n",
      "          4.9950e-02,  1.1465e-01, -2.8565e-02, -1.5426e-02,  6.3365e-02,\n",
      "         -8.7801e-02, -5.5814e-02, -2.9711e-02, -4.6012e-02,  5.1017e-02,\n",
      "         -5.9998e-02, -5.6344e-02,  1.9328e-02,  5.6837e-02, -1.0112e-01,\n",
      "          6.0685e-02,  2.1634e-01,  6.4866e-02,  4.1050e-02, -1.4189e-01,\n",
      "          2.7794e-04,  1.7429e-02, -1.1599e-01, -1.3567e-01,  1.4536e-02,\n",
      "          1.4035e-01, -8.0357e-02, -3.8648e-02,  7.3983e-02,  4.3363e-03,\n",
      "          2.0783e-02,  3.3647e-02,  9.2760e-02, -4.8220e-02,  7.3824e-02,\n",
      "          1.2055e-01,  7.1450e-02,  1.0658e-01,  3.1737e-02,  8.7044e-02,\n",
      "         -7.5780e-02, -4.4330e-02,  7.0032e-02, -9.1638e-02, -1.4300e-02,\n",
      "         -8.2493e-02,  2.9836e-02,  6.0507e-02, -1.9124e-01,  7.1464e-02,\n",
      "         -4.8039e-02, -1.0152e-01,  3.9097e-02, -9.1804e-02,  4.7638e-02,\n",
      "          2.9929e-02,  4.3534e-02,  7.2097e-03, -9.5899e-02,  3.0660e-02,\n",
      "          1.1116e-01, -1.1061e-01, -1.6612e-02,  4.4224e-02,  1.7665e-01,\n",
      "          1.1252e-01,  3.1940e-02,  1.1963e-01, -5.7508e-02, -7.7359e-02,\n",
      "         -1.1260e-02, -1.2801e-02, -1.7463e-01,  1.3028e-01,  1.8361e-02,\n",
      "          1.4732e-01, -1.0829e-01,  5.0006e-02, -1.3744e-01, -4.1077e-02,\n",
      "          4.5282e-02,  9.0445e-02, -4.1732e-02,  3.1818e-03,  6.6808e-02,\n",
      "          2.1272e-02,  5.3622e-03, -5.1982e-03, -7.2377e-02, -3.8665e-02,\n",
      "          1.3853e-01, -9.4416e-02, -9.7404e-02],\n",
      "        [ 1.3332e-01,  5.2620e-02, -1.1519e-01, -1.6759e-01,  1.5969e-02,\n",
      "          1.7671e-02,  6.6241e-02,  1.5738e-01, -1.3794e-01, -7.7834e-02,\n",
      "          1.0045e-01, -1.2893e-01, -1.7681e-01, -2.8739e-02,  9.2928e-02,\n",
      "          3.9722e-02, -1.2362e-02,  5.4025e-02, -6.4348e-02, -7.4432e-02,\n",
      "         -8.8026e-02,  1.5442e-01,  2.6003e-02, -7.7192e-02, -6.9950e-03,\n",
      "         -1.6222e-01,  3.9400e-02, -1.2530e-01,  1.1297e-01, -9.0717e-02,\n",
      "          1.1387e-01, -1.0852e-01, -4.5804e-02,  1.2942e-01,  9.4159e-02,\n",
      "          5.5860e-02,  1.1982e-01, -1.1561e-02, -3.8727e-02,  3.9702e-02,\n",
      "         -1.2606e-01, -2.7427e-02, -2.7840e-02, -7.8724e-02,  6.0485e-02,\n",
      "         -5.8583e-02, -1.9943e-02,  1.9564e-02,  9.2908e-02, -9.8933e-02,\n",
      "          3.7518e-02,  1.6276e-01,  8.3971e-02,  3.9899e-02, -1.6775e-01,\n",
      "          2.1430e-02,  1.5194e-02, -1.1114e-01, -1.4921e-01,  1.6892e-04,\n",
      "          1.3819e-01, -8.2305e-02, -6.9020e-02,  2.5520e-02,  2.7250e-03,\n",
      "          1.0290e-02,  8.3303e-02,  6.9308e-02, -5.9691e-02,  5.5815e-02,\n",
      "          1.1587e-01,  9.5282e-02,  6.3856e-02,  4.9871e-02,  1.0629e-01,\n",
      "         -7.5052e-02, -4.2678e-02,  1.1033e-01, -1.3564e-01, -1.8660e-02,\n",
      "         -7.8890e-02,  4.3618e-02,  5.1199e-02, -1.8762e-01,  9.0890e-02,\n",
      "         -2.8274e-02, -9.4704e-02,  2.2023e-02, -7.5675e-02,  2.9205e-02,\n",
      "          2.8656e-02,  7.8956e-02,  7.9739e-03, -4.2377e-02,  1.0341e-02,\n",
      "          1.4430e-01, -9.2946e-02, -1.3016e-02,  5.3501e-02,  1.4720e-01,\n",
      "          1.1054e-01,  1.0332e-02,  1.2283e-01, -5.2799e-02, -9.2016e-02,\n",
      "          9.4505e-03, -2.0488e-02, -1.2271e-01,  8.4337e-02,  1.7266e-02,\n",
      "          1.7138e-01, -1.1699e-01,  5.8552e-02, -1.2110e-01, -6.4186e-02,\n",
      "          6.1255e-02,  1.2547e-01, -7.3465e-02, -1.6220e-02,  6.8311e-02,\n",
      "          6.7526e-03, -2.5392e-02, -2.7048e-02, -7.6107e-02, -3.3572e-02,\n",
      "          1.4094e-01, -1.2303e-01, -1.1306e-01],\n",
      "        [ 8.9355e-02,  4.0924e-02, -7.3349e-02, -1.7962e-01,  1.0835e-02,\n",
      "         -3.0969e-02,  1.2003e-01,  1.4063e-01, -1.4026e-01, -8.1836e-02,\n",
      "          7.7124e-02, -9.6941e-02, -1.6506e-01, -3.8789e-02,  7.4522e-02,\n",
      "          1.3973e-02,  6.4496e-03,  5.4686e-02, -9.0432e-02, -6.9220e-02,\n",
      "         -6.7165e-02,  1.7306e-01,  1.8452e-02, -4.1387e-02,  2.1339e-02,\n",
      "         -1.7111e-01,  7.5635e-03, -1.4289e-01,  1.6213e-01, -9.7312e-02,\n",
      "          1.2812e-01, -8.4921e-02, -6.9184e-02,  1.3613e-01,  7.9351e-02,\n",
      "          3.4468e-02,  1.0239e-01, -4.0128e-02, -2.4119e-02,  5.2112e-02,\n",
      "         -1.2432e-01, -4.7764e-02, -1.4860e-03, -2.4561e-02,  5.9458e-02,\n",
      "         -3.4140e-02, -6.3179e-02,  1.1459e-02,  9.6061e-02, -1.0964e-01,\n",
      "          5.7550e-02,  2.0352e-01,  6.5086e-02,  3.3864e-02, -1.4438e-01,\n",
      "          7.0440e-03,  1.5998e-02, -1.3273e-01, -1.2490e-01,  3.1638e-02,\n",
      "          1.2331e-01, -1.0410e-01, -5.7631e-02,  7.0482e-02, -2.8530e-02,\n",
      "          8.8377e-03,  7.9052e-02,  3.6630e-02, -6.0127e-02,  9.1025e-02,\n",
      "          1.3668e-01,  4.3931e-02,  1.1531e-01,  5.4043e-02,  1.0241e-01,\n",
      "         -1.1008e-01, -4.6737e-02,  1.0532e-01, -1.3046e-01, -2.7651e-02,\n",
      "         -8.8138e-02,  2.2545e-02,  1.0049e-01, -1.9795e-01,  5.1088e-02,\n",
      "         -3.4143e-02, -1.0793e-01,  6.1078e-02, -5.7349e-02,  3.9000e-02,\n",
      "          1.0758e-02,  7.0580e-02,  6.3988e-03, -8.5670e-02,  3.6672e-02,\n",
      "          1.0948e-01, -1.0070e-01, -2.1732e-02, -8.5849e-03,  1.4946e-01,\n",
      "          7.3089e-02,  4.0018e-02,  1.2848e-01, -7.3615e-02, -7.9440e-02,\n",
      "          5.5887e-03, -3.5135e-02, -1.6029e-01,  9.0979e-02,  1.3420e-02,\n",
      "          1.5670e-01, -6.6528e-02,  9.7594e-02, -1.3504e-01, -3.2228e-02,\n",
      "          7.4366e-02,  1.0529e-01, -3.4839e-02,  2.4703e-03,  6.9128e-02,\n",
      "          1.5964e-02, -2.1132e-02, -2.9132e-02, -5.6461e-02, -3.4610e-02,\n",
      "          1.1885e-01, -1.1100e-01, -1.0041e-01],\n",
      "        [ 9.1065e-02,  3.2330e-02, -9.9175e-02, -1.5277e-01,  5.3192e-03,\n",
      "          3.3594e-02,  1.0046e-01,  1.0602e-01, -1.1344e-01, -7.4939e-02,\n",
      "          9.7555e-02, -1.1215e-01, -1.9594e-01, -5.0583e-02,  7.7249e-02,\n",
      "          2.8922e-02,  2.2064e-04,  3.1129e-02, -9.3191e-02, -8.0559e-02,\n",
      "         -6.6178e-02,  1.9517e-01,  3.2270e-02, -6.1714e-02,  9.5698e-03,\n",
      "         -1.5253e-01,  4.9460e-02, -1.5168e-01,  1.4707e-01, -1.1149e-01,\n",
      "          9.6144e-02, -1.0585e-01, -8.0922e-02,  1.3705e-01,  8.9232e-02,\n",
      "          4.3808e-02,  1.5005e-01, -5.2866e-02, -7.7036e-02,  5.5827e-02,\n",
      "         -9.9763e-02, -4.7545e-02, -2.6486e-02, -3.7596e-02,  4.0604e-02,\n",
      "         -8.5119e-02, -7.6196e-02,  1.6562e-02,  1.1531e-01, -1.3345e-01,\n",
      "          7.5197e-02,  1.7989e-01,  9.5750e-02,  8.6955e-02, -1.3698e-01,\n",
      "         -1.2605e-02,  2.9636e-02, -9.6192e-02, -1.4150e-01,  1.2060e-02,\n",
      "          1.2634e-01, -8.2300e-02, -4.6394e-02,  6.4737e-02,  3.2103e-02,\n",
      "          2.8335e-02,  7.5006e-02,  7.4667e-02, -4.2391e-02,  1.1116e-01,\n",
      "          1.3529e-01,  7.5047e-02,  1.1851e-01,  9.2573e-02,  5.3395e-02,\n",
      "         -9.0907e-02, -5.0131e-02,  4.7549e-02, -9.8438e-02, -4.3102e-02,\n",
      "         -4.9427e-02,  1.2996e-02,  6.9039e-02, -1.7192e-01,  5.5811e-02,\n",
      "         -1.5592e-02, -5.5483e-02,  2.5535e-03, -9.1051e-02,  7.0663e-02,\n",
      "          4.5514e-02,  6.4864e-02,  1.4585e-02, -1.0971e-01,  3.4949e-02,\n",
      "          1.2520e-01, -1.4318e-01,  1.8694e-02,  1.9870e-02,  1.5451e-01,\n",
      "          7.9643e-02,  1.3685e-02,  1.4851e-01, -8.7680e-02, -8.5028e-02,\n",
      "         -4.3087e-03, -1.4672e-02, -1.5674e-01,  1.0658e-01, -7.5119e-03,\n",
      "          1.0268e-01, -8.6896e-02,  4.2818e-02, -1.4528e-01, -3.1751e-02,\n",
      "          2.1929e-02,  1.1097e-01, -5.9843e-02, -1.2854e-02,  4.8266e-02,\n",
      "         -7.5233e-03, -1.3631e-02, -1.3247e-02, -8.7210e-02, -8.6508e-03,\n",
      "          1.2943e-01, -6.5214e-02, -9.3487e-02]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.7252, 13.6841, 13.6635, 13.6236],\n",
      "        [13.6204, 13.6833, 13.6188, 13.4212],\n",
      "        [13.6545, 13.5876, 13.7051, 13.4956],\n",
      "        [13.7044, 13.6073, 13.6381, 13.5762]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7252, 13.6833, 13.7051, 13.5762], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(1.3418, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[13.6841, 13.6635, 13.6236],\n",
      "        [13.6204, 13.6188, 13.4212],\n",
      "        [13.6545, 13.5876, 13.4956],\n",
      "        [13.7044, 13.6073, 13.6381]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.2826, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.8122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 7: 0.8122225999832153\n",
      "Epoch [1/10], Loss: 1.3241\n",
      "Batch 1/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1247,  0.0290, -0.0960,  ...,  0.1289, -0.1040, -0.1054],\n",
      "        [ 0.0982,  0.0337, -0.1077,  ...,  0.1282, -0.1165, -0.1245],\n",
      "        [ 0.1178,  0.0274, -0.1168,  ...,  0.0715, -0.1023, -0.0553],\n",
      "        ...,\n",
      "        [ 0.1151,  0.0260, -0.1215,  ...,  0.1480, -0.1009, -0.1247],\n",
      "        [ 0.1128,  0.0241, -0.0716,  ...,  0.1384, -0.0950, -0.1110],\n",
      "        [ 0.1260,  0.0339, -0.1172,  ...,  0.1227, -0.0934, -0.1039]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1246,  0.0267, -0.1252,  ...,  0.0891, -0.0966, -0.1091],\n",
      "        [ 0.0970,  0.0165, -0.0892,  ...,  0.1114, -0.1496, -0.1088],\n",
      "        [ 0.0837, -0.0006, -0.0808,  ...,  0.1203, -0.0951, -0.0909],\n",
      "        ...,\n",
      "        [ 0.1320,  0.0640, -0.1316,  ...,  0.1420, -0.1344, -0.0806],\n",
      "        [ 0.1011,  0.0512, -0.0826,  ...,  0.1094, -0.0972, -0.0607],\n",
      "        [ 0.1284,  0.0172, -0.1278,  ...,  0.0973, -0.1134, -0.0972]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.7883, 13.4688, 13.4300, 13.5458, 12.8187, 13.5071, 13.4243, 13.5547,\n",
      "         13.4965, 13.5617, 13.6209, 13.5571, 13.6110, 12.7984, 13.7912, 13.7108],\n",
      "        [13.7330, 13.6806, 13.4348, 13.5417, 12.9706, 13.4616, 13.4560, 13.5928,\n",
      "         13.4901, 13.6863, 13.6767, 13.5984, 13.6365, 13.0910, 13.7531, 13.6950],\n",
      "        [13.6963, 13.5407, 13.7239, 13.3793, 12.5605, 13.5807, 13.5501, 13.6074,\n",
      "         13.6655, 13.3721, 13.5597, 13.6532, 13.5371, 12.7386, 13.8277, 13.7042],\n",
      "        [13.6697, 13.3893, 13.3979, 13.7299, 12.6759, 13.6604, 13.5954, 13.5901,\n",
      "         13.4879, 13.6376, 13.6053, 13.4552, 13.6063, 12.7396, 13.7812, 13.6753],\n",
      "        [13.7333, 13.7197, 13.2890, 13.3439, 13.6002, 13.3113, 13.2826, 13.5856,\n",
      "         13.3872, 13.7539, 13.7681, 13.6871, 13.7243, 13.5555, 13.6126, 13.7352],\n",
      "        [13.6609, 13.3646, 13.4944, 13.5303, 12.4542, 13.6468, 13.5337, 13.6587,\n",
      "         13.4884, 13.4609, 13.5888, 13.4686, 13.4835, 12.5261, 13.7401, 13.7176],\n",
      "        [13.5736, 13.3293, 13.3982, 13.5714, 12.4474, 13.6947, 13.7602, 13.6540,\n",
      "         13.4997, 13.4770, 13.5457, 13.4323, 13.5866, 12.6201, 13.7604, 13.5799],\n",
      "        [13.8086, 13.5601, 13.7599, 13.4845, 12.7266, 13.7564, 13.6398, 13.7663,\n",
      "         13.7281, 13.5641, 13.7222, 13.6476, 13.6649, 12.8857, 13.8380, 13.7343],\n",
      "        [13.6023, 13.3520, 13.5007, 13.4935, 12.5006, 13.5752, 13.6560, 13.5225,\n",
      "         13.6324, 13.4530, 13.5083, 13.5057, 13.4347, 12.6749, 13.7365, 13.5060],\n",
      "        [13.7916, 13.5321, 13.4541, 13.5997, 13.0631, 13.5748, 13.4921, 13.5950,\n",
      "         13.5454, 13.8044, 13.7572, 13.5356, 13.6412, 13.0620, 13.7769, 13.7025],\n",
      "        [13.7951, 13.4392, 13.5024, 13.4939, 13.0543, 13.6854, 13.5360, 13.7546,\n",
      "         13.6280, 13.7246, 13.8191, 13.7144, 13.7264, 13.0540, 13.7042, 13.8116],\n",
      "        [13.7201, 13.5222, 13.5449, 13.2365, 13.0520, 13.5602, 13.4501, 13.7702,\n",
      "         13.5539, 13.5220, 13.7463, 13.8172, 13.7099, 13.1834, 13.7081, 13.7400],\n",
      "        [13.7201, 13.5001, 13.4307, 13.5970, 12.9319, 13.5456, 13.5387, 13.5832,\n",
      "         13.5529, 13.6923, 13.7037, 13.6561, 13.6413, 13.0271, 13.7347, 13.7524],\n",
      "        [13.6130, 13.4939, 13.3411, 13.3880, 13.0922, 13.2962, 13.2718, 13.5343,\n",
      "         13.3568, 13.6476, 13.6167, 13.5567, 13.5843, 13.1690, 13.5464, 13.6710],\n",
      "        [13.6881, 13.5090, 13.4913, 13.6181, 12.5418, 13.5551, 13.6322, 13.5839,\n",
      "         13.5039, 13.5010, 13.5479, 13.4983, 13.5764, 12.5864, 13.8188, 13.6551],\n",
      "        [13.7342, 13.5310, 13.5222, 13.4871, 12.8386, 13.6728, 13.5675, 13.7352,\n",
      "         13.5478, 13.5946, 13.6732, 13.5965, 13.7059, 13.0352, 13.7104, 13.7674]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7883, 13.6806, 13.7239, 13.7299, 13.6002, 13.6468, 13.7602, 13.7663,\n",
      "        13.6324, 13.8044, 13.8191, 13.8172, 13.6413, 13.1690, 13.8188, 13.7674],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(2.6128, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[13.4688, 13.4300, 13.5458, 12.8187, 13.5071, 13.4243, 13.5547, 13.4965,\n",
      "         13.5617, 13.6209, 13.5571, 13.6110, 12.7984, 13.7912, 13.7108],\n",
      "        [13.7330, 13.4348, 13.5417, 12.9706, 13.4616, 13.4560, 13.5928, 13.4901,\n",
      "         13.6863, 13.6767, 13.5984, 13.6365, 13.0910, 13.7531, 13.6950],\n",
      "        [13.6963, 13.5407, 13.3793, 12.5605, 13.5807, 13.5501, 13.6074, 13.6655,\n",
      "         13.3721, 13.5597, 13.6532, 13.5371, 12.7386, 13.8277, 13.7042],\n",
      "        [13.6697, 13.3893, 13.3979, 12.6759, 13.6604, 13.5954, 13.5901, 13.4879,\n",
      "         13.6376, 13.6053, 13.4552, 13.6063, 12.7396, 13.7812, 13.6753],\n",
      "        [13.7333, 13.7197, 13.2890, 13.3439, 13.3113, 13.2826, 13.5856, 13.3872,\n",
      "         13.7539, 13.7681, 13.6871, 13.7243, 13.5555, 13.6126, 13.7352],\n",
      "        [13.6609, 13.3646, 13.4944, 13.5303, 12.4542, 13.5337, 13.6587, 13.4884,\n",
      "         13.4609, 13.5888, 13.4686, 13.4835, 12.5261, 13.7401, 13.7176],\n",
      "        [13.5736, 13.3293, 13.3982, 13.5714, 12.4474, 13.6947, 13.6540, 13.4997,\n",
      "         13.4770, 13.5457, 13.4323, 13.5866, 12.6201, 13.7604, 13.5799],\n",
      "        [13.8086, 13.5601, 13.7599, 13.4845, 12.7266, 13.7564, 13.6398, 13.7281,\n",
      "         13.5641, 13.7222, 13.6476, 13.6649, 12.8857, 13.8380, 13.7343],\n",
      "        [13.6023, 13.3520, 13.5007, 13.4935, 12.5006, 13.5752, 13.6560, 13.5225,\n",
      "         13.4530, 13.5083, 13.5057, 13.4347, 12.6749, 13.7365, 13.5060],\n",
      "        [13.7916, 13.5321, 13.4541, 13.5997, 13.0631, 13.5748, 13.4921, 13.5950,\n",
      "         13.5454, 13.7572, 13.5356, 13.6412, 13.0620, 13.7769, 13.7025],\n",
      "        [13.7951, 13.4392, 13.5024, 13.4939, 13.0543, 13.6854, 13.5360, 13.7546,\n",
      "         13.6280, 13.7246, 13.7144, 13.7264, 13.0540, 13.7042, 13.8116],\n",
      "        [13.7201, 13.5222, 13.5449, 13.2365, 13.0520, 13.5602, 13.4501, 13.7702,\n",
      "         13.5539, 13.5220, 13.7463, 13.7099, 13.1834, 13.7081, 13.7400],\n",
      "        [13.7201, 13.5001, 13.4307, 13.5970, 12.9319, 13.5456, 13.5387, 13.5832,\n",
      "         13.5529, 13.6923, 13.7037, 13.6561, 13.0271, 13.7347, 13.7524],\n",
      "        [13.6130, 13.4939, 13.3411, 13.3880, 13.0922, 13.2962, 13.2718, 13.5343,\n",
      "         13.3568, 13.6476, 13.6167, 13.5567, 13.5843, 13.5464, 13.6710],\n",
      "        [13.6881, 13.5090, 13.4913, 13.6181, 12.5418, 13.5551, 13.6322, 13.5839,\n",
      "         13.5039, 13.5010, 13.5479, 13.4983, 13.5764, 12.5864, 13.6551],\n",
      "        [13.7342, 13.5310, 13.5222, 13.4871, 12.8386, 13.6728, 13.5675, 13.7352,\n",
      "         13.5478, 13.5946, 13.6732, 13.5965, 13.7059, 13.0352, 13.7104]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0638, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(1.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 1: 1.3383135795593262\n",
      "Batch 2/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1103,  0.0335, -0.1189,  ...,  0.1309, -0.0934, -0.1226],\n",
      "        [ 0.1204,  0.0311, -0.1110,  ...,  0.1227, -0.0872, -0.0757],\n",
      "        [ 0.1310,  0.0233, -0.0846,  ...,  0.1414, -0.0565, -0.0898],\n",
      "        ...,\n",
      "        [ 0.1138,  0.0363, -0.1047,  ...,  0.1464, -0.1095, -0.1012],\n",
      "        [ 0.1301,  0.0404, -0.1086,  ...,  0.1080, -0.0792, -0.1188],\n",
      "        [ 0.1304,  0.0433, -0.0766,  ...,  0.1420, -0.0745, -0.0969]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1011,  0.0610, -0.1048,  ...,  0.1197, -0.0727, -0.0945],\n",
      "        [ 0.1016,  0.0373, -0.0554,  ...,  0.0799, -0.1099, -0.0947],\n",
      "        [ 0.1115,  0.0117, -0.0872,  ...,  0.1427, -0.0963, -0.0423],\n",
      "        ...,\n",
      "        [ 0.1194,  0.0600, -0.0993,  ...,  0.1331, -0.1117, -0.0834],\n",
      "        [ 0.1217,  0.0567, -0.0997,  ...,  0.1434, -0.0752, -0.0692],\n",
      "        [ 0.1627,  0.0730, -0.1154,  ...,  0.1325, -0.0780, -0.0433]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.6536, 13.3862, 13.2616, 13.0630, 13.3834, 13.4770, 13.5506, 13.6692,\n",
      "         13.4296, 13.5971, 13.8070, 13.7108, 12.8229, 13.2311, 13.3909, 12.5953],\n",
      "        [13.5762, 13.5286, 13.1989, 13.2073, 13.4304, 13.6114, 13.6228, 13.5770,\n",
      "         13.5174, 13.6050, 13.8564, 13.7611, 12.9202, 13.3784, 13.5364, 12.4814],\n",
      "        [13.3280, 13.0971, 13.6695, 12.7139, 13.7151, 13.0778, 13.1593, 13.4034,\n",
      "         13.2798, 13.3049, 13.5976, 13.5902, 13.0687, 12.9785, 13.2427, 12.5543],\n",
      "        [13.7084, 13.7004, 12.6298, 13.7034, 12.8384, 13.6131, 13.6913, 13.5691,\n",
      "         13.4857, 13.6003, 13.6662, 13.4364, 12.7782, 13.5588, 13.4490, 12.3771],\n",
      "        [13.3711, 13.1176, 13.4185, 12.7528, 13.5926, 13.2593, 13.3345, 13.3807,\n",
      "         13.3005, 13.3129, 13.6939, 13.6046, 12.9012, 12.9881, 13.3160, 12.2541],\n",
      "        [13.5947, 13.5045, 13.1229, 13.2555, 13.2420, 13.5923, 13.5701, 13.5380,\n",
      "         13.4156, 13.6141, 13.7435, 13.5182, 13.0192, 13.3112, 13.5162, 12.4082],\n",
      "        [13.6886, 13.4242, 12.9816, 13.3563, 13.1707, 13.4478, 13.6181, 13.6102,\n",
      "         13.3860, 13.5991, 13.7026, 13.6817, 12.7435, 13.4741, 13.4718, 12.5227],\n",
      "        [13.5645, 13.3593, 13.2776, 13.1209, 13.3846, 13.4807, 13.5907, 13.6436,\n",
      "         13.3719, 13.5157, 13.8199, 13.6926, 12.8825, 13.2841, 13.3385, 12.2999],\n",
      "        [13.7339, 13.5690, 13.3157, 13.2861, 13.4064, 13.5281, 13.6838, 13.6800,\n",
      "         13.5948, 13.6430, 13.8232, 13.7399, 12.8197, 13.5289, 13.5188, 12.8591],\n",
      "        [13.6886, 13.4708, 13.2561, 13.2047, 13.4255, 13.5541, 13.5622, 13.7163,\n",
      "         13.4456, 13.6775, 13.8218, 13.6235, 12.8802, 13.3753, 13.4885, 12.5245],\n",
      "        [13.5909, 13.4883, 13.0671, 13.1497, 13.1300, 13.4403, 13.6076, 13.6390,\n",
      "         13.3499, 13.5632, 13.7844, 13.6477, 12.6693, 13.3517, 13.3618, 12.4203],\n",
      "        [13.7103, 13.5073, 13.4966, 13.2803, 13.6172, 13.4926, 13.6036, 13.6210,\n",
      "         13.5739, 13.5975, 13.8234, 13.8271, 13.1424, 13.3784, 13.5086, 12.8169],\n",
      "        [13.3845, 13.2627, 13.0680, 13.0814, 13.2850, 13.5548, 13.3535, 13.3813,\n",
      "         13.2581, 13.5149, 13.7331, 13.3769, 13.6192, 13.0441, 13.5076, 11.6353],\n",
      "        [13.6185, 13.5341, 12.9312, 13.4114, 13.0487, 13.5714, 13.6699, 13.5921,\n",
      "         13.4148, 13.6803, 13.8188, 13.5860, 12.9729, 13.5248, 13.4470, 12.2531],\n",
      "        [13.5999, 13.4183, 13.2410, 13.1673, 13.5248, 13.4945, 13.5664, 13.5863,\n",
      "         13.5376, 13.6322, 13.8172, 13.6856, 13.0251, 13.3048, 13.5376, 12.4615],\n",
      "        [13.6349, 13.5282, 13.4102, 13.2571, 13.4836, 13.2954, 13.5247, 13.4754,\n",
      "         13.4859, 13.5689, 13.7755, 13.7534, 12.8568, 13.3290, 13.3819, 13.1162]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6536, 13.5286, 13.6695, 13.7034, 13.5926, 13.5923, 13.6181, 13.6436,\n",
      "        13.5948, 13.6775, 13.7844, 13.8271, 13.6192, 13.5248, 13.5376, 13.1162],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(2.5860, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[13.3862, 13.2616, 13.0630, 13.3834, 13.4770, 13.5506, 13.6692, 13.4296,\n",
      "         13.5971, 13.8070, 13.7108, 12.8229, 13.2311, 13.3909, 12.5953],\n",
      "        [13.5762, 13.1989, 13.2073, 13.4304, 13.6114, 13.6228, 13.5770, 13.5174,\n",
      "         13.6050, 13.8564, 13.7611, 12.9202, 13.3784, 13.5364, 12.4814],\n",
      "        [13.3280, 13.0971, 12.7139, 13.7151, 13.0778, 13.1593, 13.4034, 13.2798,\n",
      "         13.3049, 13.5976, 13.5902, 13.0687, 12.9785, 13.2427, 12.5543],\n",
      "        [13.7084, 13.7004, 12.6298, 12.8384, 13.6131, 13.6913, 13.5691, 13.4857,\n",
      "         13.6003, 13.6662, 13.4364, 12.7782, 13.5588, 13.4490, 12.3771],\n",
      "        [13.3711, 13.1176, 13.4185, 12.7528, 13.2593, 13.3345, 13.3807, 13.3005,\n",
      "         13.3129, 13.6939, 13.6046, 12.9012, 12.9881, 13.3160, 12.2541],\n",
      "        [13.5947, 13.5045, 13.1229, 13.2555, 13.2420, 13.5701, 13.5380, 13.4156,\n",
      "         13.6141, 13.7435, 13.5182, 13.0192, 13.3112, 13.5162, 12.4082],\n",
      "        [13.6886, 13.4242, 12.9816, 13.3563, 13.1707, 13.4478, 13.6102, 13.3860,\n",
      "         13.5991, 13.7026, 13.6817, 12.7435, 13.4741, 13.4718, 12.5227],\n",
      "        [13.5645, 13.3593, 13.2776, 13.1209, 13.3846, 13.4807, 13.5907, 13.3719,\n",
      "         13.5157, 13.8199, 13.6926, 12.8825, 13.2841, 13.3385, 12.2999],\n",
      "        [13.7339, 13.5690, 13.3157, 13.2861, 13.4064, 13.5281, 13.6838, 13.6800,\n",
      "         13.6430, 13.8232, 13.7399, 12.8197, 13.5289, 13.5188, 12.8591],\n",
      "        [13.6886, 13.4708, 13.2561, 13.2047, 13.4255, 13.5541, 13.5622, 13.7163,\n",
      "         13.4456, 13.8218, 13.6235, 12.8802, 13.3753, 13.4885, 12.5245],\n",
      "        [13.5909, 13.4883, 13.0671, 13.1497, 13.1300, 13.4403, 13.6076, 13.6390,\n",
      "         13.3499, 13.5632, 13.6477, 12.6693, 13.3517, 13.3618, 12.4203],\n",
      "        [13.7103, 13.5073, 13.4966, 13.2803, 13.6172, 13.4926, 13.6036, 13.6210,\n",
      "         13.5739, 13.5975, 13.8234, 13.1424, 13.3784, 13.5086, 12.8169],\n",
      "        [13.3845, 13.2627, 13.0680, 13.0814, 13.2850, 13.5548, 13.3535, 13.3813,\n",
      "         13.2581, 13.5149, 13.7331, 13.3769, 13.0441, 13.5076, 11.6353],\n",
      "        [13.6185, 13.5341, 12.9312, 13.4114, 13.0487, 13.5714, 13.6699, 13.5921,\n",
      "         13.4148, 13.6803, 13.8188, 13.5860, 12.9729, 13.4470, 12.2531],\n",
      "        [13.5999, 13.4183, 13.2410, 13.1673, 13.5248, 13.4945, 13.5664, 13.5863,\n",
      "         13.5376, 13.6322, 13.8172, 13.6856, 13.0251, 13.3048, 12.4615],\n",
      "        [13.6349, 13.5282, 13.4102, 13.2571, 13.4836, 13.2954, 13.5247, 13.4754,\n",
      "         13.4859, 13.5689, 13.7755, 13.7534, 12.8568, 13.3290, 13.3819]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0637, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(1.3249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 2: 1.3248815536499023\n",
      "Batch 3/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1139,  0.0640, -0.1206,  ...,  0.1193, -0.1096, -0.1234],\n",
      "        [ 0.1348,  0.0173, -0.1056,  ...,  0.1225, -0.1229, -0.1062],\n",
      "        [ 0.1307,  0.0448, -0.1086,  ...,  0.0946, -0.0775, -0.1036],\n",
      "        ...,\n",
      "        [ 0.1110,  0.0363, -0.1150,  ...,  0.1429, -0.0990, -0.1174],\n",
      "        [ 0.1195,  0.0024, -0.0889,  ...,  0.1324, -0.1075, -0.0993],\n",
      "        [ 0.1302,  0.0554, -0.1046,  ...,  0.1239, -0.1151, -0.0958]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1176,  0.0697, -0.1435,  ...,  0.0727, -0.1505, -0.0831],\n",
      "        [ 0.1251,  0.0321, -0.1063,  ...,  0.1339, -0.1279, -0.0878],\n",
      "        [ 0.1219,  0.0730, -0.1021,  ...,  0.1482, -0.1440, -0.0949],\n",
      "        ...,\n",
      "        [ 0.1166,  0.0501, -0.0689,  ...,  0.1345, -0.0861, -0.0987],\n",
      "        [ 0.0945,  0.0483, -0.0606,  ...,  0.1440, -0.1313, -0.0852],\n",
      "        [ 0.1200,  0.0611, -0.1018,  ...,  0.1198, -0.1353, -0.0898]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.6262, 13.0877, 13.1117, 13.5540, 12.1881, 13.3549, 12.9682, 13.1783,\n",
      "         13.4202, 13.2936, 13.1999, 13.5471, 13.1784, 13.5199, 12.9654, 13.3591],\n",
      "        [13.1013, 13.6726, 12.8624, 13.1983, 13.3356, 13.6404, 13.2640, 13.6807,\n",
      "         13.5539, 13.7692, 13.7355, 13.6496, 13.5819, 13.4831, 13.5796, 13.3657],\n",
      "        [13.4211, 13.5667, 13.0819, 13.3662, 12.9866, 13.6274, 13.2617, 13.6799,\n",
      "         13.6244, 13.6432, 13.6354, 13.7387, 13.6552, 13.7901, 13.4563, 13.5553],\n",
      "        [13.5388, 13.3155, 13.2709, 13.6208, 12.5659, 13.3989, 12.9431, 13.3854,\n",
      "         13.4184, 13.4768, 13.4219, 13.5833, 13.3075, 13.5401, 13.0825, 13.5115],\n",
      "        [12.3528, 13.4945, 12.2307, 12.5555, 13.7449, 13.3827, 13.2949, 13.5862,\n",
      "         13.3752, 13.6758, 13.5838, 13.2064, 13.5853, 13.0807, 13.6514, 13.0030],\n",
      "        [12.9981, 13.5588, 12.6683, 13.0395, 13.2178, 13.7782, 13.4160, 13.6375,\n",
      "         13.5441, 13.7812, 13.6331, 13.5013, 13.5274, 13.4561, 13.6455, 13.4213],\n",
      "        [12.7010, 12.9829, 12.2398, 12.7005, 12.9882, 13.5368, 13.7033, 13.1897,\n",
      "         13.3920, 13.4362, 13.2350, 13.2865, 13.2491, 13.1313, 13.5684, 13.1207],\n",
      "        [12.8669, 13.5632, 12.6450, 12.9995, 13.5225, 13.6832, 13.3088, 13.8962,\n",
      "         13.6154, 13.8585, 13.7939, 13.5234, 13.6485, 13.5366, 13.6679, 13.3009],\n",
      "        [13.3977, 13.4500, 12.9387, 13.2787, 12.9732, 13.7514, 13.5913, 13.5789,\n",
      "         13.6849, 13.6953, 13.6049, 13.6888, 13.4487, 13.6715, 13.5787, 13.4635],\n",
      "        [12.9889, 13.3741, 12.6640, 12.9944, 13.1595, 13.6296, 13.4039, 13.5883,\n",
      "         13.4913, 13.7167, 13.5532, 13.4935, 13.4885, 13.4800, 13.5451, 13.2294],\n",
      "        [12.9005, 13.5805, 12.5912, 12.9769, 13.3387, 13.5959, 13.2102, 13.7966,\n",
      "         13.5297, 13.6788, 13.8227, 13.5215, 13.6007, 13.4936, 13.5940, 13.3328],\n",
      "        [13.4140, 13.5627, 13.0721, 13.3834, 13.1426, 13.7432, 13.4423, 13.6446,\n",
      "         13.6420, 13.7408, 13.7018, 13.7649, 13.6060, 13.6780, 13.6337, 13.5468],\n",
      "        [12.8380, 13.5109, 12.5150, 13.0715, 13.2846, 13.5486, 13.2595, 13.6700,\n",
      "         13.4241, 13.6582, 13.5515, 13.4677, 13.6123, 13.3905, 13.4067, 13.1547],\n",
      "        [13.1077, 13.4797, 12.7637, 13.1524, 13.2120, 13.6029, 13.3221, 13.7080,\n",
      "         13.6466, 13.6707, 13.6897, 13.6038, 13.5161, 13.6690, 13.4873, 13.3511],\n",
      "        [12.7812, 13.3952, 12.3496, 12.7864, 13.2326, 13.5977, 13.3439, 13.5651,\n",
      "         13.3698, 13.5983, 13.4758, 13.3434, 13.3636, 13.2073, 13.6758, 13.1418],\n",
      "        [13.5927, 13.6552, 13.2700, 13.4833, 12.9558, 13.7268, 13.2241, 13.5958,\n",
      "         13.6515, 13.6937, 13.6038, 13.7759, 13.5129, 13.7780, 13.4660, 13.7792]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6262, 13.6726, 13.0819, 13.6208, 13.7449, 13.7782, 13.7033, 13.8962,\n",
      "        13.6849, 13.7167, 13.8227, 13.7649, 13.6123, 13.6690, 13.6758, 13.7792],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(2.5222, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[13.0877, 13.1117, 13.5540, 12.1881, 13.3549, 12.9682, 13.1783, 13.4202,\n",
      "         13.2936, 13.1999, 13.5471, 13.1784, 13.5199, 12.9654, 13.3591],\n",
      "        [13.1013, 12.8624, 13.1983, 13.3356, 13.6404, 13.2640, 13.6807, 13.5539,\n",
      "         13.7692, 13.7355, 13.6496, 13.5819, 13.4831, 13.5796, 13.3657],\n",
      "        [13.4211, 13.5667, 13.3662, 12.9866, 13.6274, 13.2617, 13.6799, 13.6244,\n",
      "         13.6432, 13.6354, 13.7387, 13.6552, 13.7901, 13.4563, 13.5553],\n",
      "        [13.5388, 13.3155, 13.2709, 12.5659, 13.3989, 12.9431, 13.3854, 13.4184,\n",
      "         13.4768, 13.4219, 13.5833, 13.3075, 13.5401, 13.0825, 13.5115],\n",
      "        [12.3528, 13.4945, 12.2307, 12.5555, 13.3827, 13.2949, 13.5862, 13.3752,\n",
      "         13.6758, 13.5838, 13.2064, 13.5853, 13.0807, 13.6514, 13.0030],\n",
      "        [12.9981, 13.5588, 12.6683, 13.0395, 13.2178, 13.4160, 13.6375, 13.5441,\n",
      "         13.7812, 13.6331, 13.5013, 13.5274, 13.4561, 13.6455, 13.4213],\n",
      "        [12.7010, 12.9829, 12.2398, 12.7005, 12.9882, 13.5368, 13.1897, 13.3920,\n",
      "         13.4362, 13.2350, 13.2865, 13.2491, 13.1313, 13.5684, 13.1207],\n",
      "        [12.8669, 13.5632, 12.6450, 12.9995, 13.5225, 13.6832, 13.3088, 13.6154,\n",
      "         13.8585, 13.7939, 13.5234, 13.6485, 13.5366, 13.6679, 13.3009],\n",
      "        [13.3977, 13.4500, 12.9387, 13.2787, 12.9732, 13.7514, 13.5913, 13.5789,\n",
      "         13.6953, 13.6049, 13.6888, 13.4487, 13.6715, 13.5787, 13.4635],\n",
      "        [12.9889, 13.3741, 12.6640, 12.9944, 13.1595, 13.6296, 13.4039, 13.5883,\n",
      "         13.4913, 13.5532, 13.4935, 13.4885, 13.4800, 13.5451, 13.2294],\n",
      "        [12.9005, 13.5805, 12.5912, 12.9769, 13.3387, 13.5959, 13.2102, 13.7966,\n",
      "         13.5297, 13.6788, 13.5215, 13.6007, 13.4936, 13.5940, 13.3328],\n",
      "        [13.4140, 13.5627, 13.0721, 13.3834, 13.1426, 13.7432, 13.4423, 13.6446,\n",
      "         13.6420, 13.7408, 13.7018, 13.6060, 13.6780, 13.6337, 13.5468],\n",
      "        [12.8380, 13.5109, 12.5150, 13.0715, 13.2846, 13.5486, 13.2595, 13.6700,\n",
      "         13.4241, 13.6582, 13.5515, 13.4677, 13.3905, 13.4067, 13.1547],\n",
      "        [13.1077, 13.4797, 12.7637, 13.1524, 13.2120, 13.6029, 13.3221, 13.7080,\n",
      "         13.6466, 13.6707, 13.6897, 13.6038, 13.5161, 13.4873, 13.3511],\n",
      "        [12.7812, 13.3952, 12.3496, 12.7864, 13.2326, 13.5977, 13.3439, 13.5651,\n",
      "         13.3698, 13.5983, 13.4758, 13.3434, 13.3636, 13.2073, 13.1418],\n",
      "        [13.5927, 13.6552, 13.2700, 13.4833, 12.9558, 13.7268, 13.2241, 13.5958,\n",
      "         13.6515, 13.6937, 13.6038, 13.7759, 13.5129, 13.7780, 13.4660]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0633, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(1.2928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 3: 1.2927744388580322\n",
      "Batch 4/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1286,  0.0342, -0.0822,  ...,  0.1444, -0.0772, -0.0960],\n",
      "        [ 0.1079,  0.0403, -0.0914,  ...,  0.1408, -0.1006, -0.1272],\n",
      "        [ 0.1387,  0.0667, -0.0800,  ...,  0.1400, -0.1079, -0.0442],\n",
      "        ...,\n",
      "        [ 0.1040,  0.0360, -0.1035,  ...,  0.1266, -0.0670, -0.1305],\n",
      "        [ 0.1356,  0.0519, -0.1148,  ...,  0.1353, -0.0925, -0.1094],\n",
      "        [ 0.1337,  0.0588, -0.1397,  ...,  0.1285, -0.1011, -0.1233]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1070,  0.0095, -0.0922,  ...,  0.1523, -0.0561, -0.0847],\n",
      "        [ 0.1127,  0.0206, -0.0598,  ...,  0.0985, -0.0686, -0.0723],\n",
      "        [ 0.1059,  0.0851, -0.1028,  ...,  0.1013, -0.0880, -0.0162],\n",
      "        ...,\n",
      "        [ 0.0727,  0.0628, -0.0951,  ...,  0.0981, -0.1330, -0.0955],\n",
      "        [ 0.0879,  0.0586, -0.0922,  ...,  0.1076, -0.0950, -0.0556],\n",
      "        [ 0.0864,  0.0303, -0.1309,  ...,  0.1055, -0.1049, -0.0982]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.4114, 13.5712, 12.1476, 13.7561, 13.0780, 13.2990, 12.3406, 12.9264,\n",
      "         13.1718, 13.3487, 13.1916, 13.6560, 12.6186, 13.1190, 13.4813, 13.3791],\n",
      "        [13.1830, 13.5726, 12.2954, 13.6544, 12.8836, 13.3237, 12.2588, 12.9836,\n",
      "         13.3559, 13.2942, 13.0676, 13.4530, 12.8068, 13.1191, 13.4355, 13.4884],\n",
      "        [12.6109, 13.2578, 13.1784, 13.3487, 12.5965, 13.4767, 12.6113, 13.0178,\n",
      "         13.4009, 13.0808, 12.5517, 13.0871, 13.4552, 13.4863, 13.1541, 13.2445],\n",
      "        [12.8133, 13.3770, 12.3969, 13.7679, 12.5272, 13.5970, 12.7765, 13.4473,\n",
      "         13.5776, 13.3432, 12.6302, 13.2795, 12.9879, 13.5252, 13.3299, 13.7250],\n",
      "        [13.2566, 13.5195, 12.2320, 13.5583, 13.2270, 13.1785, 11.8841, 12.7178,\n",
      "         13.3033, 13.1467, 13.1201, 13.3465, 12.7292, 13.0642, 13.2280, 13.2349],\n",
      "        [12.4466, 13.1721, 12.7208, 13.6079, 12.2315, 13.7709, 13.0309, 13.5518,\n",
      "         13.6075, 13.2311, 12.2517, 13.0592, 13.3093, 13.6759, 13.1446, 13.5759],\n",
      "        [11.7703, 12.5114, 11.8062, 13.0976, 11.2599, 13.0638, 13.4059, 13.4948,\n",
      "         12.8869, 12.9077, 11.6793, 12.5403, 12.3641, 13.1328, 12.6519, 12.9718],\n",
      "        [12.2723, 12.9091, 12.2318, 13.4770, 11.9013, 13.3658, 13.1908, 13.7080,\n",
      "         13.4253, 13.1990, 12.1914, 12.9878, 12.7951, 13.3617, 13.0453, 13.4568],\n",
      "        [12.3460, 13.2272, 12.3632, 13.4100, 12.3464, 13.3538, 12.6651, 13.5218,\n",
      "         13.8365, 13.4687, 12.4930, 12.8900, 13.0795, 13.3861, 13.1357, 13.5576],\n",
      "        [12.4289, 13.1297, 12.0490, 13.4473, 12.0796, 13.3771, 12.8310, 13.5416,\n",
      "         13.6086, 13.3897, 12.5424, 13.0613, 12.7461, 13.2273, 13.1834, 13.4620],\n",
      "        [13.2394, 13.5520, 11.9049, 13.5510, 12.9358, 12.9970, 11.9343, 12.7283,\n",
      "         13.1477, 13.2651, 13.5068, 13.5708, 12.4257, 12.8311, 13.5129, 13.3231],\n",
      "        [13.3118, 13.6253, 12.3496, 13.5963, 12.8741, 13.3874, 12.5472, 12.9707,\n",
      "         13.3440, 13.4840, 13.3745, 13.6321, 12.9451, 13.2348, 13.7082, 13.3840],\n",
      "        [12.3858, 13.1600, 12.8353, 13.4847, 12.3464, 13.5635, 12.6416, 13.2744,\n",
      "         13.6819, 13.2349, 12.3883, 12.9162, 13.3464, 13.5478, 13.0311, 13.5194],\n",
      "        [12.1264, 12.9408, 12.1034, 13.4687, 11.9414, 13.4220, 12.9836, 13.4750,\n",
      "         13.3882, 13.1890, 12.0591, 12.7164, 12.7495, 13.5224, 12.8216, 13.3661],\n",
      "        [12.8234, 13.4874, 12.4409, 13.6454, 12.5649, 13.5746, 12.6676, 13.3116,\n",
      "         13.5229, 13.3590, 12.9482, 13.3749, 12.9492, 13.3719, 13.5323, 13.6183],\n",
      "        [12.5048, 13.0746, 12.4612, 13.5456, 12.3384, 13.5236, 12.4219, 13.1151,\n",
      "         13.4561, 13.1553, 12.3067, 13.0131, 13.0173, 13.3834, 12.9290, 13.5283]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.4114, 13.5726, 13.1784, 13.7679, 13.2270, 13.7709, 13.4059, 13.7080,\n",
      "        13.8365, 13.3897, 13.5068, 13.6321, 13.3464, 13.5224, 13.5323, 13.5283],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(2.4007, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[13.5712, 12.1476, 13.7561, 13.0780, 13.2990, 12.3406, 12.9264, 13.1718,\n",
      "         13.3487, 13.1916, 13.6560, 12.6186, 13.1190, 13.4813, 13.3791],\n",
      "        [13.1830, 12.2954, 13.6544, 12.8836, 13.3237, 12.2588, 12.9836, 13.3559,\n",
      "         13.2942, 13.0676, 13.4530, 12.8068, 13.1191, 13.4355, 13.4884],\n",
      "        [12.6109, 13.2578, 13.3487, 12.5965, 13.4767, 12.6113, 13.0178, 13.4009,\n",
      "         13.0808, 12.5517, 13.0871, 13.4552, 13.4863, 13.1541, 13.2445],\n",
      "        [12.8133, 13.3770, 12.3969, 12.5272, 13.5970, 12.7765, 13.4473, 13.5776,\n",
      "         13.3432, 12.6302, 13.2795, 12.9879, 13.5252, 13.3299, 13.7250],\n",
      "        [13.2566, 13.5195, 12.2320, 13.5583, 13.1785, 11.8841, 12.7178, 13.3033,\n",
      "         13.1467, 13.1201, 13.3465, 12.7292, 13.0642, 13.2280, 13.2349],\n",
      "        [12.4466, 13.1721, 12.7208, 13.6079, 12.2315, 13.0309, 13.5518, 13.6075,\n",
      "         13.2311, 12.2517, 13.0592, 13.3093, 13.6759, 13.1446, 13.5759],\n",
      "        [11.7703, 12.5114, 11.8062, 13.0976, 11.2599, 13.0638, 13.4948, 12.8869,\n",
      "         12.9077, 11.6793, 12.5403, 12.3641, 13.1328, 12.6519, 12.9718],\n",
      "        [12.2723, 12.9091, 12.2318, 13.4770, 11.9013, 13.3658, 13.1908, 13.4253,\n",
      "         13.1990, 12.1914, 12.9878, 12.7951, 13.3617, 13.0453, 13.4568],\n",
      "        [12.3460, 13.2272, 12.3632, 13.4100, 12.3464, 13.3538, 12.6651, 13.5218,\n",
      "         13.4687, 12.4930, 12.8900, 13.0795, 13.3861, 13.1357, 13.5576],\n",
      "        [12.4289, 13.1297, 12.0490, 13.4473, 12.0796, 13.3771, 12.8310, 13.5416,\n",
      "         13.6086, 12.5424, 13.0613, 12.7461, 13.2273, 13.1834, 13.4620],\n",
      "        [13.2394, 13.5520, 11.9049, 13.5510, 12.9358, 12.9970, 11.9343, 12.7283,\n",
      "         13.1477, 13.2651, 13.5708, 12.4257, 12.8311, 13.5129, 13.3231],\n",
      "        [13.3118, 13.6253, 12.3496, 13.5963, 12.8741, 13.3874, 12.5472, 12.9707,\n",
      "         13.3440, 13.4840, 13.3745, 12.9451, 13.2348, 13.7082, 13.3840],\n",
      "        [12.3858, 13.1600, 12.8353, 13.4847, 12.3464, 13.5635, 12.6416, 13.2744,\n",
      "         13.6819, 13.2349, 12.3883, 12.9162, 13.5478, 13.0311, 13.5194],\n",
      "        [12.1264, 12.9408, 12.1034, 13.4687, 11.9414, 13.4220, 12.9836, 13.4750,\n",
      "         13.3882, 13.1890, 12.0591, 12.7164, 12.7495, 12.8216, 13.3661],\n",
      "        [12.8234, 13.4874, 12.4409, 13.6454, 12.5649, 13.5746, 12.6676, 13.3116,\n",
      "         13.5229, 13.3590, 12.9482, 13.3749, 12.9492, 13.3719, 13.6183],\n",
      "        [12.5048, 13.0746, 12.4612, 13.5456, 12.3384, 13.5236, 12.4219, 13.1151,\n",
      "         13.4561, 13.1553, 12.3067, 13.0131, 13.0173, 13.3834, 12.9290]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0627, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(1.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 4: 1.2317110300064087\n",
      "Batch 5/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1056,  0.0398, -0.0849,  ...,  0.1680,  0.0006, -0.1320],\n",
      "        [ 0.1475,  0.0348, -0.1040,  ...,  0.1621, -0.0594, -0.0780],\n",
      "        [ 0.1474,  0.0503, -0.1288,  ...,  0.0999, -0.0887, -0.1278],\n",
      "        ...,\n",
      "        [ 0.1023,  0.0365, -0.0522,  ...,  0.1942, -0.0507, -0.1416],\n",
      "        [ 0.1261,  0.0301, -0.1396,  ...,  0.1482, -0.1229, -0.1394],\n",
      "        [ 0.1289,  0.0466, -0.0973,  ...,  0.1984, -0.0742, -0.1022]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0850,  0.0504, -0.0835,  ...,  0.1614, -0.0375, -0.1433],\n",
      "        [ 0.1212,  0.0042, -0.1116,  ...,  0.1177, -0.0584, -0.0645],\n",
      "        [ 0.1246,  0.0556, -0.1296,  ...,  0.1250, -0.0884, -0.0822],\n",
      "        ...,\n",
      "        [ 0.0417,  0.0243, -0.0545,  ...,  0.1399, -0.0236, -0.0748],\n",
      "        [ 0.1168,  0.0629, -0.1419,  ...,  0.1072, -0.1166, -0.0954],\n",
      "        [ 0.1276,  0.0115, -0.0818,  ...,  0.1752, -0.0757, -0.0650]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.5544, 13.0161, 12.9957, 12.2958, 13.1339, 11.6674, 12.2023, 12.7007,\n",
      "         11.5721, 13.0002, 12.7117,  9.9590, 13.2031, 13.3063, 12.7266, 13.1376],\n",
      "        [12.8466, 13.5800, 12.9443, 12.4662, 13.0054, 11.6047, 12.9019, 12.4866,\n",
      "         10.8778, 12.3142, 12.8944,  9.6186, 13.0650, 12.7277, 12.4817, 13.3465],\n",
      "        [12.4355, 12.3168, 13.5391, 13.2823, 12.3836, 13.1273, 11.9768, 12.9064,\n",
      "         12.4768, 13.1090, 11.0549, 12.2793, 13.1979, 11.7114, 13.4333, 12.0807],\n",
      "        [11.7390, 11.3681, 13.0372, 13.3830, 11.7915, 13.4138, 11.1085, 12.7468,\n",
      "         12.9600, 12.7323, 10.0201, 12.9948, 12.7692, 10.8881, 13.3458, 10.9951],\n",
      "        [12.9780, 12.4425, 12.7341, 12.0613, 13.2300, 12.0084, 11.6270, 12.7403,\n",
      "         11.8008, 12.6030, 12.3991, 10.2224, 13.1334, 12.6313, 12.4050, 12.7258],\n",
      "        [11.7515, 10.6822, 12.8414, 12.8123, 11.6076, 13.5825, 10.3727, 12.8554,\n",
      "         13.2989, 12.8613,  9.4638, 13.1554, 12.6992, 10.6372, 13.0873, 10.5201],\n",
      "        [12.3258, 13.3001, 12.6079, 12.2661, 12.3796, 11.2409, 13.0940, 11.8982,\n",
      "         10.1572, 11.8715, 12.4526,  9.5655, 12.4389, 12.1224, 12.1032, 12.8832],\n",
      "        [11.9565, 10.8622, 12.7181, 12.5639, 11.9675, 13.3137, 10.8183, 13.2248,\n",
      "         12.9540, 12.6410,  9.9862, 12.6542, 12.9752, 10.8952, 12.7490, 11.0531],\n",
      "        [11.9983, 10.0704, 12.3918, 12.1916, 11.5833, 12.8839,  9.3988, 12.7533,\n",
      "         13.3913, 12.8964,  9.5884, 12.4730, 12.6141, 11.1905, 12.9166, 10.3898],\n",
      "        [12.5988, 11.3029, 13.0777, 12.6545, 12.1626, 13.0106, 10.8059, 12.8677,\n",
      "         13.1161, 13.4412, 10.5466, 12.3440, 12.9236, 11.8557, 13.1973, 11.2942],\n",
      "        [12.8648, 13.1770, 11.8282, 10.9882, 13.0737,  9.9335, 12.1236, 11.7393,\n",
      "          9.8047, 11.5084, 13.5728,  7.5910, 12.3588, 13.1740, 11.2938, 13.3436],\n",
      "        [ 9.5614,  8.0491, 11.3948, 11.6513,  9.3638, 13.0780,  8.1634, 11.5364,\n",
      "         12.7456, 11.4958,  6.4614, 13.4599, 11.1224,  8.1502, 12.0088,  7.8805],\n",
      "        [12.6884, 11.9849, 13.2451, 12.9851, 12.6077, 13.1668, 11.6108, 13.0945,\n",
      "         12.7327, 12.9464, 11.0615, 12.1362, 13.3053, 11.7028, 13.0961, 11.9835],\n",
      "        [13.4725, 12.5372, 12.7322, 11.9119, 12.8645, 11.3166, 11.5608, 12.5994,\n",
      "         11.7227, 13.0647, 12.7647,  9.7676, 13.0156, 13.5416, 12.5390, 12.7856],\n",
      "        [12.5992, 11.8810, 13.3113, 12.9676, 12.2490, 12.9593, 11.0416, 12.8482,\n",
      "         12.9870, 13.3386, 10.9701, 12.1597, 13.1321, 12.0562, 13.6066, 11.7178],\n",
      "        [13.2139, 13.0420, 12.8990, 12.0498, 13.1931, 11.4035, 12.2845, 12.5851,\n",
      "         11.2018, 12.5534, 12.7901,  9.4450, 13.1938, 12.9436, 12.5440, 13.4670]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.5544, 13.5800, 13.5391, 13.3830, 13.2300, 13.5825, 13.0940, 13.2248,\n",
      "        13.3913, 13.4412, 13.5728, 13.4599, 13.3053, 13.5416, 13.6066, 13.4670],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(1.9020, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[13.0161, 12.9957, 12.2958, 13.1339, 11.6674, 12.2023, 12.7007, 11.5721,\n",
      "         13.0002, 12.7117,  9.9590, 13.2031, 13.3063, 12.7266, 13.1376],\n",
      "        [12.8466, 12.9443, 12.4662, 13.0054, 11.6047, 12.9019, 12.4866, 10.8778,\n",
      "         12.3142, 12.8944,  9.6186, 13.0650, 12.7277, 12.4817, 13.3465],\n",
      "        [12.4355, 12.3168, 13.2823, 12.3836, 13.1273, 11.9768, 12.9064, 12.4768,\n",
      "         13.1090, 11.0549, 12.2793, 13.1979, 11.7114, 13.4333, 12.0807],\n",
      "        [11.7390, 11.3681, 13.0372, 11.7915, 13.4138, 11.1085, 12.7468, 12.9600,\n",
      "         12.7323, 10.0201, 12.9948, 12.7692, 10.8881, 13.3458, 10.9951],\n",
      "        [12.9780, 12.4425, 12.7341, 12.0613, 12.0084, 11.6270, 12.7403, 11.8008,\n",
      "         12.6030, 12.3991, 10.2224, 13.1334, 12.6313, 12.4050, 12.7258],\n",
      "        [11.7515, 10.6822, 12.8414, 12.8123, 11.6076, 10.3727, 12.8554, 13.2989,\n",
      "         12.8613,  9.4638, 13.1554, 12.6992, 10.6372, 13.0873, 10.5201],\n",
      "        [12.3258, 13.3001, 12.6079, 12.2661, 12.3796, 11.2409, 11.8982, 10.1572,\n",
      "         11.8715, 12.4526,  9.5655, 12.4389, 12.1224, 12.1032, 12.8832],\n",
      "        [11.9565, 10.8622, 12.7181, 12.5639, 11.9675, 13.3137, 10.8183, 12.9540,\n",
      "         12.6410,  9.9862, 12.6542, 12.9752, 10.8952, 12.7490, 11.0531],\n",
      "        [11.9983, 10.0704, 12.3918, 12.1916, 11.5833, 12.8839,  9.3988, 12.7533,\n",
      "         12.8964,  9.5884, 12.4730, 12.6141, 11.1905, 12.9166, 10.3898],\n",
      "        [12.5988, 11.3029, 13.0777, 12.6545, 12.1626, 13.0106, 10.8059, 12.8677,\n",
      "         13.1161, 10.5466, 12.3440, 12.9236, 11.8557, 13.1973, 11.2942],\n",
      "        [12.8648, 13.1770, 11.8282, 10.9882, 13.0737,  9.9335, 12.1236, 11.7393,\n",
      "          9.8047, 11.5084,  7.5910, 12.3588, 13.1740, 11.2938, 13.3436],\n",
      "        [ 9.5614,  8.0491, 11.3948, 11.6513,  9.3638, 13.0780,  8.1634, 11.5364,\n",
      "         12.7456, 11.4958,  6.4614, 11.1224,  8.1502, 12.0088,  7.8805],\n",
      "        [12.6884, 11.9849, 13.2451, 12.9851, 12.6077, 13.1668, 11.6108, 13.0945,\n",
      "         12.7327, 12.9464, 11.0615, 12.1362, 11.7028, 13.0961, 11.9835],\n",
      "        [13.4725, 12.5372, 12.7322, 11.9119, 12.8645, 11.3166, 11.5608, 12.5994,\n",
      "         11.7227, 13.0647, 12.7647,  9.7676, 13.0156, 12.5390, 12.7856],\n",
      "        [12.5992, 11.8810, 13.3113, 12.9676, 12.2490, 12.9593, 11.0416, 12.8482,\n",
      "         12.9870, 13.3386, 10.9701, 12.1597, 13.1321, 12.0562, 11.7178],\n",
      "        [13.2139, 13.0420, 12.8990, 12.0498, 13.1931, 11.4035, 12.2845, 12.5851,\n",
      "         11.2018, 12.5534, 12.7901,  9.4450, 13.1938, 12.9436, 12.5440]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0589, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.9804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 5: 0.9804468154907227\n",
      "Batch 6/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0978,  0.0733, -0.1597,  ...,  0.0827, -0.0189, -0.0446],\n",
      "        [ 0.1743, -0.0024, -0.0528,  ...,  0.1475, -0.0179, -0.0771],\n",
      "        [ 0.0764,  0.0679, -0.1155,  ...,  0.2094, -0.0650, -0.1235],\n",
      "        ...,\n",
      "        [ 0.1558,  0.0776, -0.0954,  ...,  0.1693, -0.0905, -0.1099],\n",
      "        [ 0.1401,  0.0875, -0.1155,  ...,  0.1561, -0.0328, -0.0580],\n",
      "        [ 0.1139,  0.0926, -0.0565,  ...,  0.1525, -0.0415, -0.1597]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0995,  0.0744, -0.1468,  ...,  0.0772, -0.0853, -0.0184],\n",
      "        [ 0.1169,  0.0103, -0.0492,  ...,  0.1249, -0.0309, -0.0569],\n",
      "        [ 0.0759,  0.0869, -0.0864,  ...,  0.1748, -0.0876, -0.1099],\n",
      "        ...,\n",
      "        [ 0.1127,  0.0528, -0.1111,  ...,  0.1341, -0.1136, -0.1096],\n",
      "        [ 0.1343,  0.0901, -0.1268,  ...,  0.1295, -0.1119, -0.0613],\n",
      "        [ 0.1037,  0.0854, -0.0860,  ...,  0.1566, -0.0976, -0.1169]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[12.1221,  4.0460,  8.3089,  8.2084,  3.4601, 10.8197,  7.1534,  6.8657,\n",
      "          6.8818,  8.4375, 10.2462, 12.3876,  6.8881,  8.0159, 11.5531,  8.9291],\n",
      "        [ 9.0236, 12.8264, 11.3584, 11.6877, 11.8729,  7.5253, 10.0398, 12.1686,\n",
      "          8.3778, 11.4863, 10.2049,  4.3109, 11.0850, 11.8523,  9.4171, 11.2794],\n",
      "        [10.9498,  9.1002, 12.7077, 10.4792, 10.3539, 11.7341, 12.2079,  9.9017,\n",
      "          9.2600, 11.3320, 11.6586, 10.2812, 11.0867, 11.3081, 10.9515, 11.7120],\n",
      "        [12.1473, 10.3896, 11.6785, 12.4267,  9.7936, 10.3579, 10.5758, 11.1202,\n",
      "         10.2929, 11.7644, 11.7972,  9.6324, 10.5986, 11.7190, 11.8032, 12.5386],\n",
      "        [ 7.5670, 11.4168, 10.9549, 10.5089, 12.2732,  7.0621, 10.7777, 11.2168,\n",
      "         10.5572, 10.0572,  8.1478,  4.4588,  9.1818, 10.2990,  8.2317, 10.8073],\n",
      "        [ 9.1877,  2.8368,  9.2322,  6.1364,  5.0354, 12.2655,  9.8336,  4.9741,\n",
      "          7.2393,  7.5656,  8.9594, 12.7072,  6.9530,  7.2543,  9.1394,  8.3767],\n",
      "        [ 7.1889,  4.8822,  9.9787,  6.5771,  7.5941, 10.5284, 11.0291,  5.0941,\n",
      "          8.0217,  7.6195,  8.3134,  9.7707,  7.9792,  7.6380,  7.1151,  8.5794],\n",
      "        [10.6819, 11.7960, 11.1889, 11.8062, 10.6028,  8.3751,  9.5035, 13.1206,\n",
      "          9.4428, 11.7172, 10.4353,  6.3270, 10.3069, 11.8221, 11.3109, 11.5874],\n",
      "        [ 3.9072,  0.1558,  3.8904,  2.4114,  1.5637,  4.9805,  4.9721,  2.7092,\n",
      "          9.3727,  2.3000,  1.7178,  6.5317,  0.3464,  1.5438,  4.1998,  3.4097],\n",
      "        [12.1967,  8.0161, 10.8710, 10.6814,  7.2602, 11.0301,  9.6556,  9.7424,\n",
      "          9.0119, 11.0252, 11.5267, 10.7158,  9.5717, 10.3941, 12.1116, 10.8599],\n",
      "        [12.8999,  8.2548, 10.9849, 11.0877,  7.0101, 11.6028,  9.1168,  9.8832,\n",
      "          7.5476, 11.4222, 12.6127, 11.2285, 10.3461, 11.3405, 12.5321, 11.3153],\n",
      "        [ 8.5678, -0.8120,  5.8853,  3.8157,  0.8262, 10.1266,  6.2846,  2.3354,\n",
      "          5.6775,  4.5065,  6.5880, 12.6243,  3.3048,  3.9995,  8.2517,  5.8999],\n",
      "        [11.5131, 11.9273, 12.6741, 12.3058, 11.0349, 10.4459, 11.1750, 12.1955,\n",
      "          8.5689, 12.8318, 12.4805,  8.1650, 12.7888, 13.0533, 11.6546, 12.3474],\n",
      "        [11.8494, 10.6455, 12.4772, 11.8710, 10.0020, 11.3823, 11.0344, 11.6129,\n",
      "          8.6160, 12.2471, 12.3484,  9.7815, 11.9793, 12.9635, 12.1790, 12.3993],\n",
      "        [12.3385,  6.5037,  9.2435,  9.7479,  5.5245, 10.2256,  8.1165,  9.3749,\n",
      "          8.7177,  9.5090, 10.1519, 11.0590,  7.4822,  9.3613, 12.4338, 10.2302],\n",
      "        [12.3080,  9.1936, 11.7815, 11.5860,  9.3725, 11.5167, 11.1934, 10.8442,\n",
      "         10.6066, 11.1905, 11.4134, 11.2018,  9.8205, 11.4933, 12.3628, 12.7171]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([12.1221, 12.8264, 12.7077, 12.4267, 12.2732, 12.2655, 11.0291, 13.1206,\n",
      "         9.3727, 11.0252, 12.6127, 12.6243, 12.7888, 12.9635, 12.4338, 12.7171],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(1.3207, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 4.0460,  8.3089,  8.2084,  3.4601, 10.8197,  7.1534,  6.8657,  6.8818,\n",
      "          8.4375, 10.2462, 12.3876,  6.8881,  8.0159, 11.5531,  8.9291],\n",
      "        [ 9.0236, 11.3584, 11.6877, 11.8729,  7.5253, 10.0398, 12.1686,  8.3778,\n",
      "         11.4863, 10.2049,  4.3109, 11.0850, 11.8523,  9.4171, 11.2794],\n",
      "        [10.9498,  9.1002, 10.4792, 10.3539, 11.7341, 12.2079,  9.9017,  9.2600,\n",
      "         11.3320, 11.6586, 10.2812, 11.0867, 11.3081, 10.9515, 11.7120],\n",
      "        [12.1473, 10.3896, 11.6785,  9.7936, 10.3579, 10.5758, 11.1202, 10.2929,\n",
      "         11.7644, 11.7972,  9.6324, 10.5986, 11.7190, 11.8032, 12.5386],\n",
      "        [ 7.5670, 11.4168, 10.9549, 10.5089,  7.0621, 10.7777, 11.2168, 10.5572,\n",
      "         10.0572,  8.1478,  4.4588,  9.1818, 10.2990,  8.2317, 10.8073],\n",
      "        [ 9.1877,  2.8368,  9.2322,  6.1364,  5.0354,  9.8336,  4.9741,  7.2393,\n",
      "          7.5656,  8.9594, 12.7072,  6.9530,  7.2543,  9.1394,  8.3767],\n",
      "        [ 7.1889,  4.8822,  9.9787,  6.5771,  7.5941, 10.5284,  5.0941,  8.0217,\n",
      "          7.6195,  8.3134,  9.7707,  7.9792,  7.6380,  7.1151,  8.5794],\n",
      "        [10.6819, 11.7960, 11.1889, 11.8062, 10.6028,  8.3751,  9.5035,  9.4428,\n",
      "         11.7172, 10.4353,  6.3270, 10.3069, 11.8221, 11.3109, 11.5874],\n",
      "        [ 3.9072,  0.1558,  3.8904,  2.4114,  1.5637,  4.9805,  4.9721,  2.7092,\n",
      "          2.3000,  1.7178,  6.5317,  0.3464,  1.5438,  4.1998,  3.4097],\n",
      "        [12.1967,  8.0161, 10.8710, 10.6814,  7.2602, 11.0301,  9.6556,  9.7424,\n",
      "          9.0119, 11.5267, 10.7158,  9.5717, 10.3941, 12.1116, 10.8599],\n",
      "        [12.8999,  8.2548, 10.9849, 11.0877,  7.0101, 11.6028,  9.1168,  9.8832,\n",
      "          7.5476, 11.4222, 11.2285, 10.3461, 11.3405, 12.5321, 11.3153],\n",
      "        [ 8.5678, -0.8120,  5.8853,  3.8157,  0.8262, 10.1266,  6.2846,  2.3354,\n",
      "          5.6775,  4.5065,  6.5880,  3.3048,  3.9995,  8.2517,  5.8999],\n",
      "        [11.5131, 11.9273, 12.6741, 12.3058, 11.0349, 10.4459, 11.1750, 12.1955,\n",
      "          8.5689, 12.8318, 12.4805,  8.1650, 13.0533, 11.6546, 12.3474],\n",
      "        [11.8494, 10.6455, 12.4772, 11.8710, 10.0020, 11.3823, 11.0344, 11.6129,\n",
      "          8.6160, 12.2471, 12.3484,  9.7815, 11.9793, 12.1790, 12.3993],\n",
      "        [12.3385,  6.5037,  9.2435,  9.7479,  5.5245, 10.2256,  8.1165,  9.3749,\n",
      "          8.7177,  9.5090, 10.1519, 11.0590,  7.4822,  9.3613, 10.2302],\n",
      "        [12.3080,  9.1936, 11.7815, 11.5860,  9.3725, 11.5167, 11.1934, 10.8442,\n",
      "         10.6066, 11.1905, 11.4134, 11.2018,  9.8205, 11.4933, 12.3628]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0485, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.6846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 6: 0.6846131682395935\n",
      "Batch 7/7: Matrix features: torch.Size([4, 128]), Vector features: torch.Size([4, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 5.0963e-02, -1.0262e-02,  8.2978e-02, -3.7078e-02,  1.0871e-01,\n",
      "          1.3737e-02,  9.2093e-02,  6.2883e-02, -1.4834e-01, -7.0302e-02,\n",
      "         -4.4570e-02, -8.1390e-02, -6.0194e-02, -4.9721e-02,  1.1760e-01,\n",
      "         -9.2956e-02, -7.4310e-02, -1.6796e-01, -1.3287e-01,  5.8151e-03,\n",
      "         -5.3898e-03,  1.4707e-01,  8.4606e-02, -2.3746e-02, -8.0161e-02,\n",
      "          1.4937e-02,  1.2473e-01, -3.8243e-02,  4.8795e-02, -1.2271e-02,\n",
      "         -7.8261e-03, -5.8012e-02, -1.1948e-01,  1.2200e-01,  6.7198e-02,\n",
      "         -4.4948e-02,  6.6656e-02, -1.5149e-01,  9.8304e-04,  8.7978e-02,\n",
      "          8.3219e-02, -9.1332e-02,  1.0119e-01,  1.4126e-01,  5.2987e-02,\n",
      "         -1.9089e-01, -1.5283e-01,  3.2228e-02,  1.2581e-01, -7.7644e-02,\n",
      "          1.3811e-01,  1.1495e-01,  1.4953e-03,  1.1970e-01, -1.2994e-01,\n",
      "          6.6652e-02,  3.4863e-02, -6.6146e-02, -1.0773e-01, -3.4035e-02,\n",
      "         -3.2124e-03,  6.1368e-02,  6.1384e-02,  9.8834e-02, -1.0643e-01,\n",
      "         -4.3321e-03,  4.6220e-02, -1.3024e-02, -2.3793e-02,  1.0332e-01,\n",
      "          7.0259e-02, -7.1170e-02,  7.2371e-02,  7.1463e-02,  6.9081e-02,\n",
      "         -3.5339e-02, -1.9325e-01, -4.7547e-02, -3.0180e-02, -1.3833e-01,\n",
      "         -4.1966e-03,  2.5589e-02,  1.1538e-01, -1.1416e-01, -4.4838e-02,\n",
      "         -8.6436e-02,  4.6774e-02,  9.7741e-02, -2.0673e-01,  1.9025e-01,\n",
      "         -4.1726e-02,  3.0842e-03,  2.4897e-02, -1.0618e-01,  8.3889e-02,\n",
      "          7.0959e-02, -1.5648e-01,  5.0521e-02, -1.7212e-02,  1.0125e-01,\n",
      "          1.7646e-01, -5.7748e-02,  4.1606e-02, -4.7984e-02, -1.9774e-02,\n",
      "         -8.7821e-02, -7.3800e-02, -7.4269e-02,  1.0953e-01, -2.9209e-02,\n",
      "          1.7181e-02,  9.0626e-02,  2.5457e-02, -5.3711e-02, -3.6032e-02,\n",
      "         -2.6736e-02, -4.3204e-02,  5.1106e-04,  1.6724e-02, -6.5309e-03,\n",
      "         -1.3941e-01,  5.9854e-02,  4.3852e-02, -1.5799e-01,  7.5443e-02,\n",
      "          1.7848e-01,  8.4343e-02, -4.4978e-02],\n",
      "        [-1.4504e-01,  6.9151e-02,  1.4326e-01,  1.6852e-02,  1.0506e-01,\n",
      "         -5.5317e-02,  5.8956e-02, -9.8206e-02, -2.0112e-01, -1.7163e-01,\n",
      "         -1.8281e-01,  8.1712e-02, -9.0188e-02,  1.8255e-01, -9.1121e-02,\n",
      "         -3.7633e-02,  1.0227e-01,  2.8372e-02, -4.4983e-02, -3.4717e-02,\n",
      "         -7.4448e-02,  1.1997e-01,  7.0038e-03,  4.5871e-02, -9.5911e-02,\n",
      "          1.8186e-01,  5.4591e-03,  2.6042e-02, -1.2551e-01,  1.1302e-01,\n",
      "          5.4295e-02,  6.8012e-02, -4.0455e-02, -1.4488e-01,  1.0640e-01,\n",
      "          2.9613e-02, -1.1274e-01,  1.9089e-01,  2.5952e-02, -5.6355e-02,\n",
      "          4.6486e-02, -3.4962e-02,  1.1645e-01, -1.5046e-02,  3.4039e-03,\n",
      "         -3.5299e-02, -8.1899e-03,  3.8047e-02, -8.4636e-02, -5.0796e-02,\n",
      "         -1.8530e-02, -1.0267e-03, -2.7011e-02, -6.2088e-02,  1.7138e-02,\n",
      "          1.2088e-01,  2.4982e-02, -4.6807e-02,  2.1986e-04, -1.5356e-01,\n",
      "         -1.1620e-01,  1.5713e-01,  4.8244e-02,  1.1946e-01, -4.6373e-02,\n",
      "         -7.4583e-02,  6.5560e-02,  5.5655e-02,  6.8778e-02, -1.5083e-01,\n",
      "         -1.5160e-03, -7.2101e-02,  5.5179e-02, -1.3120e-01,  5.0637e-02,\n",
      "          3.5456e-03,  5.1180e-02,  8.3819e-02,  1.2518e-01,  1.0228e-01,\n",
      "          6.2881e-02, -3.8155e-02, -1.0403e-01, -5.7290e-03, -3.2140e-02,\n",
      "         -1.7420e-01,  1.3819e-02,  5.4586e-03, -9.0341e-02, -4.5471e-02,\n",
      "         -9.6737e-02,  3.0643e-02,  9.7078e-02, -8.1534e-02,  6.8580e-02,\n",
      "          5.9180e-02,  1.2883e-01,  1.0620e-01, -1.3350e-01,  7.3327e-02,\n",
      "          4.0946e-02,  2.6232e-02, -5.4215e-02, -1.0101e-01, -1.3198e-01,\n",
      "         -1.0841e-01,  1.3443e-01, -3.4356e-02,  4.2721e-02,  7.9772e-02,\n",
      "          8.9587e-02, -1.1019e-01, -2.7112e-02,  2.6963e-02,  8.5439e-02,\n",
      "         -1.1265e-01,  2.2994e-02, -8.5754e-02,  6.1731e-03, -6.6999e-02,\n",
      "          2.6821e-02, -2.3330e-02,  8.0530e-02, -5.8606e-02,  6.4443e-02,\n",
      "          1.9550e-01, -9.7424e-03, -2.8956e-02],\n",
      "        [ 1.1440e-01, -2.2069e-02, -1.8590e-01,  5.1640e-02,  1.1617e-01,\n",
      "          2.5792e-02, -5.5914e-02,  1.1083e-01,  2.5133e-02, -2.7229e-02,\n",
      "          2.5438e-02, -4.0045e-02, -1.3676e-01, -1.3357e-01,  1.4117e-01,\n",
      "          9.9913e-02, -8.1880e-02, -7.2885e-02, -3.5196e-02, -1.1220e-02,\n",
      "          4.1412e-02,  1.6727e-02,  1.2330e-01, -1.3390e-01, -5.6243e-02,\n",
      "         -9.8963e-02,  5.7131e-02,  1.6444e-02,  8.3546e-02, -3.5944e-02,\n",
      "         -1.4318e-01, -6.1578e-02, -4.8783e-02,  9.2633e-02, -3.9862e-02,\n",
      "          5.1743e-02,  3.1544e-02, -2.2133e-01, -1.5115e-02, -8.3914e-02,\n",
      "          1.4371e-01, -9.8523e-04, -5.8997e-02, -9.5997e-02, -1.0444e-01,\n",
      "         -1.4644e-01, -1.3796e-01, -2.1462e-02,  8.7478e-02, -3.2413e-03,\n",
      "         -6.5633e-02,  1.1697e-01,  2.9827e-02,  2.1085e-02, -2.4708e-01,\n",
      "          2.2305e-02,  2.9972e-02,  2.1701e-02, -4.0910e-02, -4.1313e-02,\n",
      "          8.7743e-02,  1.1994e-01,  5.4049e-02, -1.0558e-02, -6.7955e-02,\n",
      "          1.0194e-01, -2.0416e-02, -7.9680e-02, -2.3785e-02,  1.3701e-01,\n",
      "          1.0333e-01, -2.3242e-02,  1.1159e-01,  7.0559e-02, -6.2284e-02,\n",
      "         -2.1503e-02,  5.8965e-02,  3.5518e-02, -7.0988e-02, -7.9340e-02,\n",
      "         -6.9069e-02, -8.0313e-02,  5.2735e-02, -1.4585e-01,  1.0940e-01,\n",
      "          1.2243e-01, -7.8691e-02, -1.1474e-01,  3.9167e-02,  9.3414e-02,\n",
      "          7.3087e-03,  4.3761e-02, -4.3180e-02,  7.5298e-02,  8.1208e-02,\n",
      "         -3.1732e-02, -1.5041e-01, -1.5961e-01,  1.7191e-01, -5.1653e-02,\n",
      "          1.7312e-02, -7.8929e-02,  1.2122e-01,  6.3384e-02,  3.4772e-02,\n",
      "         -1.2083e-02,  6.9363e-02, -7.0314e-02,  1.8182e-01,  1.1533e-02,\n",
      "          9.9835e-02, -1.1459e-01, -3.3184e-02,  2.5406e-02, -2.2354e-03,\n",
      "          2.3774e-01,  1.2041e-01, -3.6344e-02,  1.5863e-02, -2.7609e-02,\n",
      "         -8.5563e-03, -2.6877e-02,  6.9940e-02, -1.0624e-01,  1.5892e-03,\n",
      "          7.1401e-02,  8.1416e-02,  3.8629e-03],\n",
      "        [ 1.6530e-01, -1.5200e-02, -1.1961e-01, -9.0785e-02,  7.9685e-02,\n",
      "          8.0235e-03,  1.0555e-01,  1.5633e-01, -1.9447e-02, -7.0435e-03,\n",
      "          8.5600e-02, -1.3800e-01, -1.6232e-01, -1.2291e-01,  1.0800e-01,\n",
      "          1.1135e-01, -9.9540e-02, -5.6029e-02, -5.6041e-02, -3.5260e-02,\n",
      "         -6.1092e-03,  2.0145e-02,  1.2736e-01, -9.6602e-02, -2.5691e-02,\n",
      "         -1.9080e-01,  1.2299e-01, -8.0683e-02,  3.0783e-02, -4.1155e-02,\n",
      "         -8.5006e-02, -8.7214e-02, -5.8473e-02,  1.4570e-01,  9.9532e-03,\n",
      "          1.0848e-02,  1.4157e-01, -1.4208e-01, -1.1040e-01, -6.5987e-02,\n",
      "          9.8946e-02,  2.2925e-02, -1.0658e-01, -6.5125e-02, -5.2574e-03,\n",
      "         -1.3124e-01, -1.4594e-01, -1.1402e-02,  1.9080e-01, -1.0696e-02,\n",
      "         -1.2113e-02,  1.6316e-01,  2.3462e-02,  6.7493e-02, -1.8332e-01,\n",
      "         -1.1897e-03,  4.1196e-02, -4.5078e-02, -9.1611e-02,  3.1606e-03,\n",
      "          1.4179e-01,  3.5345e-02,  3.8572e-02, -6.1563e-02,  1.6743e-02,\n",
      "          2.3023e-02, -6.5269e-02, -5.1128e-02, -3.0009e-02,  1.3022e-01,\n",
      "          1.1073e-01,  3.2742e-02,  3.6806e-02,  1.2805e-01,  1.3182e-02,\n",
      "          1.4475e-02, -6.3391e-02,  1.2320e-03, -8.9892e-02, -9.7668e-02,\n",
      "         -7.7690e-02, -3.4819e-02,  5.6875e-02, -1.4405e-01,  1.2331e-01,\n",
      "          8.8396e-02, -6.4061e-02, -3.1541e-02, -2.5823e-02,  1.0507e-01,\n",
      "          8.2841e-02,  5.1231e-02, -1.1631e-02,  4.5527e-02,  8.0288e-02,\n",
      "         -1.0012e-02, -1.8497e-01, -6.7895e-02,  1.8016e-01,  3.5486e-02,\n",
      "          4.2070e-02, -1.8957e-02,  1.2733e-01,  2.3464e-02,  1.5026e-03,\n",
      "          2.9980e-02, -1.5290e-02, -1.5447e-01,  1.5873e-01, -3.3403e-02,\n",
      "          8.9232e-02, -6.1931e-02, -2.6192e-02, -1.0361e-01, -2.8898e-02,\n",
      "          1.2928e-01,  1.2872e-01,  1.5278e-02,  1.9114e-02,  2.6501e-02,\n",
      "         -8.7232e-02,  3.7991e-04, -3.2300e-03, -8.8933e-02, -1.6577e-03,\n",
      "          1.3938e-01, -4.7761e-02, -4.9260e-02]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 1.6983e-02,  2.4293e-02,  4.1526e-02, -9.8886e-02,  4.6548e-02,\n",
      "         -1.6836e-02,  1.1953e-01,  1.1905e-01, -1.6256e-01, -5.8325e-02,\n",
      "         -3.1436e-02, -9.1677e-02, -4.9146e-02, -2.4363e-02,  1.2109e-01,\n",
      "         -5.3443e-02, -3.1664e-02, -6.0240e-02, -1.3897e-01, -5.2010e-02,\n",
      "         -3.6805e-02,  2.2455e-01,  9.9367e-03, -3.1175e-02, -1.1669e-02,\n",
      "         -8.4720e-02,  1.8120e-02, -9.7016e-02,  1.7069e-01, -2.1504e-02,\n",
      "          6.6239e-02, -4.0829e-02, -1.1917e-01,  1.3002e-01,  1.0145e-01,\n",
      "          2.0811e-02,  5.8593e-02, -9.4569e-02,  7.0851e-03,  1.3544e-01,\n",
      "         -4.4254e-02, -9.8844e-02,  1.0304e-01,  1.0664e-01,  8.7588e-02,\n",
      "         -1.1512e-01, -1.3031e-01, -9.7189e-04,  1.3321e-01, -9.3097e-02,\n",
      "          9.8313e-02,  1.4949e-01,  7.9958e-02,  8.6279e-02, -1.4598e-01,\n",
      "          1.4383e-02,  2.2403e-02, -1.2443e-01, -1.2593e-01,  1.1551e-02,\n",
      "          4.3833e-02, -1.5636e-02, -1.3860e-03,  1.3123e-01, -1.2036e-01,\n",
      "         -6.0758e-05,  1.0763e-01,  1.6199e-02, -5.4175e-02,  1.1594e-01,\n",
      "          1.1334e-01, -3.2489e-02,  6.7286e-02,  5.3691e-02,  7.4283e-02,\n",
      "         -8.8603e-02, -1.8019e-01,  3.4902e-02, -6.5027e-02, -9.6981e-02,\n",
      "         -3.7566e-02,  3.8447e-02,  1.2061e-01, -1.4330e-01, -1.7251e-02,\n",
      "         -9.2145e-02, -5.1197e-02,  9.1737e-02, -1.5012e-01,  1.3484e-01,\n",
      "         -2.9551e-02,  3.0508e-02,  3.0554e-02, -1.4961e-01,  5.8587e-02,\n",
      "          1.1289e-01, -1.6698e-01, -6.6262e-03, -8.2456e-02,  1.3908e-01,\n",
      "          1.5993e-01, -1.5580e-02,  5.5751e-02, -5.7333e-02, -3.6169e-02,\n",
      "         -6.0691e-02, -7.8492e-02, -9.3702e-02,  1.2450e-01,  2.2863e-02,\n",
      "          8.2676e-02, -1.3814e-02,  8.9248e-02, -1.0593e-01, -2.2948e-02,\n",
      "          2.2353e-02, -6.5838e-03, -2.0294e-02, -1.0332e-02,  2.3993e-02,\n",
      "         -8.8549e-02,  4.4715e-02, -2.8380e-02, -1.1219e-01,  2.6336e-02,\n",
      "          1.7922e-01,  2.4301e-04, -6.4785e-02],\n",
      "        [-9.3071e-02,  1.2211e-01,  2.0761e-02, -4.5514e-02, -2.1015e-02,\n",
      "         -6.5496e-02,  8.4634e-02, -6.9639e-02, -1.9294e-01, -1.7358e-01,\n",
      "         -9.1089e-03,  5.5713e-03, -9.1567e-02,  1.4989e-01,  8.1106e-03,\n",
      "         -2.7015e-02,  1.0718e-01,  1.4878e-01,  4.5131e-03, -1.4591e-01,\n",
      "         -1.2930e-01,  1.4643e-01, -7.8614e-02,  2.2321e-02, -2.0322e-02,\n",
      "          3.8173e-02, -4.6918e-02, -9.6365e-02,  3.4819e-03,  1.1993e-02,\n",
      "          8.4260e-02,  6.6644e-02,  1.0508e-02, -4.5486e-02,  1.5293e-01,\n",
      "          9.9232e-02, -3.8297e-02,  2.3297e-01,  2.2186e-02, -2.1882e-03,\n",
      "         -1.2436e-01, -8.4367e-02,  5.0194e-02, -6.9826e-02,  4.3242e-02,\n",
      "          8.2799e-02,  5.7686e-02, -1.9116e-02, -1.3150e-01, -1.2502e-01,\n",
      "         -1.6528e-03,  4.4156e-02,  6.3734e-02, -7.7709e-02, -1.5040e-02,\n",
      "          4.4963e-02, -1.1590e-03, -1.1367e-01, -4.3491e-03, -8.0643e-02,\n",
      "          1.4401e-02, -1.2130e-02, -2.8864e-02,  1.4042e-01, -3.0025e-02,\n",
      "         -9.1750e-02,  1.2557e-01,  8.6105e-02, -2.1694e-04, -1.5774e-01,\n",
      "          4.4161e-03,  2.1969e-02,  8.0318e-02, -1.5306e-01,  6.3987e-02,\n",
      "         -3.5184e-02,  8.8426e-02,  2.0288e-01, -9.1637e-03,  1.6149e-01,\n",
      "         -2.1707e-02, -2.6317e-03, -7.6929e-02, -8.7301e-02,  2.0638e-02,\n",
      "         -1.3878e-01, -1.0511e-01, -2.2096e-02, -2.1983e-02, -1.2796e-01,\n",
      "         -4.7612e-02,  4.4417e-02,  8.7432e-02, -7.4741e-02, -1.9066e-02,\n",
      "          9.3788e-02,  1.3402e-01, -1.5158e-02, -8.9008e-02,  1.3210e-01,\n",
      "          6.8140e-02,  2.2179e-02,  7.9900e-03, -1.1286e-01, -1.0515e-01,\n",
      "         -2.8249e-02,  1.4587e-01, -2.2291e-02,  1.8304e-02,  1.4416e-01,\n",
      "          1.6041e-01, -1.6771e-01,  1.4698e-02, -1.0502e-02,  2.6746e-02,\n",
      "         -3.8206e-02,  9.6151e-02, -1.1064e-01,  1.0046e-03,  9.8385e-03,\n",
      "          1.3324e-01, -2.0013e-02, -3.2961e-03, -1.4744e-02, -2.3567e-02,\n",
      "          1.5437e-01, -1.2302e-01, -5.0548e-02],\n",
      "        [ 1.0211e-01,  6.6381e-02, -1.2824e-01, -9.4950e-02, -9.6983e-03,\n",
      "         -3.4801e-02,  3.0967e-02,  5.0700e-02, -1.7454e-02, -7.6362e-02,\n",
      "          9.4089e-02, -1.3861e-01, -2.0764e-01, -4.9396e-05,  9.1828e-02,\n",
      "          1.0287e-01,  2.1454e-02,  9.9198e-02,  5.9876e-03, -8.4635e-02,\n",
      "         -7.5325e-02,  1.4670e-01,  2.7547e-02, -5.3848e-02,  7.4197e-02,\n",
      "         -1.9799e-01, -4.1168e-02, -1.3001e-01,  1.6909e-01, -1.1439e-01,\n",
      "         -2.5718e-02, -8.0038e-02, -6.1225e-02,  5.0490e-02,  2.5477e-02,\n",
      "          6.3993e-02,  9.3103e-02, -1.2574e-01,  2.4071e-02,  4.3305e-03,\n",
      "         -6.2830e-02, -2.8978e-02, -5.2460e-02, -1.0168e-01, -8.0590e-02,\n",
      "         -9.6383e-03, -7.3423e-02,  2.6942e-02, -6.9116e-03, -2.9063e-02,\n",
      "         -4.8778e-03,  1.7572e-01,  5.1797e-02, -6.3800e-02, -1.9833e-01,\n",
      "         -6.8049e-02,  2.2140e-02, -4.3836e-02, -9.5010e-02, -1.1190e-02,\n",
      "          1.0560e-01, -7.0577e-02, -7.1169e-03,  5.8007e-02, -6.4621e-02,\n",
      "          1.2443e-02,  7.0754e-02,  6.0160e-02, -1.0046e-02,  7.3443e-02,\n",
      "          1.5416e-01,  2.5194e-02,  9.5497e-02,  3.6517e-02,  2.1391e-02,\n",
      "         -1.0313e-01,  1.0516e-01,  1.2172e-01, -1.3381e-01,  2.9103e-02,\n",
      "         -1.0752e-01, -3.6124e-02, -3.3235e-03, -1.7584e-01,  7.3418e-02,\n",
      "          5.5757e-02, -1.6815e-01, -3.5761e-03,  7.8172e-02, -5.2303e-02,\n",
      "          5.6410e-02,  5.6470e-02,  5.5637e-04,  1.1852e-02,  7.9173e-03,\n",
      "          5.3236e-04, -6.7498e-02, -1.4205e-01,  7.9103e-02,  7.8218e-02,\n",
      "          3.8934e-02,  1.9844e-02,  1.5860e-01,  5.9070e-03,  3.9389e-02,\n",
      "          7.1691e-02,  8.0091e-02, -1.0667e-01,  1.7649e-01,  7.4293e-02,\n",
      "          1.7758e-01, -1.6404e-01,  7.6194e-02, -4.6133e-02, -2.9044e-02,\n",
      "          1.5672e-01,  2.0585e-01, -5.4023e-02, -6.7971e-02,  7.7460e-02,\n",
      "          8.0428e-02, -4.6230e-04, -6.9953e-02, -3.2898e-02, -1.3573e-01,\n",
      "          5.3343e-02, -5.4634e-02, -5.5056e-02],\n",
      "        [ 1.4112e-01,  3.6351e-02, -1.7214e-01, -1.3146e-01, -2.2374e-02,\n",
      "          1.7154e-02,  4.5206e-02,  1.1246e-01, -4.1756e-02, -6.3174e-02,\n",
      "          1.8289e-01, -1.3052e-01, -2.3119e-01, -4.9699e-02,  5.0997e-02,\n",
      "          1.3638e-01, -3.1732e-02,  5.6221e-02, -2.4507e-02, -7.0842e-02,\n",
      "         -3.6117e-02,  1.0050e-01,  7.5015e-02, -1.0673e-01, -4.2987e-02,\n",
      "         -1.5451e-01,  3.9112e-02, -1.3738e-01,  1.0138e-01, -1.1771e-01,\n",
      "         -2.1335e-02, -1.0810e-01, -1.5735e-02,  1.1825e-01,  2.5935e-02,\n",
      "          8.6141e-02,  1.3599e-01, -5.5794e-02, -6.4067e-02, -4.7328e-02,\n",
      "         -3.8215e-02,  2.8485e-02, -9.9656e-02, -1.1615e-01, -4.4220e-02,\n",
      "         -6.0490e-02, -5.9082e-02,  2.1523e-02,  9.0743e-02,  3.5228e-03,\n",
      "         -4.2394e-02,  1.8823e-01,  9.1336e-02, -4.7193e-03, -1.6216e-01,\n",
      "         -2.6240e-02, -1.7058e-02, -4.6962e-02, -8.5410e-02, -1.1297e-02,\n",
      "          1.4356e-01, -5.4088e-02, -4.0361e-03, -1.3678e-02,  2.4933e-02,\n",
      "          8.3884e-03, -4.0660e-03,  5.3713e-02, -2.9788e-02,  1.0666e-01,\n",
      "          1.4094e-01,  6.6686e-02,  8.2034e-02,  1.0651e-01,  3.0027e-02,\n",
      "         -2.4675e-02,  2.9787e-02,  6.5880e-02, -1.0788e-01, -3.8074e-02,\n",
      "         -1.0134e-01,  1.9529e-02,  5.8040e-02, -7.7832e-02,  1.7171e-01,\n",
      "          4.9570e-02, -1.2428e-01, -4.4324e-02,  1.8951e-02, -1.5618e-02,\n",
      "          2.9065e-02,  8.8390e-02, -2.4580e-02,  5.7939e-02, -5.0922e-04,\n",
      "          5.7162e-02, -5.8701e-02, -6.3409e-02,  1.2909e-01,  9.6115e-02,\n",
      "          1.2883e-02,  9.1322e-03,  1.0516e-01,  9.0001e-03, -2.1741e-02,\n",
      "          4.6228e-02,  2.1855e-02, -1.6725e-01,  1.3781e-01, -5.7582e-02,\n",
      "          1.5710e-01, -1.6163e-01, -3.2320e-02, -8.4230e-02, -9.9594e-02,\n",
      "          1.3404e-01,  2.4310e-01, -7.0440e-02, -3.6175e-02,  1.1713e-01,\n",
      "         -1.4048e-02, -3.8369e-02, -2.4058e-02, -5.6190e-02, -6.5991e-02,\n",
      "          6.8855e-02, -1.3109e-01, -5.1793e-02]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[12.2929, -1.5020,  1.5263,  2.5989],\n",
      "        [ 1.0346,  9.9246, -2.6834, -4.0834],\n",
      "        [ 3.8635, -3.6512,  8.4108,  9.0360],\n",
      "        [ 7.0880, -3.3372,  8.8311, 11.4874]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([12.2929,  9.9246,  8.4108, 11.4874], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.2843, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[-1.5020,  1.5263,  2.5989],\n",
      "        [ 1.0346, -2.6834, -4.0834],\n",
      "        [ 3.8635, -3.6512,  9.0360],\n",
      "        [ 7.0880, -3.3372,  8.8311]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0941, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 7: 0.18918254971504211\n",
      "Epoch [2/10], Loss: 1.0060\n",
      "Batch 1/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0807, -0.1062, -0.0008,  ...,  0.0220,  0.1206,  0.0462],\n",
      "        [-0.1171, -0.0018,  0.0997,  ...,  0.0223,  0.1001,  0.0832],\n",
      "        [-0.0319, -0.0326,  0.1536,  ...,  0.1353,  0.0912, -0.0192],\n",
      "        ...,\n",
      "        [ 0.0058, -0.0682,  0.1230,  ...,  0.0838,  0.2117,  0.0091],\n",
      "        [ 0.0334, -0.0499,  0.0413,  ...,  0.1374,  0.0945, -0.0110],\n",
      "        [-0.1389, -0.0038,  0.0438,  ...,  0.0114,  0.3002,  0.0350]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1159,  0.0592, -0.1452,  ...,  0.0572, -0.1687, -0.0422],\n",
      "        [ 0.0351,  0.0884, -0.0302,  ...,  0.0308, -0.0367,  0.0370],\n",
      "        [-0.0309, -0.0087,  0.1176,  ...,  0.1183,  0.0621,  0.0048],\n",
      "        ...,\n",
      "        [ 0.0311, -0.0099,  0.0759,  ...,  0.1318,  0.1226, -0.0213],\n",
      "        [ 0.0977, -0.0192, -0.0268,  ...,  0.0985,  0.0536, -0.0157],\n",
      "        [ 0.0088,  0.0959, -0.0990,  ...,  0.0380,  0.0697, -0.0003]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 4.2951e-01,  9.9902e-01, -7.7175e-01, -1.0769e+00, -4.2082e+00,\n",
      "         -4.8455e+00, -1.9711e+00, -4.5126e+00,  1.8929e+00,  3.6394e+00,\n",
      "         -9.0014e-01,  6.5817e-03,  1.8867e+00,  1.7357e+00,  7.4713e-01,\n",
      "         -1.1961e+00],\n",
      "        [-4.7773e+00,  5.1483e+00, -3.5615e+00,  2.7346e+00,  1.6686e+00,\n",
      "          1.5584e+00, -2.3298e+00,  1.4963e+00, -2.8237e+00,  3.9947e+00,\n",
      "         -1.2481e-01, -1.5927e+00, -1.5763e+00, -2.7293e+00, -5.2778e+00,\n",
      "         -1.4808e+00],\n",
      "        [-7.5788e+00, -9.3930e+00,  1.2841e+01, -1.1260e+01, -5.0825e+00,\n",
      "         -8.5055e-01,  4.0435e+00, -8.2633e-01,  6.5300e+00, -2.0787e+00,\n",
      "         -1.0996e+01,  7.6636e+00,  1.0864e+01,  7.9933e+00,  9.0200e+00,\n",
      "         -6.6797e+00],\n",
      "        [ 2.9280e+00,  9.7893e+00, -1.0111e+01,  1.1314e+01,  8.7240e+00,\n",
      "          5.5900e+00, -6.1146e-01,  5.8713e+00, -8.4561e+00,  2.2968e+00,\n",
      "          7.4305e+00, -6.1349e+00, -8.4944e+00, -6.8314e+00, -1.0792e+01,\n",
      "          4.1074e+00],\n",
      "        [-5.6045e+00,  6.4012e-01, -1.3570e-01,  2.7819e+00,  9.5041e+00,\n",
      "          7.2848e+00,  4.9761e+00,  1.0265e+01, -8.4364e+00, -4.1677e+00,\n",
      "         -2.9884e+00, -2.3124e+00, -2.9518e+00, -4.8387e+00, -7.7932e+00,\n",
      "         -1.3213e+00],\n",
      "        [-5.7474e+00, -8.8591e-01,  4.5864e+00, -3.2613e-01,  5.9277e+00,\n",
      "          9.5673e+00,  6.3000e+00,  9.3372e+00, -2.3245e+00, -1.4779e+00,\n",
      "         -4.5322e+00,  3.1849e+00,  3.2824e+00,  5.3086e-01, -1.6808e+00,\n",
      "         -2.5145e+00],\n",
      "        [-7.3033e+00, -6.7766e+00,  9.2354e+00, -6.8152e+00, -5.5978e-01,\n",
      "          1.9935e+00,  7.8883e+00,  4.0182e+00,  1.5452e+00, -2.4121e+00,\n",
      "         -8.6740e+00,  5.1670e+00,  8.1251e+00,  4.4819e+00,  3.9007e+00,\n",
      "         -3.0324e+00],\n",
      "        [-6.3195e+00, -4.8904e-02,  1.7475e+00,  1.2600e+00,  7.7909e+00,\n",
      "          8.0526e+00,  5.7369e+00,  1.0315e+01, -5.7058e+00, -2.3353e+00,\n",
      "         -3.5476e+00,  1.8542e-01, -1.8331e-02, -2.7812e+00, -4.9254e+00,\n",
      "         -1.4239e+00],\n",
      "        [-3.4656e+00, -5.7188e+00,  1.0400e+01, -1.0489e+01, -1.0392e+01,\n",
      "         -3.9536e+00, -7.2593e-01, -6.8554e+00,  1.2432e+01,  4.5036e+00,\n",
      "         -6.4346e+00,  9.7602e+00,  1.2071e+01,  1.0876e+01,  1.2512e+01,\n",
      "         -4.5940e+00],\n",
      "        [-5.6833e+00,  2.7583e+00,  1.3322e+00, -2.0970e+00, -3.2831e+00,\n",
      "         -2.6704e-01, -1.8730e+00, -1.2707e+00,  3.8371e+00,  7.9828e+00,\n",
      "         -2.1870e+00,  4.2039e+00,  5.0794e+00,  3.2424e+00,  1.4203e+00,\n",
      "         -2.8637e+00],\n",
      "        [ 2.1950e+00,  1.0366e+01, -8.9213e+00,  8.9073e+00,  4.0172e+00,\n",
      "          1.7692e+00, -2.1157e+00,  2.0291e+00, -3.5546e+00,  6.4525e+00,\n",
      "          8.3255e+00, -2.3653e+00, -4.5698e+00, -4.3593e+00, -6.8833e+00,\n",
      "          6.0362e+00],\n",
      "        [-6.7198e+00, -5.7497e+00,  1.0976e+01, -9.6795e+00, -6.6123e+00,\n",
      "         -1.3622e+00,  2.1388e+00, -2.4338e+00,  8.7115e+00,  2.2826e+00,\n",
      "         -8.0844e+00,  9.7640e+00,  1.1361e+01,  9.0591e+00,  9.3216e+00,\n",
      "         -4.4973e+00],\n",
      "        [-7.6482e+00, -5.9380e+00,  1.0466e+01, -9.9914e+00, -6.6419e+00,\n",
      "         -1.7906e+00,  2.4210e+00, -2.1328e+00,  7.7595e+00,  2.4630e+00,\n",
      "         -8.9302e+00,  8.5776e+00,  1.1483e+01,  7.7838e+00,  8.3089e+00,\n",
      "         -5.1549e+00],\n",
      "        [-6.3486e+00, -5.7391e+00,  1.0710e+01, -9.8047e+00, -7.6769e+00,\n",
      "         -2.5295e+00,  1.6841e+00, -3.6384e+00,  9.0931e+00,  3.1338e+00,\n",
      "         -8.1593e+00,  9.0599e+00,  1.1390e+01,  9.9644e+00,  9.7678e+00,\n",
      "         -5.0598e+00],\n",
      "        [-4.0322e+00, -7.3354e+00,  1.2251e+01, -1.0949e+01, -8.5312e+00,\n",
      "         -2.7230e+00,  2.1522e+00, -4.4607e+00,  1.1218e+01,  2.0894e+00,\n",
      "         -7.3469e+00,  1.0017e+01,  1.2685e+01,  1.0957e+01,  1.2833e+01,\n",
      "         -3.7559e+00],\n",
      "        [-3.8192e+00,  1.4068e+00, -2.5682e-01,  1.7798e+00,  3.0220e+00,\n",
      "          1.7780e+00,  5.4313e+00,  4.7760e+00, -2.9875e+00,  7.3268e-01,\n",
      "          7.3695e-01,  1.1509e+00,  1.5045e+00, -1.1618e+00, -2.2479e+00,\n",
      "          5.0774e+00]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([ 0.4295,  5.1483, 12.8415, 11.3143,  9.5041,  9.5673,  7.8883, 10.3149,\n",
      "        12.4318,  7.9828,  8.3255,  9.7640, 11.4834,  9.9644, 12.8332,  5.0774],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(1.2081, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 9.9902e-01, -7.7175e-01, -1.0769e+00, -4.2082e+00, -4.8455e+00,\n",
      "         -1.9711e+00, -4.5126e+00,  1.8929e+00,  3.6394e+00, -9.0014e-01,\n",
      "          6.5817e-03,  1.8867e+00,  1.7357e+00,  7.4713e-01, -1.1961e+00],\n",
      "        [-4.7773e+00, -3.5615e+00,  2.7346e+00,  1.6686e+00,  1.5584e+00,\n",
      "         -2.3298e+00,  1.4963e+00, -2.8237e+00,  3.9947e+00, -1.2481e-01,\n",
      "         -1.5927e+00, -1.5763e+00, -2.7293e+00, -5.2778e+00, -1.4808e+00],\n",
      "        [-7.5788e+00, -9.3930e+00, -1.1260e+01, -5.0825e+00, -8.5055e-01,\n",
      "          4.0435e+00, -8.2633e-01,  6.5300e+00, -2.0787e+00, -1.0996e+01,\n",
      "          7.6636e+00,  1.0864e+01,  7.9933e+00,  9.0200e+00, -6.6797e+00],\n",
      "        [ 2.9280e+00,  9.7893e+00, -1.0111e+01,  8.7240e+00,  5.5900e+00,\n",
      "         -6.1146e-01,  5.8713e+00, -8.4561e+00,  2.2968e+00,  7.4305e+00,\n",
      "         -6.1349e+00, -8.4944e+00, -6.8314e+00, -1.0792e+01,  4.1074e+00],\n",
      "        [-5.6045e+00,  6.4012e-01, -1.3570e-01,  2.7819e+00,  7.2848e+00,\n",
      "          4.9761e+00,  1.0265e+01, -8.4364e+00, -4.1677e+00, -2.9884e+00,\n",
      "         -2.3124e+00, -2.9518e+00, -4.8387e+00, -7.7932e+00, -1.3213e+00],\n",
      "        [-5.7474e+00, -8.8591e-01,  4.5864e+00, -3.2613e-01,  5.9277e+00,\n",
      "          6.3000e+00,  9.3372e+00, -2.3245e+00, -1.4779e+00, -4.5322e+00,\n",
      "          3.1849e+00,  3.2824e+00,  5.3086e-01, -1.6808e+00, -2.5145e+00],\n",
      "        [-7.3033e+00, -6.7766e+00,  9.2354e+00, -6.8152e+00, -5.5978e-01,\n",
      "          1.9935e+00,  4.0182e+00,  1.5452e+00, -2.4121e+00, -8.6740e+00,\n",
      "          5.1670e+00,  8.1251e+00,  4.4819e+00,  3.9007e+00, -3.0324e+00],\n",
      "        [-6.3195e+00, -4.8904e-02,  1.7475e+00,  1.2600e+00,  7.7909e+00,\n",
      "          8.0526e+00,  5.7369e+00, -5.7058e+00, -2.3353e+00, -3.5476e+00,\n",
      "          1.8542e-01, -1.8331e-02, -2.7812e+00, -4.9254e+00, -1.4239e+00],\n",
      "        [-3.4656e+00, -5.7188e+00,  1.0400e+01, -1.0489e+01, -1.0392e+01,\n",
      "         -3.9536e+00, -7.2593e-01, -6.8554e+00,  4.5036e+00, -6.4346e+00,\n",
      "          9.7602e+00,  1.2071e+01,  1.0876e+01,  1.2512e+01, -4.5940e+00],\n",
      "        [-5.6833e+00,  2.7583e+00,  1.3322e+00, -2.0970e+00, -3.2831e+00,\n",
      "         -2.6704e-01, -1.8730e+00, -1.2707e+00,  3.8371e+00, -2.1870e+00,\n",
      "          4.2039e+00,  5.0794e+00,  3.2424e+00,  1.4203e+00, -2.8637e+00],\n",
      "        [ 2.1950e+00,  1.0366e+01, -8.9213e+00,  8.9073e+00,  4.0172e+00,\n",
      "          1.7692e+00, -2.1157e+00,  2.0291e+00, -3.5546e+00,  6.4525e+00,\n",
      "         -2.3653e+00, -4.5698e+00, -4.3593e+00, -6.8833e+00,  6.0362e+00],\n",
      "        [-6.7198e+00, -5.7497e+00,  1.0976e+01, -9.6795e+00, -6.6123e+00,\n",
      "         -1.3622e+00,  2.1388e+00, -2.4338e+00,  8.7115e+00,  2.2826e+00,\n",
      "         -8.0844e+00,  1.1361e+01,  9.0591e+00,  9.3216e+00, -4.4973e+00],\n",
      "        [-7.6482e+00, -5.9380e+00,  1.0466e+01, -9.9914e+00, -6.6419e+00,\n",
      "         -1.7906e+00,  2.4210e+00, -2.1328e+00,  7.7595e+00,  2.4630e+00,\n",
      "         -8.9302e+00,  8.5776e+00,  7.7838e+00,  8.3089e+00, -5.1549e+00],\n",
      "        [-6.3486e+00, -5.7391e+00,  1.0710e+01, -9.8047e+00, -7.6769e+00,\n",
      "         -2.5295e+00,  1.6841e+00, -3.6384e+00,  9.0931e+00,  3.1338e+00,\n",
      "         -8.1593e+00,  9.0599e+00,  1.1390e+01,  9.7678e+00, -5.0598e+00],\n",
      "        [-4.0322e+00, -7.3354e+00,  1.2251e+01, -1.0949e+01, -8.5312e+00,\n",
      "         -2.7230e+00,  2.1522e+00, -4.4607e+00,  1.1218e+01,  2.0894e+00,\n",
      "         -7.3469e+00,  1.0017e+01,  1.2685e+01,  1.0957e+01, -3.7559e+00],\n",
      "        [-3.8192e+00,  1.4068e+00, -2.5682e-01,  1.7798e+00,  3.0220e+00,\n",
      "          1.7780e+00,  5.4313e+00,  4.7760e+00, -2.9875e+00,  7.3268e-01,\n",
      "          7.3695e-01,  1.1509e+00,  1.5045e+00, -1.1618e+00, -2.2479e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0486, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.6284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 1: 0.6283621788024902\n",
      "Batch 2/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0366, -0.0594,  0.0741,  ...,  0.1043,  0.2258,  0.0100],\n",
      "        [-0.0492,  0.0272, -0.0287,  ..., -0.0948,  0.0847,  0.0353],\n",
      "        [-0.0113, -0.0452,  0.0817,  ...,  0.1534,  0.1849, -0.0338],\n",
      "        ...,\n",
      "        [ 0.0478, -0.1005,  0.0901,  ...,  0.0717,  0.1034, -0.0157],\n",
      "        [-0.0532,  0.0526, -0.0529,  ..., -0.0659,  0.0736,  0.0110],\n",
      "        [-0.0985,  0.0439,  0.0196,  ..., -0.0723,  0.0507,  0.0138]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0428, -0.0557,  0.0215,  ...,  0.1124,  0.1144, -0.0315],\n",
      "        [-0.0086,  0.0886, -0.0651,  ..., -0.0809,  0.0030, -0.0155],\n",
      "        [-0.0113, -0.0237,  0.0886,  ...,  0.1577,  0.1408, -0.0488],\n",
      "        ...,\n",
      "        [ 0.0612, -0.0516,  0.0484,  ...,  0.0821,  0.0568, -0.0049],\n",
      "        [-0.0106,  0.1016, -0.1043,  ..., -0.0122, -0.0532, -0.0124],\n",
      "        [-0.0798,  0.1083, -0.0042,  ..., -0.0588, -0.0213,  0.0107]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 11.7460,  -8.3960,  11.2408,  10.8633,  -3.3136,   2.3935,  11.1421,\n",
      "          -7.7328,  -2.0339,   3.8757,   3.9302,   3.3964,  -7.6135,  11.3609,\n",
      "          -8.9595,  -9.3842],\n",
      "        [ -9.5809,  12.5270, -10.3221,  -7.3647,   9.9898,   3.5737, -11.0428,\n",
      "           6.2496,   9.6457,  -3.1492, -10.0337,   3.5876,  11.9125,  -9.5232,\n",
      "          10.7870,  11.8077],\n",
      "        [ 10.9175, -11.4975,  13.3510,   8.6562,  -7.9349,   0.4723,  12.7767,\n",
      "          -5.2333,  -7.4617,   8.5673,   9.6786,   2.1286, -10.1974,  10.6446,\n",
      "         -11.5869, -10.7438],\n",
      "        [ 11.2430,  -7.1374,   9.4707,  12.6008,  -0.6470,   3.8180,  10.1666,\n",
      "          -9.5829,   1.3890,   0.6921,   2.0194,   2.2060,  -5.6519,  11.7375,\n",
      "          -7.5989,  -8.7685],\n",
      "        [ -3.6748,   8.3254,  -6.2338,  -0.4051,  11.0684,   6.9478,  -5.9825,\n",
      "           1.5921,  11.4673,  -3.7090,  -9.1651,   3.4676,   9.3589,  -3.4773,\n",
      "           7.2174,   7.1747],\n",
      "        [  0.2790,   1.4153,   1.8983,   1.2208,   2.8534,   8.8760,   1.1044,\n",
      "          -0.5272,   3.5179,   2.6456,  -2.7650,   6.7814,   2.7454,   3.2384,\n",
      "          -0.9568,   1.2856],\n",
      "        [ 11.7827, -11.2738,  13.1169,  10.9680,  -6.6205,   0.4659,  13.4946,\n",
      "          -8.1436,  -5.6536,   5.8405,   8.0349,   1.7482, -10.2890,  12.2596,\n",
      "         -11.9297, -11.4648],\n",
      "        [ -8.0358,   6.8783,  -5.4068,  -9.6891,   3.6289,   3.7402,  -6.8309,\n",
      "          12.0780,   1.3765,   6.7660,  -0.0661,   3.4062,   7.6619,  -9.2475,\n",
      "           6.7825,   9.7885],\n",
      "        [ -2.4456,   8.4454,  -5.6165,   0.7877,  11.4417,   6.0332,  -5.6411,\n",
      "           1.1141,  12.1954,  -3.5109,  -9.3451,   3.4444,   9.3688,  -3.1164,\n",
      "           7.3850,   7.0382],\n",
      "        [  2.8117,  -4.5734,   7.4158,  -0.2023,  -4.5670,   1.6618,   5.7022,\n",
      "           3.8575,  -5.6736,  12.6942,   7.5155,   4.9310,  -3.4151,   1.8528,\n",
      "          -5.4611,  -1.9217],\n",
      "        [  6.5268,  -9.8340,  10.7608,   3.7701,  -8.0656,   0.1569,  10.2769,\n",
      "          -0.0263,  -8.9531,  11.3098,  11.9157,   0.2655,  -8.0162,   6.2209,\n",
      "          -9.7322,  -7.0201],\n",
      "        [ -0.7955,   1.4949,   2.3872,  -0.8638,   0.3513,   4.0413,   1.0344,\n",
      "           0.2577,   0.6511,   4.5547,  -2.4006,   9.3237,   1.0803,   1.4689,\n",
      "          -2.0771,   0.9861],\n",
      "        [ -9.5404,  10.9317,  -8.7451,  -7.7437,   9.0282,   5.4058,  -9.7187,\n",
      "           7.7802,   8.1060,  -0.2717,  -7.3589,   4.0175,  11.8722,  -8.6240,\n",
      "           9.4365,  11.6614],\n",
      "        [ 11.0128, -10.8405,  12.0128,  10.6794,  -6.1383,   1.9648,  12.3698,\n",
      "          -9.3918,  -4.6081,   3.1627,   5.8022,   1.1449,  -9.4309,  12.9714,\n",
      "         -11.5502, -11.3229],\n",
      "        [ -9.9522,  12.6077, -10.8503,  -7.9734,  10.0451,   4.3581, -11.5451,\n",
      "           7.2049,   9.4804,  -3.1531,  -9.4745,   3.0367,  12.1540,  -9.8805,\n",
      "          11.5027,  12.1926],\n",
      "        [-10.1625,  11.2280,  -9.6798,  -9.0883,   8.2226,   4.6160, -10.6962,\n",
      "           8.8946,   7.2316,  -0.2281,  -7.0334,   2.8458,  11.7625, -10.0657,\n",
      "          10.1454,  12.2288]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([11.7460, 12.5270, 13.3510, 12.6008, 11.0684,  8.8760, 13.4946, 12.0780,\n",
      "        12.1954, 12.6942, 11.9157,  9.3237, 11.8722, 12.9714, 11.5027, 12.2288],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.6890, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ -8.3960,  11.2408,  10.8633,  -3.3136,   2.3935,  11.1421,  -7.7328,\n",
      "          -2.0339,   3.8757,   3.9302,   3.3964,  -7.6135,  11.3609,  -8.9595,\n",
      "          -9.3842],\n",
      "        [ -9.5809, -10.3221,  -7.3647,   9.9898,   3.5737, -11.0428,   6.2496,\n",
      "           9.6457,  -3.1492, -10.0337,   3.5876,  11.9125,  -9.5232,  10.7870,\n",
      "          11.8077],\n",
      "        [ 10.9175, -11.4975,   8.6562,  -7.9349,   0.4723,  12.7767,  -5.2333,\n",
      "          -7.4617,   8.5673,   9.6786,   2.1286, -10.1974,  10.6446, -11.5869,\n",
      "         -10.7438],\n",
      "        [ 11.2430,  -7.1374,   9.4707,  -0.6470,   3.8180,  10.1666,  -9.5829,\n",
      "           1.3890,   0.6921,   2.0194,   2.2060,  -5.6519,  11.7375,  -7.5989,\n",
      "          -8.7685],\n",
      "        [ -3.6748,   8.3254,  -6.2338,  -0.4051,   6.9478,  -5.9825,   1.5921,\n",
      "          11.4673,  -3.7090,  -9.1651,   3.4676,   9.3589,  -3.4773,   7.2174,\n",
      "           7.1747],\n",
      "        [  0.2790,   1.4153,   1.8983,   1.2208,   2.8534,   1.1044,  -0.5272,\n",
      "           3.5179,   2.6456,  -2.7650,   6.7814,   2.7454,   3.2384,  -0.9568,\n",
      "           1.2856],\n",
      "        [ 11.7827, -11.2738,  13.1169,  10.9680,  -6.6205,   0.4659,  -8.1436,\n",
      "          -5.6536,   5.8405,   8.0349,   1.7482, -10.2890,  12.2596, -11.9297,\n",
      "         -11.4648],\n",
      "        [ -8.0358,   6.8783,  -5.4068,  -9.6891,   3.6289,   3.7402,  -6.8309,\n",
      "           1.3765,   6.7660,  -0.0661,   3.4062,   7.6619,  -9.2475,   6.7825,\n",
      "           9.7885],\n",
      "        [ -2.4456,   8.4454,  -5.6165,   0.7877,  11.4417,   6.0332,  -5.6411,\n",
      "           1.1141,  -3.5109,  -9.3451,   3.4444,   9.3688,  -3.1164,   7.3850,\n",
      "           7.0382],\n",
      "        [  2.8117,  -4.5734,   7.4158,  -0.2023,  -4.5670,   1.6618,   5.7022,\n",
      "           3.8575,  -5.6736,   7.5155,   4.9310,  -3.4151,   1.8528,  -5.4611,\n",
      "          -1.9217],\n",
      "        [  6.5268,  -9.8340,  10.7608,   3.7701,  -8.0656,   0.1569,  10.2769,\n",
      "          -0.0263,  -8.9531,  11.3098,   0.2655,  -8.0162,   6.2209,  -9.7322,\n",
      "          -7.0201],\n",
      "        [ -0.7955,   1.4949,   2.3872,  -0.8638,   0.3513,   4.0413,   1.0344,\n",
      "           0.2577,   0.6511,   4.5547,  -2.4006,   1.0803,   1.4689,  -2.0771,\n",
      "           0.9861],\n",
      "        [ -9.5404,  10.9317,  -8.7451,  -7.7437,   9.0282,   5.4058,  -9.7187,\n",
      "           7.7802,   8.1060,  -0.2717,  -7.3589,   4.0175,  -8.6240,   9.4365,\n",
      "          11.6614],\n",
      "        [ 11.0128, -10.8405,  12.0128,  10.6794,  -6.1383,   1.9648,  12.3698,\n",
      "          -9.3918,  -4.6081,   3.1627,   5.8022,   1.1449,  -9.4309, -11.5502,\n",
      "         -11.3229],\n",
      "        [ -9.9522,  12.6077, -10.8503,  -7.9734,  10.0451,   4.3581, -11.5451,\n",
      "           7.2049,   9.4804,  -3.1531,  -9.4745,   3.0367,  12.1540,  -9.8805,\n",
      "          12.1926],\n",
      "        [-10.1625,  11.2280,  -9.6798,  -9.0883,   8.2226,   4.6160, -10.6962,\n",
      "           8.8946,   7.2316,  -0.2281,  -7.0334,   2.8458,  11.7625, -10.0657,\n",
      "          10.1454]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0337, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 2: 0.36131060123443604\n",
      "Batch 3/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.1173,  0.0085,  0.1376,  ..., -0.0012,  0.1892,  0.0471],\n",
      "        [-0.1808,  0.0055,  0.2020,  ...,  0.0880,  0.0253,  0.0150],\n",
      "        [-0.0858, -0.0231,  0.0959,  ...,  0.0979,  0.2315, -0.0704],\n",
      "        ...,\n",
      "        [ 0.1288, -0.0753, -0.0280,  ..., -0.0098,  0.1084,  0.0387],\n",
      "        [-0.1373,  0.0864,  0.0956,  ..., -0.0005,  0.0414,  0.0114],\n",
      "        [-0.0153,  0.0135, -0.0612,  ..., -0.1418,  0.1678,  0.0774]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.1406,  0.0198,  0.1442,  ...,  0.0889,  0.1511,  0.0259],\n",
      "        [-0.1115,  0.0166,  0.1174,  ...,  0.2453, -0.1021, -0.0042],\n",
      "        [-0.0377, -0.0117,  0.0206,  ...,  0.1448,  0.1077, -0.0030],\n",
      "        ...,\n",
      "        [ 0.1202, -0.0283,  0.0225,  ...,  0.0856,  0.0471,  0.0840],\n",
      "        [-0.2021,  0.1165,  0.0887,  ...,  0.0277, -0.0224,  0.0134],\n",
      "        [ 0.0153,  0.0569, -0.0604,  ..., -0.1159,  0.2008,  0.0959]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[  9.9844,   3.5188,   1.2052,  -1.7970,   2.7584,   0.5875,   1.1696,\n",
      "           8.6554,   1.4490,   2.2203,   6.5671,   5.5242,   4.0989,  -2.4882,\n",
      "           3.6240,   4.3684],\n",
      "        [  8.0326,  10.5674,   1.2472,  -6.8950,  -1.7034,   0.7067,   0.6679,\n",
      "           2.9761,  -0.2245,  -3.7364,   5.6592,  -2.7307,  -0.2308,  -5.4323,\n",
      "           7.4195,  -4.3251],\n",
      "        [ 10.2643,   3.9521,   6.3464,  -2.2654,  -0.7179,   1.6217,   3.2435,\n",
      "           6.0652,  -1.4175,   2.0753,   1.9553,   2.2649,   7.8636,  -1.3939,\n",
      "           0.6097,   1.3793],\n",
      "        [ -1.5642,  -6.3644,  -3.9465,   8.6443,   9.9329,  -7.1686,  -6.9722,\n",
      "          10.2905,   9.1103,  -0.6583,   8.7336,  11.0554,  -0.7429,  -2.0149,\n",
      "           4.2966,  10.6841],\n",
      "        [ -1.8726,  -5.3273,  -7.1817,   4.4235,  11.9900,  -8.8676,  -8.8107,\n",
      "          11.3367,  11.4251,  -2.2459,  11.3261,  10.7123,  -5.0192,  -5.3700,\n",
      "           6.8872,  10.5127],\n",
      "        [  9.7019,   4.3477,   7.7721,  -1.5877,  -7.5143,  11.7207,  11.7435,\n",
      "          -4.1033, -11.0554,   9.6486,  -7.3375,  -3.3655,   9.5452,   8.5851,\n",
      "          -7.5470,  -3.3911],\n",
      "        [ 10.6406,   4.9625,   9.7552,  -1.4888,  -7.2144,  12.3742,  12.9904,\n",
      "          -4.3928, -11.7718,  10.2056,  -8.1384,  -4.0344,   9.7190,   8.2663,\n",
      "          -7.4418,  -3.7739],\n",
      "        [  1.4127,  -3.7941,  -5.1131,   0.7382,   8.2416,  -8.1974,  -7.6878,\n",
      "          12.9083,   9.6847,  -2.9326,  10.2676,  10.0925,  -0.3227,  -6.0196,\n",
      "           5.2465,   9.3468],\n",
      "        [ -4.5186,  -5.0497,  -8.8192,   2.3734,  10.5776, -11.8943, -12.0715,\n",
      "          11.1870,  13.5504,  -7.1357,  12.0552,   9.5780,  -6.0711,  -8.4553,\n",
      "           8.6153,   8.9099],\n",
      "        [  7.6837,  -3.4037,   3.0882,   3.6839,   1.9684,   5.9925,   6.5901,\n",
      "           3.6156,  -3.6592,  11.4508,  -1.5928,   6.2862,   7.2559,   6.8757,\n",
      "          -6.2429,   6.8086],\n",
      "        [ -0.0200,  -0.9953,  -6.9685,   0.7599,   9.8877,  -9.7095,  -9.6374,\n",
      "          11.7967,  11.6150,  -5.8211,  13.2518,   8.7640,  -4.9039,  -8.6669,\n",
      "           9.9741,   7.7097],\n",
      "        [  1.0673,  -5.9402,  -5.9254,   1.9685,   8.2944,  -6.7999,  -6.7249,\n",
      "          12.2986,   9.1747,  -0.9624,   8.7870,  11.7383,   1.2380,  -3.8221,\n",
      "           3.0580,  10.8285],\n",
      "        [  7.1185,  -1.4388,   2.4672,  -0.9418,  -0.8711,   1.2359,   1.7537,\n",
      "           7.1730,  -0.4229,   2.9900,   0.8016,   6.1904,  10.3454,   1.3722,\n",
      "          -3.4086,   5.0022],\n",
      "        [  3.6508,  -5.2872,   3.3815,   4.0107,  -1.9012,   7.1138,   7.1905,\n",
      "          -0.6217,  -5.7172,  10.4573,  -6.4868,   3.3440,   9.0328,  11.5237,\n",
      "         -10.2343,   4.4819],\n",
      "        [  0.1729,   3.3701,  -5.6148,  -0.8957,   7.9415,  -8.8392,  -9.0420,\n",
      "           8.9917,  10.3952,  -8.4901,  13.1800,   4.2549,  -7.4067, -10.6593,\n",
      "          13.0662,   2.9345],\n",
      "        [  0.8202,  -7.3775,  -4.4672,   4.0634,   8.4039,  -6.0473,  -5.5527,\n",
      "          11.7314,   8.2026,   1.1670,   7.4639,  12.0305,   1.9695,  -1.8241,\n",
      "           1.4619,  11.9767]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([ 9.9844, 10.5674,  6.3464,  8.6443, 11.9900, 11.7207, 12.9904, 12.9083,\n",
      "        13.5504, 11.4508, 13.2518, 11.7383, 10.3454, 11.5237, 13.0662, 11.9767],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.9407, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  3.5188,   1.2052,  -1.7970,   2.7584,   0.5875,   1.1696,   8.6554,\n",
      "           1.4490,   2.2203,   6.5671,   5.5242,   4.0989,  -2.4882,   3.6240,\n",
      "           4.3684],\n",
      "        [  8.0326,   1.2472,  -6.8950,  -1.7034,   0.7067,   0.6679,   2.9761,\n",
      "          -0.2245,  -3.7364,   5.6592,  -2.7307,  -0.2308,  -5.4323,   7.4195,\n",
      "          -4.3251],\n",
      "        [ 10.2643,   3.9521,  -2.2654,  -0.7179,   1.6217,   3.2435,   6.0652,\n",
      "          -1.4175,   2.0753,   1.9553,   2.2649,   7.8636,  -1.3939,   0.6097,\n",
      "           1.3793],\n",
      "        [ -1.5642,  -6.3644,  -3.9465,   9.9329,  -7.1686,  -6.9722,  10.2905,\n",
      "           9.1103,  -0.6583,   8.7336,  11.0554,  -0.7429,  -2.0149,   4.2966,\n",
      "          10.6841],\n",
      "        [ -1.8726,  -5.3273,  -7.1817,   4.4235,  -8.8676,  -8.8107,  11.3367,\n",
      "          11.4251,  -2.2459,  11.3261,  10.7123,  -5.0192,  -5.3700,   6.8872,\n",
      "          10.5127],\n",
      "        [  9.7019,   4.3477,   7.7721,  -1.5877,  -7.5143,  11.7435,  -4.1033,\n",
      "         -11.0554,   9.6486,  -7.3375,  -3.3655,   9.5452,   8.5851,  -7.5470,\n",
      "          -3.3911],\n",
      "        [ 10.6406,   4.9625,   9.7552,  -1.4888,  -7.2144,  12.3742,  -4.3928,\n",
      "         -11.7718,  10.2056,  -8.1384,  -4.0344,   9.7190,   8.2663,  -7.4418,\n",
      "          -3.7739],\n",
      "        [  1.4127,  -3.7941,  -5.1131,   0.7382,   8.2416,  -8.1974,  -7.6878,\n",
      "           9.6847,  -2.9326,  10.2676,  10.0925,  -0.3227,  -6.0196,   5.2465,\n",
      "           9.3468],\n",
      "        [ -4.5186,  -5.0497,  -8.8192,   2.3734,  10.5776, -11.8943, -12.0715,\n",
      "          11.1870,  -7.1357,  12.0552,   9.5780,  -6.0711,  -8.4553,   8.6153,\n",
      "           8.9099],\n",
      "        [  7.6837,  -3.4037,   3.0882,   3.6839,   1.9684,   5.9925,   6.5901,\n",
      "           3.6156,  -3.6592,  -1.5928,   6.2862,   7.2559,   6.8757,  -6.2429,\n",
      "           6.8086],\n",
      "        [ -0.0200,  -0.9953,  -6.9685,   0.7599,   9.8877,  -9.7095,  -9.6374,\n",
      "          11.7967,  11.6150,  -5.8211,   8.7640,  -4.9039,  -8.6669,   9.9741,\n",
      "           7.7097],\n",
      "        [  1.0673,  -5.9402,  -5.9254,   1.9685,   8.2944,  -6.7999,  -6.7249,\n",
      "          12.2986,   9.1747,  -0.9624,   8.7870,   1.2380,  -3.8221,   3.0580,\n",
      "          10.8285],\n",
      "        [  7.1185,  -1.4388,   2.4672,  -0.9418,  -0.8711,   1.2359,   1.7537,\n",
      "           7.1730,  -0.4229,   2.9900,   0.8016,   6.1904,   1.3722,  -3.4086,\n",
      "           5.0022],\n",
      "        [  3.6508,  -5.2872,   3.3815,   4.0107,  -1.9012,   7.1138,   7.1905,\n",
      "          -0.6217,  -5.7172,  10.4573,  -6.4868,   3.3440,   9.0328, -10.2343,\n",
      "           4.4819],\n",
      "        [  0.1729,   3.3701,  -5.6148,  -0.8957,   7.9415,  -8.8392,  -9.0420,\n",
      "           8.9917,  10.3952,  -8.4901,  13.1800,   4.2549,  -7.4067, -10.6593,\n",
      "           2.9345],\n",
      "        [  0.8202,  -7.3775,  -4.4672,   4.0634,   8.4039,  -6.0473,  -5.5527,\n",
      "          11.7314,   8.2026,   1.1670,   7.4639,  12.0305,   1.9695,  -1.8241,\n",
      "           1.4619]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0398, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.4903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 3: 0.4902593195438385\n",
      "Batch 4/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0985,  0.0077, -0.1234,  ..., -0.1049, -0.0243,  0.0164],\n",
      "        [ 0.0100,  0.0217, -0.0334,  ..., -0.1245,  0.0909,  0.0380],\n",
      "        [-0.0102, -0.0445,  0.1310,  ...,  0.1451,  0.1055, -0.0416],\n",
      "        ...,\n",
      "        [-0.0014,  0.0485, -0.1008,  ..., -0.0994, -0.0055,  0.0068],\n",
      "        [-0.0475,  0.0495, -0.0668,  ..., -0.1092,  0.0418,  0.0234],\n",
      "        [-0.1262,  0.0829,  0.0389,  ..., -0.0414,  0.1733,  0.0469]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1799, -0.0112, -0.0872,  ...,  0.0173, -0.1784,  0.0570],\n",
      "        [-0.0384, -0.0105, -0.0209,  ..., -0.0996,  0.0315,  0.0464],\n",
      "        [-0.0411, -0.0243,  0.0882,  ...,  0.1307,  0.0910, -0.0193],\n",
      "        ...,\n",
      "        [-0.0256,  0.0603, -0.1098,  ..., -0.0815, -0.0459,  0.0037],\n",
      "        [-0.0817,  0.0543, -0.0327,  ..., -0.0571,  0.0143,  0.0244],\n",
      "        [-0.2060,  0.1069,  0.0598,  ..., -0.0311,  0.1361,  0.0628]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[  7.9883,   9.2059,  -9.4853,  10.4503,  11.1747,  10.7365,  -6.3773,\n",
      "          -8.5477,   2.3342,  11.6190,  -9.4957,  11.6104,  11.1313,  10.3597,\n",
      "           8.0937,   3.0236],\n",
      "        [  2.2577,  12.6928,  -8.7464,  10.1979,  12.0017,  10.3696,  -6.0397,\n",
      "          -7.6674,   0.9410,  10.2817,  -6.4945,  11.8873,  11.4266,  10.6600,\n",
      "          10.3925,   8.4913],\n",
      "        [ -6.1559,  -5.8726,  13.3591, -11.9742,  -8.5942,  -5.3052,  11.6646,\n",
      "          13.0470,   6.7873, -10.3951,  12.4472,  -4.9965,  -9.0966, -11.6638,\n",
      "         -10.8093,  -4.0618],\n",
      "        [  5.4597,  10.1472, -12.2158,  13.0509,  12.0017,   9.1317, -10.0819,\n",
      "         -11.4865,  -2.7557,  12.5283, -10.3276,  10.4752,  11.3606,  12.9818,\n",
      "          11.7876,   6.8427],\n",
      "        [  2.6673,  10.8957,  -9.5914,  10.1580,  13.4092,  10.8319,  -6.6480,\n",
      "          -9.1342,   0.8843,  11.8233,  -7.1610,  12.1926,  11.3827,  11.6528,\n",
      "          11.0472,   8.0892],\n",
      "        [  4.5886,  10.7380,  -7.5871,   8.1652,  11.5471,  13.2485,  -3.2709,\n",
      "          -6.6770,   5.4958,  10.0946,  -7.4975,  12.5378,  12.8959,   9.4827,\n",
      "           8.5462,   5.1349],\n",
      "        [ -2.7566,  -3.3030,  11.3011, -10.5496,  -5.1755,   0.8217,  13.0419,\n",
      "          11.7996,  11.4812,  -8.0614,   8.9509,  -0.8217,  -3.6876,  -9.7996,\n",
      "          -9.1832,  -4.3701],\n",
      "        [ -5.1990,  -2.9952,  11.4880, -10.1207,  -5.7398,  -2.2655,  10.7861,\n",
      "          12.1862,   8.6991,  -7.7695,  10.6950,  -1.5355,  -6.6010,  -9.8788,\n",
      "          -9.6353,  -3.9660],\n",
      "        [  2.1988,   4.2785,   3.4719,  -2.5769,   2.9723,   9.7932,   7.8254,\n",
      "           4.5953,  13.1239,   0.6154,   1.1238,   7.7528,   5.9283,  -1.4388,\n",
      "          -2.1023,  -1.5096],\n",
      "        [  4.4839,   9.9035, -10.8855,  11.1017,  12.4010,  10.0896,  -8.9907,\n",
      "         -10.6978,  -0.1176,  13.4256,  -9.0530,  11.5579,  10.9267,  12.5006,\n",
      "          10.6372,   5.8107],\n",
      "        [ -9.7741,  -3.5542,  11.3299, -10.2353,  -5.6383,  -6.1725,   8.8203,\n",
      "          10.9959,   3.5248,  -8.6034,  13.4165,  -4.2969,  -9.1234,  -8.9545,\n",
      "          -7.4825,   0.6318],\n",
      "        [  2.4343,  11.3315,  -7.1277,   7.8729,  12.2620,  11.5170,  -4.3034,\n",
      "          -6.4416,   4.2993,  10.8149,  -5.3040,  13.0633,  10.7692,   9.5710,\n",
      "           8.0447,   6.2813],\n",
      "        [  4.5133,  10.7592,  -8.9620,   9.5891,  12.0180,  12.7906,  -5.1485,\n",
      "          -8.3441,   3.7571,  11.3454,  -8.3188,  12.3988,  13.0320,  10.8857,\n",
      "           9.9755,   6.0532],\n",
      "        [  3.3163,  10.5325, -11.9642,  12.2552,  12.9718,   9.2795,  -9.9482,\n",
      "         -11.6568,  -2.6399,  12.8090,  -9.1172,  10.5849,  11.2643,  13.5275,\n",
      "          12.6665,   8.4984],\n",
      "        [  2.2705,  10.2157, -12.0209,  12.2191,  12.5703,   8.2686,  -9.7359,\n",
      "         -11.5813,  -4.0568,  11.5509,  -8.8185,   9.3104,  11.1445,  13.2855,\n",
      "          13.5923,   9.9122],\n",
      "        [ -4.1948,   9.4343,  -6.1265,   7.2127,  10.0661,   4.9179,  -4.6134,\n",
      "          -5.8928,  -3.4186,   5.9944,  -1.2432,   6.6105,   6.9248,   8.7733,\n",
      "          11.2260,  13.2472]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([ 7.9883, 12.6928, 13.3591, 13.0509, 13.4092, 13.2485, 13.0419, 12.1862,\n",
      "        13.1239, 13.4256, 13.4165, 13.0633, 13.0320, 13.5275, 13.5923, 13.2472],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(1.0189, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  9.2059,  -9.4853,  10.4503,  11.1747,  10.7365,  -6.3773,  -8.5477,\n",
      "           2.3342,  11.6190,  -9.4957,  11.6104,  11.1313,  10.3597,   8.0937,\n",
      "           3.0236],\n",
      "        [  2.2577,  -8.7464,  10.1979,  12.0017,  10.3696,  -6.0397,  -7.6674,\n",
      "           0.9410,  10.2817,  -6.4945,  11.8873,  11.4266,  10.6600,  10.3925,\n",
      "           8.4913],\n",
      "        [ -6.1559,  -5.8726, -11.9742,  -8.5942,  -5.3052,  11.6646,  13.0470,\n",
      "           6.7873, -10.3951,  12.4472,  -4.9965,  -9.0966, -11.6638, -10.8093,\n",
      "          -4.0618],\n",
      "        [  5.4597,  10.1472, -12.2158,  12.0017,   9.1317, -10.0819, -11.4865,\n",
      "          -2.7557,  12.5283, -10.3276,  10.4752,  11.3606,  12.9818,  11.7876,\n",
      "           6.8427],\n",
      "        [  2.6673,  10.8957,  -9.5914,  10.1580,  10.8319,  -6.6480,  -9.1342,\n",
      "           0.8843,  11.8233,  -7.1610,  12.1926,  11.3827,  11.6528,  11.0472,\n",
      "           8.0892],\n",
      "        [  4.5886,  10.7380,  -7.5871,   8.1652,  11.5471,  -3.2709,  -6.6770,\n",
      "           5.4958,  10.0946,  -7.4975,  12.5378,  12.8959,   9.4827,   8.5462,\n",
      "           5.1349],\n",
      "        [ -2.7566,  -3.3030,  11.3011, -10.5496,  -5.1755,   0.8217,  11.7996,\n",
      "          11.4812,  -8.0614,   8.9509,  -0.8217,  -3.6876,  -9.7996,  -9.1832,\n",
      "          -4.3701],\n",
      "        [ -5.1990,  -2.9952,  11.4880, -10.1207,  -5.7398,  -2.2655,  10.7861,\n",
      "           8.6991,  -7.7695,  10.6950,  -1.5355,  -6.6010,  -9.8788,  -9.6353,\n",
      "          -3.9660],\n",
      "        [  2.1988,   4.2785,   3.4719,  -2.5769,   2.9723,   9.7932,   7.8254,\n",
      "           4.5953,   0.6154,   1.1238,   7.7528,   5.9283,  -1.4388,  -2.1023,\n",
      "          -1.5096],\n",
      "        [  4.4839,   9.9035, -10.8855,  11.1017,  12.4010,  10.0896,  -8.9907,\n",
      "         -10.6978,  -0.1176,  -9.0530,  11.5579,  10.9267,  12.5006,  10.6372,\n",
      "           5.8107],\n",
      "        [ -9.7741,  -3.5542,  11.3299, -10.2353,  -5.6383,  -6.1725,   8.8203,\n",
      "          10.9959,   3.5248,  -8.6034,  -4.2969,  -9.1234,  -8.9545,  -7.4825,\n",
      "           0.6318],\n",
      "        [  2.4343,  11.3315,  -7.1277,   7.8729,  12.2620,  11.5170,  -4.3034,\n",
      "          -6.4416,   4.2993,  10.8149,  -5.3040,  10.7692,   9.5710,   8.0447,\n",
      "           6.2813],\n",
      "        [  4.5133,  10.7592,  -8.9620,   9.5891,  12.0180,  12.7906,  -5.1485,\n",
      "          -8.3441,   3.7571,  11.3454,  -8.3188,  12.3988,  10.8857,   9.9755,\n",
      "           6.0532],\n",
      "        [  3.3163,  10.5325, -11.9642,  12.2552,  12.9718,   9.2795,  -9.9482,\n",
      "         -11.6568,  -2.6399,  12.8090,  -9.1172,  10.5849,  11.2643,  12.6665,\n",
      "           8.4984],\n",
      "        [  2.2705,  10.2157, -12.0209,  12.2191,  12.5703,   8.2686,  -9.7359,\n",
      "         -11.5813,  -4.0568,  11.5509,  -8.8185,   9.3104,  11.1445,  13.2855,\n",
      "           9.9122],\n",
      "        [ -4.1948,   9.4343,  -6.1265,   7.2127,  10.0661,   4.9179,  -4.6134,\n",
      "          -5.8928,  -3.4186,   5.9944,  -1.2432,   6.6105,   6.9248,   8.7733,\n",
      "          11.2260]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0381, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.5285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 4: 0.528473973274231\n",
      "Batch 5/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0259,  0.0088, -0.0817,  ..., -0.0632,  0.1203,  0.0212],\n",
      "        [ 0.0516, -0.0583,  0.0810,  ...,  0.0173,  0.1317, -0.0006],\n",
      "        [-0.1062,  0.0460,  0.0821,  ...,  0.0762, -0.0406, -0.0330],\n",
      "        ...,\n",
      "        [-0.1752,  0.0599,  0.1195,  ...,  0.1068,  0.0275, -0.0328],\n",
      "        [ 0.0378,  0.0045, -0.1856,  ..., -0.0920,  0.0238, -0.0239],\n",
      "        [-0.0038,  0.0360, -0.1170,  ..., -0.1549,  0.1234, -0.0040]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0214,  0.0323, -0.0866,  ..., -0.0915,  0.1214,  0.0527],\n",
      "        [-0.0084, -0.0092,  0.1402,  ...,  0.0596,  0.1173,  0.0533],\n",
      "        [-0.1422,  0.0534,  0.1097,  ...,  0.0824, -0.0956, -0.0614],\n",
      "        ...,\n",
      "        [-0.2215,  0.0576,  0.1751,  ...,  0.1202, -0.0088,  0.0143],\n",
      "        [ 0.0294, -0.0111, -0.1242,  ..., -0.1098, -0.0174,  0.0180],\n",
      "        [-0.0209,  0.0368, -0.0688,  ..., -0.1434,  0.1483,  0.0411]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3184e+01,  2.2671e+00,  9.5634e-01,  2.6759e+00,  1.9194e+00,\n",
      "          3.2814e+00,  4.0529e+00,  8.1796e+00,  9.3723e-01,  3.4383e+00,\n",
      "          6.8960e+00,  2.7223e+00, -3.2163e+00, -1.7246e+00,  1.0857e+01,\n",
      "          8.8090e+00],\n",
      "        [ 6.4847e+00,  1.2964e+01, -1.9772e+00, -3.0656e+00, -9.0373e+00,\n",
      "         -9.4534e+00, -1.5265e+00, -5.5568e+00, -4.3285e+00, -3.7555e+00,\n",
      "         -7.7941e+00, -1.0667e+01, -4.3308e+00,  3.9294e-01, -2.8003e+00,\n",
      "         -3.5860e+00],\n",
      "        [ 4.4085e+00, -6.0966e-01,  1.2912e+01, -6.1074e-01, -2.1685e+00,\n",
      "          1.7525e+00,  1.1175e+01, -8.0728e-01,  9.9600e-01,  7.4361e+00,\n",
      "          4.0937e+00,  7.3936e-01,  6.8810e+00,  1.0642e+01,  2.9930e+00,\n",
      "         -4.9249e-01],\n",
      "        [ 6.4449e+00, -4.5379e+00, -7.7719e-01,  1.1732e+01,  1.0784e+01,\n",
      "          1.0909e+01,  5.4254e+00,  9.8859e+00,  1.0285e+01,  9.1527e+00,\n",
      "          8.4460e+00,  9.3275e+00,  3.1728e+00, -1.0784e+00,  8.5547e+00,\n",
      "          1.1857e+01],\n",
      "        [ 2.6930e+00, -1.0303e+01, -1.3677e+00,  8.0518e+00,  1.3168e+01,\n",
      "          1.2885e+01,  1.9727e+00,  1.2546e+01,  6.7498e+00,  5.6831e+00,\n",
      "          1.1677e+01,  1.3204e+01,  1.2783e+00, -4.4715e+00,  1.0288e+01,\n",
      "          1.1992e+01],\n",
      "        [ 4.5063e+00, -9.7725e+00,  1.1513e+00,  8.0032e+00,  1.2263e+01,\n",
      "          1.3040e+01,  4.5161e+00,  1.2470e+01,  6.9615e+00,  7.2205e+00,\n",
      "          1.2490e+01,  1.3011e+01,  2.5579e+00, -2.2037e+00,  1.1144e+01,\n",
      "          1.1981e+01],\n",
      "        [ 6.8541e+00, -9.5422e-01,  1.0008e+01,  4.7078e+00,  1.1970e+00,\n",
      "          4.6694e+00,  1.2901e+01,  2.0174e+00,  5.6753e+00,  1.1165e+01,\n",
      "          5.3368e+00,  2.9336e+00,  7.4429e+00,  9.4504e+00,  5.0939e+00,\n",
      "          3.8940e+00],\n",
      "        [ 6.4854e+00, -8.3227e+00, -1.9042e+00,  5.2229e+00,  1.0507e+01,\n",
      "          1.0587e+01,  9.6033e-01,  1.3764e+01,  3.7724e+00,  3.4214e+00,\n",
      "          1.2330e+01,  1.1564e+01, -3.0187e+00, -6.3468e+00,  1.2770e+01,\n",
      "          1.2501e+01],\n",
      "        [ 6.6760e+00, -3.1748e+00,  2.7418e+00,  1.0743e+01,  8.0949e+00,\n",
      "          8.8790e+00,  7.9119e+00,  7.4606e+00,  1.1409e+01,  9.7858e+00,\n",
      "          7.3667e+00,  7.9525e+00,  4.7714e+00,  1.8975e+00,  7.1041e+00,\n",
      "          1.0147e+01],\n",
      "        [ 4.2421e+00, -6.0701e+00,  6.1792e+00,  9.8294e+00,  8.4362e+00,\n",
      "          1.0511e+01,  1.1317e+01,  6.2644e+00,  1.0042e+01,  1.2812e+01,\n",
      "          8.4892e+00,  8.8884e+00,  8.6662e+00,  6.0460e+00,  6.5785e+00,\n",
      "          8.2415e+00],\n",
      "        [ 6.7951e+00, -8.8222e+00,  1.9136e+00,  4.8326e+00,  9.9818e+00,\n",
      "          1.1070e+01,  4.5675e+00,  1.2918e+01,  4.1342e+00,  6.1080e+00,\n",
      "          1.3524e+01,  1.1874e+01, -1.8921e-02, -3.0582e+00,  1.3064e+01,\n",
      "          1.2134e+01],\n",
      "        [ 2.7777e+00, -1.1410e+01,  1.1329e+00,  5.9760e+00,  1.1824e+01,\n",
      "          1.2604e+01,  2.9954e+00,  1.2390e+01,  5.8437e+00,  5.4613e+00,\n",
      "          1.3131e+01,  1.3554e+01,  1.2814e+00, -3.3997e+00,  1.0855e+01,\n",
      "          1.1048e+01],\n",
      "        [ 6.2520e-01, -1.8858e+00,  8.5718e+00,  8.2736e+00,  4.0296e+00,\n",
      "          6.2650e+00,  1.1795e+01, -1.1797e+00,  8.6604e+00,  1.2223e+01,\n",
      "          2.3746e+00,  3.6584e+00,  1.2884e+01,  1.0964e+01, -6.6593e-01,\n",
      "          1.5717e+00],\n",
      "        [ 2.2805e+00,  1.5364e+00,  1.1670e+01,  1.2250e+00, -3.0591e+00,\n",
      "          4.0205e-01,  1.1896e+01, -4.5140e+00,  2.4242e+00,  8.7854e+00,\n",
      "         -1.2126e-02, -1.6973e+00,  9.5859e+00,  1.3203e+01, -1.2754e+00,\n",
      "         -2.9309e+00],\n",
      "        [ 9.0454e+00, -6.2880e+00,  1.0671e+00,  3.0845e+00,  7.3673e+00,\n",
      "          8.6239e+00,  3.4912e+00,  1.2416e+01,  1.8986e+00,  4.1320e+00,\n",
      "          1.2115e+01,  9.3569e+00, -2.7426e+00, -4.0841e+00,  1.3580e+01,\n",
      "          1.1310e+01],\n",
      "        [ 7.7801e+00, -6.4758e+00, -1.3223e+00,  7.4231e+00,  1.0508e+01,\n",
      "          1.0376e+01,  2.9435e+00,  1.3174e+01,  6.2298e+00,  5.6176e+00,\n",
      "          1.1665e+01,  1.0871e+01, -1.4049e+00, -4.8958e+00,  1.2391e+01,\n",
      "          1.3552e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.1840, 12.9636, 12.9116, 11.7319, 13.1681, 13.0401, 12.9008, 13.7636,\n",
      "        11.4086, 12.8115, 13.5240, 13.5544, 12.8836, 13.2030, 13.5800, 13.5517],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.6939, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 2.2671e+00,  9.5634e-01,  2.6759e+00,  1.9194e+00,  3.2814e+00,\n",
      "          4.0529e+00,  8.1796e+00,  9.3723e-01,  3.4383e+00,  6.8960e+00,\n",
      "          2.7223e+00, -3.2163e+00, -1.7246e+00,  1.0857e+01,  8.8090e+00],\n",
      "        [ 6.4847e+00, -1.9772e+00, -3.0656e+00, -9.0373e+00, -9.4534e+00,\n",
      "         -1.5265e+00, -5.5568e+00, -4.3285e+00, -3.7555e+00, -7.7941e+00,\n",
      "         -1.0667e+01, -4.3308e+00,  3.9294e-01, -2.8003e+00, -3.5860e+00],\n",
      "        [ 4.4085e+00, -6.0966e-01, -6.1074e-01, -2.1685e+00,  1.7525e+00,\n",
      "          1.1175e+01, -8.0728e-01,  9.9600e-01,  7.4361e+00,  4.0937e+00,\n",
      "          7.3936e-01,  6.8810e+00,  1.0642e+01,  2.9930e+00, -4.9249e-01],\n",
      "        [ 6.4449e+00, -4.5379e+00, -7.7719e-01,  1.0784e+01,  1.0909e+01,\n",
      "          5.4254e+00,  9.8859e+00,  1.0285e+01,  9.1527e+00,  8.4460e+00,\n",
      "          9.3275e+00,  3.1728e+00, -1.0784e+00,  8.5547e+00,  1.1857e+01],\n",
      "        [ 2.6930e+00, -1.0303e+01, -1.3677e+00,  8.0518e+00,  1.2885e+01,\n",
      "          1.9727e+00,  1.2546e+01,  6.7498e+00,  5.6831e+00,  1.1677e+01,\n",
      "          1.3204e+01,  1.2783e+00, -4.4715e+00,  1.0288e+01,  1.1992e+01],\n",
      "        [ 4.5063e+00, -9.7725e+00,  1.1513e+00,  8.0032e+00,  1.2263e+01,\n",
      "          4.5161e+00,  1.2470e+01,  6.9615e+00,  7.2205e+00,  1.2490e+01,\n",
      "          1.3011e+01,  2.5579e+00, -2.2037e+00,  1.1144e+01,  1.1981e+01],\n",
      "        [ 6.8541e+00, -9.5422e-01,  1.0008e+01,  4.7078e+00,  1.1970e+00,\n",
      "          4.6694e+00,  2.0174e+00,  5.6753e+00,  1.1165e+01,  5.3368e+00,\n",
      "          2.9336e+00,  7.4429e+00,  9.4504e+00,  5.0939e+00,  3.8940e+00],\n",
      "        [ 6.4854e+00, -8.3227e+00, -1.9042e+00,  5.2229e+00,  1.0507e+01,\n",
      "          1.0587e+01,  9.6033e-01,  3.7724e+00,  3.4214e+00,  1.2330e+01,\n",
      "          1.1564e+01, -3.0187e+00, -6.3468e+00,  1.2770e+01,  1.2501e+01],\n",
      "        [ 6.6760e+00, -3.1748e+00,  2.7418e+00,  1.0743e+01,  8.0949e+00,\n",
      "          8.8790e+00,  7.9119e+00,  7.4606e+00,  9.7858e+00,  7.3667e+00,\n",
      "          7.9525e+00,  4.7714e+00,  1.8975e+00,  7.1041e+00,  1.0147e+01],\n",
      "        [ 4.2421e+00, -6.0701e+00,  6.1792e+00,  9.8294e+00,  8.4362e+00,\n",
      "          1.0511e+01,  1.1317e+01,  6.2644e+00,  1.0042e+01,  8.4892e+00,\n",
      "          8.8884e+00,  8.6662e+00,  6.0460e+00,  6.5785e+00,  8.2415e+00],\n",
      "        [ 6.7951e+00, -8.8222e+00,  1.9136e+00,  4.8326e+00,  9.9818e+00,\n",
      "          1.1070e+01,  4.5675e+00,  1.2918e+01,  4.1342e+00,  6.1080e+00,\n",
      "          1.1874e+01, -1.8921e-02, -3.0582e+00,  1.3064e+01,  1.2134e+01],\n",
      "        [ 2.7777e+00, -1.1410e+01,  1.1329e+00,  5.9760e+00,  1.1824e+01,\n",
      "          1.2604e+01,  2.9954e+00,  1.2390e+01,  5.8437e+00,  5.4613e+00,\n",
      "          1.3131e+01,  1.2814e+00, -3.3997e+00,  1.0855e+01,  1.1048e+01],\n",
      "        [ 6.2520e-01, -1.8858e+00,  8.5718e+00,  8.2736e+00,  4.0296e+00,\n",
      "          6.2650e+00,  1.1795e+01, -1.1797e+00,  8.6604e+00,  1.2223e+01,\n",
      "          2.3746e+00,  3.6584e+00,  1.0964e+01, -6.6593e-01,  1.5717e+00],\n",
      "        [ 2.2805e+00,  1.5364e+00,  1.1670e+01,  1.2250e+00, -3.0591e+00,\n",
      "          4.0205e-01,  1.1896e+01, -4.5140e+00,  2.4242e+00,  8.7854e+00,\n",
      "         -1.2126e-02, -1.6973e+00,  9.5859e+00, -1.2754e+00, -2.9309e+00],\n",
      "        [ 9.0454e+00, -6.2880e+00,  1.0671e+00,  3.0845e+00,  7.3673e+00,\n",
      "          8.6239e+00,  3.4912e+00,  1.2416e+01,  1.8986e+00,  4.1320e+00,\n",
      "          1.2115e+01,  9.3569e+00, -2.7426e+00, -4.0841e+00,  1.1310e+01],\n",
      "        [ 7.7801e+00, -6.4758e+00, -1.3223e+00,  7.4231e+00,  1.0508e+01,\n",
      "          1.0376e+01,  2.9435e+00,  1.3174e+01,  6.2298e+00,  5.6176e+00,\n",
      "          1.1665e+01,  1.0871e+01, -1.4049e+00, -4.8958e+00,  1.2391e+01]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0330, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.3635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 5: 0.3634803295135498\n",
      "Batch 6/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.0306, -0.0214,  0.1071,  ...,  0.1304,  0.1294, -0.0199],\n",
      "        [ 0.0078, -0.0213,  0.0968,  ...,  0.1137, -0.0115, -0.0565],\n",
      "        [ 0.0506, -0.0472, -0.0871,  ..., -0.0477,  0.1930, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0669, -0.0485, -0.0781,  ..., -0.0331,  0.0133, -0.0260],\n",
      "        [ 0.1402, -0.0426, -0.0341,  ...,  0.0070,  0.2085, -0.0039],\n",
      "        [ 0.1142, -0.0709, -0.0627,  ..., -0.0147,  0.0928,  0.0177]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0968, -0.0136,  0.1305,  ...,  0.1179,  0.0987, -0.0190],\n",
      "        [-0.0627, -0.0055,  0.1600,  ...,  0.1811, -0.0285,  0.0192],\n",
      "        [-0.0156, -0.0438, -0.0448,  ...,  0.0420,  0.2998, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0440, -0.0515, -0.0715,  ..., -0.0267, -0.0119,  0.0346],\n",
      "        [ 0.0538, -0.0726, -0.0030,  ...,  0.0195,  0.1855,  0.0163],\n",
      "        [ 0.1091, -0.0647, -0.0328,  ..., -0.0112,  0.0674,  0.0531]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.5430,  11.8102,   9.0675,   1.4654,  11.5291,   8.3675,  12.7618,\n",
      "          -1.5038,  -6.9376,   1.1682,   6.2279,  12.7860,  -8.2277,   7.2067,\n",
      "           8.4232,   7.0998],\n",
      "        [ 12.6066,  12.9215,   5.4532,   0.3497,  11.5803,   6.7742,  11.9423,\n",
      "          -3.3534,  -6.9792,   0.3514,   6.4016,  11.5376,  -9.6150,   7.0359,\n",
      "           6.1644,   6.0009],\n",
      "        [  3.3581,  -1.8928,  12.4352,  10.6085,   5.2788,  -0.7623,   5.9661,\n",
      "          11.1374,  -6.8142,  10.3884,   9.7022,   5.4949,   6.6079,   9.1659,\n",
      "           9.5762,   9.2343],\n",
      "        [ -0.0190,  -2.7480,   8.1321,  13.6130,   5.1635,  -6.3667,   4.3919,\n",
      "          12.6797,  -7.8707,  13.2843,  11.7199,   2.8447,   9.2056,  11.4535,\n",
      "           7.8080,  10.5437],\n",
      "        [  9.2722,   8.5995,   9.3541,   7.3489,  13.3700,   0.9623,   9.8333,\n",
      "           3.6202, -12.4430,   7.7472,  10.6550,  12.1839,  -2.4345,   9.8683,\n",
      "          11.7807,  11.8982],\n",
      "        [ 10.5421,   8.0118,   6.8318,  -4.7482,   5.1840,  12.7979,   7.8423,\n",
      "          -4.3634,   0.5897,  -5.2956,  -0.7118,   8.2208,  -8.4146,   0.0882,\n",
      "           3.5537,   0.2982],\n",
      "        [ 11.9907,   9.6266,  10.3285,   5.8788,  11.6763,   5.0992,  13.3563,\n",
      "           3.0173,  -8.3309,   5.4549,   9.8680,  11.7926,  -4.5309,  10.7230,\n",
      "           9.2287,   9.3730],\n",
      "        [ -3.5473,  -6.8386,   6.7132,  12.3558,   0.7849,  -7.7142,   1.0367,\n",
      "          13.6307,  -4.7210,  12.0889,   9.1410,  -0.8477,  11.4345,   8.7198,\n",
      "           5.0220,   7.0536],\n",
      "        [ -6.0594,  -6.1359,  -7.0536,  -6.7592, -11.7116,   2.6171,  -5.8407,\n",
      "          -2.5076,  13.5145,  -7.8682,  -8.2456, -10.0526,   0.9765,  -6.8054,\n",
      "         -11.7807, -11.2991],\n",
      "        [ -0.1672,  -2.3704,   7.7388,  13.3532,   5.7479,  -7.6598,   4.0364,\n",
      "          11.8606,  -9.3417,  13.6863,  12.2010,   3.1098,   8.5745,  11.1046,\n",
      "           8.1081,  10.6369],\n",
      "        [  2.9177,   1.1657,   8.1249,  11.7204,   8.0278,  -4.8952,   6.6770,\n",
      "           9.9066,  -9.8440,  12.2252,  13.7150,   5.4201,   4.7933,  12.3962,\n",
      "           7.8075,  10.3441],\n",
      "        [ 11.4421,   9.5390,  10.5685,   5.1537,  13.0459,   4.5629,  11.0611,\n",
      "           1.9465, -10.9129,   5.4291,   8.7267,  13.4281,  -4.4380,   8.4648,\n",
      "          11.7850,  10.7616],\n",
      "        [ -9.1622, -11.3282,   1.7201,   9.4664,  -5.0778,  -9.6404,  -5.3982,\n",
      "          11.5818,  -0.2989,   9.4458,   4.1226,  -6.6858,  13.7203,   3.2168,\n",
      "           0.4761,   2.7061],\n",
      "        [  4.5149,   2.1742,   8.8297,  12.1545,   8.1626,  -3.0599,   8.7506,\n",
      "          10.2710,  -8.5424,  11.7859,  13.3754,   6.0067,   4.4804,  13.6309,\n",
      "           7.7899,  10.7432],\n",
      "        [  5.3166,   2.3142,  11.5671,   9.3251,   9.9307,  -1.3505,   5.9111,\n",
      "           7.3558, -11.7442,   9.9324,   8.9278,   9.6413,   3.3822,   7.6617,\n",
      "          13.3086,  11.9633],\n",
      "        [  5.4062,   3.4651,  10.4117,  11.6841,  10.8542,  -2.9332,   7.7113,\n",
      "           8.8143, -12.0696,  11.8972,  12.0946,   9.1744,   3.7932,  11.4156,\n",
      "          12.1219,  13.3469]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.5430, 12.9215, 12.4352, 13.6130, 13.3700, 12.7979, 13.3563, 13.6307,\n",
      "        13.5145, 13.6863, 13.7150, 13.4281, 13.7203, 13.6309, 13.3086, 13.3469],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.5958, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 11.8102,   9.0675,   1.4654,  11.5291,   8.3675,  12.7618,  -1.5038,\n",
      "          -6.9376,   1.1682,   6.2279,  12.7860,  -8.2277,   7.2067,   8.4232,\n",
      "           7.0998],\n",
      "        [ 12.6066,   5.4532,   0.3497,  11.5803,   6.7742,  11.9423,  -3.3534,\n",
      "          -6.9792,   0.3514,   6.4016,  11.5376,  -9.6150,   7.0359,   6.1644,\n",
      "           6.0009],\n",
      "        [  3.3581,  -1.8928,  10.6085,   5.2788,  -0.7623,   5.9661,  11.1374,\n",
      "          -6.8142,  10.3884,   9.7022,   5.4949,   6.6079,   9.1659,   9.5762,\n",
      "           9.2343],\n",
      "        [ -0.0190,  -2.7480,   8.1321,   5.1635,  -6.3667,   4.3919,  12.6797,\n",
      "          -7.8707,  13.2843,  11.7199,   2.8447,   9.2056,  11.4535,   7.8080,\n",
      "          10.5437],\n",
      "        [  9.2722,   8.5995,   9.3541,   7.3489,   0.9623,   9.8333,   3.6202,\n",
      "         -12.4430,   7.7472,  10.6550,  12.1839,  -2.4345,   9.8683,  11.7807,\n",
      "          11.8982],\n",
      "        [ 10.5421,   8.0118,   6.8318,  -4.7482,   5.1840,   7.8423,  -4.3634,\n",
      "           0.5897,  -5.2956,  -0.7118,   8.2208,  -8.4146,   0.0882,   3.5537,\n",
      "           0.2982],\n",
      "        [ 11.9907,   9.6266,  10.3285,   5.8788,  11.6763,   5.0992,   3.0173,\n",
      "          -8.3309,   5.4549,   9.8680,  11.7926,  -4.5309,  10.7230,   9.2287,\n",
      "           9.3730],\n",
      "        [ -3.5473,  -6.8386,   6.7132,  12.3558,   0.7849,  -7.7142,   1.0367,\n",
      "          -4.7210,  12.0889,   9.1410,  -0.8477,  11.4345,   8.7198,   5.0220,\n",
      "           7.0536],\n",
      "        [ -6.0594,  -6.1359,  -7.0536,  -6.7592, -11.7116,   2.6171,  -5.8407,\n",
      "          -2.5076,  -7.8682,  -8.2456, -10.0526,   0.9765,  -6.8054, -11.7807,\n",
      "         -11.2991],\n",
      "        [ -0.1672,  -2.3704,   7.7388,  13.3532,   5.7479,  -7.6598,   4.0364,\n",
      "          11.8606,  -9.3417,  12.2010,   3.1098,   8.5745,  11.1046,   8.1081,\n",
      "          10.6369],\n",
      "        [  2.9177,   1.1657,   8.1249,  11.7204,   8.0278,  -4.8952,   6.6770,\n",
      "           9.9066,  -9.8440,  12.2252,   5.4201,   4.7933,  12.3962,   7.8075,\n",
      "          10.3441],\n",
      "        [ 11.4421,   9.5390,  10.5685,   5.1537,  13.0459,   4.5629,  11.0611,\n",
      "           1.9465, -10.9129,   5.4291,   8.7267,  -4.4380,   8.4648,  11.7850,\n",
      "          10.7616],\n",
      "        [ -9.1622, -11.3282,   1.7201,   9.4664,  -5.0778,  -9.6404,  -5.3982,\n",
      "          11.5818,  -0.2989,   9.4458,   4.1226,  -6.6858,   3.2168,   0.4761,\n",
      "           2.7061],\n",
      "        [  4.5149,   2.1742,   8.8297,  12.1545,   8.1626,  -3.0599,   8.7506,\n",
      "          10.2710,  -8.5424,  11.7859,  13.3754,   6.0067,   4.4804,   7.7899,\n",
      "          10.7432],\n",
      "        [  5.3166,   2.3142,  11.5671,   9.3251,   9.9307,  -1.3505,   5.9111,\n",
      "           7.3558, -11.7442,   9.9324,   8.9278,   9.6413,   3.3822,   7.6617,\n",
      "          11.9633],\n",
      "        [  5.4062,   3.4651,  10.4117,  11.6841,  10.8542,  -2.9332,   7.7113,\n",
      "           8.8143, -12.0696,  11.8972,  12.0946,   9.1744,   3.7932,  11.4156,\n",
      "          12.1219]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0308, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 6: 0.3133338689804077\n",
      "Batch 7/7: Matrix features: torch.Size([4, 128]), Vector features: torch.Size([4, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0663, -0.0341,  0.0581, -0.0588,  0.0228,  0.0334,  0.0838,  0.1020,\n",
      "         -0.1036, -0.0173, -0.0142, -0.1066, -0.0498, -0.0721,  0.1323, -0.1062,\n",
      "         -0.1039, -0.1100, -0.0954,  0.0072,  0.0754,  0.1448,  0.0269,  0.0013,\n",
      "          0.0887, -0.0104,  0.1015, -0.0135,  0.1319, -0.0625, -0.0372, -0.0609,\n",
      "         -0.0652,  0.1103,  0.0258, -0.0553,  0.0848, -0.2731, -0.0265,  0.1043,\n",
      "          0.0848, -0.0320,  0.0639,  0.1450,  0.0635, -0.1659, -0.1156,  0.0595,\n",
      "          0.1956, -0.0452,  0.1914,  0.0572,  0.0202,  0.1362, -0.1492,  0.0032,\n",
      "          0.0421,  0.0185, -0.1097,  0.0526,  0.1028, -0.0083,  0.0352,  0.0179,\n",
      "          0.0208,  0.0536,  0.0443, -0.0072,  0.0299,  0.0804,  0.0532,  0.0063,\n",
      "          0.0183,  0.1321,  0.0673, -0.0089, -0.1870, -0.1399, -0.0717, -0.1212,\n",
      "         -0.0485, -0.0063,  0.0582, -0.1283, -0.1430,  0.0163,  0.0381,  0.1148,\n",
      "         -0.1342,  0.1568,  0.0006, -0.0459, -0.0048, -0.1558,  0.0754, -0.0113,\n",
      "         -0.1973,  0.0486, -0.0297,  0.0482,  0.0830, -0.0474,  0.0362, -0.0204,\n",
      "          0.0199, -0.0409, -0.1222, -0.0362,  0.1001, -0.0108, -0.0839,  0.1493,\n",
      "          0.0265, -0.1838, -0.0010, -0.0212, -0.0770,  0.0527, -0.0118, -0.0733,\n",
      "         -0.1231,  0.0372, -0.0304, -0.1065,  0.1042,  0.0907,  0.0671,  0.0003],\n",
      "        [ 0.0431, -0.0443,  0.0602, -0.0657,  0.0407,  0.0066,  0.0482,  0.1420,\n",
      "         -0.0420,  0.0239, -0.0484, -0.0929, -0.0489, -0.0961,  0.1211, -0.0771,\n",
      "         -0.1134, -0.1283, -0.1233,  0.0815,  0.0620,  0.1169,  0.0288,  0.0262,\n",
      "          0.0750, -0.0559,  0.0821, -0.0464,  0.1760, -0.0837, -0.0063, -0.1001,\n",
      "         -0.1029,  0.1150, -0.0202, -0.0812,  0.0635, -0.2362,  0.0258,  0.0839,\n",
      "          0.0879, -0.0757,  0.0659,  0.1509,  0.0434, -0.1511, -0.1050,  0.0222,\n",
      "          0.1784, -0.0490,  0.1426,  0.0512,  0.0164,  0.1292, -0.1358,  0.0004,\n",
      "          0.0375, -0.0246, -0.1133,  0.0314,  0.0561, -0.0087,  0.0217,  0.0398,\n",
      "         -0.0642,  0.0750,  0.0397, -0.0063,  0.0137,  0.1182,  0.0490, -0.0110,\n",
      "          0.0107,  0.0882,  0.0595, -0.0335, -0.1721, -0.1045, -0.0954, -0.1298,\n",
      "         -0.0305, -0.0016,  0.1199, -0.1012, -0.0988, -0.0102,  0.0278,  0.1288,\n",
      "         -0.1682,  0.2200,  0.0243, -0.0479, -0.0199, -0.0979,  0.0831,  0.0056,\n",
      "         -0.1904, -0.0031, -0.0071,  0.0482,  0.1527, -0.0379,  0.0621, -0.0357,\n",
      "          0.0253, -0.0532, -0.1481, -0.0518,  0.1254, -0.0087, -0.0256,  0.1327,\n",
      "          0.0541, -0.1571, -0.0286,  0.0253, -0.0860,  0.0670, -0.0074, -0.0427,\n",
      "         -0.1174,  0.0595, -0.0107, -0.1287,  0.0795,  0.0876,  0.1261, -0.0060],\n",
      "        [-0.0226, -0.0144,  0.0365, -0.0087,  0.0502, -0.1270, -0.0185,  0.0665,\n",
      "         -0.0229, -0.0074, -0.0832, -0.0928, -0.0140, -0.0054,  0.1087, -0.1165,\n",
      "         -0.0257, -0.0067,  0.0114, -0.0145, -0.0159,  0.1528, -0.0447,  0.0803,\n",
      "          0.2094, -0.0692,  0.0414, -0.0479,  0.2633, -0.0723, -0.0106,  0.0597,\n",
      "         -0.1171, -0.0804, -0.0131,  0.0054, -0.0810, -0.2064,  0.1002,  0.0297,\n",
      "         -0.0044, -0.1476,  0.1556,  0.1781,  0.0535, -0.0427, -0.1556,  0.0394,\n",
      "          0.1174,  0.0085,  0.0810,  0.0837, -0.0103, -0.0478, -0.1533,  0.0769,\n",
      "          0.0241, -0.0329, -0.1265,  0.0239,  0.0758, -0.0231,  0.0258,  0.0853,\n",
      "         -0.1887,  0.1107,  0.0827,  0.0053,  0.0651,  0.0263,  0.0493, -0.0327,\n",
      "          0.0375, -0.0704,  0.0361, -0.0566, -0.0476,  0.0446, -0.1249, -0.0407,\n",
      "         -0.0657,  0.0121,  0.0782, -0.1775, -0.2034, -0.0217, -0.0276,  0.1093,\n",
      "         -0.0426,  0.1103, -0.0325, -0.0323,  0.0348, -0.0699,  0.0717,  0.0082,\n",
      "         -0.1304, -0.1163, -0.1110, -0.0064,  0.1657, -0.0482,  0.0586, -0.0396,\n",
      "          0.0236, -0.0547, -0.0530,  0.0171,  0.1153,  0.1436, -0.0110,  0.1179,\n",
      "          0.1432, -0.1191,  0.1427,  0.0313, -0.0656,  0.0257, -0.0509, -0.1122,\n",
      "          0.0318,  0.0575,  0.0020, -0.0519, -0.0761,  0.0580,  0.1888, -0.0931],\n",
      "        [-0.1067,  0.0116,  0.1846, -0.0168, -0.0115, -0.0252,  0.0868,  0.0026,\n",
      "         -0.2176, -0.1022, -0.1163, -0.0087, -0.0096,  0.0677, -0.0153, -0.2116,\n",
      "          0.0126, -0.0175, -0.0592, -0.0126,  0.0011,  0.2063, -0.0375,  0.0667,\n",
      "          0.0281,  0.0808,  0.0302, -0.0514,  0.0886,  0.0136,  0.0854,  0.0368,\n",
      "         -0.0758, -0.0379,  0.0894,  0.0089, -0.0372, -0.0308,  0.0163,  0.0856,\n",
      "          0.0288, -0.1248,  0.1747,  0.1832,  0.0965, -0.0515, -0.0684,  0.0266,\n",
      "          0.0422, -0.0746,  0.1781,  0.0384,  0.0266,  0.1000, -0.0028,  0.1094,\n",
      "          0.0322, -0.0495, -0.0887, -0.0211, -0.0084,  0.0274,  0.0254,  0.1247,\n",
      "         -0.0568, -0.0413,  0.1225,  0.0702,  0.0422, -0.0728,  0.0241, -0.0209,\n",
      "          0.0086, -0.0379,  0.0831, -0.0447, -0.1505, -0.0239, -0.0005, -0.0120,\n",
      "          0.0131,  0.0384,  0.0432, -0.0613, -0.1781, -0.1341,  0.0639,  0.1718,\n",
      "         -0.1938,  0.1154, -0.0832, -0.0547,  0.0666, -0.1784,  0.0756,  0.0564,\n",
      "         -0.0426,  0.0927, -0.1939,  0.1102,  0.1613, -0.0053, -0.0440, -0.0988,\n",
      "         -0.0945, -0.1221, -0.0407, -0.0192,  0.0379,  0.0449, -0.0450,  0.1081,\n",
      "          0.0565, -0.1209,  0.0451, -0.1669, -0.1456,  0.0092, -0.0071, -0.0600,\n",
      "         -0.0708,  0.0217,  0.0076, -0.0887,  0.1058,  0.1451,  0.0738, -0.0411]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-9.9367e-03, -6.1783e-02,  5.8614e-02, -4.2819e-02,  2.2549e-02,\n",
      "          2.5249e-02,  6.3445e-02,  6.8575e-02, -7.8302e-02,  9.8159e-03,\n",
      "         -2.9078e-02, -6.2880e-02,  3.9419e-03, -4.0713e-02,  5.3163e-02,\n",
      "         -1.3521e-01, -9.6355e-02, -9.8340e-02, -1.0518e-01,  3.7528e-03,\n",
      "          2.8471e-02,  1.7328e-01,  2.7831e-02,  9.9580e-03,  5.3854e-02,\n",
      "          6.1653e-03,  4.7382e-02, -3.1874e-02,  9.4431e-02, -3.8039e-02,\n",
      "         -3.2450e-02, -1.8968e-02, -7.3547e-02,  8.9637e-02,  4.7407e-02,\n",
      "         -4.6719e-02,  8.2005e-02, -2.4085e-01,  2.2249e-02,  1.4311e-01,\n",
      "          3.5416e-02, -7.4173e-02,  7.1269e-02,  1.9137e-01,  7.9457e-02,\n",
      "         -1.4098e-01, -9.9639e-02,  4.5918e-02,  1.7214e-01, -6.7602e-02,\n",
      "          2.1919e-01,  4.8581e-02,  6.0309e-02,  1.8452e-01, -1.0218e-01,\n",
      "         -3.4245e-03,  4.6650e-02, -1.4662e-02, -7.9031e-02,  2.4497e-02,\n",
      "         -9.9672e-03,  2.4016e-02,  4.9928e-02,  7.7410e-02, -8.6795e-03,\n",
      "          3.5262e-02,  5.2229e-02, -2.2773e-02,  1.4952e-03,  1.1404e-01,\n",
      "          5.3462e-02, -4.2694e-02,  4.5499e-02,  1.0424e-01,  3.8119e-02,\n",
      "         -2.5136e-02, -2.2631e-01, -1.1483e-01, -3.2609e-02, -1.1815e-01,\n",
      "         -1.5419e-02,  1.6186e-03,  9.2285e-02, -5.2299e-02, -1.2516e-01,\n",
      "         -4.4637e-02,  3.8830e-02,  1.3486e-01, -1.6671e-01,  1.9696e-01,\n",
      "         -8.4031e-03, -4.3211e-02,  1.6639e-02, -2.1820e-01,  7.5204e-02,\n",
      "         -1.7648e-02, -2.3323e-01,  6.9536e-02, -7.3744e-02,  7.7726e-02,\n",
      "          9.5332e-02, -6.0874e-02,  3.2567e-02, -2.3292e-02,  2.7722e-02,\n",
      "         -8.5822e-02, -8.2084e-02, -5.0718e-02,  1.0493e-01, -3.5987e-02,\n",
      "         -6.0278e-02,  1.2524e-01,  4.9778e-02, -1.4819e-01, -2.2906e-02,\n",
      "         -5.3006e-02, -8.0358e-02,  6.5795e-02,  2.6013e-03, -5.1955e-02,\n",
      "         -1.6466e-01,  6.3468e-02, -1.1223e-02, -1.0473e-01,  6.4413e-02,\n",
      "          1.0797e-01,  5.3952e-02,  4.1128e-02],\n",
      "        [ 1.0483e-02, -6.6548e-02,  5.7646e-02,  1.2006e-02,  4.0948e-02,\n",
      "          4.3973e-02,  9.8134e-03,  1.2799e-01, -2.3665e-02,  6.1832e-02,\n",
      "         -1.9490e-02, -8.5902e-02, -2.4883e-02, -1.4450e-01,  1.0835e-01,\n",
      "         -8.2943e-02, -1.3104e-01, -1.4912e-01, -1.0544e-01,  5.2871e-02,\n",
      "          4.7489e-02,  9.4058e-02,  6.9970e-02,  3.8220e-02,  1.3350e-02,\n",
      "         -1.9081e-02,  7.6573e-02, -5.1143e-02,  1.6315e-01, -8.9531e-02,\n",
      "          4.0972e-04, -1.0003e-01, -1.3673e-01,  1.4176e-01, -3.6372e-02,\n",
      "         -1.2397e-01,  5.8983e-02, -1.9410e-01,  5.1646e-02,  1.6101e-01,\n",
      "          5.8009e-02, -6.6308e-02,  6.4968e-02,  1.3131e-01,  1.8108e-02,\n",
      "         -1.6798e-01, -1.0968e-01,  1.3627e-02,  1.6000e-01, -3.0669e-02,\n",
      "          2.0859e-01,  3.6456e-02,  4.0217e-02,  1.7975e-01, -1.5799e-01,\n",
      "         -1.4958e-02,  4.3883e-02, -3.0599e-02, -4.9080e-02,  6.0485e-02,\n",
      "         -1.4193e-02,  2.0833e-02,  2.2873e-03,  3.3277e-02, -8.5942e-02,\n",
      "          3.5049e-02,  2.2484e-02, -5.0169e-02, -6.4549e-02,  1.7405e-01,\n",
      "          3.2574e-02, -8.6588e-02,  3.0268e-02,  8.6898e-02,  4.2805e-02,\n",
      "         -6.1954e-02, -1.5669e-01, -8.6018e-02, -7.5073e-02, -9.1184e-02,\n",
      "         -7.0601e-03,  1.3026e-02,  1.3567e-01, -1.1558e-01, -8.8665e-02,\n",
      "         -8.5230e-02,  1.0990e-02,  1.0479e-01, -1.6406e-01,  1.4062e-01,\n",
      "          3.8970e-03, -3.7249e-02, -6.6632e-02, -1.0004e-01,  8.0468e-02,\n",
      "          3.0599e-02, -2.4356e-01,  9.1980e-03,  1.2829e-03,  2.1561e-02,\n",
      "          1.0841e-01, -4.5225e-02,  6.6820e-02, -1.5031e-03,  5.8144e-02,\n",
      "         -6.3002e-02, -1.2651e-01, -1.8222e-02,  1.2848e-01, -5.4240e-02,\n",
      "         -1.3334e-02,  1.3543e-01,  9.8389e-02, -5.5448e-02, -2.0677e-02,\n",
      "          5.4032e-02, -8.5535e-02,  5.9157e-02, -3.0829e-02, -9.2008e-03,\n",
      "         -7.7759e-02,  8.3317e-02,  1.3614e-02, -9.4258e-02,  1.0163e-01,\n",
      "          6.3516e-02,  1.0807e-01,  1.0772e-02],\n",
      "        [-9.2660e-02, -3.3317e-02,  7.0893e-02,  3.9882e-02,  4.0160e-02,\n",
      "         -7.7304e-02, -2.7144e-02,  3.3278e-02, -5.8134e-02, -9.0088e-03,\n",
      "         -9.9237e-02, -8.9954e-02, -7.3368e-03,  3.6815e-02,  6.9943e-02,\n",
      "         -7.8747e-02,  2.9702e-03, -8.0169e-02, -2.6128e-02, -9.2259e-03,\n",
      "         -6.0615e-02,  1.4617e-01, -1.1023e-01,  2.0189e-02,  1.0811e-01,\n",
      "          5.7261e-04,  2.5545e-02, -3.3659e-02,  2.3507e-01, -3.5124e-02,\n",
      "          4.1599e-02,  5.6536e-02, -1.5447e-01, -6.0720e-02, -1.3362e-02,\n",
      "         -4.1156e-02, -1.2142e-01, -1.7659e-01,  1.1862e-01,  1.4309e-01,\n",
      "         -5.2900e-02, -1.4202e-01,  2.0938e-01,  2.3211e-01,  2.0197e-02,\n",
      "         -2.2895e-02, -1.1979e-01,  6.1698e-02,  6.6733e-02,  1.9582e-02,\n",
      "          7.2322e-02,  3.3619e-02, -1.3013e-02, -1.0437e-02, -8.8594e-02,\n",
      "          6.8933e-02,  1.9074e-02, -3.2127e-02, -9.9849e-02, -5.6999e-02,\n",
      "          1.3808e-02,  9.1748e-03,  1.4396e-02,  1.9336e-01, -2.5135e-01,\n",
      "          6.8347e-02,  7.0796e-02,  2.2712e-02,  3.6618e-02,  3.3657e-02,\n",
      "          4.6757e-02, -1.8726e-02,  2.6463e-02, -5.8711e-02,  5.4237e-02,\n",
      "         -4.4915e-02, -6.7145e-02,  6.2692e-02, -1.2549e-01, -5.2776e-02,\n",
      "         -4.6807e-04,  1.1352e-01,  9.7879e-02, -1.0937e-01, -1.3911e-01,\n",
      "         -7.3364e-02, -1.3851e-02,  1.7010e-01, -5.4998e-02,  1.3039e-01,\n",
      "         -1.1521e-01, -2.8577e-02, -7.6461e-03, -7.6037e-02,  3.3452e-02,\n",
      "          7.8704e-03, -1.1995e-01, -4.4558e-02, -1.8376e-01,  4.1065e-03,\n",
      "          2.1737e-01, -1.4490e-02,  3.1534e-02, -2.8873e-02,  8.1575e-03,\n",
      "         -7.1778e-02, -6.4419e-02, -1.1988e-02,  5.7434e-02,  1.2892e-01,\n",
      "          1.9089e-03,  1.0137e-01,  1.7135e-01, -8.4975e-02,  7.4949e-02,\n",
      "          1.6611e-02, -1.0441e-01,  1.1966e-02, -3.6619e-02, -5.8334e-02,\n",
      "         -2.5429e-02,  2.6478e-02,  4.3223e-02, -2.4311e-02, -2.2704e-02,\n",
      "          7.6093e-02,  1.8584e-01, -9.2054e-02],\n",
      "        [-1.8106e-01,  2.3306e-02,  1.8434e-01,  2.1208e-03, -3.3713e-02,\n",
      "         -1.3695e-02,  7.4620e-02, -3.2661e-02, -1.6471e-01, -1.0431e-01,\n",
      "         -1.1989e-01,  3.1331e-02, -1.9519e-02,  7.5042e-02, -3.0791e-02,\n",
      "         -1.6170e-01,  2.0315e-02, -2.2917e-02, -7.6360e-02, -3.8728e-02,\n",
      "         -2.5376e-02,  1.9742e-01, -4.3830e-02,  7.3937e-02,  4.7054e-03,\n",
      "          1.5489e-01, -1.0892e-02, -6.1093e-02,  5.0807e-02,  4.4078e-02,\n",
      "          1.0020e-01,  6.7896e-02, -6.5864e-02, -2.9331e-02,  9.7898e-02,\n",
      "         -1.7136e-02, -6.3815e-02,  1.8422e-02,  2.6913e-02,  1.2077e-01,\n",
      "          1.1564e-02, -1.1398e-01,  1.2901e-01,  1.4467e-01,  8.7703e-02,\n",
      "         -5.5261e-02, -2.6003e-02,  3.3484e-02, -2.0653e-02, -9.2646e-02,\n",
      "          1.9826e-01, -2.7313e-02,  6.5467e-02,  9.8573e-02,  7.3259e-04,\n",
      "          9.9722e-02,  3.7885e-02, -3.5384e-02, -3.6203e-02, -7.3214e-02,\n",
      "         -2.3994e-02,  5.0122e-02,  4.8563e-02,  1.4653e-01, -4.4373e-02,\n",
      "         -9.0730e-02,  1.1170e-01,  4.6405e-02,  7.9016e-03, -6.1556e-02,\n",
      "         -6.8135e-03, -2.7355e-02,  6.1568e-04, -6.1904e-02,  6.6237e-02,\n",
      "         -4.8865e-02, -1.0395e-01,  1.4712e-02,  4.1308e-02,  1.0468e-02,\n",
      "          3.4253e-02,  6.3660e-02,  5.5745e-02, -4.5460e-02, -1.1168e-01,\n",
      "         -1.9512e-01,  4.8179e-02,  1.5466e-01, -1.8958e-01,  8.9492e-02,\n",
      "         -1.0924e-01, -5.0590e-02,  3.6968e-02, -2.4417e-01,  8.0569e-02,\n",
      "          5.6987e-02, -1.6469e-02,  1.3058e-01, -2.2556e-01,  8.3649e-02,\n",
      "          1.2731e-01, -5.9237e-03, -5.5004e-02, -1.1526e-01, -8.1167e-02,\n",
      "         -1.2069e-01, -3.3567e-02,  6.8318e-03,  1.3572e-02,  5.6983e-02,\n",
      "         -2.6644e-02,  8.2354e-02,  7.5997e-02, -5.7317e-02,  6.1438e-05,\n",
      "         -1.6088e-01, -1.4593e-01,  1.8056e-03, -5.6686e-03, -2.4276e-02,\n",
      "         -5.9392e-02,  2.5171e-02,  2.8177e-02, -7.6080e-02,  1.1120e-01,\n",
      "          1.8005e-01,  7.3484e-02, -2.3423e-02]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.3563, 12.3897,  7.5646,  6.0842],\n",
      "        [12.9945, 13.3221,  8.8026,  5.6697],\n",
      "        [ 8.1372,  8.1696, 12.7498,  6.0412],\n",
      "        [ 9.8370,  6.8258,  9.7826, 13.5327]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.3563, 13.3221, 12.7498, 13.5327], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.2360, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[12.3897,  7.5646,  6.0842],\n",
      "        [12.9945,  8.8026,  5.6697],\n",
      "        [ 8.1372,  8.1696,  6.0412],\n",
      "        [ 9.8370,  6.8258,  9.7826]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0781, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 7: 0.15704570710659027\n",
      "Epoch [3/10], Loss: 0.4060\n",
      "Batch 1/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 1.1834e-01,  3.0078e-02, -1.5881e-01,  ..., -1.2696e-01,\n",
      "          7.4518e-02,  5.3099e-03],\n",
      "        [ 1.1261e-01, -3.5727e-02, -1.5752e-02,  ...,  4.2903e-02,\n",
      "          1.8058e-01, -3.4022e-05],\n",
      "        [ 7.2471e-02,  3.4894e-03, -1.7196e-01,  ..., -6.8825e-02,\n",
      "         -1.3454e-01, -5.2775e-02],\n",
      "        ...,\n",
      "        [-1.6303e-01,  7.1874e-02,  1.2795e-01,  ...,  1.3233e-01,\n",
      "         -9.9251e-02, -6.6414e-02],\n",
      "        [-8.3303e-02,  2.3413e-02,  1.3127e-01,  ...,  1.6316e-01,\n",
      "         -6.2608e-02, -6.0924e-02],\n",
      "        [-3.2266e-02, -1.1112e-02,  9.7365e-02,  ...,  1.8783e-01,\n",
      "         -4.7111e-02, -5.9424e-02]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0887, -0.0136, -0.1399,  ..., -0.1765,  0.1151,  0.0076],\n",
      "        [ 0.0743, -0.0705,  0.0080,  ...,  0.0216,  0.2156,  0.0139],\n",
      "        [ 0.0749, -0.0212, -0.1544,  ..., -0.0654, -0.1792, -0.0392],\n",
      "        ...,\n",
      "        [-0.1563,  0.0566,  0.1383,  ...,  0.1082, -0.1034, -0.0486],\n",
      "        [-0.1610,  0.0062,  0.1669,  ...,  0.2137, -0.0356, -0.0930],\n",
      "        [-0.0739, -0.0057,  0.1376,  ...,  0.1649, -0.0555, -0.0479]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.3556,   2.5241,   7.7406,  -5.5215,   3.1290,  11.9218,   2.0665,\n",
      "          -8.6269,  12.6725,   8.2616,  -4.1765,   7.5787, -10.5066,  -8.1111,\n",
      "         -12.1708, -11.0968],\n",
      "        [  2.6664,  12.7440,  -5.6253,  -0.5592,   8.1784,   6.8429,  -1.0672,\n",
      "           6.1218,   3.3581,   4.2593, -10.8133,   9.2666,   5.8659,  -9.6741,\n",
      "          -3.2057,  -0.9208],\n",
      "        [  7.7671,  -6.0612,  13.6893,  -0.0643,   2.9251,   5.7633,   8.2668,\n",
      "          -7.5913,   9.2159,  -1.9374,  -0.6485,  -2.0680,  -9.9229,  -0.4673,\n",
      "          -6.8373,  -3.8362],\n",
      "        [ -4.8062,  -0.7511,   0.6044,  13.2070,   5.8972,  -2.6454,   6.8946,\n",
      "           9.2482,  -1.7325,  -5.4360,   0.8390,  -3.1470,   7.2750,   6.6485,\n",
      "           7.2573,   9.9872],\n",
      "        [  2.7385,   6.6463,   2.1312,   5.7169,  13.3783,   6.8930,   9.6871,\n",
      "           7.2495,   5.9562,  -3.2490, -10.2620,   4.4974,   4.0868,  -4.9349,\n",
      "          -2.6532,   2.8299],\n",
      "        [ 12.6731,   6.9011,   5.3042,  -3.5237,   8.0305,  13.7434,   4.4260,\n",
      "          -3.5729,  13.2199,   7.0972,  -8.9921,  10.4446,  -6.6807, -10.6927,\n",
      "         -11.9327,  -9.4662],\n",
      "        [  4.3452,   0.2648,   8.3679,   5.2975,  11.0530,   6.2591,  12.3670,\n",
      "           2.3043,   7.6756,  -5.1339,  -6.5210,   0.7892,  -1.0961,  -1.7909,\n",
      "          -3.7970,   1.6833],\n",
      "        [ -8.6685,   5.8211,  -8.0778,   8.7228,   5.9857,  -4.2667,   1.7674,\n",
      "          13.3900,  -6.5528,  -5.1169,  -3.4021,  -0.0945,  13.2440,   2.2986,\n",
      "           8.7482,  10.4712],\n",
      "        [ 12.6772,   2.9176,   9.0167,  -2.3608,   7.1726,  12.6357,   6.4766,\n",
      "          -5.3866,  13.6881,   5.2242,  -6.5440,   7.2865,  -8.9138,  -7.9459,\n",
      "         -11.5129,  -8.7675],\n",
      "        [  9.6362,   7.0298,  -1.0744,  -5.9496,  -0.0172,   9.0281,  -4.9609,\n",
      "          -4.6610,   7.9301,  12.8944,  -2.4161,   9.6902,  -5.4334,  -7.8104,\n",
      "          -7.9245,  -9.7103],\n",
      "        [ -6.1955, -10.1178,   0.8692,   3.6750, -10.0727,  -9.6992,  -3.3605,\n",
      "          -2.5857,  -6.9408,  -1.7154,  13.5342,  -9.1810,  -0.7109,  12.1750,\n",
      "           8.2881,   4.7095],\n",
      "        [  9.1988,  11.3998,  -2.3720,  -3.6795,   6.6587,  11.5462,  -0.5696,\n",
      "           0.7846,   8.9563,   9.4319,  -9.3219,  13.2274,  -1.3042, -11.7258,\n",
      "          -8.7144,  -8.2657],\n",
      "        [ -9.1972,   6.2948,  -8.9261,   6.6866,   4.6556,  -4.9857,  -0.6309,\n",
      "          12.3047,  -7.5830,  -4.9571,  -4.1834,  -0.4119,  13.5117,   1.0826,\n",
      "           8.2667,   9.9700],\n",
      "        [ -9.6176,  -9.1051,   0.5379,   9.0361,  -4.4423, -10.9231,   1.6100,\n",
      "           3.5643,  -8.5893,  -7.5591,  10.1511, -10.7877,   4.6589,  13.4640,\n",
      "          11.4118,  10.5631],\n",
      "        [-12.6156,  -1.9613,  -6.0042,   8.8029,  -1.5381, -11.0430,  -1.0413,\n",
      "           9.4068, -11.2458,  -7.6917,   4.5606,  -7.6285,  11.4014,   9.2520,\n",
      "          13.0609,  12.9444],\n",
      "        [-11.2747,  -0.4935,  -4.1135,   9.2333,   2.3163,  -8.6450,   1.8445,\n",
      "          10.1658,  -9.0379,  -9.1523,   0.7730,  -7.0923,  11.5795,   6.9510,\n",
      "          11.1580,  13.3723]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.3556, 12.7440, 13.6893, 13.2070, 13.3783, 13.7434, 12.3670, 13.3900,\n",
      "        13.6881, 12.8944, 13.5342, 13.2274, 13.5117, 13.4640, 13.0609, 13.3723],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.3188, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  2.5241,   7.7406,  -5.5215,   3.1290,  11.9218,   2.0665,  -8.6269,\n",
      "          12.6725,   8.2616,  -4.1765,   7.5787, -10.5066,  -8.1111, -12.1708,\n",
      "         -11.0968],\n",
      "        [  2.6664,  -5.6253,  -0.5592,   8.1784,   6.8429,  -1.0672,   6.1218,\n",
      "           3.3581,   4.2593, -10.8133,   9.2666,   5.8659,  -9.6741,  -3.2057,\n",
      "          -0.9208],\n",
      "        [  7.7671,  -6.0612,  -0.0643,   2.9251,   5.7633,   8.2668,  -7.5913,\n",
      "           9.2159,  -1.9374,  -0.6485,  -2.0680,  -9.9229,  -0.4673,  -6.8373,\n",
      "          -3.8362],\n",
      "        [ -4.8062,  -0.7511,   0.6044,   5.8972,  -2.6454,   6.8946,   9.2482,\n",
      "          -1.7325,  -5.4360,   0.8390,  -3.1470,   7.2750,   6.6485,   7.2573,\n",
      "           9.9872],\n",
      "        [  2.7385,   6.6463,   2.1312,   5.7169,   6.8930,   9.6871,   7.2495,\n",
      "           5.9562,  -3.2490, -10.2620,   4.4974,   4.0868,  -4.9349,  -2.6532,\n",
      "           2.8299],\n",
      "        [ 12.6731,   6.9011,   5.3042,  -3.5237,   8.0305,   4.4260,  -3.5729,\n",
      "          13.2199,   7.0972,  -8.9921,  10.4446,  -6.6807, -10.6927, -11.9327,\n",
      "          -9.4662],\n",
      "        [  4.3452,   0.2648,   8.3679,   5.2975,  11.0530,   6.2591,   2.3043,\n",
      "           7.6756,  -5.1339,  -6.5210,   0.7892,  -1.0961,  -1.7909,  -3.7970,\n",
      "           1.6833],\n",
      "        [ -8.6685,   5.8211,  -8.0778,   8.7228,   5.9857,  -4.2667,   1.7674,\n",
      "          -6.5528,  -5.1169,  -3.4021,  -0.0945,  13.2440,   2.2986,   8.7482,\n",
      "          10.4712],\n",
      "        [ 12.6772,   2.9176,   9.0167,  -2.3608,   7.1726,  12.6357,   6.4766,\n",
      "          -5.3866,   5.2242,  -6.5440,   7.2865,  -8.9138,  -7.9459, -11.5129,\n",
      "          -8.7675],\n",
      "        [  9.6362,   7.0298,  -1.0744,  -5.9496,  -0.0172,   9.0281,  -4.9609,\n",
      "          -4.6610,   7.9301,  -2.4161,   9.6902,  -5.4334,  -7.8104,  -7.9245,\n",
      "          -9.7103],\n",
      "        [ -6.1955, -10.1178,   0.8692,   3.6750, -10.0727,  -9.6992,  -3.3605,\n",
      "          -2.5857,  -6.9408,  -1.7154,  -9.1810,  -0.7109,  12.1750,   8.2881,\n",
      "           4.7095],\n",
      "        [  9.1988,  11.3998,  -2.3720,  -3.6795,   6.6587,  11.5462,  -0.5696,\n",
      "           0.7846,   8.9563,   9.4319,  -9.3219,  -1.3042, -11.7258,  -8.7144,\n",
      "          -8.2657],\n",
      "        [ -9.1972,   6.2948,  -8.9261,   6.6866,   4.6556,  -4.9857,  -0.6309,\n",
      "          12.3047,  -7.5830,  -4.9571,  -4.1834,  -0.4119,   1.0826,   8.2667,\n",
      "           9.9700],\n",
      "        [ -9.6176,  -9.1051,   0.5379,   9.0361,  -4.4423, -10.9231,   1.6100,\n",
      "           3.5643,  -8.5893,  -7.5591,  10.1511, -10.7877,   4.6589,  11.4118,\n",
      "          10.5631],\n",
      "        [-12.6156,  -1.9613,  -6.0042,   8.8029,  -1.5381, -11.0430,  -1.0413,\n",
      "           9.4068, -11.2458,  -7.6917,   4.5606,  -7.6285,  11.4014,   9.2520,\n",
      "          12.9444],\n",
      "        [-11.2747,  -0.4935,  -4.1135,   9.2333,   2.3163,  -8.6450,   1.8445,\n",
      "          10.1658,  -9.0379,  -9.1523,   0.7730,  -7.0923,  11.5795,   6.9510,\n",
      "          11.1580]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0192, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 1: 0.16897937655448914\n",
      "Batch 2/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1157, -0.0378,  0.0843,  ...,  0.1012, -0.1502,  0.0077],\n",
      "        [-0.1027,  0.0732,  0.0179,  ...,  0.0329, -0.1400, -0.0882],\n",
      "        [-0.0807,  0.0337,  0.0946,  ...,  0.1620, -0.1087, -0.0778],\n",
      "        ...,\n",
      "        [-0.0145, -0.0266,  0.1291,  ...,  0.1467,  0.0429, -0.0438],\n",
      "        [-0.1417,  0.1012,  0.0985,  ...,  0.0517, -0.0946, -0.0401],\n",
      "        [-0.1641,  0.0782,  0.1684,  ...,  0.0933,  0.1006,  0.0195]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 9.7989e-02, -6.4454e-02,  9.0233e-02,  ...,  4.9098e-02,\n",
      "         -1.7262e-01,  3.3787e-02],\n",
      "        [-8.2733e-02,  4.6308e-02,  4.4220e-02,  ..., -5.7140e-02,\n",
      "         -1.6179e-01,  4.4467e-05],\n",
      "        [-1.0636e-01,  1.0170e-02,  1.0453e-01,  ...,  1.2069e-01,\n",
      "         -1.3831e-01, -6.1028e-02],\n",
      "        ...,\n",
      "        [-7.9040e-02, -7.0471e-03,  1.3906e-01,  ...,  1.3818e-01,\n",
      "          5.4963e-02,  2.8260e-02],\n",
      "        [-1.0346e-01,  7.0646e-02,  7.8502e-02,  ...,  4.8907e-03,\n",
      "         -4.3221e-02, -4.9444e-03],\n",
      "        [-1.8291e-01,  4.1808e-02,  1.9469e-01,  ...,  4.9747e-02,\n",
      "          1.3264e-01,  8.3528e-02]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 12.0257,  -3.1391,   5.0766,  -3.9451,  -1.8956,  -0.2865,  -9.5911,\n",
      "          -7.0502,  -4.7208,   6.1057,   7.9214,   7.1706,  -2.1893,   9.3422,\n",
      "          -6.7086,  -4.6372],\n",
      "        [ -3.5321,  12.6993,   8.8018,   8.7952,   4.9325,  -0.6780,   8.2114,\n",
      "          -1.7126,  -6.6160,   3.1646,  -8.4402, -10.3460,   6.6479,  -1.5286,\n",
      "          11.7633,   2.0146],\n",
      "        [  2.5574,   5.4067,  13.6684,  -0.4752,   7.2624,   1.2326,  -3.0689,\n",
      "         -10.3782, -11.4176,   8.1530,  -0.1886,  -4.7567,   8.5413,   9.5998,\n",
      "           4.8743,   1.2700],\n",
      "        [ -4.0108,   8.8620,   0.5419,  13.9272,  -5.0845,  -1.6428,  10.2926,\n",
      "           4.2658,  -2.0242,  -0.7031, -10.7377,  -7.0833,  -2.9593,  -8.1555,\n",
      "           5.9802,  -5.8050],\n",
      "        [ -3.3189,   1.7290,   8.6127,  -5.8843,  13.0372,   5.1703,  -2.0706,\n",
      "          -4.4141,  -3.6618,   5.8382,   2.8790,  -4.5008,  12.2127,   8.5350,\n",
      "           5.0531,  10.2344],\n",
      "        [ -3.8871,  -2.7726,  -3.4446,  -1.2501,   1.7593,  13.0249,  -3.1109,\n",
      "           5.9536,   7.3356,   5.4575,   5.0950,   6.2698,  -3.7836,   2.3722,\n",
      "          -5.4090,  -0.4879],\n",
      "        [ -8.1408,   6.9178,  -3.1688,  10.9630,  -1.7134,  -2.3451,  13.2920,\n",
      "           8.2181,   2.6202,  -4.5390, -10.6498,  -8.9795,   0.5470, -10.8603,\n",
      "           7.9136,   0.9816],\n",
      "        [ -5.4595,  -2.5194,  -9.8786,   2.9185,  -3.3440,   4.4642,   4.3882,\n",
      "          13.0455,  10.1359,  -5.2553,  -0.7404,   2.2717,  -4.6063,  -6.8571,\n",
      "          -2.8773,   1.0104],\n",
      "        [ -2.4117,  -5.6924, -11.2515,  -2.6191,  -2.4587,   5.9542,  -0.5176,\n",
      "          10.6162,  13.2546,  -3.1499,   4.8352,   7.6695,  -6.4622,  -4.3725,\n",
      "          -5.9181,   1.2793],\n",
      "        [  2.9039,   1.5942,   8.6140,  -1.9214,   5.5368,   8.7809,  -6.5947,\n",
      "          -6.2574,  -4.3291,  12.8663,   5.4274,   2.7869,   2.0722,  10.4131,\n",
      "          -2.0225,  -1.6983],\n",
      "        [  6.2592,  -8.6878,  -0.8706, -10.0931,   1.7374,   7.4056, -11.8211,\n",
      "          -1.8649,   3.5143,   5.7871,  12.9549,  11.5049,  -2.7818,   9.6738,\n",
      "         -10.5931,  -0.1076],\n",
      "        [  7.3227,  -8.8353,  -3.3713,  -7.0648,  -3.7591,   5.9687, -11.5045,\n",
      "          -0.6152,   3.9865,   3.7789,  11.0316,  13.2274,  -7.7376,   6.4898,\n",
      "         -12.4494,  -5.3219],\n",
      "        [ -3.7123,   2.7297,   8.5746,  -3.5772,  11.2267,   0.4600,   1.1340,\n",
      "          -4.1472,  -5.6321,   1.6442,  -0.9590,  -7.8654,  13.6105,   5.6751,\n",
      "           7.6781,  10.3309],\n",
      "        [  6.6921,  -4.6472,   7.2912,  -8.7886,   5.2111,   5.8275, -11.7754,\n",
      "          -8.2008,  -4.4092,   8.6283,  10.1100,   6.1673,   2.9463,  13.6834,\n",
      "          -6.0189,   0.6133],\n",
      "        [ -5.7833,   9.9652,   8.1433,   5.2379,   7.5139,  -2.7462,   8.4717,\n",
      "          -2.0390,  -6.2347,   0.1607,  -8.4441, -12.4842,  10.9529,  -1.3969,\n",
      "          13.2336,   6.6100],\n",
      "        [ -4.5105,  -0.4787,   2.7120,  -5.8427,  10.7633,   1.6005,   1.1758,\n",
      "           0.8430,   0.8106,  -1.4431,   1.5650,  -4.7537,  11.5968,   3.3008,\n",
      "           5.4973,  13.0455]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([12.0257, 12.6993, 13.6684, 13.9272, 13.0372, 13.0249, 13.2920, 13.0455,\n",
      "        13.2546, 12.8663, 12.9549, 13.2274, 13.6105, 13.6834, 13.2336, 13.0455],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1410, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ -3.1391,   5.0766,  -3.9451,  -1.8956,  -0.2865,  -9.5911,  -7.0502,\n",
      "          -4.7208,   6.1057,   7.9214,   7.1706,  -2.1893,   9.3422,  -6.7086,\n",
      "          -4.6372],\n",
      "        [ -3.5321,   8.8018,   8.7952,   4.9325,  -0.6780,   8.2114,  -1.7126,\n",
      "          -6.6160,   3.1646,  -8.4402, -10.3460,   6.6479,  -1.5286,  11.7633,\n",
      "           2.0146],\n",
      "        [  2.5574,   5.4067,  -0.4752,   7.2624,   1.2326,  -3.0689, -10.3782,\n",
      "         -11.4176,   8.1530,  -0.1886,  -4.7567,   8.5413,   9.5998,   4.8743,\n",
      "           1.2700],\n",
      "        [ -4.0108,   8.8620,   0.5419,  -5.0845,  -1.6428,  10.2926,   4.2658,\n",
      "          -2.0242,  -0.7031, -10.7377,  -7.0833,  -2.9593,  -8.1555,   5.9802,\n",
      "          -5.8050],\n",
      "        [ -3.3189,   1.7290,   8.6127,  -5.8843,   5.1703,  -2.0706,  -4.4141,\n",
      "          -3.6618,   5.8382,   2.8790,  -4.5008,  12.2127,   8.5350,   5.0531,\n",
      "          10.2344],\n",
      "        [ -3.8871,  -2.7726,  -3.4446,  -1.2501,   1.7593,  -3.1109,   5.9536,\n",
      "           7.3356,   5.4575,   5.0950,   6.2698,  -3.7836,   2.3722,  -5.4090,\n",
      "          -0.4879],\n",
      "        [ -8.1408,   6.9178,  -3.1688,  10.9630,  -1.7134,  -2.3451,   8.2181,\n",
      "           2.6202,  -4.5390, -10.6498,  -8.9795,   0.5470, -10.8603,   7.9136,\n",
      "           0.9816],\n",
      "        [ -5.4595,  -2.5194,  -9.8786,   2.9185,  -3.3440,   4.4642,   4.3882,\n",
      "          10.1359,  -5.2553,  -0.7404,   2.2717,  -4.6063,  -6.8571,  -2.8773,\n",
      "           1.0104],\n",
      "        [ -2.4117,  -5.6924, -11.2515,  -2.6191,  -2.4587,   5.9542,  -0.5176,\n",
      "          10.6162,  -3.1499,   4.8352,   7.6695,  -6.4622,  -4.3725,  -5.9181,\n",
      "           1.2793],\n",
      "        [  2.9039,   1.5942,   8.6140,  -1.9214,   5.5368,   8.7809,  -6.5947,\n",
      "          -6.2574,  -4.3291,   5.4274,   2.7869,   2.0722,  10.4131,  -2.0225,\n",
      "          -1.6983],\n",
      "        [  6.2592,  -8.6878,  -0.8706, -10.0931,   1.7374,   7.4056, -11.8211,\n",
      "          -1.8649,   3.5143,   5.7871,  11.5049,  -2.7818,   9.6738, -10.5931,\n",
      "          -0.1076],\n",
      "        [  7.3227,  -8.8353,  -3.3713,  -7.0648,  -3.7591,   5.9687, -11.5045,\n",
      "          -0.6152,   3.9865,   3.7789,  11.0316,  -7.7376,   6.4898, -12.4494,\n",
      "          -5.3219],\n",
      "        [ -3.7123,   2.7297,   8.5746,  -3.5772,  11.2267,   0.4600,   1.1340,\n",
      "          -4.1472,  -5.6321,   1.6442,  -0.9590,  -7.8654,   5.6751,   7.6781,\n",
      "          10.3309],\n",
      "        [  6.6921,  -4.6472,   7.2912,  -8.7886,   5.2111,   5.8275, -11.7754,\n",
      "          -8.2008,  -4.4092,   8.6283,  10.1100,   6.1673,   2.9463,  -6.0189,\n",
      "           0.6133],\n",
      "        [ -5.7833,   9.9652,   8.1433,   5.2379,   7.5139,  -2.7462,   8.4717,\n",
      "          -2.0390,  -6.2347,   0.1607,  -8.4441, -12.4842,  10.9529,  -1.3969,\n",
      "           6.6100],\n",
      "        [ -4.5105,  -0.4787,   2.7120,  -5.8427,  10.7633,   1.6005,   1.1758,\n",
      "           0.8430,   0.8106,  -1.4431,   1.5650,  -4.7537,  11.5968,   3.3008,\n",
      "           5.4973]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0091, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 2: 0.07500945031642914\n",
      "Batch 3/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1642, -0.0101, -0.1556,  ..., -0.0871, -0.1714,  0.0159],\n",
      "        [ 0.2438, -0.0320, -0.1913,  ..., -0.0864, -0.1159,  0.0217],\n",
      "        [-0.1063,  0.0732,  0.0555,  ...,  0.1288, -0.0369, -0.0502],\n",
      "        ...,\n",
      "        [-0.0095, -0.0430, -0.0718,  ...,  0.0578, -0.0475, -0.0623],\n",
      "        [-0.0879,  0.0635,  0.0217,  ..., -0.0420,  0.3265, -0.0065],\n",
      "        [ 0.1028, -0.0632, -0.0599,  ..., -0.0027,  0.0074, -0.0427]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 1.2219e-01, -1.1347e-02, -1.7801e-01,  ..., -1.0169e-01,\n",
      "         -1.6926e-01,  1.5366e-02],\n",
      "        [ 1.5890e-01, -5.1692e-02, -1.6143e-01,  ..., -1.2960e-01,\n",
      "         -8.4231e-02,  8.4124e-02],\n",
      "        [-1.8071e-01,  5.3662e-02,  8.1096e-02,  ...,  7.8372e-02,\n",
      "         -3.0204e-02, -3.8406e-02],\n",
      "        ...,\n",
      "        [ 1.4556e-02, -5.0006e-02, -8.7216e-02,  ..., -4.5903e-03,\n",
      "         -2.3416e-02, -3.6037e-02],\n",
      "        [-1.4364e-01,  4.4572e-02,  2.0023e-02,  ..., -1.0851e-01,\n",
      "          2.6617e-01,  7.7922e-02],\n",
      "        [ 4.2317e-02, -8.3829e-02, -4.2399e-02,  ..., -9.5147e-05,\n",
      "          1.4149e-02,  1.7961e-02]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.6980,  10.4506,  -1.5889,   5.8270,   7.9400,   5.9029,   2.2286,\n",
      "           9.2500,   2.1413,  -2.0189,   8.0280,  -5.2350,   7.8965,  -0.3379,\n",
      "          -0.7019,  -1.9238],\n",
      "        [ 10.3197,  13.1725,  -8.7611,  10.9583,   9.3741,   2.5954,   5.1575,\n",
      "           9.3578,   5.0737,  -7.9851,  10.3844,  -0.2414,  -0.0471,   3.7714,\n",
      "          -2.7436,   5.0921],\n",
      "        [ -2.1546,  -8.9867,  13.4707, -11.5379,  -8.0964,  -1.2539,  -9.5339,\n",
      "          -6.6265,  -2.2417,   7.0949,  -9.7985,  -5.1982,   6.2455,  -4.4762,\n",
      "           1.7611,  -8.9388],\n",
      "        [  6.5406,  11.5279, -10.9747,  13.5987,  11.9204,   1.5702,   7.5503,\n",
      "           6.0101,   8.4647, -10.6831,  10.7701,   2.6636,  -3.9867,   9.4423,\n",
      "          -0.9203,  10.4112],\n",
      "        [  9.3048,  10.6118,  -7.0829,  11.9130,  13.5208,   5.2009,   7.3101,\n",
      "           6.3971,   7.5983,  -7.3542,  10.7433,   0.6391,   1.5395,   8.8580,\n",
      "           2.0538,   7.4862],\n",
      "        [  8.0795,   3.9201,  -0.2261,   2.3828,   5.2853,  13.3889,   8.6144,\n",
      "          10.9199,  -6.0369,   5.3151,   9.3018,   3.4134,   9.5900,  -3.4868,\n",
      "           9.1742,  -4.4679],\n",
      "        [  3.4714,   7.3347, -10.1414,  10.2518,   8.6388,   7.5850,  12.5512,\n",
      "           9.9440,   0.0161,  -3.8344,  12.3188,   8.8049,  -1.9835,   4.2338,\n",
      "           5.8086,   6.8383],\n",
      "        [  9.5458,   9.6564,  -6.4642,   7.2329,   6.6070,   9.5735,   9.2920,\n",
      "          13.7912,  -3.3432,  -0.3933,  12.1310,   3.8515,   4.5870,  -2.3522,\n",
      "           3.9672,  -0.2881],\n",
      "        [  1.1790,   3.8180,  -2.6870,   6.0736,   6.3708,  -6.1322,  -3.3146,\n",
      "          -4.8283,  13.6667, -11.3851,   0.0540,  -2.0628,  -5.7742,  12.4378,\n",
      "          -4.8754,   9.7834],\n",
      "        [ -1.7229,  -6.3144,   7.2342,  -8.6872,  -7.5593,   6.0908,   0.5010,\n",
      "           2.9599, -11.0074,  11.5235,  -2.0713,   2.3072,   6.9139,  -9.9803,\n",
      "           7.2689,  -9.8401],\n",
      "        [  8.4318,  10.8804,  -9.7299,  11.4278,  10.5012,   8.4311,  11.3281,\n",
      "          11.9880,   1.1334,  -4.6698,  13.8794,   5.3067,   1.1662,   3.4743,\n",
      "           4.2219,   5.1855],\n",
      "        [ -5.8819,  -1.2133,  -5.4970,   2.3896,  -0.8403,   1.5847,   5.9608,\n",
      "           2.5443,  -1.0199,  -2.9472,   3.5828,  12.0239,  -7.0792,   2.8468,\n",
      "           3.3567,   5.6803],\n",
      "        [  8.4864,   0.2388,   7.6903,  -4.2853,   0.7108,   9.5822,   0.3257,\n",
      "           5.6487,  -6.2336,   8.9020,   1.8137,  -4.3992,  13.6823,  -7.0305,\n",
      "           5.9917, -10.4760],\n",
      "        [ -1.4475,   2.2745,  -3.9199,   6.6491,   6.7136,  -5.0764,  -0.8538,\n",
      "          -5.2190,  12.8650, -10.9474,   0.7467,   1.1744,  -7.3530,  13.5128,\n",
      "          -2.5757,  11.4372],\n",
      "        [ -0.7460,  -4.3367,   4.1597,  -2.9112,  -1.1082,   9.5880,   5.9407,\n",
      "           3.9315,  -7.2641,   8.2923,   3.0562,   5.8889,   6.2913,  -3.5189,\n",
      "          12.9122,  -4.9466],\n",
      "        [ -0.6239,   6.6107, -10.4347,  10.7316,   7.6110,  -3.7641,   4.2920,\n",
      "           0.6465,  10.1695, -12.1874,   5.8831,   4.9099, -10.0703,  11.5885,\n",
      "          -3.1655,  13.4897]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6980, 13.1725, 13.4707, 13.5987, 13.5208, 13.3889, 12.5512, 13.7912,\n",
      "        13.6667, 11.5235, 13.8794, 12.0239, 13.6823, 13.5128, 12.9122, 13.4897],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.2193, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 10.4506,  -1.5889,   5.8270,   7.9400,   5.9029,   2.2286,   9.2500,\n",
      "           2.1413,  -2.0189,   8.0280,  -5.2350,   7.8965,  -0.3379,  -0.7019,\n",
      "          -1.9238],\n",
      "        [ 10.3197,  -8.7611,  10.9583,   9.3741,   2.5954,   5.1575,   9.3578,\n",
      "           5.0737,  -7.9851,  10.3844,  -0.2414,  -0.0471,   3.7714,  -2.7436,\n",
      "           5.0921],\n",
      "        [ -2.1546,  -8.9867, -11.5379,  -8.0964,  -1.2539,  -9.5339,  -6.6265,\n",
      "          -2.2417,   7.0949,  -9.7985,  -5.1982,   6.2455,  -4.4762,   1.7611,\n",
      "          -8.9388],\n",
      "        [  6.5406,  11.5279, -10.9747,  11.9204,   1.5702,   7.5503,   6.0101,\n",
      "           8.4647, -10.6831,  10.7701,   2.6636,  -3.9867,   9.4423,  -0.9203,\n",
      "          10.4112],\n",
      "        [  9.3048,  10.6118,  -7.0829,  11.9130,   5.2009,   7.3101,   6.3971,\n",
      "           7.5983,  -7.3542,  10.7433,   0.6391,   1.5395,   8.8580,   2.0538,\n",
      "           7.4862],\n",
      "        [  8.0795,   3.9201,  -0.2261,   2.3828,   5.2853,   8.6144,  10.9199,\n",
      "          -6.0369,   5.3151,   9.3018,   3.4134,   9.5900,  -3.4868,   9.1742,\n",
      "          -4.4679],\n",
      "        [  3.4714,   7.3347, -10.1414,  10.2518,   8.6388,   7.5850,   9.9440,\n",
      "           0.0161,  -3.8344,  12.3188,   8.8049,  -1.9835,   4.2338,   5.8086,\n",
      "           6.8383],\n",
      "        [  9.5458,   9.6564,  -6.4642,   7.2329,   6.6070,   9.5735,   9.2920,\n",
      "          -3.3432,  -0.3933,  12.1310,   3.8515,   4.5870,  -2.3522,   3.9672,\n",
      "          -0.2881],\n",
      "        [  1.1790,   3.8180,  -2.6870,   6.0736,   6.3708,  -6.1322,  -3.3146,\n",
      "          -4.8283, -11.3851,   0.0540,  -2.0628,  -5.7742,  12.4378,  -4.8754,\n",
      "           9.7834],\n",
      "        [ -1.7229,  -6.3144,   7.2342,  -8.6872,  -7.5593,   6.0908,   0.5010,\n",
      "           2.9599, -11.0074,  -2.0713,   2.3072,   6.9139,  -9.9803,   7.2689,\n",
      "          -9.8401],\n",
      "        [  8.4318,  10.8804,  -9.7299,  11.4278,  10.5012,   8.4311,  11.3281,\n",
      "          11.9880,   1.1334,  -4.6698,   5.3067,   1.1662,   3.4743,   4.2219,\n",
      "           5.1855],\n",
      "        [ -5.8819,  -1.2133,  -5.4970,   2.3896,  -0.8403,   1.5847,   5.9608,\n",
      "           2.5443,  -1.0199,  -2.9472,   3.5828,  -7.0792,   2.8468,   3.3567,\n",
      "           5.6803],\n",
      "        [  8.4864,   0.2388,   7.6903,  -4.2853,   0.7108,   9.5822,   0.3257,\n",
      "           5.6487,  -6.2336,   8.9020,   1.8137,  -4.3992,  -7.0305,   5.9917,\n",
      "         -10.4760],\n",
      "        [ -1.4475,   2.2745,  -3.9199,   6.6491,   6.7136,  -5.0764,  -0.8538,\n",
      "          -5.2190,  12.8650, -10.9474,   0.7467,   1.1744,  -7.3530,  -2.5757,\n",
      "          11.4372],\n",
      "        [ -0.7460,  -4.3367,   4.1597,  -2.9112,  -1.1082,   9.5880,   5.9407,\n",
      "           3.9315,  -7.2641,   8.2923,   3.0562,   5.8889,   6.2913,  -3.5189,\n",
      "          -4.9466],\n",
      "        [ -0.6239,   6.6107, -10.4347,  10.7316,   7.6110,  -3.7641,   4.2920,\n",
      "           0.6465,  10.1695, -12.1874,   5.8831,   4.9099, -10.0703,  11.5885,\n",
      "          -3.1655]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0134, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 3: 0.11633042991161346\n",
      "Batch 4/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.1866,  0.0810,  0.1426,  ...,  0.1645, -0.0069, -0.0024],\n",
      "        [-0.0299,  0.0089,  0.0751,  ...,  0.1413,  0.1593,  0.0014],\n",
      "        [ 0.0095,  0.0785, -0.0964,  ..., -0.0281, -0.1531, -0.0086],\n",
      "        ...,\n",
      "        [-0.1689,  0.0466,  0.1608,  ...,  0.1965,  0.0150, -0.0611],\n",
      "        [-0.1930,  0.0707,  0.0517,  ...,  0.0823,  0.0271, -0.0749],\n",
      "        [ 0.1191, -0.0367, -0.0455,  ..., -0.0286,  0.1353,  0.0208]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.2140,  0.0640,  0.1880,  ...,  0.1210,  0.0169,  0.0073],\n",
      "        [-0.0489,  0.0290,  0.1496,  ...,  0.1384,  0.2056,  0.0193],\n",
      "        [-0.0137,  0.0120, -0.0787,  ..., -0.0600, -0.0959, -0.0380],\n",
      "        ...,\n",
      "        [-0.1443,  0.0393,  0.1737,  ...,  0.1122, -0.0219, -0.0484],\n",
      "        [-0.2233,  0.0243,  0.0360,  ...,  0.0740,  0.0275, -0.0556],\n",
      "        [ 0.0809, -0.0426, -0.0663,  ..., -0.0460,  0.1341,  0.0058]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3239e+01,  5.9111e+00,  7.7414e-01,  4.3487e+00,  1.3186e+01,\n",
      "          9.5994e+00, -1.2062e+01, -1.0167e+01,  1.6249e+00,  8.5315e+00,\n",
      "          1.2334e+01, -3.3120e+00,  9.0037e+00,  1.1340e+01,  1.0730e+01,\n",
      "         -8.3233e+00],\n",
      "        [ 4.1405e+00,  1.3015e+01, -9.9624e+00, -8.8584e+00,  6.3974e+00,\n",
      "         -1.0754e+00, -7.5965e+00, -6.4638e+00, -9.1627e+00, -4.9840e+00,\n",
      "          7.4196e+00, -1.3699e+00,  4.9012e+00,  3.9205e+00, -1.2885e+00,\n",
      "          4.9929e+00],\n",
      "        [ 2.5893e+00, -9.7829e+00,  1.3530e+01,  1.2930e+01, -2.5526e-01,\n",
      "          3.2928e+00,  2.8502e+00,  2.8112e+00,  1.2859e+01,  8.7772e+00,\n",
      "         -3.3753e+00, -5.3585e+00, -3.9650e+00, -1.6347e+00,  6.7562e+00,\n",
      "         -7.0077e+00],\n",
      "        [ 6.4054e+00, -7.7682e+00,  1.1869e+01,  1.3354e+01,  4.3717e+00,\n",
      "          7.9080e+00, -1.5036e+00, -7.2059e-01,  1.1651e+01,  1.1500e+01,\n",
      "          1.8475e+00, -3.9395e+00,  1.1385e+00,  3.6261e+00,  1.0147e+01,\n",
      "         -1.0894e+01],\n",
      "        [ 1.2477e+01,  7.1377e+00, -8.4832e-01,  2.7158e+00,  1.3298e+01,\n",
      "          9.1302e+00, -1.1876e+01, -1.0138e+01, -8.9643e-03,  7.1709e+00,\n",
      "          1.2670e+01, -2.7356e+00,  9.4794e+00,  1.1138e+01,  9.8224e+00,\n",
      "         -7.3615e+00],\n",
      "        [ 7.2932e+00, -2.1575e+00,  2.0523e+00,  6.0094e+00,  8.5689e+00,\n",
      "          1.3533e+01, -5.0529e+00, -3.9669e+00,  1.8331e+00,  9.0699e+00,\n",
      "          9.2429e+00,  5.7380e+00,  1.1325e+01,  1.1056e+01,  9.9508e+00,\n",
      "         -1.1615e+01],\n",
      "        [-1.1436e+01, -8.5806e+00,  3.2350e+00,  5.3878e-01, -1.0850e+01,\n",
      "         -5.3595e+00,  1.3465e+01,  1.1062e+01,  2.6618e+00, -4.4516e+00,\n",
      "         -1.1095e+01,  3.6362e+00, -7.1408e+00, -1.0040e+01, -6.9146e+00,\n",
      "          3.9079e+00],\n",
      "        [-8.7932e+00, -7.4999e+00,  4.6018e+00,  2.0076e+00, -8.8993e+00,\n",
      "         -4.2857e+00,  1.1735e+01,  1.3476e+01,  2.7197e+00, -2.1481e+00,\n",
      "         -1.0080e+01,  1.9988e+00, -6.1590e+00, -8.2195e+00, -3.4179e+00,\n",
      "          4.5450e+00],\n",
      "        [ 3.3522e+00, -8.3874e+00,  1.2374e+01,  1.2579e+01,  8.7031e-01,\n",
      "          3.3505e+00,  1.3074e+00,  8.0383e-01,  1.3041e+01,  9.3211e+00,\n",
      "         -2.1468e+00, -5.8717e+00, -3.7146e+00, -8.5099e-01,  6.3468e+00,\n",
      "         -7.8514e+00],\n",
      "        [ 1.0265e+01, -2.2057e+00,  7.4465e+00,  1.0376e+01,  9.4822e+00,\n",
      "          1.0305e+01, -6.3982e+00, -5.0458e+00,  8.4044e+00,  1.2600e+01,\n",
      "          7.4045e+00, -2.5951e+00,  5.4025e+00,  8.4774e+00,  1.1648e+01,\n",
      "         -1.1659e+01],\n",
      "        [ 1.0342e+01,  8.1505e+00, -5.3842e+00, -1.1610e+00,  1.2276e+01,\n",
      "          9.8530e+00, -1.1550e+01, -1.0245e+01, -4.4418e+00,  4.3255e+00,\n",
      "          1.3656e+01,  2.2649e+00,  1.2155e+01,  1.2323e+01,  7.2569e+00,\n",
      "         -6.5811e+00],\n",
      "        [-2.5021e+00, -1.2713e-01, -6.8231e+00, -4.4105e+00,  1.1538e+00,\n",
      "          6.6173e+00,  1.9117e+00,  1.5299e+00, -6.6881e+00, -5.6934e-01,\n",
      "          4.1016e+00,  1.3089e+01,  9.1709e+00,  5.6161e+00, -5.8897e-01,\n",
      "         -2.8107e+00],\n",
      "        [ 8.3408e+00,  5.9025e+00, -5.2581e+00, -1.1090e+00,  1.0972e+01,\n",
      "          1.1387e+01, -8.7042e+00, -6.4271e+00, -5.3584e+00,  4.2058e+00,\n",
      "          1.2636e+01,  5.8022e+00,  1.3708e+01,  1.2436e+01,  7.6455e+00,\n",
      "         -6.8018e+00],\n",
      "        [ 1.1220e+01,  6.1626e+00, -3.1722e+00,  1.1851e+00,  1.2555e+01,\n",
      "          1.1399e+01, -1.1179e+01, -8.9567e+00, -2.4876e+00,  7.0993e+00,\n",
      "          1.3381e+01,  2.4425e+00,  1.2377e+01,  1.3379e+01,  9.4711e+00,\n",
      "         -8.1748e+00],\n",
      "        [ 1.1805e+01,  1.4848e+00,  4.6143e+00,  7.6302e+00,  1.1491e+01,\n",
      "          1.1059e+01, -8.9277e+00, -6.0921e+00,  4.0140e+00,  1.0026e+01,\n",
      "          1.0128e+01, -2.9925e+00,  8.5879e+00,  1.0456e+01,  1.2881e+01,\n",
      "         -9.7030e+00],\n",
      "        [-7.9068e+00,  5.1504e+00, -6.3939e+00, -9.9363e+00, -7.2824e+00,\n",
      "         -1.1640e+01,  5.5409e+00,  5.3501e+00, -7.0974e+00, -1.1337e+01,\n",
      "         -6.7975e+00, -1.1965e+00, -6.8411e+00, -8.7509e+00, -1.0271e+01,\n",
      "          1.3642e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.2386, 13.0145, 13.5301, 13.3540, 13.2983, 13.5332, 13.4648, 13.4763,\n",
      "        13.0414, 12.5996, 13.6565, 13.0894, 13.7080, 13.3791, 12.8815, 13.6417],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.4864, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 5.9111e+00,  7.7414e-01,  4.3487e+00,  1.3186e+01,  9.5994e+00,\n",
      "         -1.2062e+01, -1.0167e+01,  1.6249e+00,  8.5315e+00,  1.2334e+01,\n",
      "         -3.3120e+00,  9.0037e+00,  1.1340e+01,  1.0730e+01, -8.3233e+00],\n",
      "        [ 4.1405e+00, -9.9624e+00, -8.8584e+00,  6.3974e+00, -1.0754e+00,\n",
      "         -7.5965e+00, -6.4638e+00, -9.1627e+00, -4.9840e+00,  7.4196e+00,\n",
      "         -1.3699e+00,  4.9012e+00,  3.9205e+00, -1.2885e+00,  4.9929e+00],\n",
      "        [ 2.5893e+00, -9.7829e+00,  1.2930e+01, -2.5526e-01,  3.2928e+00,\n",
      "          2.8502e+00,  2.8112e+00,  1.2859e+01,  8.7772e+00, -3.3753e+00,\n",
      "         -5.3585e+00, -3.9650e+00, -1.6347e+00,  6.7562e+00, -7.0077e+00],\n",
      "        [ 6.4054e+00, -7.7682e+00,  1.1869e+01,  4.3717e+00,  7.9080e+00,\n",
      "         -1.5036e+00, -7.2059e-01,  1.1651e+01,  1.1500e+01,  1.8475e+00,\n",
      "         -3.9395e+00,  1.1385e+00,  3.6261e+00,  1.0147e+01, -1.0894e+01],\n",
      "        [ 1.2477e+01,  7.1377e+00, -8.4832e-01,  2.7158e+00,  9.1302e+00,\n",
      "         -1.1876e+01, -1.0138e+01, -8.9643e-03,  7.1709e+00,  1.2670e+01,\n",
      "         -2.7356e+00,  9.4794e+00,  1.1138e+01,  9.8224e+00, -7.3615e+00],\n",
      "        [ 7.2932e+00, -2.1575e+00,  2.0523e+00,  6.0094e+00,  8.5689e+00,\n",
      "         -5.0529e+00, -3.9669e+00,  1.8331e+00,  9.0699e+00,  9.2429e+00,\n",
      "          5.7380e+00,  1.1325e+01,  1.1056e+01,  9.9508e+00, -1.1615e+01],\n",
      "        [-1.1436e+01, -8.5806e+00,  3.2350e+00,  5.3878e-01, -1.0850e+01,\n",
      "         -5.3595e+00,  1.1062e+01,  2.6618e+00, -4.4516e+00, -1.1095e+01,\n",
      "          3.6362e+00, -7.1408e+00, -1.0040e+01, -6.9146e+00,  3.9079e+00],\n",
      "        [-8.7932e+00, -7.4999e+00,  4.6018e+00,  2.0076e+00, -8.8993e+00,\n",
      "         -4.2857e+00,  1.1735e+01,  2.7197e+00, -2.1481e+00, -1.0080e+01,\n",
      "          1.9988e+00, -6.1590e+00, -8.2195e+00, -3.4179e+00,  4.5450e+00],\n",
      "        [ 3.3522e+00, -8.3874e+00,  1.2374e+01,  1.2579e+01,  8.7031e-01,\n",
      "          3.3505e+00,  1.3074e+00,  8.0383e-01,  9.3211e+00, -2.1468e+00,\n",
      "         -5.8717e+00, -3.7146e+00, -8.5099e-01,  6.3468e+00, -7.8514e+00],\n",
      "        [ 1.0265e+01, -2.2057e+00,  7.4465e+00,  1.0376e+01,  9.4822e+00,\n",
      "          1.0305e+01, -6.3982e+00, -5.0458e+00,  8.4044e+00,  7.4045e+00,\n",
      "         -2.5951e+00,  5.4025e+00,  8.4774e+00,  1.1648e+01, -1.1659e+01],\n",
      "        [ 1.0342e+01,  8.1505e+00, -5.3842e+00, -1.1610e+00,  1.2276e+01,\n",
      "          9.8530e+00, -1.1550e+01, -1.0245e+01, -4.4418e+00,  4.3255e+00,\n",
      "          2.2649e+00,  1.2155e+01,  1.2323e+01,  7.2569e+00, -6.5811e+00],\n",
      "        [-2.5021e+00, -1.2713e-01, -6.8231e+00, -4.4105e+00,  1.1538e+00,\n",
      "          6.6173e+00,  1.9117e+00,  1.5299e+00, -6.6881e+00, -5.6934e-01,\n",
      "          4.1016e+00,  9.1709e+00,  5.6161e+00, -5.8897e-01, -2.8107e+00],\n",
      "        [ 8.3408e+00,  5.9025e+00, -5.2581e+00, -1.1090e+00,  1.0972e+01,\n",
      "          1.1387e+01, -8.7042e+00, -6.4271e+00, -5.3584e+00,  4.2058e+00,\n",
      "          1.2636e+01,  5.8022e+00,  1.2436e+01,  7.6455e+00, -6.8018e+00],\n",
      "        [ 1.1220e+01,  6.1626e+00, -3.1722e+00,  1.1851e+00,  1.2555e+01,\n",
      "          1.1399e+01, -1.1179e+01, -8.9567e+00, -2.4876e+00,  7.0993e+00,\n",
      "          1.3381e+01,  2.4425e+00,  1.2377e+01,  9.4711e+00, -8.1748e+00],\n",
      "        [ 1.1805e+01,  1.4848e+00,  4.6143e+00,  7.6302e+00,  1.1491e+01,\n",
      "          1.1059e+01, -8.9277e+00, -6.0921e+00,  4.0140e+00,  1.0026e+01,\n",
      "          1.0128e+01, -2.9925e+00,  8.5879e+00,  1.0456e+01, -9.7030e+00],\n",
      "        [-7.9068e+00,  5.1504e+00, -6.3939e+00, -9.9363e+00, -7.2824e+00,\n",
      "         -1.1640e+01,  5.5409e+00,  5.3501e+00, -7.0974e+00, -1.1337e+01,\n",
      "         -6.7975e+00, -1.1965e+00, -6.8411e+00, -8.7509e+00, -1.0271e+01]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0256, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 4: 0.2560262084007263\n",
      "Batch 5/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.1567,  0.0734,  0.1372,  ...,  0.1428, -0.0904, -0.0035],\n",
      "        [-0.1971,  0.0558,  0.1218,  ...,  0.1226,  0.0916, -0.0690],\n",
      "        [-0.1271,  0.0374,  0.1139,  ...,  0.1585,  0.0026, -0.0837],\n",
      "        ...,\n",
      "        [-0.0395,  0.0665, -0.0015,  ..., -0.0235,  0.0472,  0.0270],\n",
      "        [-0.0913,  0.0113,  0.1412,  ...,  0.1247,  0.0725, -0.0815],\n",
      "        [ 0.0124,  0.0558, -0.0598,  ...,  0.0113, -0.1818, -0.0091]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.1474,  0.0279,  0.0981,  ...,  0.0990, -0.1159,  0.0512],\n",
      "        [-0.2338,  0.0618,  0.1380,  ...,  0.1114,  0.1279, -0.0466],\n",
      "        [-0.1840,  0.0206,  0.0943,  ...,  0.1606, -0.0048, -0.0463],\n",
      "        ...,\n",
      "        [-0.0496,  0.0490, -0.0014,  ..., -0.0426,  0.0838,  0.0123],\n",
      "        [-0.1218, -0.0108,  0.1317,  ...,  0.0966,  0.0633, -0.0446],\n",
      "        [-0.0522,  0.0460, -0.0605,  ...,  0.0046, -0.1478, -0.0352]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 12.8661,  10.8177,  12.2376,   7.6816,   8.4007,  -4.8260,   9.5488,\n",
      "          -3.4643,   4.5011,   5.4776,   3.1558,  -6.1592,  10.0850,  -1.8360,\n",
      "           7.6320,   2.5216],\n",
      "        [  8.4490,  13.6737,  11.5354,  11.8305,  11.1800,  -6.9160,   6.8368,\n",
      "          -5.8999,   4.1468,  -2.1573,  -2.9729,   0.6884,   6.4024,   1.0323,\n",
      "           7.7515,  -1.0708],\n",
      "        [ 11.0966,  11.9876,  13.8382,  10.9519,  11.8600,  -8.2325,  10.7913,\n",
      "          -8.2041,   5.7086,   2.4173,  -0.0646,  -3.0875,  10.7703,  -4.9430,\n",
      "          11.1269,  -2.3347],\n",
      "        [  5.1557,  10.6222,   9.6193,  13.4507,  12.1470, -11.7893,   4.5749,\n",
      "         -10.3765,   8.3123,  -5.6699,  -8.2678,   2.8657,   8.3355,  -3.3118,\n",
      "           9.0043,  -6.8173],\n",
      "        [  7.5776,  11.1150,  11.5221,  12.8207,  13.2827, -11.3787,   7.1975,\n",
      "         -11.1991,   8.7534,  -2.8610,  -6.0486,   1.6623,   9.9683,  -5.5920,\n",
      "          11.3502,  -7.2969],\n",
      "        [ -4.2470,  -4.9690,  -7.0946, -10.2969, -10.2786,  13.3308,  -2.7441,\n",
      "          12.1113,  -8.4202,   3.8651,   8.1512,  -1.0253, -10.0545,   8.4484,\n",
      "          -9.8807,   9.8168],\n",
      "        [  9.2392,   8.3301,  11.4871,   6.1809,   8.1918,  -3.6937,  13.3132,\n",
      "          -6.4291,   4.9607,   5.0295,   3.4011,  -3.2952,   7.9262,  -6.4303,\n",
      "           9.5069,  -1.6227],\n",
      "        [ -1.4598,  -3.5983,  -5.3631,  -8.6902, -10.2845,  11.4798,  -2.5749,\n",
      "          13.4189,  -8.1109,   6.6058,   9.7473,  -6.1261,  -6.7050,   8.8123,\n",
      "         -10.4621,  12.8484],\n",
      "        [  4.2776,   5.4609,   6.0982,   9.4290,   8.1699,  -9.6872,   5.0465,\n",
      "          -9.0613,  13.0459,  -2.6268,  -6.9657,   1.9460,   8.4483,  -6.1538,\n",
      "           6.5903,  -7.0795],\n",
      "        [  7.6380,   0.0518,   3.9316,  -4.0219,  -2.7206,   4.8769,   6.8173,\n",
      "           5.4919,  -1.7074,  13.3862,  12.4459, -11.8445,   4.8968,  -2.2172,\n",
      "          -0.0827,   8.5994],\n",
      "        [  3.4445,  -1.3251,   0.4693,  -7.2355,  -5.9348,   9.8804,   5.0705,\n",
      "           8.9434,  -6.5529,  11.2322,  13.2872,  -8.6490,  -1.6910,   2.1207,\n",
      "          -3.4143,  10.3862],\n",
      "        [ -6.0339,   1.5168,  -1.8877,   4.1653,   3.4416,  -3.0944,  -2.4358,\n",
      "          -5.5690,   4.3167, -11.2026, -10.3580,  12.4276,  -4.3558,   1.1674,\n",
      "           1.1898,  -8.1980],\n",
      "        [  9.7936,   6.5320,  10.6774,   8.5954,   9.2794,  -9.7220,   8.9469,\n",
      "          -8.6721,   9.6398,   4.5944,  -0.4465,  -5.4519,  13.4487,  -9.4589,\n",
      "           9.8631,  -4.0534],\n",
      "        [ -3.2910,   1.5812,  -4.5403,  -1.9277,  -5.5637,   6.6651,  -5.8491,\n",
      "           9.9393,  -6.3692,  -3.0126,   0.7427,   1.1677,  -8.3958,  13.6438,\n",
      "          -9.7120,   9.4929],\n",
      "        [  8.4549,   9.0060,  12.0132,  10.2473,  12.9202,  -9.7858,   9.9396,\n",
      "         -11.9753,   7.6706,   0.2966,  -2.7879,   0.4330,  10.5808,  -9.0293,\n",
      "          13.5755,  -8.1746],\n",
      "        [  2.0734,  -0.6566,  -1.9173,  -5.6146,  -7.8753,   8.6374,  -0.4474,\n",
      "          12.0205,  -6.2916,   7.5937,   9.5630,  -8.5547,  -3.0033,   8.1932,\n",
      "          -8.6219,  13.6463]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([12.8661, 13.6737, 13.8382, 13.4507, 13.2827, 13.3308, 13.3132, 13.4189,\n",
      "        13.0459, 13.3862, 13.2872, 12.4276, 13.4487, 13.6438, 13.5755, 13.6463],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.3176, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 10.8177,  12.2376,   7.6816,   8.4007,  -4.8260,   9.5488,  -3.4643,\n",
      "           4.5011,   5.4776,   3.1558,  -6.1592,  10.0850,  -1.8360,   7.6320,\n",
      "           2.5216],\n",
      "        [  8.4490,  11.5354,  11.8305,  11.1800,  -6.9160,   6.8368,  -5.8999,\n",
      "           4.1468,  -2.1573,  -2.9729,   0.6884,   6.4024,   1.0323,   7.7515,\n",
      "          -1.0708],\n",
      "        [ 11.0966,  11.9876,  10.9519,  11.8600,  -8.2325,  10.7913,  -8.2041,\n",
      "           5.7086,   2.4173,  -0.0646,  -3.0875,  10.7703,  -4.9430,  11.1269,\n",
      "          -2.3347],\n",
      "        [  5.1557,  10.6222,   9.6193,  12.1470, -11.7893,   4.5749, -10.3765,\n",
      "           8.3123,  -5.6699,  -8.2678,   2.8657,   8.3355,  -3.3118,   9.0043,\n",
      "          -6.8173],\n",
      "        [  7.5776,  11.1150,  11.5221,  12.8207, -11.3787,   7.1975, -11.1991,\n",
      "           8.7534,  -2.8610,  -6.0486,   1.6623,   9.9683,  -5.5920,  11.3502,\n",
      "          -7.2969],\n",
      "        [ -4.2470,  -4.9690,  -7.0946, -10.2969, -10.2786,  -2.7441,  12.1113,\n",
      "          -8.4202,   3.8651,   8.1512,  -1.0253, -10.0545,   8.4484,  -9.8807,\n",
      "           9.8168],\n",
      "        [  9.2392,   8.3301,  11.4871,   6.1809,   8.1918,  -3.6937,  -6.4291,\n",
      "           4.9607,   5.0295,   3.4011,  -3.2952,   7.9262,  -6.4303,   9.5069,\n",
      "          -1.6227],\n",
      "        [ -1.4598,  -3.5983,  -5.3631,  -8.6902, -10.2845,  11.4798,  -2.5749,\n",
      "          -8.1109,   6.6058,   9.7473,  -6.1261,  -6.7050,   8.8123, -10.4621,\n",
      "          12.8484],\n",
      "        [  4.2776,   5.4609,   6.0982,   9.4290,   8.1699,  -9.6872,   5.0465,\n",
      "          -9.0613,  -2.6268,  -6.9657,   1.9460,   8.4483,  -6.1538,   6.5903,\n",
      "          -7.0795],\n",
      "        [  7.6380,   0.0518,   3.9316,  -4.0219,  -2.7206,   4.8769,   6.8173,\n",
      "           5.4919,  -1.7074,  12.4459, -11.8445,   4.8968,  -2.2172,  -0.0827,\n",
      "           8.5994],\n",
      "        [  3.4445,  -1.3251,   0.4693,  -7.2355,  -5.9348,   9.8804,   5.0705,\n",
      "           8.9434,  -6.5529,  11.2322,  -8.6490,  -1.6910,   2.1207,  -3.4143,\n",
      "          10.3862],\n",
      "        [ -6.0339,   1.5168,  -1.8877,   4.1653,   3.4416,  -3.0944,  -2.4358,\n",
      "          -5.5690,   4.3167, -11.2026, -10.3580,  -4.3558,   1.1674,   1.1898,\n",
      "          -8.1980],\n",
      "        [  9.7936,   6.5320,  10.6774,   8.5954,   9.2794,  -9.7220,   8.9469,\n",
      "          -8.6721,   9.6398,   4.5944,  -0.4465,  -5.4519,  -9.4589,   9.8631,\n",
      "          -4.0534],\n",
      "        [ -3.2910,   1.5812,  -4.5403,  -1.9277,  -5.5637,   6.6651,  -5.8491,\n",
      "           9.9393,  -6.3692,  -3.0126,   0.7427,   1.1677,  -8.3958,  -9.7120,\n",
      "           9.4929],\n",
      "        [  8.4549,   9.0060,  12.0132,  10.2473,  12.9202,  -9.7858,   9.9396,\n",
      "         -11.9753,   7.6706,   0.2966,  -2.7879,   0.4330,  10.5808,  -9.0293,\n",
      "          -8.1746],\n",
      "        [  2.0734,  -0.6566,  -1.9173,  -5.6146,  -7.8753,   8.6374,  -0.4474,\n",
      "          12.0205,  -6.2916,   7.5937,   9.5630,  -8.5547,  -3.0033,   8.1932,\n",
      "          -8.6219]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0188, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 5: 0.16820326447486877\n",
      "Batch 6/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1453,  0.0348, -0.1563,  ..., -0.1066, -0.0276,  0.0465],\n",
      "        [ 0.0483,  0.0266,  0.0018,  ..., -0.0537,  0.0528,  0.0666],\n",
      "        [-0.0063,  0.0481,  0.0093,  ...,  0.0258, -0.0474, -0.0113],\n",
      "        ...,\n",
      "        [-0.1676,  0.0309,  0.2130,  ...,  0.1566,  0.0609, -0.0270],\n",
      "        [ 0.1003,  0.0143, -0.0853,  ...,  0.0229, -0.2804,  0.0238],\n",
      "        [ 0.1928, -0.0435, -0.0682,  ..., -0.0797,  0.0645,  0.0568]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0849,  0.0240, -0.1407,  ..., -0.1444,  0.0239,  0.0487],\n",
      "        [ 0.0091,  0.0246,  0.0183,  ..., -0.0204,  0.0944,  0.0673],\n",
      "        [-0.0236,  0.0125,  0.0097,  ..., -0.0267, -0.0570,  0.0191],\n",
      "        ...,\n",
      "        [-0.1726,  0.0279,  0.2166,  ...,  0.1815,  0.0467, -0.0038],\n",
      "        [ 0.0484, -0.0210, -0.0655,  ..., -0.0136, -0.2243,  0.0063],\n",
      "        [ 0.1598, -0.0505, -0.0671,  ..., -0.1155,  0.0948,  0.0837]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3471e+01,  8.9656e+00,  7.2014e+00,  1.8064e+00,  7.6542e+00,\n",
      "          3.9081e+00,  1.3062e+01,  2.0796e+00, -1.2159e+01,  1.2096e+01,\n",
      "          2.0070e+00, -1.7133e+00, -1.8799e+00, -1.1949e+01,  6.9018e+00,\n",
      "          5.1096e+00],\n",
      "        [ 9.9344e+00,  1.3241e+01,  1.0989e+01,  6.0361e+00, -1.0908e+00,\n",
      "          7.9332e+00,  8.3402e+00, -4.1633e+00, -6.6770e+00,  8.1614e+00,\n",
      "          5.4772e+00, -1.6759e+00,  3.6863e+00, -5.7003e+00,  4.0196e+00,\n",
      "          2.7640e+00],\n",
      "        [ 6.4263e+00,  1.0783e+01,  1.3017e+01,  4.6035e+00, -5.0734e+00,\n",
      "          1.1972e+01,  4.9501e+00, -6.1495e+00, -1.2740e+00,  7.3523e+00,\n",
      "          3.6225e-01, -5.3221e+00, -2.4854e-01, -9.9448e-01,  6.8248e+00,\n",
      "         -4.0135e+00],\n",
      "        [ 1.4867e+00,  6.3679e+00,  6.5391e+00,  1.2722e+01, -3.0462e+00,\n",
      "          4.3796e+00, -3.0061e-01,  1.8794e+00, -7.7982e-03, -7.9243e-01,\n",
      "          2.5679e+00,  5.5881e+00,  7.2451e+00,  5.5706e-01,  2.8354e+00,\n",
      "          2.8472e+00],\n",
      "        [ 8.1020e+00, -1.0033e+00, -1.8054e+00, -1.1713e+00,  1.3414e+01,\n",
      "         -3.7609e+00,  9.5152e+00,  8.5080e+00, -1.0269e+01,  7.4595e+00,\n",
      "         -1.5895e+00,  2.8718e+00, -5.1557e+00, -1.0990e+01,  5.4761e+00,\n",
      "          6.5898e+00],\n",
      "        [ 2.6277e+00,  6.9622e+00,  1.1549e+01,  2.1776e+00, -6.6914e+00,\n",
      "          1.3189e+01,  1.8890e+00, -7.0872e+00,  2.9542e+00,  5.1434e+00,\n",
      "         -2.2118e+00, -7.9900e+00, -3.3199e+00,  2.9822e+00,  6.7473e+00,\n",
      "         -7.9139e+00],\n",
      "        [ 1.3078e+01,  7.2543e+00,  6.2953e+00, -1.5885e+00,  8.5413e+00,\n",
      "          4.0412e+00,  1.3622e+01,  1.5704e+00, -1.1742e+01,  1.3100e+01,\n",
      "          1.8783e-01, -4.1119e+00, -5.3464e+00, -1.1776e+01,  7.6373e+00,\n",
      "          3.3721e+00],\n",
      "        [ 4.0345e-01, -5.7310e+00, -5.1341e+00,  4.8219e+00,  9.0289e+00,\n",
      "         -6.9331e+00,  8.6223e-01,  1.2364e+01, -3.9943e+00, -1.4002e+00,\n",
      "         -3.4175e+00,  9.7192e+00,  2.6690e-01, -4.8193e+00,  2.9918e+00,\n",
      "          6.5844e+00],\n",
      "        [-1.1573e+01, -4.3385e+00, -1.1076e+00,  2.6251e-02, -1.0943e+01,\n",
      "          2.6245e+00, -1.1679e+01, -6.6962e+00,  1.3699e+01, -9.3725e+00,\n",
      "         -8.1523e-01, -1.2177e+00,  1.7392e+00,  1.3553e+01, -4.1773e+00,\n",
      "         -8.0571e+00],\n",
      "        [ 1.2233e+01,  8.0922e+00,  9.0930e+00, -1.0990e+00,  5.7149e+00,\n",
      "          6.9110e+00,  1.2503e+01, -4.7337e-01, -9.6657e+00,  1.3811e+01,\n",
      "         -2.4876e+00, -5.5164e+00, -6.7418e+00, -9.9684e+00,  1.0333e+01,\n",
      "         -2.9798e-01],\n",
      "        [ 2.8477e+00,  6.6357e+00,  2.5162e-01,  3.5092e+00, -3.7405e-01,\n",
      "         -1.2560e+00,  1.8969e+00, -3.4783e+00, -2.6092e+00, -1.3738e+00,\n",
      "          1.3272e+01,  3.0208e+00,  9.5601e+00, -1.1986e+00, -7.9568e+00,\n",
      "          8.4680e+00],\n",
      "        [ 4.2487e-01,  1.0652e+00, -2.8260e+00,  7.8049e+00,  4.0621e+00,\n",
      "         -6.1938e+00, -2.5341e-01,  5.8327e+00, -3.0871e+00, -3.4492e+00,\n",
      "          5.4820e+00,  1.2384e+01,  8.2600e+00, -2.8646e+00, -2.5096e+00,\n",
      "          9.8355e+00],\n",
      "        [-1.1879e+00,  4.4758e+00, -8.3920e-01,  8.6691e+00, -3.6560e+00,\n",
      "         -2.9376e+00, -3.2716e+00,  1.0370e-01,  5.2544e-01, -6.2187e+00,\n",
      "          1.0011e+01,  7.4559e+00,  1.3454e+01,  1.9740e+00, -7.8903e+00,\n",
      "          7.5759e+00],\n",
      "        [-1.1686e+01, -4.1782e+00, -2.3158e+00, -1.0278e-01, -1.0998e+01,\n",
      "          1.3659e+00, -1.2042e+01, -6.7434e+00,  1.3484e+01, -1.0501e+01,\n",
      "          1.4127e+00, -9.9082e-01,  3.6624e+00,  1.3723e+01, -6.5891e+00,\n",
      "         -6.4577e+00],\n",
      "        [ 5.8019e+00,  2.5533e+00,  7.7151e+00,  1.6988e+00,  3.3389e+00,\n",
      "          6.6427e+00,  6.0808e+00,  2.2948e+00, -3.6849e+00,  8.6953e+00,\n",
      "         -8.5767e+00, -1.7910e+00, -7.8228e+00, -4.8530e+00,  1.2840e+01,\n",
      "         -4.2394e+00],\n",
      "        [ 4.6043e+00,  2.8087e+00, -3.1052e+00,  5.7375e+00,  7.2030e+00,\n",
      "         -6.6549e+00,  4.2326e+00,  6.1412e+00, -7.2849e+00, -4.3511e-01,\n",
      "          9.1102e+00,  9.4285e+00,  8.1425e+00, -6.6005e+00, -4.3458e+00,\n",
      "          1.3136e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.4711, 13.2407, 13.0167, 12.7222, 13.4141, 13.1887, 13.6220, 12.3643,\n",
      "        13.6992, 13.8111, 13.2721, 12.3838, 13.4536, 13.7227, 12.8400, 13.1356],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.2617, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 8.9656e+00,  7.2014e+00,  1.8064e+00,  7.6542e+00,  3.9081e+00,\n",
      "          1.3062e+01,  2.0796e+00, -1.2159e+01,  1.2096e+01,  2.0070e+00,\n",
      "         -1.7133e+00, -1.8799e+00, -1.1949e+01,  6.9018e+00,  5.1096e+00],\n",
      "        [ 9.9344e+00,  1.0989e+01,  6.0361e+00, -1.0908e+00,  7.9332e+00,\n",
      "          8.3402e+00, -4.1633e+00, -6.6770e+00,  8.1614e+00,  5.4772e+00,\n",
      "         -1.6759e+00,  3.6863e+00, -5.7003e+00,  4.0196e+00,  2.7640e+00],\n",
      "        [ 6.4263e+00,  1.0783e+01,  4.6035e+00, -5.0734e+00,  1.1972e+01,\n",
      "          4.9501e+00, -6.1495e+00, -1.2740e+00,  7.3523e+00,  3.6225e-01,\n",
      "         -5.3221e+00, -2.4854e-01, -9.9448e-01,  6.8248e+00, -4.0135e+00],\n",
      "        [ 1.4867e+00,  6.3679e+00,  6.5391e+00, -3.0462e+00,  4.3796e+00,\n",
      "         -3.0061e-01,  1.8794e+00, -7.7982e-03, -7.9243e-01,  2.5679e+00,\n",
      "          5.5881e+00,  7.2451e+00,  5.5706e-01,  2.8354e+00,  2.8472e+00],\n",
      "        [ 8.1020e+00, -1.0033e+00, -1.8054e+00, -1.1713e+00, -3.7609e+00,\n",
      "          9.5152e+00,  8.5080e+00, -1.0269e+01,  7.4595e+00, -1.5895e+00,\n",
      "          2.8718e+00, -5.1557e+00, -1.0990e+01,  5.4761e+00,  6.5898e+00],\n",
      "        [ 2.6277e+00,  6.9622e+00,  1.1549e+01,  2.1776e+00, -6.6914e+00,\n",
      "          1.8890e+00, -7.0872e+00,  2.9542e+00,  5.1434e+00, -2.2118e+00,\n",
      "         -7.9900e+00, -3.3199e+00,  2.9822e+00,  6.7473e+00, -7.9139e+00],\n",
      "        [ 1.3078e+01,  7.2543e+00,  6.2953e+00, -1.5885e+00,  8.5413e+00,\n",
      "          4.0412e+00,  1.5704e+00, -1.1742e+01,  1.3100e+01,  1.8783e-01,\n",
      "         -4.1119e+00, -5.3464e+00, -1.1776e+01,  7.6373e+00,  3.3721e+00],\n",
      "        [ 4.0345e-01, -5.7310e+00, -5.1341e+00,  4.8219e+00,  9.0289e+00,\n",
      "         -6.9331e+00,  8.6223e-01, -3.9943e+00, -1.4002e+00, -3.4175e+00,\n",
      "          9.7192e+00,  2.6690e-01, -4.8193e+00,  2.9918e+00,  6.5844e+00],\n",
      "        [-1.1573e+01, -4.3385e+00, -1.1076e+00,  2.6251e-02, -1.0943e+01,\n",
      "          2.6245e+00, -1.1679e+01, -6.6962e+00, -9.3725e+00, -8.1523e-01,\n",
      "         -1.2177e+00,  1.7392e+00,  1.3553e+01, -4.1773e+00, -8.0571e+00],\n",
      "        [ 1.2233e+01,  8.0922e+00,  9.0930e+00, -1.0990e+00,  5.7149e+00,\n",
      "          6.9110e+00,  1.2503e+01, -4.7337e-01, -9.6657e+00, -2.4876e+00,\n",
      "         -5.5164e+00, -6.7418e+00, -9.9684e+00,  1.0333e+01, -2.9798e-01],\n",
      "        [ 2.8477e+00,  6.6357e+00,  2.5162e-01,  3.5092e+00, -3.7405e-01,\n",
      "         -1.2560e+00,  1.8969e+00, -3.4783e+00, -2.6092e+00, -1.3738e+00,\n",
      "          3.0208e+00,  9.5601e+00, -1.1986e+00, -7.9568e+00,  8.4680e+00],\n",
      "        [ 4.2487e-01,  1.0652e+00, -2.8260e+00,  7.8049e+00,  4.0621e+00,\n",
      "         -6.1938e+00, -2.5341e-01,  5.8327e+00, -3.0871e+00, -3.4492e+00,\n",
      "          5.4820e+00,  8.2600e+00, -2.8646e+00, -2.5096e+00,  9.8355e+00],\n",
      "        [-1.1879e+00,  4.4758e+00, -8.3920e-01,  8.6691e+00, -3.6560e+00,\n",
      "         -2.9376e+00, -3.2716e+00,  1.0370e-01,  5.2544e-01, -6.2187e+00,\n",
      "          1.0011e+01,  7.4559e+00,  1.9740e+00, -7.8903e+00,  7.5759e+00],\n",
      "        [-1.1686e+01, -4.1782e+00, -2.3158e+00, -1.0278e-01, -1.0998e+01,\n",
      "          1.3659e+00, -1.2042e+01, -6.7434e+00,  1.3484e+01, -1.0501e+01,\n",
      "          1.4127e+00, -9.9082e-01,  3.6624e+00, -6.5891e+00, -6.4577e+00],\n",
      "        [ 5.8019e+00,  2.5533e+00,  7.7151e+00,  1.6988e+00,  3.3389e+00,\n",
      "          6.6427e+00,  6.0808e+00,  2.2948e+00, -3.6849e+00,  8.6953e+00,\n",
      "         -8.5767e+00, -1.7910e+00, -7.8228e+00, -4.8530e+00, -4.2394e+00],\n",
      "        [ 4.6043e+00,  2.8087e+00, -3.1052e+00,  5.7375e+00,  7.2030e+00,\n",
      "         -6.6549e+00,  4.2326e+00,  6.1412e+00, -7.2849e+00, -4.3511e-01,\n",
      "          9.1102e+00,  9.4285e+00,  8.1425e+00, -6.6005e+00, -4.3458e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0161, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 6: 0.13886885344982147\n",
      "Batch 7/7: Matrix features: torch.Size([4, 128]), Vector features: torch.Size([4, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-8.0600e-02,  8.8322e-02,  1.1384e-01,  9.4200e-02,  3.4572e-02,\n",
      "          2.2978e-01,  1.2596e-02, -3.1750e-02, -4.9412e-02, -2.2416e-03,\n",
      "         -3.4337e-02,  6.2277e-02, -7.9775e-02,  1.1121e-01, -1.3526e-01,\n",
      "         -1.4907e-01,  4.0680e-02,  1.1767e-02, -4.8683e-03,  4.7062e-02,\n",
      "          2.0713e-01,  1.0648e-01, -2.3534e-02,  3.7183e-02, -4.3099e-02,\n",
      "          1.5237e-01, -9.3635e-02,  8.1314e-03, -1.0832e-01,  3.7818e-03,\n",
      "          4.2305e-02, -2.5670e-02, -6.9147e-03, -7.5105e-04,  2.1416e-02,\n",
      "         -4.1370e-02, -4.7256e-02,  1.7170e-01,  3.9792e-02,  7.1572e-02,\n",
      "          7.9486e-02,  9.0668e-02,  2.6176e-02, -1.2523e-01, -7.1072e-02,\n",
      "         -1.2766e-01,  9.3820e-02, -7.4593e-02, -1.6229e-01, -1.3383e-01,\n",
      "          5.6636e-02, -1.1881e-01, -1.4144e-01,  6.5633e-02,  9.3816e-03,\n",
      "          1.8756e-02,  7.4320e-02,  1.9511e-01,  9.3510e-02, -1.7355e-01,\n",
      "         -9.3272e-03,  2.0100e-01,  2.5252e-02, -8.3332e-03,  1.1492e-01,\n",
      "         -7.9119e-02,  1.7731e-02, -3.4861e-02,  1.9097e-02, -6.7241e-02,\n",
      "         -1.1055e-01, -1.7425e-02, -1.0694e-01, -1.2866e-02, -7.4249e-02,\n",
      "         -1.3619e-01,  1.3748e-01,  2.7573e-02,  9.7204e-02,  9.7056e-02,\n",
      "          5.5058e-02, -8.6878e-02, -5.0844e-02,  5.2626e-02, -4.6106e-02,\n",
      "         -1.5994e-01,  4.0559e-02, -1.2620e-01, -1.5432e-01, -2.5068e-02,\n",
      "         -7.3313e-02, -3.6724e-02, -8.7979e-02, -9.2135e-02,  5.7295e-02,\n",
      "          5.0418e-02,  9.7167e-02,  6.4569e-02, -5.6568e-02,  1.4677e-02,\n",
      "          1.7623e-02, -7.8897e-02, -2.1788e-03,  7.5492e-02, -9.7820e-02,\n",
      "         -1.2763e-02,  2.4701e-02,  7.9124e-02, -4.4008e-02,  3.3054e-02,\n",
      "          5.6041e-02, -8.3806e-02, -9.4054e-02,  8.9809e-02, -9.4823e-02,\n",
      "          4.2124e-02, -6.3649e-02, -5.0501e-02, -1.5250e-01,  6.6545e-03,\n",
      "          1.3220e-02,  8.6565e-02,  9.2454e-02, -1.2871e-01,  1.0314e-01,\n",
      "          5.3799e-02,  1.6065e-01,  2.4804e-02],\n",
      "        [-9.9010e-02,  3.4839e-02,  2.3758e-01,  1.2551e-02, -2.7149e-02,\n",
      "          1.4651e-01,  8.9407e-02, -6.3519e-03, -1.8623e-01, -1.1878e-01,\n",
      "         -1.1201e-01,  6.3674e-02, -5.4868e-03,  8.5173e-02, -1.0363e-01,\n",
      "         -1.8135e-01, -9.9131e-03, -9.8449e-02, -9.3927e-02,  5.6555e-02,\n",
      "          7.8532e-02,  1.2379e-01, -4.7622e-02,  1.3322e-02, -9.3520e-02,\n",
      "          1.8431e-01, -8.5606e-03,  1.4328e-02, -4.4310e-02,  5.5984e-02,\n",
      "          6.9695e-02, -2.8271e-03, -2.3326e-02,  3.6015e-02,  1.0390e-01,\n",
      "         -3.0096e-02,  3.1501e-02,  9.0877e-02, -1.1169e-02,  9.7282e-02,\n",
      "          5.8066e-02, -4.5534e-02,  8.9515e-02,  1.2134e-02,  6.2365e-02,\n",
      "         -1.3592e-01,  5.9191e-02, -4.2371e-03, -4.2136e-02, -9.7614e-02,\n",
      "          1.7504e-01, -3.6662e-02,  4.4153e-04,  1.4570e-01,  7.1020e-02,\n",
      "          5.6050e-02,  4.2638e-02,  5.3958e-02,  1.0612e-02, -4.6961e-02,\n",
      "         -8.3099e-02,  1.2503e-01,  2.7554e-02,  8.3791e-02,  9.5326e-02,\n",
      "         -1.2980e-01,  4.5334e-02,  1.7410e-02,  1.9506e-02, -7.0610e-02,\n",
      "         -3.7766e-02, -2.1642e-02, -5.8545e-02,  2.8161e-02,  4.9385e-02,\n",
      "         -6.1351e-02, -7.6899e-02, -4.8584e-02,  5.9348e-02,  3.2892e-02,\n",
      "          4.8425e-02, -1.6972e-02,  1.7978e-02,  6.8634e-04, -5.7088e-02,\n",
      "         -1.8244e-01,  8.8127e-02,  4.6293e-02, -2.4110e-01,  4.1230e-02,\n",
      "         -7.4986e-02, -6.4788e-02,  1.2246e-02, -2.1058e-01,  8.0741e-02,\n",
      "          3.1651e-02,  1.2343e-02,  2.0030e-01, -1.6913e-01,  8.6460e-02,\n",
      "          9.1414e-02, -6.0179e-02, -5.0924e-02, -6.3531e-02, -9.5277e-02,\n",
      "         -1.0262e-01,  1.1550e-02,  4.9771e-02, -4.9558e-03, -2.2222e-02,\n",
      "         -3.9695e-02,  5.7462e-02, -4.1568e-02, -4.2221e-02, -8.1944e-02,\n",
      "         -1.8641e-01, -1.0800e-01,  6.2431e-04,  9.3020e-03, -1.1562e-02,\n",
      "         -1.2408e-01,  5.8304e-02,  7.8646e-02, -1.0016e-01,  2.0723e-01,\n",
      "          1.2388e-01,  4.9941e-02, -6.4418e-03],\n",
      "        [-1.6124e-01,  2.4093e-02,  1.4894e-01,  2.8567e-03, -4.1936e-02,\n",
      "         -2.2817e-02,  8.9854e-02, -4.8206e-02, -2.3984e-01, -1.4120e-01,\n",
      "         -9.2837e-02, -1.9176e-03, -4.5516e-02,  1.3372e-01, -9.9007e-02,\n",
      "         -1.9683e-01,  8.4607e-02,  5.5104e-02, -1.8646e-03, -2.1774e-02,\n",
      "         -1.0012e-02,  1.8322e-01, -9.2611e-02,  8.8253e-02,  3.5807e-02,\n",
      "          1.2490e-01, -4.6229e-03, -7.2862e-02,  6.2425e-02,  2.0191e-02,\n",
      "          1.3250e-01,  7.5273e-02, -6.7564e-02, -1.3366e-01,  7.1897e-02,\n",
      "          9.7992e-04, -7.9164e-02,  6.2395e-02,  5.0543e-02,  7.9725e-02,\n",
      "         -3.4764e-02, -9.2312e-02,  1.5210e-01,  1.3879e-01,  9.6610e-02,\n",
      "         -1.9506e-02, -5.0714e-03,  2.7774e-02, -6.9536e-02, -2.9102e-02,\n",
      "          1.0959e-01,  1.2374e-02,  2.4046e-02,  3.2939e-02,  6.5567e-02,\n",
      "          1.3572e-01,  3.0928e-02, -2.4160e-02, -6.1934e-02, -1.1605e-01,\n",
      "          3.0037e-02,  5.4278e-02,  3.9213e-02,  1.6643e-01, -4.5550e-02,\n",
      "         -1.0550e-01,  7.8887e-02,  5.9062e-02,  5.6477e-02, -1.0169e-01,\n",
      "         -4.8176e-02,  4.0619e-03, -3.2681e-02, -8.2903e-02,  8.0712e-02,\n",
      "         -3.6642e-02, -3.7605e-02,  6.5906e-02,  2.1663e-02,  5.6250e-02,\n",
      "          4.7014e-03,  8.4820e-02,  1.2453e-02, -3.4758e-02, -1.4005e-01,\n",
      "         -1.6184e-01,  2.6588e-02,  9.7890e-02, -1.5352e-01,  5.3365e-02,\n",
      "         -1.1735e-01, -1.9572e-02,  3.4228e-02, -1.8523e-01,  3.9257e-02,\n",
      "          8.4013e-02,  7.0978e-02,  1.6503e-01, -2.7257e-01,  7.1577e-02,\n",
      "          1.0337e-01,  1.6735e-02, -7.8402e-02, -7.9990e-02, -1.4009e-01,\n",
      "         -9.5254e-02,  1.3103e-02,  3.2545e-02, -5.7905e-03,  1.0284e-01,\n",
      "         -1.2555e-02,  4.9723e-02,  5.3218e-02, -6.8739e-02,  6.7092e-02,\n",
      "         -1.1074e-01, -1.2904e-01, -3.1502e-02, -4.4067e-02, -2.1939e-02,\n",
      "          1.1700e-02,  2.2949e-02,  7.9403e-02, -4.2787e-02,  2.9976e-02,\n",
      "          1.1012e-01,  4.9671e-02, -9.8539e-02],\n",
      "        [-8.4097e-02,  2.7731e-02,  8.6201e-02,  1.0447e-01, -3.6987e-04,\n",
      "          1.8880e-01, -2.7462e-03, -5.4472e-02, -7.4196e-02, -4.1090e-02,\n",
      "          3.8413e-02,  6.8359e-02, -9.3833e-02,  9.8256e-02, -1.4390e-01,\n",
      "         -1.2018e-01,  4.6364e-02,  8.4586e-02,  3.7669e-02,  3.9024e-02,\n",
      "          1.8740e-01,  4.6677e-02, -1.9701e-02,  3.1369e-02, -4.4779e-02,\n",
      "          1.7758e-01, -6.2140e-02, -1.0839e-02, -1.0673e-01,  4.5641e-02,\n",
      "          2.1942e-02, -5.2066e-02,  3.6293e-02, -3.1562e-02,  5.7083e-03,\n",
      "         -2.4617e-02, -2.0752e-02,  2.4356e-01, -8.3986e-03, -3.0002e-02,\n",
      "          6.3103e-02,  1.0862e-01, -5.1405e-02, -1.9606e-01, -8.0072e-02,\n",
      "         -9.0372e-02,  1.6535e-01, -5.3291e-02, -1.5712e-01, -7.2292e-02,\n",
      "         -2.6501e-02, -1.1122e-01, -1.5850e-01,  2.9827e-03,  2.1675e-02,\n",
      "          9.3346e-03,  3.6965e-02,  1.9811e-01,  8.8302e-02, -7.8098e-02,\n",
      "         -7.0221e-03,  1.9098e-01,  9.9676e-03, -6.4111e-02,  1.8293e-01,\n",
      "         -9.3949e-02, -2.4640e-02, -4.1390e-02,  5.4458e-02, -1.0474e-01,\n",
      "         -1.2193e-01,  2.7101e-02, -1.5338e-01, -3.1569e-03, -1.0360e-01,\n",
      "         -6.4298e-02,  1.6517e-01,  1.4765e-02,  1.0065e-01,  9.4577e-02,\n",
      "          5.2143e-02, -8.2219e-02, -9.1634e-02,  1.0399e-01, -9.6244e-05,\n",
      "         -9.2456e-02,  2.2359e-02, -1.3213e-01, -8.6003e-02, -4.7061e-02,\n",
      "         -4.7617e-02, -1.0120e-02, -5.4034e-02, -8.6500e-02,  3.3388e-02,\n",
      "          5.2613e-03,  1.3455e-01,  6.4385e-02, -4.2789e-02,  4.7140e-06,\n",
      "         -5.7334e-02, -4.5269e-02, -3.2584e-02,  1.1648e-01, -1.0564e-01,\n",
      "          1.9393e-02,  7.5533e-02,  9.3860e-04, -2.1114e-02,  1.0046e-02,\n",
      "          4.7012e-02, -1.2645e-01, -1.2664e-01,  1.1725e-01, -8.5438e-02,\n",
      "          2.2941e-03, -2.4295e-04, -6.1300e-02, -1.0547e-01,  5.3253e-02,\n",
      "          2.6138e-02,  6.8830e-02,  1.5530e-01, -1.0143e-01,  7.9109e-02,\n",
      "          3.6787e-02,  1.1076e-01,  3.9136e-02]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.1773,  0.0846,  0.1279,  0.1268,  0.0555,  0.1860, -0.0334, -0.0420,\n",
      "         -0.0448,  0.0078, -0.0609,  0.0706, -0.0414,  0.0998, -0.0873, -0.1581,\n",
      "          0.0446, -0.0100, -0.0164,  0.0369,  0.1217,  0.0933, -0.0044,  0.0151,\n",
      "         -0.0247,  0.2053, -0.1401, -0.0164, -0.0712,  0.0297, -0.0007,  0.0494,\n",
      "         -0.0276,  0.0079,  0.0178, -0.0367, -0.0887,  0.1087,  0.0602,  0.0957,\n",
      "          0.0747,  0.0728,  0.0392, -0.0849, -0.0712, -0.0671,  0.0849, -0.0589,\n",
      "         -0.1517, -0.1363,  0.0457, -0.1261, -0.1245,  0.0626, -0.0227, -0.0231,\n",
      "          0.0908,  0.1880,  0.1251, -0.1260, -0.0329,  0.1684,  0.0322,  0.0349,\n",
      "          0.0159, -0.0887, -0.0059, -0.0626, -0.0008, -0.0254, -0.0820, -0.0581,\n",
      "         -0.0591, -0.0520, -0.1164, -0.1931,  0.1425,  0.0566,  0.1010,  0.1071,\n",
      "          0.0895, -0.1308, -0.0218,  0.0555, -0.0846, -0.1717,  0.0201, -0.1121,\n",
      "         -0.0796, -0.0218, -0.0644, -0.0540, -0.1031, -0.1488,  0.0173,  0.0381,\n",
      "          0.0537, -0.0158, -0.0906, -0.0119,  0.0426, -0.0744,  0.0117,  0.0939,\n",
      "         -0.0433, -0.0161,  0.0636,  0.0929, -0.0324,  0.0384,  0.0635, -0.1185,\n",
      "         -0.0335,  0.1685, -0.0221,  0.0686, -0.0636, -0.0168, -0.1572,  0.0025,\n",
      "          0.0271,  0.1219,  0.1213, -0.0908,  0.0899, -0.0045,  0.2126,  0.0518],\n",
      "        [-0.1347,  0.0386,  0.2390,  0.0478, -0.0101,  0.0987,  0.0452, -0.0477,\n",
      "         -0.0796, -0.0860, -0.1225,  0.0687,  0.0488,  0.0630, -0.1106, -0.1846,\n",
      "         -0.0139, -0.1110, -0.0763,  0.0223,  0.0169,  0.1591, -0.0631,  0.0420,\n",
      "         -0.0662,  0.1807, -0.0353,  0.0333, -0.0094,  0.0349,  0.0562,  0.0107,\n",
      "         -0.0528,  0.0129,  0.0734, -0.0408,  0.0105,  0.0555,  0.0503,  0.1502,\n",
      "          0.0389, -0.0919,  0.1571,  0.0922,  0.0663, -0.0583,  0.0262, -0.0128,\n",
      "         -0.0063, -0.1058,  0.2295, -0.0759,  0.0718,  0.1343,  0.0467,  0.0365,\n",
      "          0.0609, -0.0032,  0.0200, -0.0595, -0.1019,  0.0611,  0.0124,  0.1493,\n",
      "          0.0071, -0.1397,  0.0776, -0.0045, -0.0290, -0.0176, -0.0224, -0.0721,\n",
      "          0.0007, -0.0479,  0.0532, -0.0681, -0.1148, -0.0133,  0.0350,  0.0245,\n",
      "          0.0602,  0.0101,  0.0478,  0.0045, -0.1082, -0.2496,  0.0700,  0.0794,\n",
      "         -0.2153,  0.0642, -0.0663, -0.0732,  0.0551, -0.2555,  0.0712,  0.0219,\n",
      "         -0.0114,  0.0988, -0.1778,  0.0868,  0.1078, -0.0366, -0.0417, -0.0936,\n",
      "         -0.0221, -0.1246, -0.0248,  0.0835, -0.0004,  0.0489, -0.0447,  0.0315,\n",
      "          0.0291, -0.0253, -0.0386, -0.1684, -0.1404, -0.0107, -0.0225, -0.0104,\n",
      "         -0.1091,  0.0995,  0.0486, -0.0511,  0.1282,  0.1083,  0.0679,  0.0177],\n",
      "        [-0.1557,  0.0023,  0.1621, -0.0013, -0.0309, -0.0729,  0.0613, -0.0480,\n",
      "         -0.2114, -0.1258, -0.0672, -0.0505, -0.0329,  0.1262, -0.0507, -0.2102,\n",
      "          0.0519,  0.0460,  0.0133, -0.0587, -0.0385,  0.2028, -0.0723,  0.0668,\n",
      "          0.0695,  0.1031, -0.0161, -0.0762,  0.0788,  0.0368,  0.1408,  0.1240,\n",
      "         -0.0651, -0.1216,  0.0585,  0.0033, -0.1288, -0.0090,  0.0423,  0.0871,\n",
      "         -0.0378, -0.0995,  0.1958,  0.1550,  0.0768, -0.0083, -0.0292,  0.0542,\n",
      "         -0.0296, -0.0336,  0.1237, -0.0280,  0.0462,  0.0262, -0.0043,  0.1269,\n",
      "          0.0424, -0.0389, -0.0701, -0.0772, -0.0102,  0.0161,  0.0441,  0.1656,\n",
      "         -0.1122, -0.0546,  0.1168,  0.0949,  0.0487, -0.1133, -0.0210,  0.0162,\n",
      "          0.0114, -0.0965,  0.0734, -0.0289, -0.0438,  0.0314, -0.0017,  0.0609,\n",
      "          0.0090,  0.0931, -0.0300, -0.0260, -0.1823, -0.1632,  0.0092,  0.1143,\n",
      "         -0.1116,  0.0395, -0.1345, -0.0336,  0.0177, -0.1512,  0.0277,  0.0479,\n",
      "          0.0236,  0.1234, -0.2278,  0.0302,  0.1327,  0.0449, -0.0748, -0.1095,\n",
      "         -0.1174, -0.0963, -0.0134,  0.0128, -0.0164,  0.1491, -0.0193,  0.0887,\n",
      "          0.0604, -0.0186,  0.1097, -0.1143, -0.0965, -0.0091, -0.0422, -0.0369,\n",
      "          0.0393,  0.0262,  0.0589, -0.0283,  0.0366,  0.1081,  0.1267, -0.1076],\n",
      "        [-0.1361,  0.0404,  0.1153,  0.1281,  0.0271,  0.1536, -0.0186, -0.0908,\n",
      "         -0.0483, -0.0475, -0.0018,  0.0685, -0.0185,  0.1225, -0.1262, -0.1410,\n",
      "          0.0475,  0.0332,  0.0342, -0.0300,  0.1374,  0.0622, -0.0383,  0.0216,\n",
      "         -0.0345,  0.2216, -0.1022, -0.0058, -0.1436,  0.0832,  0.0536,  0.0263,\n",
      "          0.0564, -0.0624,  0.0361, -0.0068, -0.0820,  0.2432,  0.0025, -0.0193,\n",
      "          0.0322,  0.0924,  0.0175, -0.1531, -0.0698, -0.0341,  0.1513, -0.0758,\n",
      "         -0.2322, -0.0979, -0.0219, -0.1433, -0.1032,  0.0077,  0.0749,  0.0402,\n",
      "          0.0595,  0.0901,  0.1044, -0.1402, -0.0170,  0.1645,  0.0639,  0.0021,\n",
      "          0.1238, -0.1082, -0.0239, -0.0615,  0.0546, -0.1130, -0.1328,  0.0104,\n",
      "         -0.0874, -0.0895, -0.0865, -0.0966,  0.1628,  0.0437,  0.1450,  0.1136,\n",
      "          0.0863, -0.0566, -0.0952,  0.0700, -0.0387, -0.1209,  0.0364, -0.1177,\n",
      "         -0.0154, -0.0647, -0.0768, -0.0145, -0.0297, -0.1090, -0.0118, -0.0098,\n",
      "          0.1499,  0.0586, -0.0654, -0.0271, -0.0130, -0.0202, -0.0410,  0.0946,\n",
      "         -0.0735, -0.0280,  0.0862,  0.0615, -0.0630,  0.0779,  0.0170, -0.0685,\n",
      "         -0.1255,  0.1488, -0.0621, -0.0440, -0.0373, -0.0638, -0.0635,  0.0219,\n",
      "          0.0426,  0.0488,  0.1389, -0.0660,  0.0946,  0.0449,  0.0971,  0.0185]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.1667,  6.5860,  3.0849, 12.5258],\n",
      "        [ 7.2363, 12.9453,  8.4700,  6.8367],\n",
      "        [ 4.6695, 10.7081, 13.5691,  4.8062],\n",
      "        [11.4648,  3.1749,  0.5540, 13.0878]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.1667, 12.9453, 13.5691, 13.0878], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1692, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 6.5860,  3.0849, 12.5258],\n",
      "        [ 7.2363,  8.4700,  6.8367],\n",
      "        [ 4.6695, 10.7081,  4.8062],\n",
      "        [11.4648,  3.1749,  0.5540]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0564, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 7: 0.11279795318841934\n",
      "Epoch [4/10], Loss: 0.1480\n",
      "Batch 1/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.1105,  0.0140,  0.1657,  ...,  0.1125,  0.1683, -0.0387],\n",
      "        [ 0.1385, -0.0096, -0.1233,  ..., -0.0799,  0.0458,  0.0539],\n",
      "        [ 0.1031,  0.0057, -0.1124,  ..., -0.0435, -0.2620, -0.0447],\n",
      "        ...,\n",
      "        [ 0.0201,  0.0420,  0.0086,  ..., -0.0557,  0.2503,  0.0737],\n",
      "        [-0.0167,  0.0102,  0.0313,  ...,  0.0807, -0.2219, -0.0545],\n",
      "        [ 0.0158, -0.0159, -0.0490,  ...,  0.0414, -0.1464, -0.0350]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0950, -0.0121,  0.1372,  ...,  0.0514,  0.0887, -0.0426],\n",
      "        [ 0.1121,  0.0161, -0.0823,  ..., -0.0948,  0.0886,  0.0810],\n",
      "        [ 0.0707, -0.0143, -0.1283,  ..., -0.0457, -0.2748, -0.0499],\n",
      "        ...,\n",
      "        [-0.0024,  0.0395,  0.0233,  ..., -0.0757,  0.2111,  0.0704],\n",
      "        [-0.0564,  0.0292,  0.0444,  ...,  0.0911, -0.2226, -0.0600],\n",
      "        [-0.0058, -0.0338, -0.0456,  ...,  0.0068, -0.1727,  0.0070]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 12.9394,  -7.5063,  -8.9342,   0.6495,   1.2245,  -2.5087,  -2.9185,\n",
      "           0.4005,  -1.6542,  -9.9819, -11.5713,   6.3690,  -3.5463,  -1.7626,\n",
      "           2.2658,   3.4563],\n",
      "        [ -9.1278,  13.5901,   0.7411,   4.7838,   5.9261,   0.0542,   9.1594,\n",
      "          -9.4133,  11.4969,   4.2651,   3.2925,  -7.9393,  -3.2384,  10.0933,\n",
      "         -10.5160,  -5.4556],\n",
      "        [ -6.5571,   0.3812,  13.8409,  -9.1199,  -9.7961,  -4.3113,   3.6280,\n",
      "           7.9006,  -4.7951,   4.6663,  10.7413,   2.3613,  11.3998,  -6.6441,\n",
      "           7.0645,   6.2965],\n",
      "        [ -4.5684,   7.4112,  -7.7574,  13.5603,  13.0779,  11.0096,  -2.3006,\n",
      "          -9.4288,   6.4548,   6.8616,  -0.3312,  -7.3853, -12.0347,  11.6609,\n",
      "         -10.0228, -12.4405],\n",
      "        [ -3.3944,   8.9103,  -9.4028,  12.6415,  13.4782,   8.0820,  -0.3525,\n",
      "         -11.0981,   9.5457,   3.7847,  -3.3227,  -8.9876, -12.4274,  12.4788,\n",
      "         -11.7737, -11.3909],\n",
      "        [ -5.7354,   2.3543,  -3.0393,  10.2097,   8.6562,  13.2549,  -8.0538,\n",
      "          -2.6519,  -0.6124,  10.2159,   4.2764,  -5.7537,  -7.9365,   5.7539,\n",
      "          -3.5721, -11.2781],\n",
      "        [ -3.3025,   7.1542,   5.7229,  -3.9560,  -3.4832,  -8.1368,  13.1814,\n",
      "          -3.2535,   5.6849,  -1.6568,   2.8506,   2.2427,   5.0020,   2.7387,\n",
      "          -2.9292,   4.9768],\n",
      "        [  1.6310,  -8.7968,   8.4427,  -8.8829,  -9.5133,  -2.6808,  -6.2656,\n",
      "          13.5342, -10.9990,   0.2603,   3.7142,   4.5698,   8.3528, -11.8957,\n",
      "          12.2867,   6.9379],\n",
      "        [ -5.4807,  12.5904,  -4.7229,   7.2489,   9.2188,   0.8284,   7.0873,\n",
      "         -11.5478,  13.4021,   1.3885,  -2.0211,  -9.1038,  -6.9559,  11.4617,\n",
      "         -12.1881,  -7.0079],\n",
      "        [-11.4564,   7.0934,   3.8561,   6.7490,   5.3894,  10.4676,  -2.1724,\n",
      "          -2.3968,   0.8632,  13.2487,  10.2085,  -6.8915,  -3.0592,   5.8894,\n",
      "          -3.8075,  -8.8158],\n",
      "        [-10.7578,   3.2887,  11.5454,  -2.5087,  -4.2719,   3.4324,   0.8407,\n",
      "           3.9460,  -3.4578,  10.5203,  13.7064,  -1.1778,   6.5550,  -1.6821,\n",
      "           3.0685,  -0.8813],\n",
      "        [  8.0965,  -8.1799,   2.3630,  -5.8790,  -7.8173,  -5.1672,   2.0508,\n",
      "           5.7007,  -7.3479,  -6.4090,  -1.2091,  13.5567,   5.8644,  -6.2889,\n",
      "           7.8770,   8.5431],\n",
      "        [ -0.3884,  -4.4817,  11.9768, -12.0818, -12.0622,  -7.5076,   2.7482,\n",
      "          10.2707,  -6.6884,  -0.3947,   6.2304,   5.6923,  13.5556, -10.1807,\n",
      "          10.5528,  10.9226],\n",
      "        [ -6.0294,  11.7723,  -6.2305,  11.5914,  12.0126,   6.1235,   4.4983,\n",
      "         -12.3382,  11.0827,   4.7306,  -0.2765,  -7.9263, -10.1256,  13.6957,\n",
      "         -12.8486, -10.4590],\n",
      "        [  5.2718, -11.3768,   7.5114, -10.3995, -11.0087,  -4.5384,  -5.0181,\n",
      "          13.4918, -11.8238,  -2.4874,   1.8809,   7.9828,  10.1020, -13.0985,\n",
      "          13.8147,   9.9460],\n",
      "        [  7.2440,  -8.5688,   6.2234, -12.2468, -11.7905, -10.3315,   2.1142,\n",
      "           9.9933,  -7.5192,  -7.4567,  -1.5448,   9.2386,  10.8046, -11.0655,\n",
      "          10.8140,  13.6021]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([12.9394, 13.5901, 13.8409, 13.5603, 13.4782, 13.2549, 13.1814, 13.5342,\n",
      "        13.4021, 13.2487, 13.7064, 13.5567, 13.5556, 13.6957, 13.8147, 13.6021],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.2550, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ -7.5063,  -8.9342,   0.6495,   1.2245,  -2.5087,  -2.9185,   0.4005,\n",
      "          -1.6542,  -9.9819, -11.5713,   6.3690,  -3.5463,  -1.7626,   2.2658,\n",
      "           3.4563],\n",
      "        [ -9.1278,   0.7411,   4.7838,   5.9261,   0.0542,   9.1594,  -9.4133,\n",
      "          11.4969,   4.2651,   3.2925,  -7.9393,  -3.2384,  10.0933, -10.5160,\n",
      "          -5.4556],\n",
      "        [ -6.5571,   0.3812,  -9.1199,  -9.7961,  -4.3113,   3.6280,   7.9006,\n",
      "          -4.7951,   4.6663,  10.7413,   2.3613,  11.3998,  -6.6441,   7.0645,\n",
      "           6.2965],\n",
      "        [ -4.5684,   7.4112,  -7.7574,  13.0779,  11.0096,  -2.3006,  -9.4288,\n",
      "           6.4548,   6.8616,  -0.3312,  -7.3853, -12.0347,  11.6609, -10.0228,\n",
      "         -12.4405],\n",
      "        [ -3.3944,   8.9103,  -9.4028,  12.6415,   8.0820,  -0.3525, -11.0981,\n",
      "           9.5457,   3.7847,  -3.3227,  -8.9876, -12.4274,  12.4788, -11.7737,\n",
      "         -11.3909],\n",
      "        [ -5.7354,   2.3543,  -3.0393,  10.2097,   8.6562,  -8.0538,  -2.6519,\n",
      "          -0.6124,  10.2159,   4.2764,  -5.7537,  -7.9365,   5.7539,  -3.5721,\n",
      "         -11.2781],\n",
      "        [ -3.3025,   7.1542,   5.7229,  -3.9560,  -3.4832,  -8.1368,  -3.2535,\n",
      "           5.6849,  -1.6568,   2.8506,   2.2427,   5.0020,   2.7387,  -2.9292,\n",
      "           4.9768],\n",
      "        [  1.6310,  -8.7968,   8.4427,  -8.8829,  -9.5133,  -2.6808,  -6.2656,\n",
      "         -10.9990,   0.2603,   3.7142,   4.5698,   8.3528, -11.8957,  12.2867,\n",
      "           6.9379],\n",
      "        [ -5.4807,  12.5904,  -4.7229,   7.2489,   9.2188,   0.8284,   7.0873,\n",
      "         -11.5478,   1.3885,  -2.0211,  -9.1038,  -6.9559,  11.4617, -12.1881,\n",
      "          -7.0079],\n",
      "        [-11.4564,   7.0934,   3.8561,   6.7490,   5.3894,  10.4676,  -2.1724,\n",
      "          -2.3968,   0.8632,  10.2085,  -6.8915,  -3.0592,   5.8894,  -3.8075,\n",
      "          -8.8158],\n",
      "        [-10.7578,   3.2887,  11.5454,  -2.5087,  -4.2719,   3.4324,   0.8407,\n",
      "           3.9460,  -3.4578,  10.5203,  -1.1778,   6.5550,  -1.6821,   3.0685,\n",
      "          -0.8813],\n",
      "        [  8.0965,  -8.1799,   2.3630,  -5.8790,  -7.8173,  -5.1672,   2.0508,\n",
      "           5.7007,  -7.3479,  -6.4090,  -1.2091,   5.8644,  -6.2889,   7.8770,\n",
      "           8.5431],\n",
      "        [ -0.3884,  -4.4817,  11.9768, -12.0818, -12.0622,  -7.5076,   2.7482,\n",
      "          10.2707,  -6.6884,  -0.3947,   6.2304,   5.6923, -10.1807,  10.5528,\n",
      "          10.9226],\n",
      "        [ -6.0294,  11.7723,  -6.2305,  11.5914,  12.0126,   6.1235,   4.4983,\n",
      "         -12.3382,  11.0827,   4.7306,  -0.2765,  -7.9263, -10.1256, -12.8486,\n",
      "         -10.4590],\n",
      "        [  5.2718, -11.3768,   7.5114, -10.3995, -11.0087,  -4.5384,  -5.0181,\n",
      "          13.4918, -11.8238,  -2.4874,   1.8809,   7.9828,  10.1020, -13.0985,\n",
      "           9.9460],\n",
      "        [  7.2440,  -8.5688,   6.2234, -12.2468, -11.7905, -10.3315,   2.1142,\n",
      "           9.9933,  -7.5192,  -7.4567,  -1.5448,   9.2386,  10.8046, -11.0655,\n",
      "          10.8140]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0155, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 1: 0.13523049652576447\n",
      "Batch 2/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 3.3578e-02,  5.4651e-03,  8.5439e-02,  ...,  1.5814e-02,\n",
      "          1.2955e-01,  6.3872e-02],\n",
      "        [-3.9077e-02,  1.8145e-02,  1.1960e-01,  ...,  1.0613e-01,\n",
      "         -1.9880e-01,  2.0893e-04],\n",
      "        [ 7.6537e-02, -3.5099e-02, -1.7293e-02,  ...,  4.5692e-02,\n",
      "         -1.5282e-01, -3.9926e-02],\n",
      "        ...,\n",
      "        [ 6.3973e-02, -6.7691e-03, -1.2208e-01,  ..., -1.0257e-02,\n",
      "         -2.3747e-01, -7.4424e-02],\n",
      "        [-1.6909e-01,  2.3034e-02,  8.6506e-02,  ...,  1.1186e-01,\n",
      "          3.4366e-02, -6.4422e-02],\n",
      "        [ 6.2365e-02,  1.7472e-02, -3.2397e-02,  ..., -7.0680e-02,\n",
      "          1.8596e-01,  3.3884e-02]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0424, -0.0007,  0.0922,  ...,  0.0006,  0.2024,  0.0776],\n",
      "        [-0.0863, -0.0085,  0.1158,  ...,  0.1530, -0.2235, -0.0225],\n",
      "        [ 0.0265, -0.0288,  0.0068,  ...,  0.0073, -0.1090, -0.0180],\n",
      "        ...,\n",
      "        [ 0.0289, -0.0279, -0.1052,  ..., -0.0067, -0.2457, -0.0655],\n",
      "        [-0.1855, -0.0162,  0.0619,  ...,  0.1232,  0.0380, -0.0855],\n",
      "        [-0.0027,  0.0065, -0.0353,  ..., -0.0845,  0.1801,  0.0043]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.6096,  -0.6831,  -7.8441,  -1.5847,  -4.5457,  -9.5123,  11.9029,\n",
      "         -11.8380,   5.0195,  -5.2344,   9.4382,  -7.4975, -10.2799, -12.5074,\n",
      "          -5.8160,  10.4944],\n",
      "        [ -0.1620,  13.5749,  -4.7347,   5.8602,   6.2048,   1.5770,  -0.5251,\n",
      "           3.8088,   2.5196,   1.1191,  -4.8591,   5.9120,   6.7484,   1.4527,\n",
      "           1.1630,  -4.7362],\n",
      "        [ -7.6988,  -2.8279,  13.3674,  -3.1942,  -4.3981,   5.3367,  -5.7627,\n",
      "           8.7833,   4.1389,   0.4551,  -3.6657,   3.5766,   2.9721,   7.9904,\n",
      "           5.5557, -10.0000],\n",
      "        [ -2.4443,   3.6465,  -5.9301,  13.4856,  11.1489,   1.2230,  -3.5945,\n",
      "           4.7020,  -7.7099,  12.4066,   3.1156,  10.8722,   3.3002,   5.4782,\n",
      "          -8.7975,   1.0891],\n",
      "        [ -4.9704,   6.0182,  -6.6176,  12.4867,  13.5366,   3.9572,  -6.5186,\n",
      "           5.8922,  -9.6985,  11.3500,  -1.2474,  10.5330,   7.6086,   6.9216,\n",
      "          -5.0891,  -0.3284],\n",
      "        [ -7.9014,   1.1697,   2.4639,   1.0371,   4.2379,  12.8991, -10.1565,\n",
      "           5.4391,  -3.1618,   3.5293,  -8.2565,   4.4291,   8.7255,   7.7100,\n",
      "           7.7529,  -6.3426],\n",
      "        [ 13.0974,  -2.7607,  -3.7343,  -3.9197,  -8.0920, -10.6356,  13.0343,\n",
      "         -10.8702,   7.5606,  -6.5053,   9.9038,  -8.1769, -11.8811, -11.9948,\n",
      "          -5.6118,   8.8913],\n",
      "        [-11.3902,   6.0302,   6.0053,   6.5368,   7.0365,   8.0952,  -9.9706,\n",
      "          13.4485,  -2.6023,   7.7164,  -7.5209,  11.7850,  10.6624,  12.5345,\n",
      "           2.9987, -11.2138],\n",
      "        [  8.0719,   1.9386,   2.8808,  -6.8444, -10.0910,  -4.8727,   8.7011,\n",
      "          -4.9452,  13.0537,  -9.1959,   2.4096,  -5.8881,  -6.1021,  -7.4157,\n",
      "           2.2447,  -0.6922],\n",
      "        [ -5.9153,   0.2101,  -1.7342,  12.2672,  10.2545,   3.7311,  -6.8491,\n",
      "           7.2078,  -9.0208,  13.8646,   2.3617,  11.7555,   3.8927,   9.0020,\n",
      "          -7.6463,  -0.8293],\n",
      "        [  8.6590,  -6.4979,  -3.2271,   3.0126,  -2.5806,  -8.2988,   8.0349,\n",
      "          -6.5318,   0.2038,   2.9826,  12.9158,  -1.5833, -10.8496,  -5.7504,\n",
      "         -11.0094,   9.4376],\n",
      "        [ -8.1126,   4.8715,   0.8652,  11.6972,  10.1053,   5.6385,  -8.0990,\n",
      "          10.8164,  -5.4745,  12.1248,  -1.9783,  13.6732,   7.6900,  10.8827,\n",
      "          -3.7437,  -6.2260],\n",
      "        [ -8.7802,   9.7401,  -2.0326,   6.5915,  10.8267,   8.9884,  -9.3422,\n",
      "           8.7363,  -5.1179,   5.5013,  -9.9244,   8.7042,  13.0491,   8.5695,\n",
      "           4.7354,  -7.3013],\n",
      "        [-12.8852,   1.3897,   5.9229,   6.4023,   7.6584,   9.8673, -12.2429,\n",
      "          12.5574,  -6.6320,   9.7654,  -6.5995,  11.1750,  10.0999,  13.8604,\n",
      "           2.1351,  -9.1188],\n",
      "        [ -3.8787,   4.4981,   4.9622,  -7.1740,  -2.9852,   7.7120,  -4.1128,\n",
      "           2.7066,   5.5563,  -7.3599, -10.7006,  -2.7140,   7.0423,   1.5263,\n",
      "          13.3782,  -7.9370],\n",
      "        [ 10.3004,  -5.7373,  -9.1583,   0.8880,  -0.7452,  -8.5521,   8.5693,\n",
      "         -11.2470,  -3.1306,  -0.0576,  10.6096,  -6.3151,  -9.8628,  -9.4590,\n",
      "          -9.0194,  13.6982]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6096, 13.5749, 13.3674, 13.4856, 13.5366, 12.8991, 13.0343, 13.4485,\n",
      "        13.0537, 13.8646, 12.9158, 13.6732, 13.0491, 13.8604, 13.3782, 13.6982],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.2344, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ -0.6831,  -7.8441,  -1.5847,  -4.5457,  -9.5123,  11.9029, -11.8380,\n",
      "           5.0195,  -5.2344,   9.4382,  -7.4975, -10.2799, -12.5074,  -5.8160,\n",
      "          10.4944],\n",
      "        [ -0.1620,  -4.7347,   5.8602,   6.2048,   1.5770,  -0.5251,   3.8088,\n",
      "           2.5196,   1.1191,  -4.8591,   5.9120,   6.7484,   1.4527,   1.1630,\n",
      "          -4.7362],\n",
      "        [ -7.6988,  -2.8279,  -3.1942,  -4.3981,   5.3367,  -5.7627,   8.7833,\n",
      "           4.1389,   0.4551,  -3.6657,   3.5766,   2.9721,   7.9904,   5.5557,\n",
      "         -10.0000],\n",
      "        [ -2.4443,   3.6465,  -5.9301,  11.1489,   1.2230,  -3.5945,   4.7020,\n",
      "          -7.7099,  12.4066,   3.1156,  10.8722,   3.3002,   5.4782,  -8.7975,\n",
      "           1.0891],\n",
      "        [ -4.9704,   6.0182,  -6.6176,  12.4867,   3.9572,  -6.5186,   5.8922,\n",
      "          -9.6985,  11.3500,  -1.2474,  10.5330,   7.6086,   6.9216,  -5.0891,\n",
      "          -0.3284],\n",
      "        [ -7.9014,   1.1697,   2.4639,   1.0371,   4.2379, -10.1565,   5.4391,\n",
      "          -3.1618,   3.5293,  -8.2565,   4.4291,   8.7255,   7.7100,   7.7529,\n",
      "          -6.3426],\n",
      "        [ 13.0974,  -2.7607,  -3.7343,  -3.9197,  -8.0920, -10.6356, -10.8702,\n",
      "           7.5606,  -6.5053,   9.9038,  -8.1769, -11.8811, -11.9948,  -5.6118,\n",
      "           8.8913],\n",
      "        [-11.3902,   6.0302,   6.0053,   6.5368,   7.0365,   8.0952,  -9.9706,\n",
      "          -2.6023,   7.7164,  -7.5209,  11.7850,  10.6624,  12.5345,   2.9987,\n",
      "         -11.2138],\n",
      "        [  8.0719,   1.9386,   2.8808,  -6.8444, -10.0910,  -4.8727,   8.7011,\n",
      "          -4.9452,  -9.1959,   2.4096,  -5.8881,  -6.1021,  -7.4157,   2.2447,\n",
      "          -0.6922],\n",
      "        [ -5.9153,   0.2101,  -1.7342,  12.2672,  10.2545,   3.7311,  -6.8491,\n",
      "           7.2078,  -9.0208,   2.3617,  11.7555,   3.8927,   9.0020,  -7.6463,\n",
      "          -0.8293],\n",
      "        [  8.6590,  -6.4979,  -3.2271,   3.0126,  -2.5806,  -8.2988,   8.0349,\n",
      "          -6.5318,   0.2038,   2.9826,  -1.5833, -10.8496,  -5.7504, -11.0094,\n",
      "           9.4376],\n",
      "        [ -8.1126,   4.8715,   0.8652,  11.6972,  10.1053,   5.6385,  -8.0990,\n",
      "          10.8164,  -5.4745,  12.1248,  -1.9783,   7.6900,  10.8827,  -3.7437,\n",
      "          -6.2260],\n",
      "        [ -8.7802,   9.7401,  -2.0326,   6.5915,  10.8267,   8.9884,  -9.3422,\n",
      "           8.7363,  -5.1179,   5.5013,  -9.9244,   8.7042,   8.5695,   4.7354,\n",
      "          -7.3013],\n",
      "        [-12.8852,   1.3897,   5.9229,   6.4023,   7.6584,   9.8673, -12.2429,\n",
      "          12.5574,  -6.6320,   9.7654,  -6.5995,  11.1750,  10.0999,   2.1351,\n",
      "          -9.1188],\n",
      "        [ -3.8787,   4.4981,   4.9622,  -7.1740,  -2.9852,   7.7120,  -4.1128,\n",
      "           2.7066,   5.5563,  -7.3599, -10.7006,  -2.7140,   7.0423,   1.5263,\n",
      "          -7.9370],\n",
      "        [ 10.3004,  -5.7373,  -9.1583,   0.8880,  -0.7452,  -8.5521,   8.5693,\n",
      "         -11.2470,  -3.1306,  -0.0576,  10.6096,  -6.3151,  -9.8628,  -9.4590,\n",
      "          -9.0194]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0143, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 2: 0.1243424341082573\n",
      "Batch 3/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0954,  0.0051, -0.0319,  ..., -0.0329, -0.0576,  0.0561],\n",
      "        [ 0.1088,  0.0039, -0.1410,  ..., -0.1575,  0.0932,  0.0341],\n",
      "        [-0.0703,  0.0522,  0.0704,  ...,  0.0854, -0.0725,  0.0037],\n",
      "        ...,\n",
      "        [ 0.0687, -0.0574, -0.0577,  ...,  0.0364, -0.1542, -0.0196],\n",
      "        [-0.1490,  0.0710,  0.1701,  ...,  0.1520, -0.0460, -0.0028],\n",
      "        [ 0.0770, -0.0400, -0.1144,  ...,  0.0297, -0.1996, -0.0728]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0771,  0.0044, -0.0069,  ...,  0.0117, -0.0475,  0.0480],\n",
      "        [ 0.0512, -0.0053, -0.1528,  ..., -0.1684,  0.0906,  0.0747],\n",
      "        [-0.1043,  0.0257,  0.0713,  ...,  0.0820, -0.0696, -0.0247],\n",
      "        ...,\n",
      "        [ 0.0211, -0.0702, -0.0475,  ...,  0.0421, -0.1346, -0.0383],\n",
      "        [-0.1962,  0.0339,  0.1427,  ...,  0.1498, -0.0484, -0.0063],\n",
      "        [ 0.0400, -0.0614, -0.0817,  ...,  0.0230, -0.1808, -0.0694]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3295e+01,  3.9403e+00,  8.1016e+00,  8.4043e+00,  4.3104e-01,\n",
      "         -3.3435e+00,  7.9750e+00, -7.5292e+00, -7.4921e+00,  1.0751e+01,\n",
      "         -7.1473e+00,  1.2220e+01,  8.6085e+00, -9.4124e+00, -4.4502e-01,\n",
      "         -5.7682e+00],\n",
      "        [ 4.0665e+00,  1.3683e+01, -5.3520e+00,  1.0791e+01,  6.3985e+00,\n",
      "         -5.1549e+00, -4.7541e+00, -3.0828e+00, -4.7034e+00,  1.1373e+01,\n",
      "         -1.3006e+00,  8.1271e+00, -2.3032e-01, -3.6755e+00, -1.0037e+01,\n",
      "         -3.0339e+00],\n",
      "        [ 8.9228e+00, -5.7159e+00,  1.3284e+01, -3.0214e-01,  1.9332e+00,\n",
      "          2.1040e+00,  1.3116e+01, -5.0229e+00, -2.9478e+00,  1.8300e+00,\n",
      "         -9.0321e+00,  6.3115e+00,  2.6213e+00, -7.9415e+00,  1.0170e+01,\n",
      "         -5.2038e+00],\n",
      "        [ 7.1633e+00,  1.0285e+01,  2.8542e-01,  1.3666e+01,  4.7719e-01,\n",
      "         -1.0608e+01,  1.1623e+00,  8.6921e-01, -9.6842e+00,  1.1699e+01,\n",
      "          6.7770e-01,  8.7284e+00,  4.7642e+00, -2.9034e+00, -7.8904e+00,\n",
      "          5.6089e-01],\n",
      "        [ 3.0109e+00,  6.2249e+00,  9.3835e-01,  2.2029e+00,  1.3489e+01,\n",
      "          2.9951e+00,  7.8849e-01, -6.7990e+00, -8.6697e-01,  5.7600e+00,\n",
      "         -9.2781e+00,  6.4653e+00, -7.2819e+00, -7.8441e+00,  3.8175e-01,\n",
      "         -8.1955e+00],\n",
      "        [ 1.6554e+00, -4.7595e+00,  2.9592e+00, -7.8301e+00,  2.9071e+00,\n",
      "          1.3078e+01,  2.3292e+00, -9.4943e+00,  7.8251e+00, -2.6253e+00,\n",
      "         -7.6489e+00,  1.4189e+00,  6.0752e-03, -7.0040e+00,  6.4380e+00,\n",
      "         -9.5551e+00],\n",
      "        [ 1.0790e+01, -2.5800e+00,  1.2770e+01,  3.6270e+00,  1.4814e+00,\n",
      "         -3.5275e-01,  1.3072e+01, -4.7213e+00, -5.0684e+00,  5.0954e+00,\n",
      "         -8.2510e+00,  8.7125e+00,  4.7487e+00, -8.6716e+00,  7.5637e+00,\n",
      "         -5.2598e+00],\n",
      "        [-7.0700e+00, -3.7911e+00, -1.6432e+00, -3.3738e-01, -5.3878e+00,\n",
      "         -6.7656e+00, -4.1822e-01,  1.3603e+01, -4.6043e-01, -6.6743e+00,\n",
      "          1.0575e+01, -8.5882e+00, -1.5329e+00,  1.1382e+01,  7.6165e-01,\n",
      "          1.2278e+01],\n",
      "        [-3.7801e+00, -3.9318e+00, -1.6777e+00, -8.6146e+00,  9.6320e-01,\n",
      "          1.1771e+01, -1.9598e+00, -4.4719e+00,  1.1619e+01, -5.4004e+00,\n",
      "         -1.2710e+00, -3.4752e+00, -9.9339e-01, -7.4871e-01,  3.6998e+00,\n",
      "         -4.3196e+00],\n",
      "        [ 9.5070e+00,  1.1527e+01,  3.3772e-01,  1.1980e+01,  4.5904e+00,\n",
      "         -5.3974e+00,  7.8861e-01, -6.1245e+00, -7.5603e+00,  1.3724e+01,\n",
      "         -5.1261e+00,  1.2204e+01,  3.6971e+00, -8.0090e+00, -7.0401e+00,\n",
      "         -5.8689e+00],\n",
      "        [-7.5733e+00, -1.4187e-01, -7.3427e+00,  2.8092e-01, -8.3324e+00,\n",
      "         -5.9267e+00, -6.8683e+00,  1.0936e+01,  2.0602e+00, -5.1072e+00,\n",
      "          1.3541e+01, -8.7853e+00,  2.4607e+00,  1.2496e+01, -6.0079e+00,\n",
      "          1.2197e+01],\n",
      "        [ 1.2129e+01,  7.4182e+00,  5.2609e+00,  9.5468e+00,  4.0369e+00,\n",
      "         -2.5206e+00,  5.7381e+00, -8.7345e+00, -7.8430e+00,  1.2778e+01,\n",
      "         -8.8719e+00,  1.3659e+01,  5.3031e+00, -1.1055e+01, -2.0649e+00,\n",
      "         -8.4269e+00],\n",
      "        [ 9.0958e+00,  1.0695e-01,  5.1823e+00,  5.0395e+00, -7.8018e+00,\n",
      "         -2.3262e+00,  4.8501e+00, -3.9654e+00, -3.4543e+00,  5.7915e+00,\n",
      "         -9.8077e-02,  6.5267e+00,  1.3182e+01, -3.7412e+00, -1.6668e+00,\n",
      "         -1.2710e+00],\n",
      "        [-9.5271e+00, -2.7965e+00, -7.0365e+00, -3.3879e+00, -6.2821e+00,\n",
      "         -4.1620e+00, -6.5785e+00,  1.1334e+01,  3.2146e+00, -8.3762e+00,\n",
      "          1.2239e+01, -1.1097e+01, -1.2191e+00,  1.3792e+01, -3.2804e+00,\n",
      "          1.2790e+01],\n",
      "        [ 2.3938e+00, -1.0152e+01,  1.0246e+01, -7.2996e+00,  1.5210e+00,\n",
      "          7.6034e+00,  1.0322e+01, -2.8642e+00,  3.1090e+00, -5.1819e+00,\n",
      "         -7.1968e+00,  1.7377e-02, -1.6531e+00, -4.5409e+00,  1.3556e+01,\n",
      "         -4.2534e+00],\n",
      "        [-6.8602e+00, -2.2424e+00, -3.7530e+00, -4.9394e-02, -6.2428e+00,\n",
      "         -8.1551e+00, -3.4352e+00,  1.2320e+01, -9.5771e-01, -6.0186e+00,\n",
      "          1.1753e+01, -8.8246e+00,  2.3384e-01,  1.2630e+01, -3.1443e+00,\n",
      "          1.3866e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.2953, 13.6834, 13.2844, 13.6661, 13.4888, 13.0778, 13.0725, 13.6030,\n",
      "        11.6194, 13.7238, 13.5406, 13.6590, 13.1819, 13.7916, 13.5558, 13.8663],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.3508, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 3.9403e+00,  8.1016e+00,  8.4043e+00,  4.3104e-01, -3.3435e+00,\n",
      "          7.9750e+00, -7.5292e+00, -7.4921e+00,  1.0751e+01, -7.1473e+00,\n",
      "          1.2220e+01,  8.6085e+00, -9.4124e+00, -4.4502e-01, -5.7682e+00],\n",
      "        [ 4.0665e+00, -5.3520e+00,  1.0791e+01,  6.3985e+00, -5.1549e+00,\n",
      "         -4.7541e+00, -3.0828e+00, -4.7034e+00,  1.1373e+01, -1.3006e+00,\n",
      "          8.1271e+00, -2.3032e-01, -3.6755e+00, -1.0037e+01, -3.0339e+00],\n",
      "        [ 8.9228e+00, -5.7159e+00, -3.0214e-01,  1.9332e+00,  2.1040e+00,\n",
      "          1.3116e+01, -5.0229e+00, -2.9478e+00,  1.8300e+00, -9.0321e+00,\n",
      "          6.3115e+00,  2.6213e+00, -7.9415e+00,  1.0170e+01, -5.2038e+00],\n",
      "        [ 7.1633e+00,  1.0285e+01,  2.8542e-01,  4.7719e-01, -1.0608e+01,\n",
      "          1.1623e+00,  8.6921e-01, -9.6842e+00,  1.1699e+01,  6.7770e-01,\n",
      "          8.7284e+00,  4.7642e+00, -2.9034e+00, -7.8904e+00,  5.6089e-01],\n",
      "        [ 3.0109e+00,  6.2249e+00,  9.3835e-01,  2.2029e+00,  2.9951e+00,\n",
      "          7.8849e-01, -6.7990e+00, -8.6697e-01,  5.7600e+00, -9.2781e+00,\n",
      "          6.4653e+00, -7.2819e+00, -7.8441e+00,  3.8175e-01, -8.1955e+00],\n",
      "        [ 1.6554e+00, -4.7595e+00,  2.9592e+00, -7.8301e+00,  2.9071e+00,\n",
      "          2.3292e+00, -9.4943e+00,  7.8251e+00, -2.6253e+00, -7.6489e+00,\n",
      "          1.4189e+00,  6.0752e-03, -7.0040e+00,  6.4380e+00, -9.5551e+00],\n",
      "        [ 1.0790e+01, -2.5800e+00,  1.2770e+01,  3.6270e+00,  1.4814e+00,\n",
      "         -3.5275e-01, -4.7213e+00, -5.0684e+00,  5.0954e+00, -8.2510e+00,\n",
      "          8.7125e+00,  4.7487e+00, -8.6716e+00,  7.5637e+00, -5.2598e+00],\n",
      "        [-7.0700e+00, -3.7911e+00, -1.6432e+00, -3.3738e-01, -5.3878e+00,\n",
      "         -6.7656e+00, -4.1822e-01, -4.6043e-01, -6.6743e+00,  1.0575e+01,\n",
      "         -8.5882e+00, -1.5329e+00,  1.1382e+01,  7.6165e-01,  1.2278e+01],\n",
      "        [-3.7801e+00, -3.9318e+00, -1.6777e+00, -8.6146e+00,  9.6320e-01,\n",
      "          1.1771e+01, -1.9598e+00, -4.4719e+00, -5.4004e+00, -1.2710e+00,\n",
      "         -3.4752e+00, -9.9339e-01, -7.4871e-01,  3.6998e+00, -4.3196e+00],\n",
      "        [ 9.5070e+00,  1.1527e+01,  3.3772e-01,  1.1980e+01,  4.5904e+00,\n",
      "         -5.3974e+00,  7.8861e-01, -6.1245e+00, -7.5603e+00, -5.1261e+00,\n",
      "          1.2204e+01,  3.6971e+00, -8.0090e+00, -7.0401e+00, -5.8689e+00],\n",
      "        [-7.5733e+00, -1.4187e-01, -7.3427e+00,  2.8092e-01, -8.3324e+00,\n",
      "         -5.9267e+00, -6.8683e+00,  1.0936e+01,  2.0602e+00, -5.1072e+00,\n",
      "         -8.7853e+00,  2.4607e+00,  1.2496e+01, -6.0079e+00,  1.2197e+01],\n",
      "        [ 1.2129e+01,  7.4182e+00,  5.2609e+00,  9.5468e+00,  4.0369e+00,\n",
      "         -2.5206e+00,  5.7381e+00, -8.7345e+00, -7.8430e+00,  1.2778e+01,\n",
      "         -8.8719e+00,  5.3031e+00, -1.1055e+01, -2.0649e+00, -8.4269e+00],\n",
      "        [ 9.0958e+00,  1.0695e-01,  5.1823e+00,  5.0395e+00, -7.8018e+00,\n",
      "         -2.3262e+00,  4.8501e+00, -3.9654e+00, -3.4543e+00,  5.7915e+00,\n",
      "         -9.8077e-02,  6.5267e+00, -3.7412e+00, -1.6668e+00, -1.2710e+00],\n",
      "        [-9.5271e+00, -2.7965e+00, -7.0365e+00, -3.3879e+00, -6.2821e+00,\n",
      "         -4.1620e+00, -6.5785e+00,  1.1334e+01,  3.2146e+00, -8.3762e+00,\n",
      "          1.2239e+01, -1.1097e+01, -1.2191e+00, -3.2804e+00,  1.2790e+01],\n",
      "        [ 2.3938e+00, -1.0152e+01,  1.0246e+01, -7.2996e+00,  1.5210e+00,\n",
      "          7.6034e+00,  1.0322e+01, -2.8642e+00,  3.1090e+00, -5.1819e+00,\n",
      "         -7.1968e+00,  1.7377e-02, -1.6531e+00, -4.5409e+00, -4.2534e+00],\n",
      "        [-6.8602e+00, -2.2424e+00, -3.7530e+00, -4.9394e-02, -6.2428e+00,\n",
      "         -8.1551e+00, -3.4352e+00,  1.2320e+01, -9.5771e-01, -6.0186e+00,\n",
      "          1.1753e+01, -8.8246e+00,  2.3384e-01,  1.2630e+01, -3.1443e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0214, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 3: 0.1861269325017929\n",
      "Batch 4/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 1.7469e-04,  5.6112e-02, -2.0215e-02,  ..., -2.9091e-02,\n",
      "         -5.2868e-02,  4.1650e-02],\n",
      "        [ 1.5230e-02,  5.2683e-02,  9.4425e-04,  ..., -6.3499e-02,\n",
      "          1.5202e-01,  4.7371e-02],\n",
      "        [-1.3149e-01,  5.7689e-02,  1.2064e-01,  ...,  3.6093e-02,\n",
      "          2.0688e-01, -1.5550e-02],\n",
      "        ...,\n",
      "        [-8.9081e-02,  4.2187e-02,  2.2421e-01,  ...,  1.2194e-01,\n",
      "          9.2127e-02, -1.5075e-02],\n",
      "        [ 1.0246e-01,  8.0474e-03, -1.8135e-02,  ..., -4.6542e-02,\n",
      "          2.0398e-01,  3.8891e-02],\n",
      "        [ 5.3966e-02,  5.9171e-02, -2.1078e-02,  ..., -4.7773e-02,\n",
      "          1.3784e-01,  8.6278e-02]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0046,  0.0367, -0.0356,  ..., -0.0376, -0.0376,  0.0149],\n",
      "        [ 0.0275, -0.0024, -0.0158,  ..., -0.0690,  0.1859,  0.0338],\n",
      "        [-0.1680,  0.0379,  0.0797,  ...,  0.0474,  0.1952, -0.0255],\n",
      "        ...,\n",
      "        [-0.1519,  0.0203,  0.2232,  ...,  0.1076,  0.1181,  0.0134],\n",
      "        [ 0.0371,  0.0134, -0.0099,  ..., -0.0676,  0.2562,  0.0911],\n",
      "        [ 0.0124,  0.0379,  0.0096,  ..., -0.0459,  0.1545,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.4197,   7.1872,   0.5152,   1.5323,  11.4179,  -4.5604,   4.9279,\n",
      "          11.9965,  11.1974,  -2.9583,  -1.7370,  -4.5990,  11.5451,  -5.3389,\n",
      "          -0.4555,   8.0391],\n",
      "        [  7.1334,  13.6686,   6.4933,   9.8488,   0.3314,  -7.4819,  -0.3129,\n",
      "          11.3926,  11.0181,  -6.8451,   9.5787,  -9.8903,   3.7811,   0.4947,\n",
      "          10.6838,  13.1737],\n",
      "        [ -0.4382,   7.5319,  13.6438,   3.8925,  -3.9442,   2.8880,  -8.9808,\n",
      "           4.7510,   3.3531,  -6.4173,   6.5228,  -4.1891,  -4.5416,  10.3714,\n",
      "           7.6157,   7.7322],\n",
      "        [ -1.6653,   8.4080,   1.2075,  13.1747,  -6.2882,  -4.1448,  -2.5127,\n",
      "           2.3479,   5.6538,   1.4255,   8.9663,  -4.6851,  -2.8939,   1.5706,\n",
      "           9.5192,   6.1645],\n",
      "        [ 11.5305,  -0.2874,  -3.1114,  -4.6839,  13.8108,  -0.5397,   6.3124,\n",
      "           7.0688,   6.1200,   0.6975,  -8.1782,   0.5455,  11.5844,  -6.8233,\n",
      "          -7.7491,   1.2244],\n",
      "        [ -5.8884,  -5.8890,   3.4592,  -1.1590,  -1.3969,  13.6686,  -9.9447,\n",
      "          -5.9907,  -5.0388,   7.9559,  -6.4600,   9.5917,  -7.5672,   9.6769,\n",
      "          -5.6507,  -6.0231],\n",
      "        [  8.4043,   3.6332,  -5.7016,  -0.2369,   6.2915, -10.7351,  12.9622,\n",
      "           6.6627,   5.4766,  -3.1848,   2.0632,  -4.8261,  10.0959, -11.6505,\n",
      "           1.5181,   3.6063],\n",
      "        [ 12.2154,  11.5526,   4.3493,   4.8854,   7.3132,  -7.2536,   3.5401,\n",
      "          13.7266,  12.2643,  -6.5641,   4.3063,  -8.3412,   9.2755,  -3.2911,\n",
      "           5.4721,  12.1740],\n",
      "        [ 10.4987,  10.2591,   2.4450,   7.4952,   6.7493,  -5.9648,   2.2093,\n",
      "          11.2801,  13.3620,  -2.4473,   2.5388,  -7.0046,   9.0454,  -3.4380,\n",
      "           4.3383,   9.9179],\n",
      "        [ -5.4251,  -7.4538,  -6.9657,   1.8728,  -0.4222,   7.3737,  -1.2386,\n",
      "          -7.9667,  -3.5244,  13.5489,  -6.9698,  10.2879,  -3.4045,   0.0846,\n",
      "          -6.5895,  -9.0253],\n",
      "        [ -2.0006,   9.9727,   5.9176,   9.1836,  -8.3973,  -6.9132,  -1.4868,\n",
      "           3.8549,   3.1117,  -6.8613,  13.3990,  -8.5945,  -3.8665,   2.4158,\n",
      "          13.0669,   8.6365],\n",
      "        [ -6.5307,  -9.4737,  -2.6738,  -3.4549,  -0.6895,  11.1191,  -3.3365,\n",
      "          -8.3216,  -7.3907,  11.1322,  -8.0745,  13.2703,  -5.7153,   4.1969,\n",
      "          -7.4312,  -9.7925],\n",
      "        [ 12.4412,   4.1049,  -4.2805,  -0.4789,  11.4210,  -7.7254,   9.8259,\n",
      "           9.2712,   9.1652,  -2.2274,  -2.6115,  -4.8203,  13.5039, -10.3549,\n",
      "          -2.2194,   4.8746],\n",
      "        [ -6.2148,   2.0258,  10.0836,   4.2567,  -7.0399,   8.7653, -12.9748,\n",
      "          -2.0569,  -1.6467,   0.7503,   2.6911,   2.0803,  -9.6030,  13.5019,\n",
      "           4.0705,   1.8508],\n",
      "        [  0.6543,  11.7276,   5.4798,  10.7489,  -6.5504,  -8.0170,  -0.7444,\n",
      "           6.2468,   6.2916,  -5.9372,  12.8056,  -8.7292,  -1.4073,   1.7260,\n",
      "          13.6304,  10.5504],\n",
      "        [  8.5899,  13.5060,   6.0504,   8.6733,   1.8612,  -7.8801,   0.6482,\n",
      "          12.1915,  11.6040,  -7.2110,   8.6681,  -9.5805,   5.1044,  -0.2594,\n",
      "          10.0507,  13.5254]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.4197, 13.6686, 13.6438, 13.1747, 13.8108, 13.6686, 12.9622, 13.7266,\n",
      "        13.3620, 13.5489, 13.3990, 13.2703, 13.5039, 13.5019, 13.6304, 13.5254],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.3157, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  7.1872,   0.5152,   1.5323,  11.4179,  -4.5604,   4.9279,  11.9965,\n",
      "          11.1974,  -2.9583,  -1.7370,  -4.5990,  11.5451,  -5.3389,  -0.4555,\n",
      "           8.0391],\n",
      "        [  7.1334,   6.4933,   9.8488,   0.3314,  -7.4819,  -0.3129,  11.3926,\n",
      "          11.0181,  -6.8451,   9.5787,  -9.8903,   3.7811,   0.4947,  10.6838,\n",
      "          13.1737],\n",
      "        [ -0.4382,   7.5319,   3.8925,  -3.9442,   2.8880,  -8.9808,   4.7510,\n",
      "           3.3531,  -6.4173,   6.5228,  -4.1891,  -4.5416,  10.3714,   7.6157,\n",
      "           7.7322],\n",
      "        [ -1.6653,   8.4080,   1.2075,  -6.2882,  -4.1448,  -2.5127,   2.3479,\n",
      "           5.6538,   1.4255,   8.9663,  -4.6851,  -2.8939,   1.5706,   9.5192,\n",
      "           6.1645],\n",
      "        [ 11.5305,  -0.2874,  -3.1114,  -4.6839,  -0.5397,   6.3124,   7.0688,\n",
      "           6.1200,   0.6975,  -8.1782,   0.5455,  11.5844,  -6.8233,  -7.7491,\n",
      "           1.2244],\n",
      "        [ -5.8884,  -5.8890,   3.4592,  -1.1590,  -1.3969,  -9.9447,  -5.9907,\n",
      "          -5.0388,   7.9559,  -6.4600,   9.5917,  -7.5672,   9.6769,  -5.6507,\n",
      "          -6.0231],\n",
      "        [  8.4043,   3.6332,  -5.7016,  -0.2369,   6.2915, -10.7351,   6.6627,\n",
      "           5.4766,  -3.1848,   2.0632,  -4.8261,  10.0959, -11.6505,   1.5181,\n",
      "           3.6063],\n",
      "        [ 12.2154,  11.5526,   4.3493,   4.8854,   7.3132,  -7.2536,   3.5401,\n",
      "          12.2643,  -6.5641,   4.3063,  -8.3412,   9.2755,  -3.2911,   5.4721,\n",
      "          12.1740],\n",
      "        [ 10.4987,  10.2591,   2.4450,   7.4952,   6.7493,  -5.9648,   2.2093,\n",
      "          11.2801,  -2.4473,   2.5388,  -7.0046,   9.0454,  -3.4380,   4.3383,\n",
      "           9.9179],\n",
      "        [ -5.4251,  -7.4538,  -6.9657,   1.8728,  -0.4222,   7.3737,  -1.2386,\n",
      "          -7.9667,  -3.5244,  -6.9698,  10.2879,  -3.4045,   0.0846,  -6.5895,\n",
      "          -9.0253],\n",
      "        [ -2.0006,   9.9727,   5.9176,   9.1836,  -8.3973,  -6.9132,  -1.4868,\n",
      "           3.8549,   3.1117,  -6.8613,  -8.5945,  -3.8665,   2.4158,  13.0669,\n",
      "           8.6365],\n",
      "        [ -6.5307,  -9.4737,  -2.6738,  -3.4549,  -0.6895,  11.1191,  -3.3365,\n",
      "          -8.3216,  -7.3907,  11.1322,  -8.0745,  -5.7153,   4.1969,  -7.4312,\n",
      "          -9.7925],\n",
      "        [ 12.4412,   4.1049,  -4.2805,  -0.4789,  11.4210,  -7.7254,   9.8259,\n",
      "           9.2712,   9.1652,  -2.2274,  -2.6115,  -4.8203, -10.3549,  -2.2194,\n",
      "           4.8746],\n",
      "        [ -6.2148,   2.0258,  10.0836,   4.2567,  -7.0399,   8.7653, -12.9748,\n",
      "          -2.0569,  -1.6467,   0.7503,   2.6911,   2.0803,  -9.6030,   4.0705,\n",
      "           1.8508],\n",
      "        [  0.6543,  11.7276,   5.4798,  10.7489,  -6.5504,  -8.0170,  -0.7444,\n",
      "           6.2468,   6.2916,  -5.9372,  12.8056,  -8.7292,  -1.4073,   1.7260,\n",
      "          10.5504],\n",
      "        [  8.5899,  13.5060,   6.0504,   8.6733,   1.8612,  -7.8801,   0.6482,\n",
      "          12.1915,  11.6040,  -7.2110,   8.6681,  -9.5805,   5.1044,  -0.2594,\n",
      "          10.0507]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0183, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 4: 0.16703222692012787\n",
      "Batch 5/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.2007, -0.0284, -0.0719,  ..., -0.0757, -0.1622,  0.0025],\n",
      "        [-0.1557,  0.0381,  0.0714,  ...,  0.0622,  0.2706, -0.1220],\n",
      "        [ 0.1311, -0.0390, -0.0202,  ..., -0.0234,  0.1643,  0.0269],\n",
      "        ...,\n",
      "        [-0.1016,  0.0575,  0.2172,  ...,  0.0868,  0.1098,  0.0697],\n",
      "        [ 0.1414, -0.0205, -0.1003,  ...,  0.0170, -0.3102,  0.0102],\n",
      "        [-0.0593, -0.0082, -0.0980,  ..., -0.0278,  0.1443, -0.0537]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1337, -0.0329, -0.0805,  ..., -0.0920, -0.1718,  0.0106],\n",
      "        [-0.1856, -0.0111,  0.1259,  ...,  0.0787,  0.2311, -0.1470],\n",
      "        [ 0.0386, -0.0283,  0.0200,  ..., -0.0538,  0.1859,  0.0288],\n",
      "        ...,\n",
      "        [-0.1519,  0.0516,  0.2587,  ...,  0.1402,  0.0739,  0.0188],\n",
      "        [ 0.0853, -0.0355, -0.1007,  ..., -0.0111, -0.2562,  0.0107],\n",
      "        [-0.0864, -0.0328, -0.0746,  ..., -0.0359,  0.1407, -0.0454]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3619e+01, -1.2195e+01, -1.5377e+00,  6.3506e+00,  9.2919e+00,\n",
      "         -8.5309e+00, -6.9395e+00,  1.4455e+00,  3.6364e+00,  3.0752e+00,\n",
      "          4.0979e+00,  3.2258e+00,  1.0026e+01, -8.2714e+00,  9.3334e+00,\n",
      "         -7.5727e+00],\n",
      "        [-1.2174e+01,  1.3374e+01,  3.1427e+00, -3.0478e+00, -6.7431e+00,\n",
      "          7.7448e+00,  8.0233e+00, -9.7876e-01, -3.7281e+00, -3.8270e+00,\n",
      "         -4.3212e+00, -6.0913e+00, -1.0035e+01,  7.6208e+00, -1.0500e+01,\n",
      "          7.1117e+00],\n",
      "        [-1.1640e+00,  2.8735e-01,  1.3380e+01,  8.0945e+00, -3.1061e-01,\n",
      "          7.3411e+00,  9.2451e+00, -3.7225e+00, -1.1489e+01, -7.6969e+00,\n",
      "         -1.0991e+01, -1.2213e+00,  4.2540e+00, -3.7807e-01, -6.3854e+00,\n",
      "          5.9829e-01],\n",
      "        [ 6.7397e+00, -5.4011e+00,  7.5372e+00,  1.3630e+01,  9.0682e+00,\n",
      "         -2.4605e+00,  4.3293e+00, -1.6890e+00, -2.3075e+00, -3.8014e+00,\n",
      "         -2.1897e+00, -6.3654e+00,  6.0912e+00, -5.3789e+00, -2.4336e+00,\n",
      "         -1.4376e+00],\n",
      "        [ 9.8614e+00, -7.8627e+00,  8.1763e-01,  9.9595e+00,  1.3149e+01,\n",
      "         -9.6950e+00, -2.1251e+00,  1.2747e+00,  2.5769e+00,  5.5433e-02,\n",
      "          3.3499e+00, -5.2044e+00,  4.0828e+00, -8.2661e+00,  2.9152e+00,\n",
      "         -1.4463e+00],\n",
      "        [-8.4054e+00,  6.7272e+00,  7.8384e+00, -2.6826e+00, -1.0959e+01,\n",
      "          1.3447e+01,  9.0560e+00, -9.0247e-01, -8.9609e+00, -5.5852e+00,\n",
      "         -8.4609e+00,  3.2933e+00, -6.6723e-01,  8.8002e+00, -7.0132e+00,\n",
      "          7.8742e-03],\n",
      "        [-5.4378e+00,  4.3133e+00,  1.0684e+01,  4.6361e+00, -3.0612e+00,\n",
      "          9.0572e+00,  1.3194e+01,  3.3519e+00, -9.1408e+00, -1.1159e+01,\n",
      "         -5.9367e+00, -4.9677e+00, -2.4023e+00,  7.8419e+00, -1.1165e+01,\n",
      "         -1.2093e+00],\n",
      "        [ 2.1741e+00, -2.0436e+00, -3.1549e-01, -5.3571e-01,  1.2371e+00,\n",
      "         -1.3042e+00,  3.4265e+00,  1.3288e+01, -5.3749e-01, -8.4798e+00,\n",
      "          6.1657e+00, -2.4886e+00, -3.6942e+00,  7.3911e+00, -2.9584e+00,\n",
      "         -9.7772e+00],\n",
      "        [ 5.8288e+00, -3.7147e+00, -1.2054e+01, -3.1767e+00,  4.7926e+00,\n",
      "         -9.8088e+00, -9.4170e+00,  3.7680e+00,  1.3436e+01,  8.0680e+00,\n",
      "          1.2272e+01, -2.2491e-01, -6.8239e-01, -2.0927e+00,  7.5526e+00,\n",
      "         -2.5605e+00],\n",
      "        [ 4.6206e+00, -2.8793e+00, -8.7872e+00, -3.6677e+00,  1.5972e+00,\n",
      "         -5.2041e+00, -1.0602e+01, -5.2873e+00,  8.7957e+00,  1.3646e+01,\n",
      "          3.5885e+00,  6.9165e+00,  4.9169e+00, -6.1756e+00,  1.1022e+01,\n",
      "          2.5106e+00],\n",
      "        [ 5.6183e+00, -4.4513e+00, -9.9125e+00, -2.8147e+00,  4.2912e+00,\n",
      "         -8.9140e+00, -5.8814e+00,  9.7712e+00,  1.0501e+01,  1.2216e+00,\n",
      "          1.3505e+01, -2.2105e+00, -2.8793e+00,  1.8887e+00,  3.9276e+00,\n",
      "         -7.2468e+00],\n",
      "        [ 4.4404e+00, -5.3382e+00, -1.9087e+00, -5.6929e+00, -3.7961e+00,\n",
      "          1.3021e+00, -6.8348e+00, -1.7830e+00, -9.5857e-01,  6.1611e+00,\n",
      "         -2.3002e+00,  1.3667e+01,  8.2041e+00, -2.3855e+00,  1.0225e+01,\n",
      "         -3.9337e+00],\n",
      "        [ 1.0534e+01, -1.0845e+01,  2.8354e+00,  4.8571e+00,  3.9479e+00,\n",
      "         -1.8725e+00, -4.4101e+00, -2.8992e+00, -1.3302e+00,  3.1706e+00,\n",
      "         -2.5470e+00,  8.2007e+00,  1.3098e+01, -7.1522e+00,  8.8242e+00,\n",
      "         -5.8337e+00],\n",
      "        [-5.8262e+00,  4.9198e+00,  3.3948e+00, -2.9013e+00, -6.9179e+00,\n",
      "          7.9223e+00,  9.2066e+00,  9.2320e+00, -3.8206e+00, -9.1309e+00,\n",
      "          7.0661e-01, -1.8035e+00, -5.4562e+00,  1.2903e+01, -8.3925e+00,\n",
      "         -5.7881e+00],\n",
      "        [ 9.1866e+00, -8.8483e+00, -7.0256e+00, -3.0058e+00,  3.7739e+00,\n",
      "         -7.2140e+00, -1.1856e+01, -1.8444e+00,  5.6464e+00,  9.9175e+00,\n",
      "          3.4404e+00,  9.9431e+00,  7.8617e+00, -7.8501e+00,  1.3696e+01,\n",
      "         -2.4957e+00],\n",
      "        [-6.3371e+00,  6.8756e+00,  3.2818e+00,  2.6888e+00,  1.3477e+00,\n",
      "          1.6170e+00,  3.4144e+00, -8.8736e+00, -1.7216e+00,  2.3712e+00,\n",
      "         -6.0725e+00, -5.2654e+00, -3.7027e+00, -3.5501e+00, -4.1856e+00,\n",
      "          1.3425e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6186, 13.3743, 13.3805, 13.6298, 13.1488, 13.4466, 13.1943, 13.2881,\n",
      "        13.4359, 13.6457, 13.5046, 13.6667, 13.0985, 12.9027, 13.6965, 13.4254],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0614, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[-1.2195e+01, -1.5377e+00,  6.3506e+00,  9.2919e+00, -8.5309e+00,\n",
      "         -6.9395e+00,  1.4455e+00,  3.6364e+00,  3.0752e+00,  4.0979e+00,\n",
      "          3.2258e+00,  1.0026e+01, -8.2714e+00,  9.3334e+00, -7.5727e+00],\n",
      "        [-1.2174e+01,  3.1427e+00, -3.0478e+00, -6.7431e+00,  7.7448e+00,\n",
      "          8.0233e+00, -9.7876e-01, -3.7281e+00, -3.8270e+00, -4.3212e+00,\n",
      "         -6.0913e+00, -1.0035e+01,  7.6208e+00, -1.0500e+01,  7.1117e+00],\n",
      "        [-1.1640e+00,  2.8735e-01,  8.0945e+00, -3.1061e-01,  7.3411e+00,\n",
      "          9.2451e+00, -3.7225e+00, -1.1489e+01, -7.6969e+00, -1.0991e+01,\n",
      "         -1.2213e+00,  4.2540e+00, -3.7807e-01, -6.3854e+00,  5.9829e-01],\n",
      "        [ 6.7397e+00, -5.4011e+00,  7.5372e+00,  9.0682e+00, -2.4605e+00,\n",
      "          4.3293e+00, -1.6890e+00, -2.3075e+00, -3.8014e+00, -2.1897e+00,\n",
      "         -6.3654e+00,  6.0912e+00, -5.3789e+00, -2.4336e+00, -1.4376e+00],\n",
      "        [ 9.8614e+00, -7.8627e+00,  8.1763e-01,  9.9595e+00, -9.6950e+00,\n",
      "         -2.1251e+00,  1.2747e+00,  2.5769e+00,  5.5433e-02,  3.3499e+00,\n",
      "         -5.2044e+00,  4.0828e+00, -8.2661e+00,  2.9152e+00, -1.4463e+00],\n",
      "        [-8.4054e+00,  6.7272e+00,  7.8384e+00, -2.6826e+00, -1.0959e+01,\n",
      "          9.0560e+00, -9.0247e-01, -8.9609e+00, -5.5852e+00, -8.4609e+00,\n",
      "          3.2933e+00, -6.6723e-01,  8.8002e+00, -7.0132e+00,  7.8742e-03],\n",
      "        [-5.4378e+00,  4.3133e+00,  1.0684e+01,  4.6361e+00, -3.0612e+00,\n",
      "          9.0572e+00,  3.3519e+00, -9.1408e+00, -1.1159e+01, -5.9367e+00,\n",
      "         -4.9677e+00, -2.4023e+00,  7.8419e+00, -1.1165e+01, -1.2093e+00],\n",
      "        [ 2.1741e+00, -2.0436e+00, -3.1549e-01, -5.3571e-01,  1.2371e+00,\n",
      "         -1.3042e+00,  3.4265e+00, -5.3749e-01, -8.4798e+00,  6.1657e+00,\n",
      "         -2.4886e+00, -3.6942e+00,  7.3911e+00, -2.9584e+00, -9.7772e+00],\n",
      "        [ 5.8288e+00, -3.7147e+00, -1.2054e+01, -3.1767e+00,  4.7926e+00,\n",
      "         -9.8088e+00, -9.4170e+00,  3.7680e+00,  8.0680e+00,  1.2272e+01,\n",
      "         -2.2491e-01, -6.8239e-01, -2.0927e+00,  7.5526e+00, -2.5605e+00],\n",
      "        [ 4.6206e+00, -2.8793e+00, -8.7872e+00, -3.6677e+00,  1.5972e+00,\n",
      "         -5.2041e+00, -1.0602e+01, -5.2873e+00,  8.7957e+00,  3.5885e+00,\n",
      "          6.9165e+00,  4.9169e+00, -6.1756e+00,  1.1022e+01,  2.5106e+00],\n",
      "        [ 5.6183e+00, -4.4513e+00, -9.9125e+00, -2.8147e+00,  4.2912e+00,\n",
      "         -8.9140e+00, -5.8814e+00,  9.7712e+00,  1.0501e+01,  1.2216e+00,\n",
      "         -2.2105e+00, -2.8793e+00,  1.8887e+00,  3.9276e+00, -7.2468e+00],\n",
      "        [ 4.4404e+00, -5.3382e+00, -1.9087e+00, -5.6929e+00, -3.7961e+00,\n",
      "          1.3021e+00, -6.8348e+00, -1.7830e+00, -9.5857e-01,  6.1611e+00,\n",
      "         -2.3002e+00,  8.2041e+00, -2.3855e+00,  1.0225e+01, -3.9337e+00],\n",
      "        [ 1.0534e+01, -1.0845e+01,  2.8354e+00,  4.8571e+00,  3.9479e+00,\n",
      "         -1.8725e+00, -4.4101e+00, -2.8992e+00, -1.3302e+00,  3.1706e+00,\n",
      "         -2.5470e+00,  8.2007e+00, -7.1522e+00,  8.8242e+00, -5.8337e+00],\n",
      "        [-5.8262e+00,  4.9198e+00,  3.3948e+00, -2.9013e+00, -6.9179e+00,\n",
      "          7.9223e+00,  9.2066e+00,  9.2320e+00, -3.8206e+00, -9.1309e+00,\n",
      "          7.0661e-01, -1.8035e+00, -5.4562e+00, -8.3925e+00, -5.7881e+00],\n",
      "        [ 9.1866e+00, -8.8483e+00, -7.0256e+00, -3.0058e+00,  3.7739e+00,\n",
      "         -7.2140e+00, -1.1856e+01, -1.8444e+00,  5.6464e+00,  9.9175e+00,\n",
      "          3.4404e+00,  9.9431e+00,  7.8617e+00, -7.8501e+00, -2.4957e+00],\n",
      "        [-6.3371e+00,  6.8756e+00,  3.2818e+00,  2.6888e+00,  1.3477e+00,\n",
      "          1.6170e+00,  3.4144e+00, -8.8736e+00, -1.7216e+00,  2.3712e+00,\n",
      "         -6.0725e+00, -5.2654e+00, -3.7027e+00, -3.5501e+00, -4.1856e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0040, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 5: 0.03274417296051979\n",
      "Batch 6/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0011, -0.0165, -0.0948,  ...,  0.0063, -0.1670, -0.0952],\n",
      "        [ 0.1543, -0.0255, -0.0682,  ..., -0.0703,  0.1266,  0.0328],\n",
      "        [-0.0068,  0.0332,  0.2255,  ...,  0.1194, -0.0154,  0.0129],\n",
      "        ...,\n",
      "        [ 0.1503, -0.0519, -0.1325,  ..., -0.0348, -0.1316, -0.0420],\n",
      "        [ 0.1586, -0.0495, -0.1876,  ..., -0.1011, -0.0966, -0.0103],\n",
      "        [-0.0073,  0.0142,  0.1469,  ...,  0.0404,  0.1998,  0.0102]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0055, -0.0326, -0.0907,  ..., -0.0241, -0.1818, -0.0955],\n",
      "        [ 0.1076, -0.0383, -0.0967,  ..., -0.0512,  0.1599,  0.0096],\n",
      "        [-0.0839,  0.0349,  0.2129,  ...,  0.1276,  0.0178,  0.0594],\n",
      "        ...,\n",
      "        [ 0.1329, -0.0850, -0.1370,  ..., -0.0446, -0.1273, -0.0443],\n",
      "        [ 0.1057, -0.0824, -0.1840,  ..., -0.0864, -0.0974, -0.0164],\n",
      "        [-0.0914, -0.0148,  0.1298,  ...,  0.0469,  0.2672, -0.0075]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.8171,  -4.8464,  -7.5548,   5.6876,   5.8907,  -4.2604,  12.7730,\n",
      "           3.7108,   8.6035,  -3.9989, -12.6599,   6.2260,  -4.3339,  11.2721,\n",
      "           7.1021,  -5.9356],\n",
      "        [ -4.9294,  13.7741,  -5.7781,  -2.8624,   4.9733,  -9.3138,  -3.5011,\n",
      "          -1.5378,  -7.1626,   3.4745,   8.0064, -12.7298,   9.1810,   2.4372,\n",
      "           6.2343,   5.3795],\n",
      "        [ -8.0926,  -5.2016,  13.4902,  -6.6420,  -6.8700,   9.5782,  -5.9535,\n",
      "          -7.8690,   2.0185,  -5.4623,   5.5383,   5.6183,  -1.8131,  -9.4604,\n",
      "         -11.1886,   5.5786],\n",
      "        [  7.0449,  -3.3880,  -7.2273,  13.4734,   5.2254,   1.7417,   1.3858,\n",
      "          12.8059,  -4.4765,   5.5669,  -5.8736,   1.7135,  -7.7445,   5.3839,\n",
      "           8.2716, -12.9971],\n",
      "        [  5.8933,   4.3694,  -8.1206,   6.8468,  13.6584,  -7.0515,   3.4660,\n",
      "           2.3930,  -2.5905,  -4.1133,  -2.7786,  -2.0121,  -2.2797,  10.7717,\n",
      "          11.5426,  -4.4835],\n",
      "        [ -5.8953,  -7.8769,  10.3597,   0.9765,  -7.4546,  13.4528,  -7.4047,\n",
      "           1.2357,  -1.9816,   0.7232,   3.2091,   6.2039,  -7.2871,  -9.5015,\n",
      "          -8.2825,  -2.9584],\n",
      "        [ 12.3272,  -3.4722,  -5.7917,   0.6180,   3.8585,  -5.9149,  13.9095,\n",
      "          -0.8477,  11.2843,  -5.8090, -11.3506,   5.3921,  -0.8353,  10.4221,\n",
      "           4.6993,  -0.9107],\n",
      "        [  5.6689,  -1.2008,  -8.2287,  11.8902,   2.7142,   0.5485,   0.7878,\n",
      "          13.7401,  -5.3894,   9.3688,  -4.4530,  -1.4066,  -4.3002,   4.1603,\n",
      "           7.9062, -11.3678],\n",
      "        [  8.1823,  -6.9392,   1.8837,  -3.8376,  -0.6212,  -0.4378,  10.9634,\n",
      "          -5.9368,  13.5989,  -9.5832,  -8.9647,   9.4175,  -2.3691,   4.6910,\n",
      "          -2.5659,   2.5036],\n",
      "        [ -4.0540,   3.4627,  -2.8150,   4.5121,  -4.6419,   1.8912,  -6.5674,\n",
      "           9.2837,  -9.0426,  13.5518,   4.8494,  -7.0545,   2.6543,  -4.2670,\n",
      "           1.4940,  -3.9645],\n",
      "        [-12.0866,   7.2600,   5.2302,  -5.3568,  -3.0684,   1.5424, -10.5282,\n",
      "          -4.1199,  -8.1403,   2.8335,  13.2877,  -7.8379,   5.3045,  -7.2067,\n",
      "          -3.3554,   6.6960],\n",
      "        [  6.6815, -12.1438,   5.0262,   2.7801,  -0.5814,   7.4167,   5.5843,\n",
      "          -0.7966,   8.8759,  -7.8936,  -8.6851,  13.6363,  -9.8025,   0.8604,\n",
      "          -3.8557,  -4.4744],\n",
      "        [ -5.7569,   9.4420,   0.1562,  -8.9693,  -3.0858,  -6.8585,  -1.6439,\n",
      "          -5.7462,  -0.9294,   3.0641,   7.4682,  -9.1855,  13.7511,  -1.9366,\n",
      "          -1.7394,  11.1592],\n",
      "        [ 11.0586,   2.1765, -10.3646,   5.4322,  11.4217,  -9.1175,  10.2027,\n",
      "           2.4961,   3.4937,  -4.2892,  -8.1751,  -0.1535,  -1.1039,  13.8683,\n",
      "          11.6812,  -3.9217],\n",
      "        [  7.1279,   5.9926, -12.0819,   7.8098,  11.0754,  -8.7440,   4.7526,\n",
      "           6.4696,  -3.5645,   1.9440,  -3.2686,  -5.5134,  -0.1045,  11.6644,\n",
      "          13.8593,  -5.7204],\n",
      "        [ -7.5892,   6.1689,   6.1266, -12.3556,  -3.1840,  -3.2578,  -2.1173,\n",
      "         -11.8479,   2.3294,  -4.4517,   8.1740,  -4.2812,   9.8208,  -3.6981,\n",
      "          -5.6761,  13.5628]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.8171, 13.7741, 13.4902, 13.4734, 13.6584, 13.4528, 13.9095, 13.7401,\n",
      "        13.5989, 13.5518, 13.2877, 13.6363, 13.7511, 13.8683, 13.8593, 13.5628],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1315, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ -4.8464,  -7.5548,   5.6876,   5.8907,  -4.2604,  12.7730,   3.7108,\n",
      "           8.6035,  -3.9989, -12.6599,   6.2260,  -4.3339,  11.2721,   7.1021,\n",
      "          -5.9356],\n",
      "        [ -4.9294,  -5.7781,  -2.8624,   4.9733,  -9.3138,  -3.5011,  -1.5378,\n",
      "          -7.1626,   3.4745,   8.0064, -12.7298,   9.1810,   2.4372,   6.2343,\n",
      "           5.3795],\n",
      "        [ -8.0926,  -5.2016,  -6.6420,  -6.8700,   9.5782,  -5.9535,  -7.8690,\n",
      "           2.0185,  -5.4623,   5.5383,   5.6183,  -1.8131,  -9.4604, -11.1886,\n",
      "           5.5786],\n",
      "        [  7.0449,  -3.3880,  -7.2273,   5.2254,   1.7417,   1.3858,  12.8059,\n",
      "          -4.4765,   5.5669,  -5.8736,   1.7135,  -7.7445,   5.3839,   8.2716,\n",
      "         -12.9971],\n",
      "        [  5.8933,   4.3694,  -8.1206,   6.8468,  -7.0515,   3.4660,   2.3930,\n",
      "          -2.5905,  -4.1133,  -2.7786,  -2.0121,  -2.2797,  10.7717,  11.5426,\n",
      "          -4.4835],\n",
      "        [ -5.8953,  -7.8769,  10.3597,   0.9765,  -7.4546,  -7.4047,   1.2357,\n",
      "          -1.9816,   0.7232,   3.2091,   6.2039,  -7.2871,  -9.5015,  -8.2825,\n",
      "          -2.9584],\n",
      "        [ 12.3272,  -3.4722,  -5.7917,   0.6180,   3.8585,  -5.9149,  -0.8477,\n",
      "          11.2843,  -5.8090, -11.3506,   5.3921,  -0.8353,  10.4221,   4.6993,\n",
      "          -0.9107],\n",
      "        [  5.6689,  -1.2008,  -8.2287,  11.8902,   2.7142,   0.5485,   0.7878,\n",
      "          -5.3894,   9.3688,  -4.4530,  -1.4066,  -4.3002,   4.1603,   7.9062,\n",
      "         -11.3678],\n",
      "        [  8.1823,  -6.9392,   1.8837,  -3.8376,  -0.6212,  -0.4378,  10.9634,\n",
      "          -5.9368,  -9.5832,  -8.9647,   9.4175,  -2.3691,   4.6910,  -2.5659,\n",
      "           2.5036],\n",
      "        [ -4.0540,   3.4627,  -2.8150,   4.5121,  -4.6419,   1.8912,  -6.5674,\n",
      "           9.2837,  -9.0426,   4.8494,  -7.0545,   2.6543,  -4.2670,   1.4940,\n",
      "          -3.9645],\n",
      "        [-12.0866,   7.2600,   5.2302,  -5.3568,  -3.0684,   1.5424, -10.5282,\n",
      "          -4.1199,  -8.1403,   2.8335,  -7.8379,   5.3045,  -7.2067,  -3.3554,\n",
      "           6.6960],\n",
      "        [  6.6815, -12.1438,   5.0262,   2.7801,  -0.5814,   7.4167,   5.5843,\n",
      "          -0.7966,   8.8759,  -7.8936,  -8.6851,  -9.8025,   0.8604,  -3.8557,\n",
      "          -4.4744],\n",
      "        [ -5.7569,   9.4420,   0.1562,  -8.9693,  -3.0858,  -6.8585,  -1.6439,\n",
      "          -5.7462,  -0.9294,   3.0641,   7.4682,  -9.1855,  -1.9366,  -1.7394,\n",
      "          11.1592],\n",
      "        [ 11.0586,   2.1765, -10.3646,   5.4322,  11.4217,  -9.1175,  10.2027,\n",
      "           2.4961,   3.4937,  -4.2892,  -8.1751,  -0.1535,  -1.1039,  11.6812,\n",
      "          -3.9217],\n",
      "        [  7.1279,   5.9926, -12.0819,   7.8098,  11.0754,  -8.7440,   4.7526,\n",
      "           6.4696,  -3.5645,   1.9440,  -3.2686,  -5.5134,  -0.1045,  11.6644,\n",
      "          -5.7204],\n",
      "        [ -7.5892,   6.1689,   6.1266, -12.3556,  -3.1840,  -3.2578,  -2.1173,\n",
      "         -11.8479,   2.3294,  -4.4517,   8.1740,  -4.2812,   9.8208,  -3.6981,\n",
      "          -5.6761]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0084, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 6: 0.06996066123247147\n",
      "Batch 7/7: Matrix features: torch.Size([4, 128]), Vector features: torch.Size([4, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0887, -0.0048,  0.0014,  0.0123,  0.0499,  0.0464, -0.0476,  0.1623,\n",
      "          0.1137,  0.1025, -0.0107, -0.0481,  0.0055, -0.1663,  0.1190,  0.0266,\n",
      "         -0.1034, -0.1446, -0.0807,  0.0747,  0.0616, -0.0179,  0.0876,  0.0159,\n",
      "          0.0454, -0.1459,  0.0274,  0.0022,  0.1416, -0.1568, -0.0653, -0.1922,\n",
      "         -0.0928,  0.1148, -0.0734, -0.1353,  0.0881, -0.1787,  0.0625,  0.1132,\n",
      "          0.0449, -0.0305, -0.0343, -0.0139, -0.0083, -0.1062, -0.0147, -0.0012,\n",
      "          0.1559, -0.0551,  0.1024, -0.0139, -0.0490,  0.0673, -0.1756, -0.1027,\n",
      "          0.0459,  0.0434, -0.0051,  0.1122,  0.0134,  0.0262, -0.0144, -0.0208,\n",
      "         -0.1300,  0.0493,  0.0168, -0.1268, -0.0669,  0.2303,  0.1002, -0.0838,\n",
      "          0.0534,  0.0709, -0.0049, -0.1354, -0.0390, -0.0047, -0.1429, -0.0626,\n",
      "         -0.0619, -0.0780,  0.1406, -0.1338, -0.0428, -0.0042, -0.0550, -0.0008,\n",
      "         -0.0428,  0.0992,  0.0509, -0.0597, -0.0618,  0.0271,  0.0826, -0.0332,\n",
      "         -0.2011, -0.1599,  0.1141, -0.0292,  0.0821, -0.0590,  0.1053, -0.0044,\n",
      "          0.1559,  0.0185, -0.0910,  0.0625,  0.1252, -0.0148,  0.0431,  0.0368,\n",
      "          0.1260, -0.0195, -0.0570,  0.1793,  0.0012,  0.0642, -0.0135, -0.0308,\n",
      "         -0.0794,  0.1221, -0.0458, -0.0110,  0.0321, -0.0376,  0.1247,  0.0426],\n",
      "        [ 0.1286, -0.0208, -0.1161,  0.0203,  0.0461,  0.0140, -0.0570,  0.1512,\n",
      "          0.1293,  0.1409,  0.0868, -0.1131, -0.0755, -0.1496,  0.1659,  0.0607,\n",
      "         -0.0629, -0.0224, -0.0217,  0.0625,  0.0593, -0.0191,  0.0783,  0.0087,\n",
      "          0.1213, -0.1707,  0.0262, -0.0418,  0.1584, -0.1436, -0.0541, -0.1499,\n",
      "         -0.0665,  0.0835, -0.1215, -0.0641,  0.0680, -0.1698,  0.0447,  0.0206,\n",
      "          0.0255,  0.0155, -0.0663, -0.0640, -0.0861, -0.0881, -0.0460, -0.0184,\n",
      "          0.0883, -0.0125,  0.0259,  0.0182, -0.0793, -0.0213, -0.2102, -0.0928,\n",
      "          0.0586,  0.0797, -0.0443,  0.0666,  0.0978, -0.0038,  0.0044, -0.0529,\n",
      "         -0.1166,  0.1194, -0.0334, -0.0763, -0.0351,  0.1270,  0.0913, -0.0196,\n",
      "          0.0104,  0.0689, -0.0625, -0.0948,  0.0870,  0.0296, -0.1400, -0.0393,\n",
      "         -0.0878, -0.0544,  0.0450, -0.1325, -0.0196,  0.1071, -0.0979, -0.0653,\n",
      "          0.0302,  0.0514,  0.0614, -0.0188, -0.1049,  0.0705,  0.0278, -0.0438,\n",
      "         -0.1677, -0.2234,  0.1171, -0.0823,  0.0470, -0.0671,  0.1314,  0.0824,\n",
      "          0.1010,  0.1007, -0.0424,  0.0109,  0.1308,  0.0235,  0.0806, -0.0344,\n",
      "          0.0659,  0.0374, -0.0041,  0.2812,  0.0713,  0.0294, -0.0660, -0.0339,\n",
      "          0.0360,  0.0792, -0.0075, -0.0431, -0.0403, -0.0744,  0.1326,  0.0140],\n",
      "        [ 0.1450, -0.0474,  0.0650, -0.1209, -0.1190, -0.1120,  0.0950, -0.0108,\n",
      "         -0.0559, -0.0935, -0.0093,  0.0249,  0.0451, -0.0614, -0.0197,  0.0673,\n",
      "         -0.0824, -0.1111, -0.0990, -0.0279, -0.0957,  0.0028, -0.0106, -0.0287,\n",
      "         -0.1385, -0.0500,  0.0906,  0.0183, -0.0060,  0.0257, -0.0326, -0.0324,\n",
      "          0.1025,  0.0267,  0.0803,  0.0029,  0.1580, -0.0842, -0.1319, -0.0534,\n",
      "          0.0117, -0.0606, -0.0232,  0.0829,  0.1523,  0.0598, -0.0327,  0.0675,\n",
      "          0.1361,  0.0399,  0.1071,  0.1015,  0.1846,  0.0528,  0.0451, -0.0095,\n",
      "         -0.0080, -0.1528, -0.0723,  0.1436, -0.0698, -0.0843, -0.0398,  0.0252,\n",
      "          0.0613, -0.0732,  0.0740,  0.0683, -0.0176, -0.0492,  0.0750,  0.0120,\n",
      "          0.0887,  0.0997,  0.1743,  0.1466, -0.0846, -0.1450, -0.0526, -0.0591,\n",
      "         -0.0652,  0.0071,  0.0426, -0.0659,  0.0912,  0.0401,  0.0349,  0.1369,\n",
      "         -0.0751, -0.0201,  0.0165, -0.0191,  0.1573, -0.0081,  0.0641, -0.0979,\n",
      "         -0.0727,  0.0894,  0.0123,  0.1111,  0.0274,  0.0373, -0.0115, -0.1453,\n",
      "          0.0607, -0.0685, -0.0465,  0.0080,  0.0280, -0.0596, -0.1113,  0.1066,\n",
      "         -0.0215, -0.1962, -0.0115, -0.1533, -0.0044,  0.0444,  0.1942,  0.0174,\n",
      "         -0.1567, -0.0590, -0.1606,  0.0933,  0.0836,  0.0878, -0.2872,  0.0214],\n",
      "        [-0.0486, -0.0010, -0.0797,  0.0142,  0.0996,  0.0760, -0.0780,  0.1226,\n",
      "          0.0407,  0.1377,  0.0308, -0.0734, -0.0642, -0.0390,  0.1013, -0.0570,\n",
      "         -0.0196,  0.0475,  0.0085,  0.0244,  0.1223,  0.0390,  0.0280,  0.0662,\n",
      "          0.2068, -0.0601, -0.0207, -0.0404,  0.1447, -0.1543,  0.0037, -0.0599,\n",
      "         -0.1183,  0.0088, -0.1031, -0.0486, -0.0749, -0.1028,  0.1457,  0.0762,\n",
      "         -0.0067, -0.0061,  0.0057, -0.0340, -0.0838, -0.1211, -0.0156, -0.0286,\n",
      "          0.0270, -0.0867,  0.0062, -0.0051, -0.1424, -0.0096, -0.1707, -0.0561,\n",
      "          0.0615,  0.0735, -0.0051, -0.0063,  0.1133,  0.0543, -0.0126, -0.0098,\n",
      "         -0.1404,  0.1259,  0.0159, -0.0567, -0.0014,  0.1314,  0.0596, -0.0320,\n",
      "         -0.0242, -0.0202, -0.0861, -0.1929,  0.1403,  0.0841, -0.1161,  0.0128,\n",
      "         -0.0556, -0.0898,  0.0262, -0.0968, -0.1067, -0.0023, -0.1058, -0.0668,\n",
      "          0.0360,  0.1044, -0.0049, -0.0201, -0.2104, -0.0280,  0.0057,  0.0703,\n",
      "         -0.1178, -0.1363,  0.0604, -0.0719,  0.0821, -0.0844,  0.1323,  0.1355,\n",
      "          0.0338,  0.0577,  0.0078, -0.0058,  0.1030,  0.1122,  0.1298, -0.0789,\n",
      "          0.0995,  0.0726,  0.0242,  0.2162,  0.0399, -0.0168, -0.1594, -0.0805,\n",
      "          0.1419,  0.0754,  0.0486, -0.1069, -0.0935, -0.0554,  0.2422, -0.0070]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 5.3774e-02, -1.2571e-02,  5.7059e-03,  3.4251e-02,  4.9771e-02,\n",
      "          3.9329e-02, -6.1812e-02,  1.5604e-01,  1.0023e-01,  1.4745e-01,\n",
      "          3.4366e-03, -4.7459e-02, -7.2046e-03, -1.5018e-01,  1.2691e-01,\n",
      "          2.6409e-02, -1.1285e-01, -1.5258e-01, -6.0549e-02,  9.4821e-02,\n",
      "          4.0979e-02, -2.4610e-02,  1.0326e-01,  2.8637e-02,  5.5398e-02,\n",
      "         -1.3008e-01,  2.6496e-02,  2.3934e-02,  1.2979e-01, -1.3871e-01,\n",
      "         -4.1993e-02, -1.3041e-01, -1.2209e-01,  1.2753e-01, -7.6098e-02,\n",
      "         -1.3401e-01,  5.4878e-02, -1.9655e-01,  1.0422e-01,  9.7874e-02,\n",
      "          3.7738e-02, -6.9475e-03, -1.9077e-02,  1.0349e-02, -4.3714e-02,\n",
      "         -6.3904e-02, -4.0817e-02, -1.4021e-02,  1.6169e-01, -3.8121e-02,\n",
      "          9.2857e-02, -2.6471e-02, -1.9730e-02,  6.5983e-02, -1.5837e-01,\n",
      "         -1.0110e-01,  7.6516e-02,  5.1298e-02,  3.5599e-03,  1.0285e-01,\n",
      "          4.2735e-03, -1.6820e-02,  7.8776e-03,  2.2532e-02, -1.6656e-01,\n",
      "          7.2510e-02, -4.0075e-02, -8.3766e-02, -9.8466e-02,  1.9125e-01,\n",
      "          7.3004e-02, -1.0084e-01,  5.0280e-02,  5.0437e-02, -3.9455e-02,\n",
      "         -1.5508e-01, -2.2713e-02,  2.3868e-02, -1.5962e-01, -5.5477e-02,\n",
      "         -5.9593e-02, -6.7187e-02,  1.4754e-01, -1.2055e-01, -6.6151e-02,\n",
      "         -1.6832e-02, -5.5934e-02, -6.6972e-03, -1.4204e-02,  1.0419e-01,\n",
      "          3.8183e-02, -4.7978e-02, -9.8949e-02,  3.7519e-02,  2.5370e-02,\n",
      "         -2.0699e-02, -2.1419e-01, -2.0095e-01,  1.4118e-01, -4.1009e-02,\n",
      "          8.9366e-02, -5.0939e-02,  9.5477e-02,  1.7840e-02,  1.6924e-01,\n",
      "          2.1749e-02, -8.4813e-02,  4.9433e-02,  9.7812e-02, -2.1997e-02,\n",
      "          7.7172e-02,  2.8501e-02,  8.2140e-02,  2.5740e-02, -3.0821e-02,\n",
      "          2.1038e-01,  2.5916e-02,  5.2248e-02, -5.0117e-02, -2.9399e-03,\n",
      "         -3.2336e-02,  1.0198e-01, -2.8676e-02, -4.8196e-02, -2.6555e-02,\n",
      "         -7.5053e-02,  1.4236e-01,  4.0178e-02],\n",
      "        [ 5.9256e-02, -3.3236e-02, -1.3292e-01,  4.2849e-02,  6.7389e-02,\n",
      "         -2.9044e-03, -7.7640e-02,  1.0805e-01,  1.6764e-01,  1.3056e-01,\n",
      "          6.2035e-02, -8.1244e-02, -5.1378e-02, -1.3384e-01,  1.5719e-01,\n",
      "          7.5788e-02, -9.2408e-02, -5.0753e-02, -3.2575e-02,  4.9593e-02,\n",
      "          2.9596e-02, -4.7062e-02,  8.6282e-02, -1.1889e-02,  1.0173e-01,\n",
      "         -1.1877e-01,  1.3217e-02, -1.9539e-02,  1.4876e-01, -1.1001e-01,\n",
      "         -7.1665e-02, -1.0984e-01, -7.0038e-02,  8.4328e-02, -1.2145e-01,\n",
      "         -7.8850e-02,  3.4828e-02, -2.6212e-01,  7.7635e-02,  2.9005e-02,\n",
      "          2.8784e-02,  1.8011e-02, -5.5730e-02, -4.0369e-02, -9.8674e-02,\n",
      "         -6.2253e-02, -5.0512e-02, -3.6924e-03,  1.1045e-01, -1.8556e-02,\n",
      "          4.3391e-03, -1.1459e-02, -4.8989e-02,  9.8658e-03, -1.9218e-01,\n",
      "         -1.3282e-01,  8.0683e-02,  8.5718e-02, -2.4055e-03,  8.8635e-02,\n",
      "          5.4158e-02, -5.9171e-03,  2.4590e-02, -2.4545e-02, -1.2447e-01,\n",
      "          1.2716e-01, -6.0455e-02, -4.5008e-02, -8.4084e-03,  2.2086e-01,\n",
      "          8.8101e-02, -1.8441e-02,  1.4848e-02,  6.4147e-02, -9.9263e-02,\n",
      "         -1.2471e-01,  8.2983e-02,  1.9779e-02, -1.0441e-01, -6.0714e-02,\n",
      "         -5.6724e-02, -3.5473e-02,  6.9799e-02, -9.0745e-02, -3.5795e-02,\n",
      "          7.4063e-02, -1.0341e-01, -5.2629e-02,  7.6100e-02,  6.6506e-02,\n",
      "          6.8837e-02, -2.5104e-02, -1.3100e-01,  7.5319e-02, -2.5389e-03,\n",
      "         -6.7558e-02, -1.7919e-01, -1.6704e-01,  1.3790e-01, -9.3779e-02,\n",
      "          2.4003e-02, -3.8731e-02,  1.4093e-01,  9.3316e-02,  1.2114e-01,\n",
      "          1.0073e-01, -6.3812e-02,  1.9021e-02,  1.3664e-01,  1.2754e-02,\n",
      "          5.9836e-02, -1.6261e-02,  7.5122e-02,  6.8155e-02, -1.1271e-02,\n",
      "          2.3650e-01,  3.5761e-02,  3.3640e-02, -7.9176e-02, -2.4635e-02,\n",
      "          3.9763e-02,  7.7041e-02, -2.3155e-02, -1.9112e-02, -6.9423e-02,\n",
      "         -1.3241e-01,  1.1893e-01,  1.1480e-02],\n",
      "        [ 5.9888e-02, -3.4363e-02,  6.2811e-02, -1.0723e-01, -1.1686e-01,\n",
      "         -9.8886e-02,  9.6611e-02, -4.2423e-02, -2.9305e-02, -6.3837e-02,\n",
      "         -3.9185e-02,  4.9195e-02,  1.2167e-01, -3.8357e-02, -4.9801e-02,\n",
      "          6.3830e-02, -7.2280e-02, -1.2224e-01, -7.3594e-02,  8.1009e-04,\n",
      "         -1.1636e-01, -3.3108e-02, -7.7739e-03, -2.5213e-02, -1.4942e-01,\n",
      "         -3.3650e-02,  6.8487e-02,  5.8382e-02, -2.7204e-02,  6.9714e-02,\n",
      "         -2.2980e-02, -1.3610e-02,  7.9736e-02,  1.6470e-02,  7.7904e-02,\n",
      "          7.9495e-03,  1.2742e-01, -6.8419e-02, -7.7818e-02, -2.5536e-02,\n",
      "          1.8202e-02, -5.3413e-02, -3.7500e-03,  8.8382e-02,  2.1957e-01,\n",
      "          9.3562e-02, -3.4156e-02,  3.5019e-02,  1.1623e-01,  4.0704e-02,\n",
      "          9.1479e-02,  8.3988e-02,  1.8230e-01,  3.7623e-02,  6.6399e-02,\n",
      "         -4.0098e-02, -2.2204e-02, -1.3283e-01, -3.5907e-02,  1.0612e-01,\n",
      "         -1.3126e-01, -8.7005e-02, -2.5134e-02,  5.9610e-02,  3.4793e-02,\n",
      "         -7.3340e-02,  5.2889e-02,  1.2313e-02, -2.3290e-02, -2.2341e-02,\n",
      "          3.3319e-02,  5.4605e-03,  1.1292e-01,  9.2794e-02,  1.2895e-01,\n",
      "          1.6738e-01, -2.6406e-01, -1.1743e-01, -3.4259e-02, -4.6198e-02,\n",
      "         -4.6228e-02, -2.2745e-02,  4.4047e-02, -3.9444e-02,  8.3451e-02,\n",
      "          7.0240e-03,  2.7965e-02,  1.3526e-01, -5.6897e-02, -2.3049e-02,\n",
      "          5.5696e-02,  1.8623e-02,  2.0724e-01,  7.9592e-03,  6.0373e-02,\n",
      "         -7.8879e-02, -3.6742e-02,  7.7772e-02, -9.1175e-04,  1.0555e-01,\n",
      "          2.1348e-02,  4.3198e-02, -5.9270e-02, -1.4609e-01,  4.6256e-02,\n",
      "         -5.0959e-02, -6.8026e-03,  4.9585e-03,  1.4278e-02, -5.8816e-02,\n",
      "         -9.1192e-02,  9.7343e-02, -2.4922e-02, -2.0421e-01, -2.0309e-02,\n",
      "         -1.9619e-01, -1.9509e-02,  6.0013e-02,  1.7075e-01,  3.3131e-03,\n",
      "         -1.7724e-01, -7.9003e-02, -1.6985e-01,  1.2161e-01,  7.8559e-02,\n",
      "          8.9859e-02, -2.2962e-01,  3.9304e-02],\n",
      "        [-5.4896e-02,  5.1344e-03, -4.7476e-02, -3.2195e-05,  1.2100e-01,\n",
      "          5.1898e-02, -6.6641e-02,  7.1027e-02,  5.8168e-02,  1.6865e-01,\n",
      "          2.9331e-02, -7.9570e-02, -7.5090e-02, -7.0301e-02,  1.1134e-01,\n",
      "         -7.4875e-02, -2.4584e-02,  3.8156e-02,  1.5358e-02,  2.4090e-02,\n",
      "          9.9336e-02,  3.9951e-02,  3.7148e-02,  4.2633e-02,  1.7040e-01,\n",
      "         -8.6890e-02, -3.7386e-02, -3.7875e-02,  1.5790e-01, -1.2297e-01,\n",
      "         -3.5980e-02, -1.4123e-02, -1.2494e-01,  2.0585e-02, -1.1196e-01,\n",
      "         -8.0329e-02, -9.8194e-02, -1.4314e-01,  1.5326e-01,  9.1103e-02,\n",
      "          7.0014e-03,  9.8958e-03,  1.2823e-02, -2.2101e-02, -1.1114e-01,\n",
      "         -1.0222e-01, -3.7065e-02,  6.4348e-03,  1.0681e-02, -8.7090e-02,\n",
      "          1.0201e-02, -4.8019e-02, -1.3943e-01, -2.0506e-02, -1.3739e-01,\n",
      "         -6.5322e-02,  7.7404e-02,  1.0215e-01,  2.1621e-02, -1.8435e-02,\n",
      "          1.0307e-01,  5.4300e-02, -2.5475e-03,  1.7648e-02, -1.6454e-01,\n",
      "          1.2043e-01, -5.7956e-03, -8.6388e-02,  6.7132e-03,  1.3960e-01,\n",
      "          7.0671e-02, -3.0451e-02,  1.6704e-03, -1.4516e-02, -1.1350e-01,\n",
      "         -1.7868e-01,  1.4841e-01,  8.9396e-02, -8.1111e-02,  1.5154e-02,\n",
      "         -2.0531e-02, -5.6473e-02,  6.8397e-03, -9.8113e-02, -1.1602e-01,\n",
      "          5.8099e-03, -9.5967e-02, -9.2704e-02,  5.5964e-02,  9.6017e-02,\n",
      "         -8.8090e-03, -3.5771e-02, -1.2673e-01, -3.1210e-02, -1.1040e-02,\n",
      "          3.5883e-02, -1.2261e-01, -1.8199e-01,  3.8685e-02, -7.5656e-02,\n",
      "          6.6267e-02, -5.5053e-02,  8.2124e-02,  7.8005e-02,  5.5068e-02,\n",
      "          5.3474e-02, -7.5287e-04,  4.1008e-03,  9.4319e-02,  9.3252e-02,\n",
      "          1.2681e-01, -7.8053e-02,  9.9181e-02,  1.0214e-01,  4.1982e-02,\n",
      "          2.5613e-01,  5.2876e-02,  8.2641e-03, -1.2788e-01, -7.8985e-02,\n",
      "          1.1897e-01,  7.6235e-02,  5.8961e-02, -9.4146e-02, -7.5383e-02,\n",
      "         -8.7087e-02,  2.8725e-01, -1.3170e-03]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.7548,  11.8698,  -0.8192,   8.8749],\n",
      "        [ 12.2419,  13.6366,  -5.4630,  11.2677],\n",
      "        [ -1.7351,  -4.1080,  13.4276,  -9.6494],\n",
      "        [  9.7863,  10.9605, -10.3630,  13.8046]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7548, 13.6366, 13.4276, 13.8046], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1288, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 11.8698,  -0.8192,   8.8749],\n",
      "        [ 12.2419,  -5.4630,  11.2677],\n",
      "        [ -1.7351,  -4.1080,  -9.6494],\n",
      "        [  9.7863,  10.9605, -10.3630]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0413, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 7: 0.08505507558584213\n",
      "Epoch [5/10], Loss: 0.1144\n",
      "Batch 1/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.0860,  0.0131, -0.0670,  ..., -0.0056,  0.2579, -0.0560],\n",
      "        [ 0.0126,  0.0399, -0.1312,  ..., -0.0305, -0.1980,  0.0046],\n",
      "        [ 0.1505, -0.0129, -0.1568,  ..., -0.0985, -0.1289,  0.0147],\n",
      "        ...,\n",
      "        [ 0.1271, -0.0604,  0.0202,  ...,  0.0975, -0.2360,  0.0077],\n",
      "        [-0.0299,  0.0149,  0.0210,  ..., -0.0133,  0.1877, -0.0395],\n",
      "        [ 0.1790, -0.0179, -0.0414,  ..., -0.0805,  0.0217,  0.0370]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.1088, -0.0074, -0.0769,  ..., -0.0246,  0.2869, -0.0515],\n",
      "        [-0.0146, -0.0057, -0.1501,  ..., -0.0560, -0.1024, -0.0042],\n",
      "        [ 0.1525, -0.0048, -0.1560,  ..., -0.1435, -0.1064,  0.0067],\n",
      "        ...,\n",
      "        [ 0.1451, -0.0727,  0.0275,  ...,  0.0886, -0.2404,  0.0655],\n",
      "        [-0.0229,  0.0129, -0.0086,  ..., -0.1001,  0.2419,  0.0199],\n",
      "        [ 0.1565, -0.0478, -0.0965,  ..., -0.0797,  0.0910,  0.0495]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3718e+01, -2.0964e+00, -1.6659e+00, -7.4709e+00, -1.1312e+01,\n",
      "         -7.6890e+00, -4.1502e+00,  2.1695e+00, -9.5252e+00,  5.3699e+00,\n",
      "          4.4452e+00,  4.0725e+00, -9.0401e+00, -1.0248e+01,  1.0523e+01,\n",
      "          3.7262e+00],\n",
      "        [-2.1880e+00,  1.3563e+01,  7.7878e+00,  5.7102e-01,  6.9273e+00,\n",
      "          6.0609e-01, -4.7148e+00, -1.2303e+01,  4.2397e+00, -1.0364e+00,\n",
      "         -5.9398e+00,  1.0861e+01,  4.2213e+00, -1.0674e+00, -7.2469e+00,\n",
      "          6.6033e-01],\n",
      "        [-2.4754e+00,  7.4680e+00,  1.3586e+01, -1.5781e+00,  2.6842e+00,\n",
      "         -1.4485e+00,  2.4995e-01, -9.4561e+00,  4.5616e+00,  1.0546e+00,\n",
      "          5.4023e+00,  3.5424e+00,  7.4322e-01,  2.4122e+00,  5.6895e-03,\n",
      "          7.9773e+00],\n",
      "        [-7.1526e+00, -1.7895e+00, -3.2874e+00,  1.3934e+01,  6.6762e+00,\n",
      "          1.3234e+01,  1.1845e+01,  3.2498e+00,  6.0299e+00, -1.3077e+01,\n",
      "         -6.5216e+00, -5.9612e+00,  1.2661e+01,  1.0048e+01, -3.9003e+00,\n",
      "         -1.0067e+01],\n",
      "        [-1.0638e+01,  5.9399e+00,  3.6577e+00,  7.3761e+00,  1.3697e+01,\n",
      "          7.8625e+00,  3.3088e+00, -5.4704e+00,  1.1662e+01, -6.1741e+00,\n",
      "         -7.3261e+00,  6.8187e-01,  1.0900e+01,  9.8825e+00, -1.1507e+01,\n",
      "         -1.5691e+00],\n",
      "        [-6.9908e+00, -1.2393e+00, -2.1104e+00,  1.3318e+01,  7.2355e+00,\n",
      "          1.3659e+01,  1.2225e+01,  2.3289e+00,  6.7677e+00, -1.2648e+01,\n",
      "         -5.8500e+00, -6.0739e+00,  1.2654e+01,  1.1256e+01, -3.6208e+00,\n",
      "         -8.0022e+00],\n",
      "        [-5.0457e+00, -4.8171e+00, -1.6946e+00,  1.2122e+01,  3.1302e+00,\n",
      "          1.1972e+01,  1.3916e+01,  5.0951e+00,  4.3039e+00, -1.1473e+01,\n",
      "         -1.0454e+00, -8.9244e+00,  9.9870e+00,  1.0599e+01,  1.1634e+00,\n",
      "         -6.5393e+00],\n",
      "        [-4.0612e-01, -1.3146e+01, -9.1556e+00,  2.9363e+00, -3.3491e+00,\n",
      "          3.1937e+00,  6.8296e+00,  1.2965e+01, -1.7516e+00, -1.3747e+00,\n",
      "          3.0416e+00, -1.1893e+01, -5.8960e-01,  4.3627e+00,  4.5625e+00,\n",
      "         -2.9521e+00],\n",
      "        [-1.0466e+01,  3.0778e+00,  5.0306e+00,  7.0633e+00,  1.1677e+01,\n",
      "          7.1831e+00,  5.2411e+00, -3.6454e+00,  1.3578e+01, -5.2774e+00,\n",
      "         -5.0603e+00, -1.7671e+00,  9.7130e+00,  1.0015e+01, -8.2550e+00,\n",
      "         -1.2544e-01],\n",
      "        [ 4.2387e+00, -1.1151e+00,  3.0195e+00, -1.2588e+01, -5.3277e+00,\n",
      "         -1.1752e+01, -9.5534e+00, -5.1307e-01, -4.0015e+00,  1.3437e+01,\n",
      "          8.0772e+00,  1.7391e+00, -1.1916e+01, -6.7621e+00,  3.7355e+00,\n",
      "          1.0573e+01],\n",
      "        [ 2.3881e+00, -5.7083e+00,  4.5144e+00, -4.9115e+00, -7.2626e+00,\n",
      "         -4.2784e+00,  2.1570e+00,  3.1583e+00, -5.2112e+00,  4.4533e+00,\n",
      "          1.3700e+01, -6.0820e+00, -6.8797e+00,  5.8710e-01,  8.9086e+00,\n",
      "          7.7409e+00],\n",
      "        [ 2.8416e+00,  1.2143e+01,  5.5314e+00, -3.8927e+00,  3.3103e+00,\n",
      "         -4.3232e+00, -8.9876e+00, -1.0922e+01,  1.6523e+00,  2.9166e+00,\n",
      "         -5.9286e+00,  1.3242e+01, -2.8274e-01, -6.5058e+00, -5.1010e+00,\n",
      "          2.2898e+00],\n",
      "        [-8.6094e+00,  2.9384e+00,  1.0263e+00,  1.2501e+01,  1.0658e+01,\n",
      "          1.2308e+01,  9.3969e+00, -1.9319e+00,  9.6962e+00, -1.1874e+01,\n",
      "         -7.7197e+00, -2.3520e+00,  1.3692e+01,  1.0934e+01, -7.3769e+00,\n",
      "         -6.5227e+00],\n",
      "        [-9.6958e+00, -2.8393e+00, -3.1722e-01,  1.0553e+01,  9.1616e+00,\n",
      "          1.1381e+01,  1.0961e+01,  2.5580e+00,  8.6040e+00, -9.5098e+00,\n",
      "         -2.2849e+00, -8.2607e+00,  1.1008e+01,  1.3583e+01, -5.2337e+00,\n",
      "         -3.4904e+00],\n",
      "        [ 9.1655e+00, -8.7199e+00, -3.4122e+00, -1.3476e+00, -1.1335e+01,\n",
      "         -1.7317e+00,  4.5879e+00,  8.3749e+00, -7.7644e+00,  8.3314e-01,\n",
      "          7.3673e+00, -5.3266e+00, -5.6483e+00, -3.4650e+00,  1.3193e+01,\n",
      "          4.7383e-01],\n",
      "        [ 2.1816e+00,  1.5126e+00,  8.5508e+00, -9.8319e+00, -1.3042e+00,\n",
      "         -8.5921e+00, -5.4871e+00, -4.1972e+00,  8.4302e-01,  9.7810e+00,\n",
      "          8.7653e+00,  2.0011e+00, -7.5358e+00, -1.6639e+00,  2.6617e+00,\n",
      "          1.3488e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7182, 13.5627, 13.5856, 13.9341, 13.6970, 13.6587, 13.9162, 12.9650,\n",
      "        13.5779, 13.4371, 13.6995, 13.2421, 13.6920, 13.5829, 13.1933, 13.4884],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.2241, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[-2.0964e+00, -1.6659e+00, -7.4709e+00, -1.1312e+01, -7.6890e+00,\n",
      "         -4.1502e+00,  2.1695e+00, -9.5252e+00,  5.3699e+00,  4.4452e+00,\n",
      "          4.0725e+00, -9.0401e+00, -1.0248e+01,  1.0523e+01,  3.7262e+00],\n",
      "        [-2.1880e+00,  7.7878e+00,  5.7102e-01,  6.9273e+00,  6.0609e-01,\n",
      "         -4.7148e+00, -1.2303e+01,  4.2397e+00, -1.0364e+00, -5.9398e+00,\n",
      "          1.0861e+01,  4.2213e+00, -1.0674e+00, -7.2469e+00,  6.6033e-01],\n",
      "        [-2.4754e+00,  7.4680e+00, -1.5781e+00,  2.6842e+00, -1.4485e+00,\n",
      "          2.4995e-01, -9.4561e+00,  4.5616e+00,  1.0546e+00,  5.4023e+00,\n",
      "          3.5424e+00,  7.4322e-01,  2.4122e+00,  5.6895e-03,  7.9773e+00],\n",
      "        [-7.1526e+00, -1.7895e+00, -3.2874e+00,  6.6762e+00,  1.3234e+01,\n",
      "          1.1845e+01,  3.2498e+00,  6.0299e+00, -1.3077e+01, -6.5216e+00,\n",
      "         -5.9612e+00,  1.2661e+01,  1.0048e+01, -3.9003e+00, -1.0067e+01],\n",
      "        [-1.0638e+01,  5.9399e+00,  3.6577e+00,  7.3761e+00,  7.8625e+00,\n",
      "          3.3088e+00, -5.4704e+00,  1.1662e+01, -6.1741e+00, -7.3261e+00,\n",
      "          6.8187e-01,  1.0900e+01,  9.8825e+00, -1.1507e+01, -1.5691e+00],\n",
      "        [-6.9908e+00, -1.2393e+00, -2.1104e+00,  1.3318e+01,  7.2355e+00,\n",
      "          1.2225e+01,  2.3289e+00,  6.7677e+00, -1.2648e+01, -5.8500e+00,\n",
      "         -6.0739e+00,  1.2654e+01,  1.1256e+01, -3.6208e+00, -8.0022e+00],\n",
      "        [-5.0457e+00, -4.8171e+00, -1.6946e+00,  1.2122e+01,  3.1302e+00,\n",
      "          1.1972e+01,  5.0951e+00,  4.3039e+00, -1.1473e+01, -1.0454e+00,\n",
      "         -8.9244e+00,  9.9870e+00,  1.0599e+01,  1.1634e+00, -6.5393e+00],\n",
      "        [-4.0612e-01, -1.3146e+01, -9.1556e+00,  2.9363e+00, -3.3491e+00,\n",
      "          3.1937e+00,  6.8296e+00, -1.7516e+00, -1.3747e+00,  3.0416e+00,\n",
      "         -1.1893e+01, -5.8960e-01,  4.3627e+00,  4.5625e+00, -2.9521e+00],\n",
      "        [-1.0466e+01,  3.0778e+00,  5.0306e+00,  7.0633e+00,  1.1677e+01,\n",
      "          7.1831e+00,  5.2411e+00, -3.6454e+00, -5.2774e+00, -5.0603e+00,\n",
      "         -1.7671e+00,  9.7130e+00,  1.0015e+01, -8.2550e+00, -1.2544e-01],\n",
      "        [ 4.2387e+00, -1.1151e+00,  3.0195e+00, -1.2588e+01, -5.3277e+00,\n",
      "         -1.1752e+01, -9.5534e+00, -5.1307e-01, -4.0015e+00,  8.0772e+00,\n",
      "          1.7391e+00, -1.1916e+01, -6.7621e+00,  3.7355e+00,  1.0573e+01],\n",
      "        [ 2.3881e+00, -5.7083e+00,  4.5144e+00, -4.9115e+00, -7.2626e+00,\n",
      "         -4.2784e+00,  2.1570e+00,  3.1583e+00, -5.2112e+00,  4.4533e+00,\n",
      "         -6.0820e+00, -6.8797e+00,  5.8710e-01,  8.9086e+00,  7.7409e+00],\n",
      "        [ 2.8416e+00,  1.2143e+01,  5.5314e+00, -3.8927e+00,  3.3103e+00,\n",
      "         -4.3232e+00, -8.9876e+00, -1.0922e+01,  1.6523e+00,  2.9166e+00,\n",
      "         -5.9286e+00, -2.8274e-01, -6.5058e+00, -5.1010e+00,  2.2898e+00],\n",
      "        [-8.6094e+00,  2.9384e+00,  1.0263e+00,  1.2501e+01,  1.0658e+01,\n",
      "          1.2308e+01,  9.3969e+00, -1.9319e+00,  9.6962e+00, -1.1874e+01,\n",
      "         -7.7197e+00, -2.3520e+00,  1.0934e+01, -7.3769e+00, -6.5227e+00],\n",
      "        [-9.6958e+00, -2.8393e+00, -3.1722e-01,  1.0553e+01,  9.1616e+00,\n",
      "          1.1381e+01,  1.0961e+01,  2.5580e+00,  8.6040e+00, -9.5098e+00,\n",
      "         -2.2849e+00, -8.2607e+00,  1.1008e+01, -5.2337e+00, -3.4904e+00],\n",
      "        [ 9.1655e+00, -8.7199e+00, -3.4122e+00, -1.3476e+00, -1.1335e+01,\n",
      "         -1.7317e+00,  4.5879e+00,  8.3749e+00, -7.7644e+00,  8.3314e-01,\n",
      "          7.3673e+00, -5.3266e+00, -5.6483e+00, -3.4650e+00,  4.7383e-01],\n",
      "        [ 2.1816e+00,  1.5126e+00,  8.5508e+00, -9.8319e+00, -1.3042e+00,\n",
      "         -8.5921e+00, -5.4871e+00, -4.1972e+00,  8.4302e-01,  9.7810e+00,\n",
      "          8.7653e+00,  2.0011e+00, -7.5358e+00, -1.6639e+00,  2.6617e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0128, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 1: 0.1184549331665039\n",
      "Batch 2/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0450,  0.0263, -0.0828,  ..., -0.0304, -0.2889, -0.0640],\n",
      "        [ 0.1085, -0.0475,  0.0615,  ...,  0.0900, -0.2725, -0.0082],\n",
      "        [-0.0263, -0.0066,  0.1838,  ...,  0.1311, -0.0168,  0.0111],\n",
      "        ...,\n",
      "        [-0.0578,  0.0027, -0.0123,  ...,  0.0521,  0.0355, -0.1308],\n",
      "        [ 0.0286, -0.0247, -0.0766,  ...,  0.0255, -0.2292, -0.0779],\n",
      "        [-0.0887, -0.0169, -0.0061,  ...,  0.0747, -0.0440, -0.0977]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0122, -0.0189, -0.0803,  ..., -0.0345, -0.2371, -0.1014],\n",
      "        [ 0.0612, -0.0255,  0.0651,  ...,  0.0908, -0.2875, -0.0044],\n",
      "        [-0.0745, -0.0306,  0.1888,  ...,  0.1466,  0.0278,  0.0126],\n",
      "        ...,\n",
      "        [-0.0593, -0.0131, -0.0296,  ...,  0.0170,  0.0448, -0.1305],\n",
      "        [ 0.0204, -0.0420, -0.0990,  ..., -0.0061, -0.1980, -0.0664],\n",
      "        [-0.0937, -0.0105,  0.0105,  ...,  0.0899, -0.0233, -0.1005]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.6475,   3.6800,  -7.0454,   3.7865,   7.9606,  -5.0494,   6.5535,\n",
      "         -11.4352,   7.1456,   8.3163,  12.5719,   6.3060,   6.9406,   1.3967,\n",
      "          10.8209,   1.6646],\n",
      "        [  1.3236,  13.7288,   7.2574,   8.1615,   2.6780,  -3.7025,   4.8809,\n",
      "          -3.1486,  10.3636,   6.7349,   1.7456,   3.5361,   5.8368,   3.0160,\n",
      "           6.7626,   5.9186],\n",
      "        [ -7.7158,   8.5129,  13.4525,   3.9221,   1.1601,   4.8340,  -1.6325,\n",
      "           3.2278,   2.4081,   2.4384,  -9.1975,   2.2489,   2.7529,   1.7048,\n",
      "          -3.0704,   5.1688],\n",
      "        [  2.1303,   7.9629,   3.4868,  14.0167,  -0.5236,  -8.7967,  12.6989,\n",
      "          -3.6456,  12.2677,   2.6161,   2.8501,  -1.1030,  11.1882,  12.1140,\n",
      "          10.0642,  12.4379],\n",
      "        [  7.3638,   6.6363,   3.7370,   0.5075,  13.3841,   5.3961,  -1.1028,\n",
      "         -10.3152,   2.3790,  12.0900,   2.8559,  11.9328,   6.4956,  -2.7256,\n",
      "           3.3756,   1.1523],\n",
      "        [ -6.0083,  -0.8583,   7.5238,  -7.5335,   3.8712,  13.0613, -11.1980,\n",
      "           3.1005,  -8.1196,   1.5444,  -8.8556,   4.9149,  -4.7042,  -7.9559,\n",
      "          -9.8678,  -4.7690],\n",
      "        [  4.9585,   5.8591,  -0.8231,  12.8853,  -0.7006, -10.9891,  13.5495,\n",
      "          -4.9274,  12.1281,   2.2906,   6.0101,  -1.3071,  10.5348,  12.0277,\n",
      "          11.6488,  11.4243],\n",
      "        [-11.6922,  -2.8961,   3.8784,  -3.6494, -10.9121,   1.4336,  -5.1530,\n",
      "          13.6126,  -4.7972, -10.7763,  -8.5941,  -9.7541,  -8.5982,  -1.6497,\n",
      "          -9.0281,  -3.5861],\n",
      "        [  4.7637,  11.4753,   3.0485,  12.2054,   1.7158,  -8.4613,  10.8063,\n",
      "          -5.4126,  13.8063,   5.3543,   5.6945,   1.5054,   9.8211,   8.5985,\n",
      "          11.4103,   9.6696],\n",
      "        [  8.5548,   9.1969,   2.1980,   3.3021,  11.3214,   1.6927,   1.8828,\n",
      "         -11.0162,   5.4192,  13.6706,   5.4779,  12.3675,   6.2224,  -1.9937,\n",
      "           7.5263,   3.0901],\n",
      "        [ 12.3228,   4.1338,  -7.8438,   6.1810,   3.7659,  -9.0161,   9.1948,\n",
      "          -9.2408,   9.2582,   5.6484,  13.3118,   2.6596,   6.4909,   3.7535,\n",
      "          12.3544,   3.0426],\n",
      "        [  5.9537,   5.6222,   2.8595,  -0.5745,  11.0007,   5.7748,  -2.0297,\n",
      "          -9.4440,   0.7227,  12.8588,   1.7936,  13.6644,   3.2154,  -4.2439,\n",
      "           3.6037,   1.7834],\n",
      "        [  5.3660,   6.8439,   3.7733,  11.8515,   6.1968,  -4.3583,  10.6391,\n",
      "          -8.3297,  10.0365,   6.8961,   3.1254,   4.3799,  13.6402,  10.5033,\n",
      "           9.3504,  11.8778],\n",
      "        [ -0.1522,   4.0161,   3.4690,  12.7051,  -2.0273,  -7.8179,  11.7871,\n",
      "          -1.3800,   9.8068,  -0.8315,   0.2053,  -3.3124,  10.5831,  13.6779,\n",
      "           7.2192,  12.7049],\n",
      "        [  9.2371,   8.0783,  -2.3304,  10.9762,   3.4932,  -9.5286,  11.9313,\n",
      "          -9.1159,  12.3227,   7.4016,   9.4710,   3.9607,   9.8460,   7.8923,\n",
      "          13.7539,   9.2522],\n",
      "        [  0.5336,   6.8580,   5.8107,  12.4733,   1.4805,  -4.9340,  10.4439,\n",
      "          -4.3262,   9.6219,   4.5027,  -0.7041,   2.5018,  10.9466,  11.5770,\n",
      "           8.1527,  13.9175]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6475, 13.7288, 13.4525, 14.0167, 13.3841, 13.0613, 13.5495, 13.6126,\n",
      "        13.8063, 13.6706, 13.3118, 13.6644, 13.6402, 13.6779, 13.7539, 13.9175],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.3655, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  3.6800,  -7.0454,   3.7865,   7.9606,  -5.0494,   6.5535, -11.4352,\n",
      "           7.1456,   8.3163,  12.5719,   6.3060,   6.9406,   1.3967,  10.8209,\n",
      "           1.6646],\n",
      "        [  1.3236,   7.2574,   8.1615,   2.6780,  -3.7025,   4.8809,  -3.1486,\n",
      "          10.3636,   6.7349,   1.7456,   3.5361,   5.8368,   3.0160,   6.7626,\n",
      "           5.9186],\n",
      "        [ -7.7158,   8.5129,   3.9221,   1.1601,   4.8340,  -1.6325,   3.2278,\n",
      "           2.4081,   2.4384,  -9.1975,   2.2489,   2.7529,   1.7048,  -3.0704,\n",
      "           5.1688],\n",
      "        [  2.1303,   7.9629,   3.4868,  -0.5236,  -8.7967,  12.6989,  -3.6456,\n",
      "          12.2677,   2.6161,   2.8501,  -1.1030,  11.1882,  12.1140,  10.0642,\n",
      "          12.4379],\n",
      "        [  7.3638,   6.6363,   3.7370,   0.5075,   5.3961,  -1.1028, -10.3152,\n",
      "           2.3790,  12.0900,   2.8559,  11.9328,   6.4956,  -2.7256,   3.3756,\n",
      "           1.1523],\n",
      "        [ -6.0083,  -0.8583,   7.5238,  -7.5335,   3.8712, -11.1980,   3.1005,\n",
      "          -8.1196,   1.5444,  -8.8556,   4.9149,  -4.7042,  -7.9559,  -9.8678,\n",
      "          -4.7690],\n",
      "        [  4.9585,   5.8591,  -0.8231,  12.8853,  -0.7006, -10.9891,  -4.9274,\n",
      "          12.1281,   2.2906,   6.0101,  -1.3071,  10.5348,  12.0277,  11.6488,\n",
      "          11.4243],\n",
      "        [-11.6922,  -2.8961,   3.8784,  -3.6494, -10.9121,   1.4336,  -5.1530,\n",
      "          -4.7972, -10.7763,  -8.5941,  -9.7541,  -8.5982,  -1.6497,  -9.0281,\n",
      "          -3.5861],\n",
      "        [  4.7637,  11.4753,   3.0485,  12.2054,   1.7158,  -8.4613,  10.8063,\n",
      "          -5.4126,   5.3543,   5.6945,   1.5054,   9.8211,   8.5985,  11.4103,\n",
      "           9.6696],\n",
      "        [  8.5548,   9.1969,   2.1980,   3.3021,  11.3214,   1.6927,   1.8828,\n",
      "         -11.0162,   5.4192,   5.4779,  12.3675,   6.2224,  -1.9937,   7.5263,\n",
      "           3.0901],\n",
      "        [ 12.3228,   4.1338,  -7.8438,   6.1810,   3.7659,  -9.0161,   9.1948,\n",
      "          -9.2408,   9.2582,   5.6484,   2.6596,   6.4909,   3.7535,  12.3544,\n",
      "           3.0426],\n",
      "        [  5.9537,   5.6222,   2.8595,  -0.5745,  11.0007,   5.7748,  -2.0297,\n",
      "          -9.4440,   0.7227,  12.8588,   1.7936,   3.2154,  -4.2439,   3.6037,\n",
      "           1.7834],\n",
      "        [  5.3660,   6.8439,   3.7733,  11.8515,   6.1968,  -4.3583,  10.6391,\n",
      "          -8.3297,  10.0365,   6.8961,   3.1254,   4.3799,  10.5033,   9.3504,\n",
      "          11.8778],\n",
      "        [ -0.1522,   4.0161,   3.4690,  12.7051,  -2.0273,  -7.8179,  11.7871,\n",
      "          -1.3800,   9.8068,  -0.8315,   0.2053,  -3.3124,  10.5831,   7.2192,\n",
      "          12.7049],\n",
      "        [  9.2371,   8.0783,  -2.3304,  10.9762,   3.4932,  -9.5286,  11.9313,\n",
      "          -9.1159,  12.3227,   7.4016,   9.4710,   3.9607,   9.8460,   7.8923,\n",
      "           9.2522],\n",
      "        [  0.5336,   6.8580,   5.8107,  12.4733,   1.4805,  -4.9340,  10.4439,\n",
      "          -4.3262,   9.6219,   4.5027,  -0.7041,   2.5018,  10.9466,  11.5770,\n",
      "           8.1527]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0206, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 2: 0.19305337965488434\n",
      "Batch 3/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.0609,  0.0286, -0.0223,  ...,  0.0501, -0.1993, -0.0806],\n",
      "        [ 0.1917, -0.0474,  0.0148,  ...,  0.0029, -0.2841, -0.0091],\n",
      "        [ 0.0162, -0.0142,  0.1374,  ...,  0.1420, -0.2050,  0.0471],\n",
      "        ...,\n",
      "        [-0.0087, -0.0178, -0.0683,  ...,  0.0403, -0.0511, -0.0763],\n",
      "        [ 0.1171, -0.0428, -0.1417,  ..., -0.0765, -0.1860, -0.0734],\n",
      "        [ 0.1537, -0.0262, -0.0183,  ...,  0.0009, -0.3340, -0.0022]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0696,  0.0116, -0.0440,  ...,  0.0674, -0.1914, -0.0637],\n",
      "        [ 0.1894, -0.0503,  0.0219,  ..., -0.0075, -0.2895, -0.0263],\n",
      "        [-0.0509, -0.0113,  0.1926,  ...,  0.1146, -0.1634,  0.0305],\n",
      "        ...,\n",
      "        [-0.0419, -0.0481, -0.0839,  ...,  0.0225, -0.0518, -0.0617],\n",
      "        [ 0.1467, -0.0686, -0.1848,  ..., -0.0715, -0.1027, -0.0494],\n",
      "        [ 0.1360, -0.0533, -0.0349,  ..., -0.0047, -0.2929, -0.0301]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.6406,   2.3816,   4.4155,  11.0426,   9.1269,  -6.1774,   1.0515,\n",
      "           7.9311,  11.3893,   1.4684,   8.4814,  -4.7321,  -6.7546,   6.9384,\n",
      "           3.0803,   7.2156],\n",
      "        [  2.3813,  13.8631,   5.9950,   7.7547,   9.3564,   2.0641,   7.6925,\n",
      "           6.7667,   4.2151,  13.1272,   1.9103,  -8.0426,   4.2688,   2.6245,\n",
      "           7.7498,  10.7562],\n",
      "        [  2.7633,   7.5548,  13.5575,   7.9180,   5.4559,   1.9971,   5.5715,\n",
      "          -1.5366,   9.7637,  10.5680,   1.2238,  -6.4319,   3.0559,   4.1182,\n",
      "          -1.6376,   5.8906],\n",
      "        [  8.7012,   7.3948,   8.0635,  13.7983,   8.3903,  -6.8011,   9.4142,\n",
      "           6.6636,  10.8034,   7.1582,   2.3756,  -2.8090,   1.8982,  11.3242,\n",
      "           6.7116,   7.1509],\n",
      "        [  9.3763,  10.0124,   5.3056,   9.4914,  13.6411,  -2.4208,   3.9494,\n",
      "          10.8311,   7.6014,   9.3288,   8.2957,  -9.9055,  -4.2660,   3.5260,\n",
      "           7.1739,  13.2717],\n",
      "        [ -5.0869,   5.0534,   3.2125,  -5.1397,  -0.3549,  13.1254,  -3.8303,\n",
      "          -4.5643,  -2.4499,   6.3882,   1.7223,  -6.6257,   2.3629,  -9.5322,\n",
      "          -5.2201,   1.9349],\n",
      "        [ -1.4854,   6.4809,   4.3418,   8.4361,   1.4469,  -6.1347,  13.8166,\n",
      "           2.5081,   2.4994,   5.9648,  -6.7034,   4.1666,   9.9217,  10.9656,\n",
      "           8.4255,   1.3259],\n",
      "        [  8.2043,   7.1095,  -3.0333,   7.0067,  11.2032,  -5.2412,   3.4680,\n",
      "          13.7936,   1.8964,   4.0151,   7.1074,  -5.0153,  -4.0658,   3.6620,\n",
      "          11.3201,  10.3582],\n",
      "        [ 10.3571,   4.5861,  10.9446,  11.1774,   7.6255,  -2.2087,   2.5688,\n",
      "           2.3551,  13.9697,   5.9013,   5.5658,  -6.2592,  -2.7975,   6.4622,\n",
      "          -0.9967,   6.6544],\n",
      "        [  0.2403,  12.6359,   8.7692,   5.8222,   7.7022,   4.2650,   6.3270,\n",
      "           2.8793,   4.4850,  13.6765,   0.9693,  -8.6576,   4.4157,   0.9413,\n",
      "           3.8368,   9.3819],\n",
      "        [ 10.3437,   4.0876,   2.8404,   4.4977,  10.7936,   1.6748,  -4.4278,\n",
      "           8.0188,   6.2017,   3.5806,  13.4448, -10.0842,  -9.1968,  -2.4711,\n",
      "           0.6571,   9.8588],\n",
      "        [ -4.7214,  -7.7114,  -3.9337,  -0.5374,  -9.6122,  -6.7960,   5.1421,\n",
      "          -4.5458,  -3.4168,  -8.2408,  -9.4244,  13.5026,   6.6868,   7.3017,\n",
      "           0.8487, -10.9256],\n",
      "        [ -7.4965,   5.0360,   3.7390,   2.6265,  -4.4556,   0.8540,  10.5490,\n",
      "          -4.1718,  -1.2859,   5.5411,  -9.9165,   5.1611,  13.4298,   5.5760,\n",
      "           3.2209,  -3.3936],\n",
      "        [  4.6143,   2.6303,   4.4902,  11.4168,   2.7989, -10.4776,  11.4227,\n",
      "           4.1183,   6.8721,   2.2206,  -3.3962,   4.3556,   4.8273,  13.8746,\n",
      "           7.3403,   1.1900],\n",
      "        [  3.6222,   7.6168,  -2.7042,   7.9707,   7.3411,  -7.5405,   9.5987,\n",
      "          11.5625,   0.1707,   4.6448,   0.0194,   0.0147,   2.8862,   8.1200,\n",
      "          13.8002,   6.7685],\n",
      "        [  7.4840,  11.4228,   5.1794,   7.6243,  13.2990,   0.4176,   2.8833,\n",
      "           9.9709,   6.3036,  10.7419,   7.8282, -11.4207,  -3.6297,   1.0516,\n",
      "           6.5589,  13.7277]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6406, 13.8631, 13.5575, 13.7983, 13.6411, 13.1254, 13.8166, 13.7936,\n",
      "        13.9697, 13.6765, 13.4448, 13.5026, 13.4298, 13.8746, 13.8002, 13.7277],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.2040, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  2.3816,   4.4155,  11.0426,   9.1269,  -6.1774,   1.0515,   7.9311,\n",
      "          11.3893,   1.4684,   8.4814,  -4.7321,  -6.7546,   6.9384,   3.0803,\n",
      "           7.2156],\n",
      "        [  2.3813,   5.9950,   7.7547,   9.3564,   2.0641,   7.6925,   6.7667,\n",
      "           4.2151,  13.1272,   1.9103,  -8.0426,   4.2688,   2.6245,   7.7498,\n",
      "          10.7562],\n",
      "        [  2.7633,   7.5548,   7.9180,   5.4559,   1.9971,   5.5715,  -1.5366,\n",
      "           9.7637,  10.5680,   1.2238,  -6.4319,   3.0559,   4.1182,  -1.6376,\n",
      "           5.8906],\n",
      "        [  8.7012,   7.3948,   8.0635,   8.3903,  -6.8011,   9.4142,   6.6636,\n",
      "          10.8034,   7.1582,   2.3756,  -2.8090,   1.8982,  11.3242,   6.7116,\n",
      "           7.1509],\n",
      "        [  9.3763,  10.0124,   5.3056,   9.4914,  -2.4208,   3.9494,  10.8311,\n",
      "           7.6014,   9.3288,   8.2957,  -9.9055,  -4.2660,   3.5260,   7.1739,\n",
      "          13.2717],\n",
      "        [ -5.0869,   5.0534,   3.2125,  -5.1397,  -0.3549,  -3.8303,  -4.5643,\n",
      "          -2.4499,   6.3882,   1.7223,  -6.6257,   2.3629,  -9.5322,  -5.2201,\n",
      "           1.9349],\n",
      "        [ -1.4854,   6.4809,   4.3418,   8.4361,   1.4469,  -6.1347,   2.5081,\n",
      "           2.4994,   5.9648,  -6.7034,   4.1666,   9.9217,  10.9656,   8.4255,\n",
      "           1.3259],\n",
      "        [  8.2043,   7.1095,  -3.0333,   7.0067,  11.2032,  -5.2412,   3.4680,\n",
      "           1.8964,   4.0151,   7.1074,  -5.0153,  -4.0658,   3.6620,  11.3201,\n",
      "          10.3582],\n",
      "        [ 10.3571,   4.5861,  10.9446,  11.1774,   7.6255,  -2.2087,   2.5688,\n",
      "           2.3551,   5.9013,   5.5658,  -6.2592,  -2.7975,   6.4622,  -0.9967,\n",
      "           6.6544],\n",
      "        [  0.2403,  12.6359,   8.7692,   5.8222,   7.7022,   4.2650,   6.3270,\n",
      "           2.8793,   4.4850,   0.9693,  -8.6576,   4.4157,   0.9413,   3.8368,\n",
      "           9.3819],\n",
      "        [ 10.3437,   4.0876,   2.8404,   4.4977,  10.7936,   1.6748,  -4.4278,\n",
      "           8.0188,   6.2017,   3.5806, -10.0842,  -9.1968,  -2.4711,   0.6571,\n",
      "           9.8588],\n",
      "        [ -4.7214,  -7.7114,  -3.9337,  -0.5374,  -9.6122,  -6.7960,   5.1421,\n",
      "          -4.5458,  -3.4168,  -8.2408,  -9.4244,   6.6868,   7.3017,   0.8487,\n",
      "         -10.9256],\n",
      "        [ -7.4965,   5.0360,   3.7390,   2.6265,  -4.4556,   0.8540,  10.5490,\n",
      "          -4.1718,  -1.2859,   5.5411,  -9.9165,   5.1611,   5.5760,   3.2209,\n",
      "          -3.3936],\n",
      "        [  4.6143,   2.6303,   4.4902,  11.4168,   2.7989, -10.4776,  11.4227,\n",
      "           4.1183,   6.8721,   2.2206,  -3.3962,   4.3556,   4.8273,   7.3403,\n",
      "           1.1900],\n",
      "        [  3.6222,   7.6168,  -2.7042,   7.9707,   7.3411,  -7.5405,   9.5987,\n",
      "          11.5625,   0.1707,   4.6448,   0.0194,   0.0147,   2.8862,   8.1200,\n",
      "           6.7685],\n",
      "        [  7.4840,  11.4228,   5.1794,   7.6243,  13.2990,   0.4176,   2.8833,\n",
      "           9.9709,   6.3036,  10.7419,   7.8282, -11.4207,  -3.6297,   1.0516,\n",
      "           6.5589]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0128, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 3: 0.10836340487003326\n",
      "Batch 4/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0641, -0.0175,  0.0939,  ...,  0.0583,  0.0193,  0.0202],\n",
      "        [-0.0793,  0.0441, -0.0039,  ...,  0.0587, -0.1315, -0.0769],\n",
      "        [ 0.1067, -0.0359,  0.0417,  ...,  0.0275, -0.0964, -0.0032],\n",
      "        ...,\n",
      "        [-0.0239,  0.0392, -0.0222,  ..., -0.0490,  0.0408,  0.0496],\n",
      "        [-0.0365, -0.0063, -0.0956,  ...,  0.0017,  0.0454, -0.0652],\n",
      "        [-0.0578,  0.0458, -0.0111,  ..., -0.0073, -0.1338, -0.0147]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0370, -0.0097,  0.0992,  ...,  0.0339,  0.0484,  0.0623],\n",
      "        [-0.1095,  0.0188, -0.0198,  ...,  0.0210, -0.1196, -0.0592],\n",
      "        [ 0.1066, -0.0382,  0.0276,  ..., -0.0372, -0.0712,  0.0155],\n",
      "        ...,\n",
      "        [-0.0532,  0.0438, -0.0091,  ..., -0.0337,  0.0641,  0.0236],\n",
      "        [-0.0643, -0.0325, -0.1160,  ..., -0.0205,  0.0659, -0.0472],\n",
      "        [-0.0708,  0.0407,  0.0078,  ...,  0.0273, -0.1436, -0.0178]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.7158, -11.5718,  11.5627,   9.2016,  10.4934,  10.9540,   8.9464,\n",
      "          -8.4069,   8.2848,   6.8738,   0.1534,  -6.2518,  -4.2465, -10.3503,\n",
      "           1.3052, -11.9062],\n",
      "        [-10.4255,  13.5482,  -8.4712,  -5.8588, -10.9381,  -7.4348,  -8.8747,\n",
      "           4.1195, -11.7694,  -5.7463,   7.5392,   0.4470,   8.4151,   5.6288,\n",
      "           0.9677,  11.9773],\n",
      "        [ 11.1815,  -8.3009,  13.4390,   8.2799,   6.9049,   7.1647,   2.9734,\n",
      "          -3.4538,   3.7659,  11.3182,   2.7860,  -8.1956,   2.2961, -12.3135,\n",
      "           4.7148,  -9.1375],\n",
      "        [  8.4983,  -6.5642,   8.3006,  13.5323,   8.6167,  10.2012,   1.6538,\n",
      "          -4.0003,   1.7699,   5.0196,  -0.3964,  -3.0476,  -0.6003,  -8.9444,\n",
      "          -4.0703,  -5.3816],\n",
      "        [ 11.1279, -11.6484,   8.3042,   9.5069,  13.3687,  11.4554,   8.9089,\n",
      "          -6.5693,   9.0166,   3.5008,  -6.9346,   1.5280,  -8.4926,  -5.2707,\n",
      "          -5.6673,  -9.5307],\n",
      "        [ 10.6903,  -8.2952,   6.7471,  11.2437,  12.0704,  13.5362,   8.0934,\n",
      "          -9.3173,   4.9580,   0.6235,  -2.9435,   0.0528,  -6.9917,  -5.7465,\n",
      "          -7.0395,  -6.7067],\n",
      "        [ 10.7775, -10.4344,   4.3742,   4.7009,  11.0796,  10.7296,  13.4297,\n",
      "         -10.1228,  10.9525,  -1.5126,  -4.1351,   0.1380, -11.1356,  -2.0059,\n",
      "          -3.1980,  -9.7236],\n",
      "        [ -8.2031,   4.7197,  -2.2889,  -3.8862,  -5.4877,  -9.2727,  -9.0684,\n",
      "          13.4622,  -2.4413,   3.4669,  -3.0301,   4.1440,   6.0965,   4.5956,\n",
      "           2.1502,   5.7308],\n",
      "        [ 10.1000, -13.0050,   7.0524,   3.9509,  10.5089,   6.8590,  10.5012,\n",
      "          -4.1005,  13.4669,   4.2478,  -7.1144,   0.2455,  -9.1224,  -3.1654,\n",
      "          -0.1342, -11.8895],\n",
      "        [  6.0043,  -5.5535,  11.8336,   4.1413,   2.3775,   0.1356,  -2.3852,\n",
      "           3.9567,   2.4838,  13.8083,   1.6227,  -6.6559,   6.1455,  -9.9161,\n",
      "           7.5990,  -6.4610],\n",
      "        [ -0.4514,   6.2001,   0.8281,   0.1701,  -7.7021,  -1.9090,  -4.2949,\n",
      "          -1.3976,  -7.1591,   1.3808,  13.8345, -10.6106,   9.8926,  -5.4012,\n",
      "           7.6346,   2.3596],\n",
      "        [ -5.0846,   1.4266,  -5.4371,  -1.0577,   3.4615,  -0.1675,  -1.1595,\n",
      "           3.5456,  -0.1803,  -5.0634, -11.0038,  13.4022,  -5.6110,   8.8984,\n",
      "         -10.6035,   5.1595],\n",
      "        [ -4.8345,   8.0798,   1.7582,  -1.3610,  -9.4394,  -7.0408, -10.9539,\n",
      "           7.0452,  -9.5020,   6.1003,   9.8409,  -7.0114,  14.0383,  -4.3439,\n",
      "           8.1070,   5.5270],\n",
      "        [ -9.6731,   6.6172, -11.9095,  -7.9658,  -3.5593,  -5.4765,  -1.2072,\n",
      "           3.8499,  -1.5513, -10.3824,  -6.1734,  11.1589,  -4.2792,  13.7212,\n",
      "          -6.3034,   8.4823],\n",
      "        [  2.4377,  -0.6239,   5.7360,  -3.0096,  -5.3945,  -4.5867,  -1.2851,\n",
      "           2.2915,   1.3058,   8.1832,   9.0965, -10.9554,   7.9434,  -6.4075,\n",
      "          13.5773,  -4.3176],\n",
      "        [-12.1452,  12.9713, -10.4406,  -5.6373,  -8.5747,  -7.2601,  -8.9705,\n",
      "           6.5778, -10.3837,  -7.4889,   1.3309,   6.3297,   5.1409,   9.5030,\n",
      "          -3.6177,  13.6367]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7158, 13.5482, 13.4390, 13.5323, 13.3687, 13.5362, 13.4297, 13.4622,\n",
      "        13.4669, 13.8083, 13.8345, 13.4022, 14.0383, 13.7212, 13.5773, 13.6367],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1501, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[-11.5718,  11.5627,   9.2016,  10.4934,  10.9540,   8.9464,  -8.4069,\n",
      "           8.2848,   6.8738,   0.1534,  -6.2518,  -4.2465, -10.3503,   1.3052,\n",
      "         -11.9062],\n",
      "        [-10.4255,  -8.4712,  -5.8588, -10.9381,  -7.4348,  -8.8747,   4.1195,\n",
      "         -11.7694,  -5.7463,   7.5392,   0.4470,   8.4151,   5.6288,   0.9677,\n",
      "          11.9773],\n",
      "        [ 11.1815,  -8.3009,   8.2799,   6.9049,   7.1647,   2.9734,  -3.4538,\n",
      "           3.7659,  11.3182,   2.7860,  -8.1956,   2.2961, -12.3135,   4.7148,\n",
      "          -9.1375],\n",
      "        [  8.4983,  -6.5642,   8.3006,   8.6167,  10.2012,   1.6538,  -4.0003,\n",
      "           1.7699,   5.0196,  -0.3964,  -3.0476,  -0.6003,  -8.9444,  -4.0703,\n",
      "          -5.3816],\n",
      "        [ 11.1279, -11.6484,   8.3042,   9.5069,  11.4554,   8.9089,  -6.5693,\n",
      "           9.0166,   3.5008,  -6.9346,   1.5280,  -8.4926,  -5.2707,  -5.6673,\n",
      "          -9.5307],\n",
      "        [ 10.6903,  -8.2952,   6.7471,  11.2437,  12.0704,   8.0934,  -9.3173,\n",
      "           4.9580,   0.6235,  -2.9435,   0.0528,  -6.9917,  -5.7465,  -7.0395,\n",
      "          -6.7067],\n",
      "        [ 10.7775, -10.4344,   4.3742,   4.7009,  11.0796,  10.7296, -10.1228,\n",
      "          10.9525,  -1.5126,  -4.1351,   0.1380, -11.1356,  -2.0059,  -3.1980,\n",
      "          -9.7236],\n",
      "        [ -8.2031,   4.7197,  -2.2889,  -3.8862,  -5.4877,  -9.2727,  -9.0684,\n",
      "          -2.4413,   3.4669,  -3.0301,   4.1440,   6.0965,   4.5956,   2.1502,\n",
      "           5.7308],\n",
      "        [ 10.1000, -13.0050,   7.0524,   3.9509,  10.5089,   6.8590,  10.5012,\n",
      "          -4.1005,   4.2478,  -7.1144,   0.2455,  -9.1224,  -3.1654,  -0.1342,\n",
      "         -11.8895],\n",
      "        [  6.0043,  -5.5535,  11.8336,   4.1413,   2.3775,   0.1356,  -2.3852,\n",
      "           3.9567,   2.4838,   1.6227,  -6.6559,   6.1455,  -9.9161,   7.5990,\n",
      "          -6.4610],\n",
      "        [ -0.4514,   6.2001,   0.8281,   0.1701,  -7.7021,  -1.9090,  -4.2949,\n",
      "          -1.3976,  -7.1591,   1.3808, -10.6106,   9.8926,  -5.4012,   7.6346,\n",
      "           2.3596],\n",
      "        [ -5.0846,   1.4266,  -5.4371,  -1.0577,   3.4615,  -0.1675,  -1.1595,\n",
      "           3.5456,  -0.1803,  -5.0634, -11.0038,  -5.6110,   8.8984, -10.6035,\n",
      "           5.1595],\n",
      "        [ -4.8345,   8.0798,   1.7582,  -1.3610,  -9.4394,  -7.0408, -10.9539,\n",
      "           7.0452,  -9.5020,   6.1003,   9.8409,  -7.0114,  -4.3439,   8.1070,\n",
      "           5.5270],\n",
      "        [ -9.6731,   6.6172, -11.9095,  -7.9658,  -3.5593,  -5.4765,  -1.2072,\n",
      "           3.8499,  -1.5513, -10.3824,  -6.1734,  11.1589,  -4.2792,  -6.3034,\n",
      "           8.4823],\n",
      "        [  2.4377,  -0.6239,   5.7360,  -3.0096,  -5.3945,  -4.5867,  -1.2851,\n",
      "           2.2915,   1.3058,   8.1832,   9.0965, -10.9554,   7.9434,  -6.4075,\n",
      "          -4.3176],\n",
      "        [-12.1452,  12.9713, -10.4406,  -5.6373,  -8.5747,  -7.2601,  -8.9705,\n",
      "           6.5778, -10.3837,  -7.4889,   1.3309,   6.3297,   5.1409,   9.5030,\n",
      "          -3.6177]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0095, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 4: 0.07978001981973648\n",
      "Batch 5/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.2249, -0.0625, -0.0595,  ..., -0.0538, -0.0433,  0.0272],\n",
      "        [-0.1316,  0.0580,  0.2259,  ...,  0.1221,  0.0026,  0.0225],\n",
      "        [-0.1137, -0.0120,  0.0399,  ...,  0.0946,  0.1713, -0.1314],\n",
      "        ...,\n",
      "        [ 0.0466, -0.0046, -0.1143,  ..., -0.0954,  0.1394,  0.0139],\n",
      "        [ 0.2088, -0.0483, -0.0008,  ...,  0.0217, -0.1266,  0.0584],\n",
      "        [ 0.1621, -0.0827, -0.0232,  ...,  0.0302, -0.0435, -0.0017]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1705, -0.0659, -0.0578,  ..., -0.0696, -0.0178,  0.0041],\n",
      "        [-0.1623,  0.0206,  0.2397,  ...,  0.1084,  0.0411,  0.0162],\n",
      "        [-0.1419, -0.0170,  0.0512,  ...,  0.0743,  0.1973, -0.1246],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0338, -0.1339,  ..., -0.1262,  0.1065,  0.0153],\n",
      "        [ 0.1377, -0.0538, -0.0073,  ...,  0.0253, -0.2442,  0.0722],\n",
      "        [ 0.0450, -0.0979,  0.0096,  ...,  0.0070,  0.0344, -0.0104]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.7817,  -8.2034,  -2.1771,   1.8699,   4.7723,   7.5316,   8.0823,\n",
      "           5.3426,   5.9590,  11.9300,   5.6286,   8.1241,  10.2177,   9.6136,\n",
      "           6.4362,  11.5341],\n",
      "        [ -6.1865,  13.3855,   4.6419,  -2.9708,   1.3183,   5.0248,   0.5716,\n",
      "           4.4663,  -7.8501,  -6.4440,   4.4046,  -9.2451,   1.8299,  -9.1370,\n",
      "          -0.2791,  -1.8639],\n",
      "        [ -1.7507,   6.1389,  13.4948,   2.7794,   7.2285,  -0.9183,   1.0629,\n",
      "          10.9825,   5.5401,  -6.1214,   1.2291, -11.1019,  -1.2051,   1.5223,\n",
      "          -4.4994,   4.7414],\n",
      "        [  1.8118,  -3.2248,   3.2958,  13.9375,  11.6341,  -5.5506,  -7.2870,\n",
      "           4.0617,   3.9858,   5.8348,  -8.9192,  -1.8600,   3.7552,   2.0521,\n",
      "           8.2061,   4.6010],\n",
      "        [  3.7889,   1.0538,   7.7247,  10.6750,  13.8464,  -0.5907,  -1.3691,\n",
      "          10.9418,   5.6189,   4.3065,  -3.6216,  -5.6816,   5.4190,   3.3969,\n",
      "           5.5588,   8.6657],\n",
      "        [  8.4869,   1.2760,  -2.1847,  -5.2934,  -0.2467,  13.6207,  10.5981,\n",
      "           4.2827,  -2.3820,   5.5924,  11.8527,   4.5250,  10.5447,   1.6177,\n",
      "           4.5688,   7.9806],\n",
      "        [  9.5801,  -0.8214,   0.6679,  -7.4267,  -0.9564,  11.3839,  13.6734,\n",
      "           6.3802,   4.0521,   3.6835,  11.7698,   4.0634,   5.8239,   7.0948,\n",
      "          -1.5711,   8.7409],\n",
      "        [  4.8395,   4.4819,   9.8535,   2.9597,  10.0037,   5.4178,   5.6313,\n",
      "          13.6432,   5.2060,   0.9179,   4.4883,  -6.8220,   5.8117,   3.8104,\n",
      "           0.9199,  10.0027],\n",
      "        [  5.8328,  -5.4044,   7.6427,   3.8953,   6.2173,  -3.1370,   4.1717,\n",
      "           7.8931,  13.8055,   1.5048,  -1.7617,  -0.8106,  -2.7003,  11.9083,\n",
      "          -4.2043,   7.3625],\n",
      "        [ 11.5005,  -7.7512,  -5.4058,   5.2341,   6.0570,   4.9081,   3.2314,\n",
      "           2.4574,   2.3588,  13.8412,   0.9535,   8.4037,  10.5742,   6.0786,\n",
      "          10.5329,   8.3836],\n",
      "        [  6.5845,   2.1035,   0.2211,  -8.0521,  -2.7876,  12.6727,  11.1540,\n",
      "           4.2479,  -1.6556,   1.5473,  13.5516,   2.5891,   7.6278,   1.5186,\n",
      "          -0.0372,   6.8431],\n",
      "        [  8.3829, -10.3658, -11.1588,  -0.9222,  -4.0460,   3.5043,   3.3543,\n",
      "          -6.6462,   0.2373,  10.2297,   1.6924,  13.7700,   4.9867,   5.0752,\n",
      "           5.6098,   2.3301],\n",
      "        [  9.6240,  -1.7855,  -1.4204,   3.7114,   6.3324,   9.1784,   4.2477,\n",
      "           5.3674,  -1.5301,  10.3340,   5.8235,   3.8909,  13.8502,   1.7910,\n",
      "          11.1080,   9.6540],\n",
      "        [  9.3140,  -7.6858,   4.3234,   1.2585,   3.8342,   0.6420,   7.5736,\n",
      "           6.4884,  13.3174,   4.3343,   1.7013,   3.7244,   0.0245,  13.5699,\n",
      "          -2.8339,   8.9144],\n",
      "        [  7.0080,  -2.7096,  -3.2091,   7.3396,   6.9890,   4.7384,  -0.5419,\n",
      "           2.1940,  -2.4857,  10.9626,   0.1530,   4.3294,  11.9051,   0.3680,\n",
      "          13.5043,   6.2636],\n",
      "        [ 11.6903,  -3.9982,   2.6806,   3.5782,   8.1336,   8.1379,   7.7892,\n",
      "           9.1456,   6.3193,   8.8343,   5.7684,   3.2710,  10.3005,   8.1892,\n",
      "           5.7184,  13.4335]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7817, 13.3855, 13.4948, 13.9375, 13.8464, 13.6207, 13.6734, 13.6432,\n",
      "        13.8055, 13.8412, 13.5516, 13.7700, 13.8502, 13.5699, 13.5043, 13.4335],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1924, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ -8.2034,  -2.1771,   1.8699,   4.7723,   7.5316,   8.0823,   5.3426,\n",
      "           5.9590,  11.9300,   5.6286,   8.1241,  10.2177,   9.6136,   6.4362,\n",
      "          11.5341],\n",
      "        [ -6.1865,   4.6419,  -2.9708,   1.3183,   5.0248,   0.5716,   4.4663,\n",
      "          -7.8501,  -6.4440,   4.4046,  -9.2451,   1.8299,  -9.1370,  -0.2791,\n",
      "          -1.8639],\n",
      "        [ -1.7507,   6.1389,   2.7794,   7.2285,  -0.9183,   1.0629,  10.9825,\n",
      "           5.5401,  -6.1214,   1.2291, -11.1019,  -1.2051,   1.5223,  -4.4994,\n",
      "           4.7414],\n",
      "        [  1.8118,  -3.2248,   3.2958,  11.6341,  -5.5506,  -7.2870,   4.0617,\n",
      "           3.9858,   5.8348,  -8.9192,  -1.8600,   3.7552,   2.0521,   8.2061,\n",
      "           4.6010],\n",
      "        [  3.7889,   1.0538,   7.7247,  10.6750,  -0.5907,  -1.3691,  10.9418,\n",
      "           5.6189,   4.3065,  -3.6216,  -5.6816,   5.4190,   3.3969,   5.5588,\n",
      "           8.6657],\n",
      "        [  8.4869,   1.2760,  -2.1847,  -5.2934,  -0.2467,  10.5981,   4.2827,\n",
      "          -2.3820,   5.5924,  11.8527,   4.5250,  10.5447,   1.6177,   4.5688,\n",
      "           7.9806],\n",
      "        [  9.5801,  -0.8214,   0.6679,  -7.4267,  -0.9564,  11.3839,   6.3802,\n",
      "           4.0521,   3.6835,  11.7698,   4.0634,   5.8239,   7.0948,  -1.5711,\n",
      "           8.7409],\n",
      "        [  4.8395,   4.4819,   9.8535,   2.9597,  10.0037,   5.4178,   5.6313,\n",
      "           5.2060,   0.9179,   4.4883,  -6.8220,   5.8117,   3.8104,   0.9199,\n",
      "          10.0027],\n",
      "        [  5.8328,  -5.4044,   7.6427,   3.8953,   6.2173,  -3.1370,   4.1717,\n",
      "           7.8931,   1.5048,  -1.7617,  -0.8106,  -2.7003,  11.9083,  -4.2043,\n",
      "           7.3625],\n",
      "        [ 11.5005,  -7.7512,  -5.4058,   5.2341,   6.0570,   4.9081,   3.2314,\n",
      "           2.4574,   2.3588,   0.9535,   8.4037,  10.5742,   6.0786,  10.5329,\n",
      "           8.3836],\n",
      "        [  6.5845,   2.1035,   0.2211,  -8.0521,  -2.7876,  12.6727,  11.1540,\n",
      "           4.2479,  -1.6556,   1.5473,   2.5891,   7.6278,   1.5186,  -0.0372,\n",
      "           6.8431],\n",
      "        [  8.3829, -10.3658, -11.1588,  -0.9222,  -4.0460,   3.5043,   3.3543,\n",
      "          -6.6462,   0.2373,  10.2297,   1.6924,   4.9867,   5.0752,   5.6098,\n",
      "           2.3301],\n",
      "        [  9.6240,  -1.7855,  -1.4204,   3.7114,   6.3324,   9.1784,   4.2477,\n",
      "           5.3674,  -1.5301,  10.3340,   5.8235,   3.8909,   1.7910,  11.1080,\n",
      "           9.6540],\n",
      "        [  9.3140,  -7.6858,   4.3234,   1.2585,   3.8342,   0.6420,   7.5736,\n",
      "           6.4884,  13.3174,   4.3343,   1.7013,   3.7244,   0.0245,  -2.8339,\n",
      "           8.9144],\n",
      "        [  7.0080,  -2.7096,  -3.2091,   7.3396,   6.9890,   4.7384,  -0.5419,\n",
      "           2.1940,  -2.4857,  10.9626,   0.1530,   4.3294,  11.9051,   0.3680,\n",
      "           6.2636],\n",
      "        [ 11.6903,  -3.9982,   2.6806,   3.5782,   8.1336,   8.1379,   7.7892,\n",
      "           9.1456,   6.3193,   8.8343,   5.7684,   3.2710,  10.3005,   8.1892,\n",
      "           5.7184]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0122, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 5: 0.10231189429759979\n",
      "Batch 6/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.0761,  0.0383,  0.1004,  ...,  0.0407, -0.1881, -0.0158],\n",
      "        [-0.1221,  0.0719,  0.0271,  ...,  0.0648, -0.1021, -0.0607],\n",
      "        [ 0.2403, -0.0653, -0.0036,  ..., -0.0154, -0.1551,  0.0735],\n",
      "        ...,\n",
      "        [ 0.1105,  0.0010, -0.1742,  ..., -0.1269, -0.0885, -0.0369],\n",
      "        [-0.1279,  0.0048, -0.0884,  ...,  0.0075,  0.1989, -0.0388],\n",
      "        [ 0.0997, -0.0098, -0.0041,  ..., -0.0811,  0.1437,  0.0052]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.1200,  0.0025,  0.0799,  ...,  0.0723, -0.1462, -0.0381],\n",
      "        [-0.1075,  0.0221,  0.0504,  ...,  0.0630, -0.0761, -0.0594],\n",
      "        [ 0.1968, -0.0504, -0.0067,  ..., -0.0204, -0.1587,  0.0552],\n",
      "        ...,\n",
      "        [ 0.1356, -0.0293, -0.1770,  ..., -0.1482, -0.0699, -0.0015],\n",
      "        [-0.1137, -0.0240, -0.0972,  ..., -0.0107,  0.2345, -0.0406],\n",
      "        [ 0.0681, -0.0063, -0.0020,  ..., -0.0590,  0.1970,  0.0038]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.5999,  12.4706,  -6.3608,  -0.9337, -11.2763,  -0.0626,   3.1702,\n",
      "           9.5395,  11.7368,  -4.0075,  -5.4131,  10.1031,   1.6204,  -5.0491,\n",
      "          -7.3301,  -9.4594],\n",
      "        [ 12.3577,  13.2606, -10.1296,   0.9911,  -8.6205,   3.9020,  -1.6916,\n",
      "           8.4877,   7.5060,  -9.1645,  -4.9846,   5.1195,   0.4490,  -2.2487,\n",
      "          -1.0246,  -9.3715],\n",
      "        [ -7.8602,  -8.4020,  13.8406,  -8.6638,   5.1850,  -2.2296,   9.0065,\n",
      "          -6.6322,  -4.6132,  10.5493,   8.8937,  -3.7569,   7.5894,   3.6621,\n",
      "          -3.7673,   2.2383],\n",
      "        [ -2.2399,  -2.3771,  -7.4409,  13.6466,  -1.2414,   0.1961, -12.0486,\n",
      "           5.1319,   0.6351,  -1.1211,  -3.3308,   1.5506,  -7.2948,  -6.8970,\n",
      "           6.5348,   6.2001],\n",
      "        [-11.0264,  -8.8444,   5.6025,  -2.9212,  13.6265,   0.7145,  -0.6212,\n",
      "         -11.7014, -13.3232,  -0.4729,   4.5947, -12.4263,  -1.0128,  10.9497,\n",
      "           7.8230,   6.9030],\n",
      "        [ -0.4316,   1.6786,  -2.6291,   1.3682,  -0.4522,  13.6273,  -3.6057,\n",
      "           1.8873,  -2.3476,  -5.3195,   8.0632,  -3.4240,   5.6819,   0.5183,\n",
      "           9.0148,  -6.8510],\n",
      "        [  1.0526,   0.5540,   9.6001, -12.1031,   0.4944,  -1.4523,  13.5873,\n",
      "          -4.7641,   1.3260,   4.5317,   3.8070,   1.1489,   7.4535,   4.8209,\n",
      "          -8.3389,  -5.2630],\n",
      "        [  7.5888,   5.4337,  -5.1860,   7.0657, -12.0012,  -0.2548,  -3.6718,\n",
      "          13.3736,  11.0280,   2.7333,  -1.7133,  10.6129,   1.0776, -12.4415,\n",
      "          -3.9242,  -3.2990],\n",
      "        [  9.8550,   6.9913,  -3.8449,   3.3812, -12.3516,  -2.9465,   1.9270,\n",
      "          10.8900,  13.5601,   2.6123,  -4.9680,  13.3767,  -0.1417, -10.7080,\n",
      "          -8.8839,  -4.7702],\n",
      "        [ -6.2265,  -8.0878,  10.7442,  -2.2174,  -0.4742,  -4.9058,   4.7166,\n",
      "          -0.1084,   0.6464,  13.8397,   6.2277,   1.7802,   5.1010,  -4.7688,\n",
      "          -5.5602,   4.4011],\n",
      "        [ -7.3885,  -6.8675,   9.0455,  -3.5914,   3.1903,   6.6890,   1.8631,\n",
      "          -1.6160,  -5.5229,   6.5255,  13.6864,  -5.3257,  10.2388,   0.8762,\n",
      "           3.8711,  -1.1165],\n",
      "        [  8.5255,   5.4321,  -3.5626,   4.7633, -11.2701,  -4.1599,   1.3478,\n",
      "          10.1018,  12.9633,   3.1418,  -5.3716,  13.3630,  -1.1976, -10.8146,\n",
      "          -8.7180,  -3.0856],\n",
      "        [  0.2488,   1.0668,   7.4017,  -6.9006,  -2.8211,   6.1373,   6.3776,\n",
      "           2.1049,   0.5902,   5.0456,  11.3322,  -0.4642,  13.7816,  -0.2737,\n",
      "          -2.0649,  -7.9593],\n",
      "        [ -4.1133,  -1.3247,   2.6594,  -7.0886,  10.5815,   3.3990,   2.9813,\n",
      "         -10.3260, -10.0539,  -6.0542,   2.7630, -10.5893,   1.0869,  13.5814,\n",
      "           5.7116,  -0.3377],\n",
      "        [ -4.1245,  -1.6082,  -5.5785,   5.9009,   5.1644,   8.9505, -10.0423,\n",
      "          -0.5785,  -7.4445,  -7.2914,   3.2815,  -7.8026,  -2.3049,   3.0707,\n",
      "          13.7904,   1.5077],\n",
      "        [ -9.3075, -10.3000,   3.0678,   4.3017,   7.2965,  -8.9725,  -4.0527,\n",
      "          -5.3276,  -5.8697,   5.6944,  -2.9739,  -3.9908,  -8.2636,   0.4632,\n",
      "           1.5495,  13.7735]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.5999, 13.2606, 13.8406, 13.6466, 13.6265, 13.6273, 13.5873, 13.3736,\n",
      "        13.5601, 13.8397, 13.6864, 13.3630, 13.7816, 13.5814, 13.7904, 13.7735],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1571, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 12.4706,  -6.3608,  -0.9337, -11.2763,  -0.0626,   3.1702,   9.5395,\n",
      "          11.7368,  -4.0075,  -5.4131,  10.1031,   1.6204,  -5.0491,  -7.3301,\n",
      "          -9.4594],\n",
      "        [ 12.3577, -10.1296,   0.9911,  -8.6205,   3.9020,  -1.6916,   8.4877,\n",
      "           7.5060,  -9.1645,  -4.9846,   5.1195,   0.4490,  -2.2487,  -1.0246,\n",
      "          -9.3715],\n",
      "        [ -7.8602,  -8.4020,  -8.6638,   5.1850,  -2.2296,   9.0065,  -6.6322,\n",
      "          -4.6132,  10.5493,   8.8937,  -3.7569,   7.5894,   3.6621,  -3.7673,\n",
      "           2.2383],\n",
      "        [ -2.2399,  -2.3771,  -7.4409,  -1.2414,   0.1961, -12.0486,   5.1319,\n",
      "           0.6351,  -1.1211,  -3.3308,   1.5506,  -7.2948,  -6.8970,   6.5348,\n",
      "           6.2001],\n",
      "        [-11.0264,  -8.8444,   5.6025,  -2.9212,   0.7145,  -0.6212, -11.7014,\n",
      "         -13.3232,  -0.4729,   4.5947, -12.4263,  -1.0128,  10.9497,   7.8230,\n",
      "           6.9030],\n",
      "        [ -0.4316,   1.6786,  -2.6291,   1.3682,  -0.4522,  -3.6057,   1.8873,\n",
      "          -2.3476,  -5.3195,   8.0632,  -3.4240,   5.6819,   0.5183,   9.0148,\n",
      "          -6.8510],\n",
      "        [  1.0526,   0.5540,   9.6001, -12.1031,   0.4944,  -1.4523,  -4.7641,\n",
      "           1.3260,   4.5317,   3.8070,   1.1489,   7.4535,   4.8209,  -8.3389,\n",
      "          -5.2630],\n",
      "        [  7.5888,   5.4337,  -5.1860,   7.0657, -12.0012,  -0.2548,  -3.6718,\n",
      "          11.0280,   2.7333,  -1.7133,  10.6129,   1.0776, -12.4415,  -3.9242,\n",
      "          -3.2990],\n",
      "        [  9.8550,   6.9913,  -3.8449,   3.3812, -12.3516,  -2.9465,   1.9270,\n",
      "          10.8900,   2.6123,  -4.9680,  13.3767,  -0.1417, -10.7080,  -8.8839,\n",
      "          -4.7702],\n",
      "        [ -6.2265,  -8.0878,  10.7442,  -2.2174,  -0.4742,  -4.9058,   4.7166,\n",
      "          -0.1084,   0.6464,   6.2277,   1.7802,   5.1010,  -4.7688,  -5.5602,\n",
      "           4.4011],\n",
      "        [ -7.3885,  -6.8675,   9.0455,  -3.5914,   3.1903,   6.6890,   1.8631,\n",
      "          -1.6160,  -5.5229,   6.5255,  -5.3257,  10.2388,   0.8762,   3.8711,\n",
      "          -1.1165],\n",
      "        [  8.5255,   5.4321,  -3.5626,   4.7633, -11.2701,  -4.1599,   1.3478,\n",
      "          10.1018,  12.9633,   3.1418,  -5.3716,  -1.1976, -10.8146,  -8.7180,\n",
      "          -3.0856],\n",
      "        [  0.2488,   1.0668,   7.4017,  -6.9006,  -2.8211,   6.1373,   6.3776,\n",
      "           2.1049,   0.5902,   5.0456,  11.3322,  -0.4642,  -0.2737,  -2.0649,\n",
      "          -7.9593],\n",
      "        [ -4.1133,  -1.3247,   2.6594,  -7.0886,  10.5815,   3.3990,   2.9813,\n",
      "         -10.3260, -10.0539,  -6.0542,   2.7630, -10.5893,   1.0869,   5.7116,\n",
      "          -0.3377],\n",
      "        [ -4.1245,  -1.6082,  -5.5785,   5.9009,   5.1644,   8.9505, -10.0423,\n",
      "          -0.5785,  -7.4445,  -7.2914,   3.2815,  -7.8026,  -2.3049,   3.0707,\n",
      "           1.5077],\n",
      "        [ -9.3075, -10.3000,   3.0678,   4.3017,   7.2965,  -8.9725,  -4.0527,\n",
      "          -5.3276,  -5.8697,   5.6944,  -2.9739,  -3.9908,  -8.2636,   0.4632,\n",
      "           1.5495]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0100, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 6: 0.08354465663433075\n",
      "Batch 7/7: Matrix features: torch.Size([4, 128]), Vector features: torch.Size([4, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 1.2671e-01, -5.6996e-04, -4.8518e-02, -6.6456e-02, -1.1061e-01,\n",
      "         -6.2446e-02,  5.8538e-02, -1.2011e-01,  3.2896e-03, -1.1391e-01,\n",
      "          8.9399e-02,  3.0616e-02, -1.5253e-02,  4.0367e-03, -9.1894e-02,\n",
      "          1.7641e-01,  9.1237e-03,  6.4034e-02,  5.3109e-02, -3.0895e-02,\n",
      "         -5.9957e-02, -6.8242e-02, -2.1868e-02, -8.0426e-02, -1.2410e-01,\n",
      "         -3.4229e-02,  2.2795e-02, -1.0109e-02, -1.0283e-01,  7.2923e-02,\n",
      "         -6.0790e-02, -1.4362e-02,  1.6639e-01, -4.2110e-02,  5.1438e-02,\n",
      "          8.3763e-02,  1.1601e-01,  4.8873e-02, -1.5967e-01, -2.0319e-01,\n",
      "          1.4386e-02,  7.8985e-02, -1.3106e-01, -6.7708e-02,  6.8627e-02,\n",
      "          1.3381e-01,  4.1441e-02,  2.9128e-02, -9.2353e-03,  8.5439e-02,\n",
      "         -7.8160e-02,  9.1988e-02,  1.0933e-01, -5.8055e-02,  5.8807e-02,\n",
      "         -5.9122e-02, -3.4788e-02, -1.1314e-01, -3.9962e-02,  7.8402e-02,\n",
      "         -5.5336e-03, -2.4202e-02, -1.9998e-02, -9.4768e-02,  1.9427e-01,\n",
      "         -5.6055e-02, -3.3940e-02,  3.8427e-02,  1.0923e-02, -9.1470e-02,\n",
      "         -6.5578e-03,  7.4157e-02,  6.0548e-03,  1.0709e-01,  4.9561e-02,\n",
      "          1.7870e-01, -1.1980e-02, -8.8762e-02,  3.9070e-02,  3.3465e-02,\n",
      "         -7.6118e-02, -8.0133e-02, -8.7931e-02,  2.1546e-02,  1.6745e-01,\n",
      "          1.5770e-01, -2.1865e-02,  3.8715e-03,  1.1677e-01, -1.8953e-01,\n",
      "          7.9557e-02,  1.9187e-02,  1.1497e-01,  1.0875e-01,  3.9211e-02,\n",
      "         -9.4686e-02,  8.2977e-02,  5.0566e-02,  9.0888e-02,  4.7339e-02,\n",
      "         -1.1944e-01,  2.9898e-02, -1.7570e-02, -2.4765e-02,  4.0500e-02,\n",
      "          7.9450e-02,  5.6791e-02, -1.1530e-02, -2.5231e-02, -7.8960e-02,\n",
      "         -3.2637e-02, -4.5479e-02, -1.4037e-01, -8.3114e-02, -9.0622e-03,\n",
      "         -6.0480e-02,  1.1983e-01, -7.2608e-03,  1.1774e-01,  9.5328e-02,\n",
      "         -5.0662e-02, -9.4080e-02, -1.2605e-01,  1.5751e-01, -9.6255e-03,\n",
      "         -2.6757e-02, -3.3521e-01,  1.1588e-02],\n",
      "        [ 5.2525e-02,  1.9651e-02, -6.6648e-02,  1.1563e-01,  5.7797e-02,\n",
      "          7.4053e-02, -1.0554e-01,  9.3135e-02,  1.4239e-01,  1.6357e-01,\n",
      "          4.5289e-02, -8.3478e-02, -1.0436e-01, -1.3126e-01,  4.3012e-02,\n",
      "          1.0546e-01, -1.9963e-02, -4.5335e-03,  4.5329e-02,  1.2392e-01,\n",
      "          6.6502e-02, -4.6462e-02,  4.2147e-02,  2.6572e-02,  4.9555e-02,\n",
      "         -1.0691e-01, -7.1369e-02, -5.8798e-02,  9.7471e-02, -1.3325e-01,\n",
      "          4.2762e-02, -1.6724e-01, -9.6798e-02,  4.0162e-02, -1.4483e-01,\n",
      "         -8.7384e-02,  1.3118e-02, -9.1937e-02,  7.4122e-02,  2.5465e-02,\n",
      "          7.2809e-04,  1.8046e-02, -3.1313e-02, -8.9736e-02, -1.7987e-01,\n",
      "         -6.5265e-02,  9.9074e-03, -6.1365e-02,  8.5031e-03, -3.1123e-02,\n",
      "         -1.2201e-02, -2.7683e-02, -1.0062e-01, -4.2963e-02, -8.3777e-02,\n",
      "         -1.0291e-01,  8.9478e-02,  1.3130e-01,  4.3910e-02, -8.1341e-04,\n",
      "          4.3554e-02,  2.8545e-02,  5.3518e-04, -3.5227e-02, -1.1886e-01,\n",
      "          8.6532e-03, -2.5853e-02, -7.2582e-02, -5.8816e-02,  1.7440e-01,\n",
      "          6.6868e-02, -7.3627e-02, -7.8068e-02,  3.7447e-02, -1.2450e-01,\n",
      "         -1.7633e-01,  1.9271e-01,  1.2713e-01, -3.7056e-02,  1.3209e-02,\n",
      "         -5.0018e-02, -4.0573e-02,  6.9885e-02, -6.9693e-02,  1.6880e-02,\n",
      "          4.4486e-02, -9.0074e-02, -1.0411e-01, -1.5758e-03, -3.1985e-02,\n",
      "          4.6601e-03, -1.5573e-02, -1.2421e-01,  1.0033e-01,  4.8333e-02,\n",
      "         -1.9280e-02, -5.3631e-02, -2.0339e-01,  7.1142e-02, -1.1608e-01,\n",
      "          1.7269e-02, -4.8689e-02,  1.4642e-01,  6.5077e-02,  9.0070e-02,\n",
      "          1.2429e-01, -2.6027e-02,  8.2648e-02,  9.6598e-02,  3.2349e-02,\n",
      "          1.0039e-01, -1.2476e-01,  7.4351e-02,  1.0631e-01, -2.8619e-02,\n",
      "          2.6673e-01,  3.1616e-02, -3.6563e-02, -1.0025e-01,  8.1374e-02,\n",
      "          8.1455e-02,  6.8796e-02,  8.7649e-02, -1.9775e-02, -5.5023e-02,\n",
      "         -1.1540e-01,  1.9949e-01, -3.1295e-02],\n",
      "        [-8.3516e-02,  2.6194e-03,  8.9967e-02, -3.9361e-02,  3.3498e-02,\n",
      "         -5.3294e-02,  4.8761e-02,  7.4600e-02, -1.1607e-01, -2.9425e-02,\n",
      "         -1.1407e-01,  7.6191e-03,  3.4853e-02,  2.7776e-02,  1.9404e-02,\n",
      "         -1.0023e-01,  6.2747e-03, -4.4140e-02, -8.6388e-02, -1.5930e-02,\n",
      "         -3.2517e-02,  1.5423e-01, -5.5205e-02,  1.1796e-01,  9.8220e-03,\n",
      "          5.9591e-02,  3.3369e-02,  5.5923e-03,  1.3226e-01, -3.1698e-02,\n",
      "          1.1747e-01,  4.1724e-02, -1.1441e-01, -3.4672e-02,  3.5173e-02,\n",
      "         -5.1539e-02, -5.8449e-02, -5.7596e-03,  9.1427e-02,  1.7499e-01,\n",
      "         -2.3725e-02, -2.0418e-01,  1.7044e-01,  1.4973e-01,  1.2447e-01,\n",
      "         -4.0824e-02, -5.5870e-02,  3.0996e-02,  5.3587e-02, -8.3743e-02,\n",
      "          1.7325e-01, -1.3539e-03,  3.6999e-02,  9.7636e-02,  2.6181e-02,\n",
      "          7.3554e-02, -3.0808e-03, -6.9575e-02, -4.8531e-02, -1.5231e-02,\n",
      "         -2.3743e-02, -7.5521e-04, -2.5042e-02,  1.7833e-01, -1.5819e-01,\n",
      "         -3.2892e-02,  9.3144e-02,  4.2588e-02,  1.1658e-02,  1.2340e-02,\n",
      "          3.0030e-02, -3.6087e-02,  3.8292e-02, -1.0531e-01,  1.2864e-01,\n",
      "         -9.8987e-02, -1.8084e-01,  5.5614e-02, -7.9912e-02, -1.5677e-02,\n",
      "          3.3003e-02,  8.1766e-02,  5.8230e-02, -1.1228e-01, -1.0226e-01,\n",
      "         -1.9695e-01,  3.5473e-02,  1.7529e-01, -2.1754e-01,  9.0222e-02,\n",
      "         -6.6845e-02, -7.5764e-03,  2.0469e-02, -1.4601e-01, -5.8755e-04,\n",
      "          6.9714e-02, -8.4320e-02,  3.2702e-02, -1.1279e-01,  1.0374e-01,\n",
      "          2.2150e-01,  3.3322e-03, -3.8973e-02, -1.3135e-01, -4.3583e-02,\n",
      "         -1.4013e-01, -3.7408e-02,  1.5520e-02,  1.4570e-02,  6.2265e-02,\n",
      "         -1.0470e-02,  1.0134e-01,  1.5589e-01, -1.4174e-01,  1.7541e-02,\n",
      "         -1.0408e-01, -1.2964e-01,  2.4690e-02,  4.5920e-02, -7.4416e-02,\n",
      "         -6.4657e-02,  4.4027e-02, -1.2629e-02, -4.6581e-02,  1.6022e-02,\n",
      "          1.5569e-01,  2.5601e-02, -7.1058e-02],\n",
      "        [-5.5596e-02,  1.2907e-02,  2.1128e-01,  1.4201e-03, -8.2802e-03,\n",
      "          9.2220e-02,  8.2020e-02,  1.8139e-04, -8.5222e-02, -5.3150e-02,\n",
      "         -1.0826e-01,  6.5691e-02,  8.6633e-03,  1.7700e-02, -4.2216e-02,\n",
      "         -1.4706e-01, -4.3846e-02, -1.3688e-01, -7.7707e-02,  6.8021e-02,\n",
      "          8.8490e-02,  8.1605e-02, -5.6894e-02,  1.2138e-03, -1.7367e-01,\n",
      "          1.9553e-01, -8.1460e-03, -3.6105e-03, -3.9124e-02,  3.6569e-02,\n",
      "          5.6349e-02, -3.5340e-02, -2.5970e-02,  9.7535e-02,  9.8647e-02,\n",
      "         -3.9289e-02,  5.2757e-02,  2.7802e-02, -3.7645e-02,  1.4711e-01,\n",
      "          6.5516e-02, -3.4729e-02,  8.8094e-02,  4.5496e-02,  8.4591e-02,\n",
      "         -1.0157e-01,  5.6923e-02, -1.4189e-02,  4.7636e-03, -9.3148e-02,\n",
      "          2.1239e-01, -4.9435e-02,  2.4252e-02,  1.7927e-01,  7.9127e-02,\n",
      "          5.1430e-02,  4.1252e-02,  2.1270e-02,  2.0358e-02, -8.1399e-02,\n",
      "         -1.1414e-01,  8.7019e-02, -9.1523e-03,  7.5148e-02,  6.1461e-02,\n",
      "         -1.3113e-01,  5.8078e-02, -3.5621e-02, -1.9650e-02, -4.1775e-02,\n",
      "         -5.2028e-02, -1.7600e-02, -5.2921e-02,  7.2696e-02,  5.9892e-02,\n",
      "         -3.4107e-02, -1.5376e-01, -1.1709e-01,  5.4479e-02, -7.2431e-04,\n",
      "          7.3117e-02, -1.4206e-02,  9.3201e-02,  3.7601e-02, -4.8873e-02,\n",
      "         -1.7593e-01,  1.2365e-01,  8.1402e-02, -3.0058e-01,  4.0154e-02,\n",
      "         -8.1518e-02, -6.5243e-02,  4.1503e-02, -1.1419e-01,  8.2763e-02,\n",
      "          3.2392e-02, -1.6990e-02,  1.1783e-01, -1.1400e-01,  1.1012e-01,\n",
      "          1.0110e-01, -3.6236e-02, -6.7568e-02, -7.6830e-02, -6.6902e-02,\n",
      "         -1.0803e-01, -7.7925e-02,  4.9120e-02, -2.1237e-02, -7.5726e-02,\n",
      "         -6.5800e-02,  1.1579e-01, -4.8833e-02, -9.1436e-02, -9.8676e-02,\n",
      "         -9.5793e-02, -1.5471e-01,  2.6462e-03,  2.6396e-03,  2.5310e-02,\n",
      "         -1.5492e-01,  9.1370e-02,  4.3376e-02, -5.6865e-02,  2.0488e-01,\n",
      "          1.3579e-01,  4.2901e-02,  1.3097e-02]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1259, -0.0078,  0.0047, -0.0597, -0.1582, -0.0584,  0.0494, -0.1333,\n",
      "          0.0199, -0.0813,  0.0824,  0.0326,  0.0322, -0.0014, -0.0945,  0.1606,\n",
      "         -0.0175,  0.0278,  0.0549, -0.0376, -0.0468, -0.1145, -0.0187, -0.0319,\n",
      "         -0.1423, -0.0445, -0.0208,  0.0209, -0.1672,  0.0812, -0.0600,  0.0278,\n",
      "          0.1689, -0.0365,  0.0423,  0.0666,  0.1033,  0.0552, -0.1417, -0.2153,\n",
      "          0.0203,  0.0890, -0.1001, -0.0775,  0.0844,  0.1383,  0.0100, -0.0005,\n",
      "         -0.0287,  0.0739, -0.0851,  0.0459,  0.0978, -0.0839,  0.0620, -0.0620,\n",
      "         -0.0323, -0.0982, -0.0052,  0.0765, -0.0432, -0.0183, -0.0022, -0.0705,\n",
      "          0.1972, -0.0480, -0.0266,  0.0112,  0.0389, -0.1188, -0.0378,  0.0942,\n",
      "          0.0152,  0.0964,  0.0154,  0.1857, -0.0303, -0.1047,  0.0388,  0.0414,\n",
      "         -0.0353, -0.0797, -0.0488,  0.0677,  0.1854,  0.1209,  0.0018, -0.0496,\n",
      "          0.1509, -0.1967,  0.0932,  0.0368,  0.1731,  0.1264,  0.0190, -0.1052,\n",
      "          0.1072,  0.0644,  0.0774,  0.0406, -0.1495,  0.0577, -0.0633, -0.0251,\n",
      "          0.0354,  0.0782,  0.0414,  0.0051, -0.0372, -0.0631, -0.0425, -0.0468,\n",
      "         -0.1457, -0.0542, -0.0086, -0.1094,  0.0955,  0.0052,  0.0926,  0.0953,\n",
      "         -0.0654, -0.0808, -0.1011,  0.1383,  0.0125, -0.0019, -0.2619,  0.0176],\n",
      "        [ 0.0396, -0.0182, -0.1127,  0.1298,  0.0617,  0.0530, -0.1241,  0.0634,\n",
      "          0.1411,  0.1378,  0.0681, -0.0981, -0.0826, -0.0946,  0.0356,  0.1463,\n",
      "          0.0027, -0.0303,  0.0534,  0.0878,  0.0306, -0.0607,  0.0425, -0.0267,\n",
      "          0.0114, -0.0715, -0.0514, -0.0552,  0.0993, -0.0863,  0.0216, -0.1141,\n",
      "         -0.0472,  0.0521, -0.1433, -0.0991,  0.0276, -0.0719,  0.0560, -0.0259,\n",
      "         -0.0285,  0.0785, -0.0511, -0.1894, -0.2326, -0.0036,  0.0012, -0.0768,\n",
      "         -0.0470,  0.0099, -0.0583, -0.0274, -0.0943, -0.0646, -0.0976, -0.1095,\n",
      "          0.0633,  0.1095,  0.0315,  0.0160,  0.0416,  0.0352,  0.0252, -0.0721,\n",
      "         -0.0582,  0.0385, -0.1067, -0.0581, -0.0306,  0.1430,  0.0514, -0.0185,\n",
      "         -0.0983,  0.0192, -0.1190, -0.0832,  0.2494,  0.1010, -0.0583,  0.0121,\n",
      "          0.0035,  0.0378,  0.0315, -0.0073,  0.0994,  0.0773, -0.0982, -0.1187,\n",
      "          0.0977, -0.1040,  0.0264, -0.0157, -0.0939,  0.1237,  0.0176, -0.0690,\n",
      "         -0.0413, -0.1898,  0.1089, -0.1838, -0.0454,  0.0051,  0.1371,  0.0836,\n",
      "          0.0911,  0.1762, -0.0140,  0.0719,  0.0721,  0.0379,  0.1042, -0.0997,\n",
      "          0.0256,  0.1474, -0.0149,  0.1861,  0.0431, -0.0328, -0.0857,  0.1165,\n",
      "          0.0683,  0.0804,  0.0765,  0.0116, -0.0745, -0.1321,  0.1428, -0.0660],\n",
      "        [-0.1847,  0.0085,  0.0975, -0.0705,  0.0334, -0.0503,  0.0146,  0.0753,\n",
      "         -0.0977, -0.0067, -0.0844, -0.0187,  0.0299,  0.0142,  0.0398, -0.1809,\n",
      "          0.0347, -0.0211, -0.0755, -0.0367, -0.0166,  0.1491, -0.0497,  0.1635,\n",
      "          0.0634,  0.0753,  0.0227, -0.0121,  0.1403, -0.0332,  0.1430,  0.0646,\n",
      "         -0.1346, -0.0311,  0.0335, -0.0204, -0.0966, -0.0057,  0.1233,  0.1932,\n",
      "         -0.0325, -0.1444,  0.1619,  0.1507,  0.0902, -0.0479, -0.0436,  0.0210,\n",
      "          0.0532, -0.0811,  0.1565, -0.0315,  0.0105,  0.1156, -0.0112,  0.0809,\n",
      "          0.0020, -0.0248, -0.0426, -0.0303,  0.0014, -0.0077, -0.0118,  0.1847,\n",
      "         -0.1657, -0.0316,  0.0797,  0.0680, -0.0073,  0.0080,  0.0356, -0.0417,\n",
      "          0.0569, -0.1032,  0.0949, -0.0767, -0.0946,  0.0732, -0.0771, -0.0028,\n",
      "         -0.0309,  0.0682,  0.0808, -0.1189, -0.1308, -0.1787,  0.0354,  0.1292,\n",
      "         -0.1854,  0.1067, -0.0691, -0.0452, -0.0151, -0.1423, -0.0091,  0.1119,\n",
      "         -0.0756, -0.0036, -0.1849,  0.1067,  0.2023,  0.0096, -0.0117, -0.1221,\n",
      "         -0.0552, -0.1322, -0.0546,  0.0066,  0.0103,  0.0960,  0.0019,  0.1038,\n",
      "          0.1634, -0.0948,  0.0214, -0.0622, -0.1016,  0.0155, -0.0217, -0.0984,\n",
      "         -0.0197,  0.0298,  0.0178, -0.0899, -0.0009,  0.0993,  0.0791, -0.0795],\n",
      "        [-0.0875, -0.0063,  0.2269,  0.0653, -0.0102,  0.0943,  0.0591, -0.0339,\n",
      "         -0.1412, -0.0673, -0.1490,  0.0626,  0.0033,  0.0428, -0.0704, -0.1315,\n",
      "         -0.0355, -0.1238, -0.0719,  0.1155,  0.0570,  0.1515, -0.0266, -0.0025,\n",
      "         -0.1151,  0.1320, -0.0547, -0.0213, -0.0191,  0.0529,  0.0758,  0.0011,\n",
      "         -0.0367,  0.0590,  0.1147, -0.0842, -0.0156,  0.0084,  0.0131,  0.1372,\n",
      "          0.0891, -0.0319,  0.1301,  0.0738,  0.0571, -0.0664,  0.0364, -0.0235,\n",
      "         -0.0447, -0.0664,  0.2456, -0.0900,  0.0657,  0.1835,  0.0447,  0.0496,\n",
      "          0.0703,  0.0511,  0.0436, -0.0783, -0.1079,  0.0831,  0.0130,  0.1387,\n",
      "          0.0685, -0.1078,  0.0531, -0.0265, -0.0473, -0.0253, -0.0714, -0.0596,\n",
      "         -0.0311,  0.0513,  0.0380, -0.0376, -0.0607, -0.0790,  0.0384,  0.0212,\n",
      "          0.0858, -0.0231,  0.0720,  0.0504, -0.0986, -0.2139,  0.0878,  0.0514,\n",
      "         -0.2652,  0.0724, -0.1121, -0.0713,  0.0104, -0.1480,  0.0859,  0.0243,\n",
      "         -0.0223,  0.1305, -0.2057,  0.0776,  0.0610, -0.0389, -0.0651, -0.1045,\n",
      "         -0.0170, -0.1188, -0.0157,  0.0544, -0.0102, -0.0364, -0.0660,  0.0867,\n",
      "          0.0048, -0.0521, -0.0854, -0.1222, -0.1487,  0.0210,  0.0094,  0.0239,\n",
      "         -0.1384,  0.0706,  0.0499, -0.0489,  0.1633,  0.0932,  0.0517,  0.0203]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.7308, -1.9443, -9.6550, -5.2555],\n",
      "        [-5.7058, 13.0347, -2.8334, -4.7860],\n",
      "        [-8.1052, -7.6697, 13.5448,  8.6753],\n",
      "        [-3.1936, -7.7100,  7.1193, 13.3680]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7308, 13.0347, 13.5448, 13.3680], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0024, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[-1.9443, -9.6550, -5.2555],\n",
      "        [-5.7058, -2.8334, -4.7860],\n",
      "        [-8.1052, -7.6697,  8.6753],\n",
      "        [-3.1936, -7.7100,  7.1193]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0008, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 7: 0.0015966868959367275\n",
      "Epoch [6/10], Loss: 0.0982\n",
      "Batch 1/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0038,  0.0294,  0.0710,  ..., -0.0244,  0.1826, -0.0256],\n",
      "        [ 0.0301,  0.0106,  0.1823,  ...,  0.0825,  0.0315,  0.0476],\n",
      "        [-0.0306,  0.0215,  0.0519,  ...,  0.0193, -0.1482,  0.0295],\n",
      "        ...,\n",
      "        [ 0.1102, -0.0609,  0.1178,  ...,  0.0853, -0.1455,  0.0647],\n",
      "        [ 0.1115, -0.0260,  0.0722,  ...,  0.0561, -0.2614,  0.0442],\n",
      "        [-0.1156,  0.0124,  0.0754,  ...,  0.1376,  0.1067, -0.0749]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0179,  0.0133,  0.0324,  ..., -0.0806,  0.2609,  0.0264],\n",
      "        [-0.0430,  0.0198,  0.1884,  ...,  0.0834,  0.0382,  0.0441],\n",
      "        [-0.0651, -0.0075,  0.0598,  ...,  0.0690, -0.1395,  0.0014],\n",
      "        ...,\n",
      "        [ 0.0979, -0.0583,  0.1491,  ...,  0.0974, -0.1127,  0.1031],\n",
      "        [ 0.0729, -0.0481,  0.0640,  ...,  0.0610, -0.2448,  0.0454],\n",
      "        [-0.2094, -0.0005,  0.0537,  ...,  0.0970,  0.1106, -0.0649]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.4483,   6.6367, -11.0637,   9.5337,  10.1176,  10.3301,   2.4151,\n",
      "          -9.1151,   4.1399,  -2.8557,   7.7881,   5.1505,   4.6701,  -0.7907,\n",
      "         -10.0965,   7.1030],\n",
      "        [  4.5112,  13.7745,  -3.2881,  11.6885,  -3.5201,  11.0928,  -8.7208,\n",
      "           3.8756,  -1.4448,   0.3102,  -2.8311,  -2.8305,   8.5144,   9.1934,\n",
      "           2.4207,   4.4137],\n",
      "        [-11.4829,  -1.7936,  13.7219,  -4.5363, -11.5077,  -8.5369,  -5.4333,\n",
      "          12.1002,  -5.4123,   5.8379,  -3.2879, -10.5268,   3.8300,   1.2868,\n",
      "           8.3864,  -3.4265],\n",
      "        [  7.3702,  12.7793,  -5.9309,  13.3634,   0.0461,  12.4978,  -4.4866,\n",
      "          -0.0784,  -2.5111,  -3.4583,   0.7484,  -1.7706,   8.2596,   6.9886,\n",
      "          -1.9459,   8.5733],\n",
      "        [ 11.2027,  -2.1963, -10.7372,   2.2364,  13.6919,   4.7259,   9.9708,\n",
      "         -12.9712,   4.3326,  -5.3615,   9.2209,   8.7615,  -2.3000,  -6.8658,\n",
      "         -12.3177,   5.5198],\n",
      "        [  9.1737,  11.2002,  -9.3774,  11.5252,   3.3600,  13.8377,  -2.2856,\n",
      "          -3.5394,  -1.1439,  -5.9784,  -0.6276,   3.3101,   4.0776,   7.1812,\n",
      "          -2.4689,   7.1277],\n",
      "        [  4.5283,  -7.2136,  -4.0779,  -2.8478,   9.9264,  -1.1474,  13.6137,\n",
      "          -9.5991,   0.4164,  -6.4971,   7.8779,   4.6992,  -4.2564, -10.0025,\n",
      "         -10.5324,   5.6932],\n",
      "        [ -9.7536,   4.8196,  10.6939,   0.5492, -13.2944,  -2.6639,  -9.7591,\n",
      "          13.8190,  -5.2255,   5.7345,  -6.9751, -10.1535,   5.7838,   6.4447,\n",
      "          10.7623,  -2.5246],\n",
      "        [  6.0914,  -0.2553,  -7.2312,  -1.1744,   6.7661,   0.8340,   0.1687,\n",
      "          -5.8304,  13.4598,   6.7298,   0.5034,   7.8548,  -3.4503,  -3.8674,\n",
      "          -3.7271,  -6.3069],\n",
      "        [ -3.9371,  -0.3770,   4.1501,  -3.2915,  -3.7068,  -6.0301,  -6.5786,\n",
      "           5.4991,   7.7699,  13.6793,  -0.8857,  -1.8332,   1.5432,  -2.5871,\n",
      "           3.5866,  -8.4793],\n",
      "        [  7.4699,  -0.8481,  -3.2782,   4.1784,   8.2939,   0.7651,   5.5882,\n",
      "          -6.7648,   1.3807,   0.6613,  13.7052,  -0.4790,   5.7192,  -8.2757,\n",
      "         -11.6304,   7.3479],\n",
      "        [  8.0139,  -2.4902, -11.4034,  -1.4202,  10.1212,   3.8628,   4.7664,\n",
      "         -10.3799,   7.5968,  -3.3291,   0.0365,  13.8353,  -8.9175,  -0.4729,\n",
      "          -4.0459,  -2.8851],\n",
      "        [  3.6464,  11.1990,   1.1835,  11.3378,  -2.8058,   7.1563,  -5.8244,\n",
      "           4.4232,  -3.7831,   1.8922,   4.4344,  -8.5601,  13.5867,   2.9320,\n",
      "          -2.2468,   8.1895],\n",
      "        [ -0.8768,   7.3561,  -0.8798,   4.6049,  -6.4576,   6.0525,  -8.8318,\n",
      "           4.9321,  -3.8043,  -2.9231,  -8.9377,   0.4090,   0.2400,  13.6221,\n",
      "           9.4570,  -1.4991],\n",
      "        [ -9.8305,   1.2767,   7.4750,  -3.4310, -11.7226,  -3.3216,  -9.0744,\n",
      "          10.7330,  -3.3985,   3.1724, -11.3315,  -3.6015,  -1.8832,   9.3679,\n",
      "          13.6892,  -7.3768],\n",
      "        [  5.7152,   6.3284,  -3.3230,   9.9035,   2.7720,   8.7195,   4.4059,\n",
      "          -2.7268,  -7.7279,  -8.8667,   5.8544,  -3.3391,   6.9684,   0.2909,\n",
      "          -6.9397,  13.8036]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.4483, 13.7745, 13.7219, 13.3634, 13.6919, 13.8377, 13.6137, 13.8190,\n",
      "        13.4598, 13.6793, 13.7052, 13.8353, 13.5867, 13.6221, 13.6892, 13.8036],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1197, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  6.6367, -11.0637,   9.5337,  10.1176,  10.3301,   2.4151,  -9.1151,\n",
      "           4.1399,  -2.8557,   7.7881,   5.1505,   4.6701,  -0.7907, -10.0965,\n",
      "           7.1030],\n",
      "        [  4.5112,  -3.2881,  11.6885,  -3.5201,  11.0928,  -8.7208,   3.8756,\n",
      "          -1.4448,   0.3102,  -2.8311,  -2.8305,   8.5144,   9.1934,   2.4207,\n",
      "           4.4137],\n",
      "        [-11.4829,  -1.7936,  -4.5363, -11.5077,  -8.5369,  -5.4333,  12.1002,\n",
      "          -5.4123,   5.8379,  -3.2879, -10.5268,   3.8300,   1.2868,   8.3864,\n",
      "          -3.4265],\n",
      "        [  7.3702,  12.7793,  -5.9309,   0.0461,  12.4978,  -4.4866,  -0.0784,\n",
      "          -2.5111,  -3.4583,   0.7484,  -1.7706,   8.2596,   6.9886,  -1.9459,\n",
      "           8.5733],\n",
      "        [ 11.2027,  -2.1963, -10.7372,   2.2364,   4.7259,   9.9708, -12.9712,\n",
      "           4.3326,  -5.3615,   9.2209,   8.7615,  -2.3000,  -6.8658, -12.3177,\n",
      "           5.5198],\n",
      "        [  9.1737,  11.2002,  -9.3774,  11.5252,   3.3600,  -2.2856,  -3.5394,\n",
      "          -1.1439,  -5.9784,  -0.6276,   3.3101,   4.0776,   7.1812,  -2.4689,\n",
      "           7.1277],\n",
      "        [  4.5283,  -7.2136,  -4.0779,  -2.8478,   9.9264,  -1.1474,  -9.5991,\n",
      "           0.4164,  -6.4971,   7.8779,   4.6992,  -4.2564, -10.0025, -10.5324,\n",
      "           5.6932],\n",
      "        [ -9.7536,   4.8196,  10.6939,   0.5492, -13.2944,  -2.6639,  -9.7591,\n",
      "          -5.2255,   5.7345,  -6.9751, -10.1535,   5.7838,   6.4447,  10.7623,\n",
      "          -2.5246],\n",
      "        [  6.0914,  -0.2553,  -7.2312,  -1.1744,   6.7661,   0.8340,   0.1687,\n",
      "          -5.8304,   6.7298,   0.5034,   7.8548,  -3.4503,  -3.8674,  -3.7271,\n",
      "          -6.3069],\n",
      "        [ -3.9371,  -0.3770,   4.1501,  -3.2915,  -3.7068,  -6.0301,  -6.5786,\n",
      "           5.4991,   7.7699,  -0.8857,  -1.8332,   1.5432,  -2.5871,   3.5866,\n",
      "          -8.4793],\n",
      "        [  7.4699,  -0.8481,  -3.2782,   4.1784,   8.2939,   0.7651,   5.5882,\n",
      "          -6.7648,   1.3807,   0.6613,  -0.4790,   5.7192,  -8.2757, -11.6304,\n",
      "           7.3479],\n",
      "        [  8.0139,  -2.4902, -11.4034,  -1.4202,  10.1212,   3.8628,   4.7664,\n",
      "         -10.3799,   7.5968,  -3.3291,   0.0365,  -8.9175,  -0.4729,  -4.0459,\n",
      "          -2.8851],\n",
      "        [  3.6464,  11.1990,   1.1835,  11.3378,  -2.8058,   7.1563,  -5.8244,\n",
      "           4.4232,  -3.7831,   1.8922,   4.4344,  -8.5601,   2.9320,  -2.2468,\n",
      "           8.1895],\n",
      "        [ -0.8768,   7.3561,  -0.8798,   4.6049,  -6.4576,   6.0525,  -8.8318,\n",
      "           4.9321,  -3.8043,  -2.9231,  -8.9377,   0.4090,   0.2400,   9.4570,\n",
      "          -1.4991],\n",
      "        [ -9.8305,   1.2767,   7.4750,  -3.4310, -11.7226,  -3.3216,  -9.0744,\n",
      "          10.7330,  -3.3985,   3.1724, -11.3315,  -3.6015,  -1.8832,   9.3679,\n",
      "          -7.3768],\n",
      "        [  5.7152,   6.3284,  -3.3230,   9.9035,   2.7720,   8.7195,   4.4059,\n",
      "          -2.7268,  -7.7279,  -8.8667,   5.8544,  -3.3391,   6.9684,   0.2909,\n",
      "          -6.9397]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0073, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 1: 0.06352200359106064\n",
      "Batch 2/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1663, -0.0448, -0.0276,  ..., -0.0526,  0.0183,  0.0011],\n",
      "        [-0.0026,  0.0065,  0.1922,  ...,  0.1323, -0.1127,  0.0392],\n",
      "        [ 0.1233,  0.0040, -0.0879,  ..., -0.0532, -0.3218,  0.0021],\n",
      "        ...,\n",
      "        [-0.1907,  0.0924,  0.1371,  ...,  0.0419,  0.0827, -0.0730],\n",
      "        [ 0.1006, -0.0565,  0.0560,  ...,  0.0323, -0.1126,  0.0492],\n",
      "        [ 0.1437, -0.0418, -0.2171,  ..., -0.0593, -0.1798, -0.0134]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1406, -0.0406, -0.0383,  ..., -0.0461,  0.0646,  0.0038],\n",
      "        [-0.0750,  0.0071,  0.1814,  ...,  0.1348, -0.1108,  0.0160],\n",
      "        [ 0.1254, -0.0035, -0.0503,  ..., -0.0427, -0.2605,  0.0170],\n",
      "        ...,\n",
      "        [-0.2052,  0.0931,  0.1258,  ...,  0.0161,  0.1082, -0.1079],\n",
      "        [ 0.1041, -0.0478,  0.0688,  ...,  0.0391, -0.0281,  0.0475],\n",
      "        [ 0.1339, -0.0359, -0.1896,  ..., -0.0685, -0.1370, -0.0384]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3909e+01, -3.3916e+00, -3.1149e+00, -2.5603e+00,  9.7741e+00,\n",
      "          1.2456e+01, -3.0499e+00, -2.0352e+00,  9.6557e+00,  3.6165e+00,\n",
      "          4.4819e+00,  7.4385e+00,  1.3308e+00, -3.2411e+00,  7.8880e+00,\n",
      "          8.4333e-02],\n",
      "        [-3.4116e-03,  1.3342e+01, -1.7920e+00,  9.8476e-02,  1.8160e+00,\n",
      "         -2.7154e+00,  6.0828e+00, -1.5517e+00,  6.4317e+00,  8.2878e+00,\n",
      "          1.9282e+00,  3.3968e+00, -3.2889e+00,  1.4770e+00,  8.7274e+00,\n",
      "         -9.1726e+00],\n",
      "        [-2.9097e+00, -2.6368e+00,  1.3583e+01, -2.2165e-01, -1.0362e+01,\n",
      "          2.3458e+00, -3.5823e-01,  6.2501e+00, -7.7301e+00,  6.3839e+00,\n",
      "         -1.1625e+01,  7.6780e+00, -1.0128e+01, -7.7641e+00,  1.1795e+00,\n",
      "          1.1542e+01],\n",
      "        [-7.5234e-01,  1.8869e-01,  1.5714e-01,  1.3478e+01,  6.1892e-01,\n",
      "         -3.7695e+00,  4.9373e+00, -1.0043e+01, -4.6177e+00, -9.2608e-01,\n",
      "          4.1461e+00, -3.7917e+00, -4.3279e+00, -1.3760e+00, -9.8410e-01,\n",
      "         -2.0508e+00],\n",
      "        [ 9.9342e+00,  3.8842e-01, -1.0882e+01, -1.0786e+00,  1.3520e+01,\n",
      "          5.3799e+00, -8.9670e-01, -4.6844e+00,  1.0156e+01, -1.7543e+00,\n",
      "          1.1307e+01, -1.4863e+00,  7.7030e+00,  2.4528e+00,  4.5908e+00,\n",
      "         -7.7660e+00],\n",
      "        [ 1.2414e+01, -5.6854e+00,  1.4581e+00, -4.7167e+00,  5.8520e+00,\n",
      "          1.3940e+01, -2.6922e+00,  1.2068e+00,  6.6702e+00,  4.8333e+00,\n",
      "          2.4790e-01,  9.9190e+00, -1.1301e+00, -5.9674e+00,  7.7012e+00,\n",
      "          4.4467e+00],\n",
      "        [-1.2084e+00,  7.4482e+00,  2.8145e+00,  3.6707e+00, -1.8675e+00,\n",
      "         -8.9810e-01,  1.3205e+01, -6.2028e+00, -6.2880e-01,  6.0977e+00,\n",
      "          2.4882e+00,  3.6093e+00, -6.9051e+00, -9.9673e-01,  7.7882e+00,\n",
      "         -4.9591e+00],\n",
      "        [-3.4850e+00, -1.6255e+00,  4.2854e+00, -9.2074e+00, -4.5840e+00,\n",
      "          2.8245e-01, -7.6399e+00,  1.3600e+01, -1.3532e+00,  1.3784e+00,\n",
      "         -8.6875e+00,  1.8162e+00,  1.4476e+00, -2.3885e+00, -2.5302e+00,\n",
      "          6.7763e+00],\n",
      "        [ 9.8903e+00,  3.2121e+00, -8.1524e+00, -5.1191e+00,  1.0298e+01,\n",
      "          6.7281e+00, -1.6185e+00, -2.2468e+00,  1.3756e+01,  1.9142e+00,\n",
      "          6.4727e+00,  4.0223e+00,  5.5564e+00,  3.9324e+00,  6.5164e+00,\n",
      "         -7.3435e+00],\n",
      "        [ 3.2628e+00,  6.9066e+00,  7.8398e+00, -5.3974e-01, -2.3806e+00,\n",
      "          4.6236e+00,  3.5632e+00,  3.3432e+00,  1.9404e+00,  1.3747e+01,\n",
      "         -5.7011e+00,  1.1274e+01, -1.0647e+01, -8.6094e+00,  1.1520e+01,\n",
      "          1.6049e+00],\n",
      "        [ 6.4003e+00,  1.6006e+00, -1.1955e+01,  1.4713e+00,  1.1942e+01,\n",
      "          1.1371e+00,  2.8201e+00, -8.5067e+00,  7.5077e+00, -4.4492e+00,\n",
      "          1.3584e+01, -5.2503e+00,  8.0193e+00,  5.5288e+00,  2.3283e+00,\n",
      "         -1.0157e+01],\n",
      "        [ 7.4001e+00,  1.4084e+00,  7.4475e+00, -3.2007e+00, -6.1135e-01,\n",
      "          1.0072e+01,  1.3643e+00,  2.6651e+00,  4.4532e+00,  1.1356e+01,\n",
      "         -5.5317e+00,  1.3765e+01, -8.4098e+00, -7.5230e+00,  1.0610e+01,\n",
      "          4.3934e+00],\n",
      "        [ 1.1101e+00, -3.1103e+00, -1.1706e+01, -4.3712e+00,  7.6961e+00,\n",
      "         -1.8006e+00, -5.0830e+00, -1.1299e+00,  5.6162e+00, -1.1090e+01,\n",
      "          8.2231e+00, -8.9338e+00,  1.3860e+01,  1.0045e+01, -6.8899e+00,\n",
      "         -5.6098e+00],\n",
      "        [-1.6492e+00,  3.0035e+00, -1.0023e+01, -1.7198e+00,  4.3316e+00,\n",
      "         -5.3018e+00, -7.7661e-01, -4.6752e+00,  6.6527e+00, -8.3328e+00,\n",
      "          6.9958e+00, -7.0081e+00,  1.0249e+01,  1.3587e+01, -5.4568e+00,\n",
      "         -8.8366e+00],\n",
      "        [ 8.3050e+00,  5.5745e+00,  2.6608e+00, -1.2787e+00,  3.9391e+00,\n",
      "          8.1201e+00,  4.9338e+00, -4.9052e-01,  5.9218e+00,  1.1690e+01,\n",
      "          8.6250e-01,  1.0427e+01, -6.8535e+00, -7.1324e+00,  1.3784e+01,\n",
      "         -1.7710e+00],\n",
      "        [ 2.8656e-01, -9.1347e+00,  1.0293e+01, -1.8425e+00, -6.4383e+00,\n",
      "          5.2493e+00, -5.9833e+00,  7.6485e+00, -6.9581e+00,  1.6889e+00,\n",
      "         -9.5072e+00,  5.1227e+00, -4.8321e+00, -7.8833e+00, -2.2450e+00,\n",
      "          1.3870e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.9091, 13.3422, 13.5834, 13.4779, 13.5202, 13.9398, 13.2054, 13.5999,\n",
      "        13.7560, 13.7466, 13.5843, 13.7648, 13.8598, 13.5870, 13.7837, 13.8696],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0988, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[-3.3916e+00, -3.1149e+00, -2.5603e+00,  9.7741e+00,  1.2456e+01,\n",
      "         -3.0499e+00, -2.0352e+00,  9.6557e+00,  3.6165e+00,  4.4819e+00,\n",
      "          7.4385e+00,  1.3308e+00, -3.2411e+00,  7.8880e+00,  8.4333e-02],\n",
      "        [-3.4116e-03, -1.7920e+00,  9.8476e-02,  1.8160e+00, -2.7154e+00,\n",
      "          6.0828e+00, -1.5517e+00,  6.4317e+00,  8.2878e+00,  1.9282e+00,\n",
      "          3.3968e+00, -3.2889e+00,  1.4770e+00,  8.7274e+00, -9.1726e+00],\n",
      "        [-2.9097e+00, -2.6368e+00, -2.2165e-01, -1.0362e+01,  2.3458e+00,\n",
      "         -3.5823e-01,  6.2501e+00, -7.7301e+00,  6.3839e+00, -1.1625e+01,\n",
      "          7.6780e+00, -1.0128e+01, -7.7641e+00,  1.1795e+00,  1.1542e+01],\n",
      "        [-7.5234e-01,  1.8869e-01,  1.5714e-01,  6.1892e-01, -3.7695e+00,\n",
      "          4.9373e+00, -1.0043e+01, -4.6177e+00, -9.2608e-01,  4.1461e+00,\n",
      "         -3.7917e+00, -4.3279e+00, -1.3760e+00, -9.8410e-01, -2.0508e+00],\n",
      "        [ 9.9342e+00,  3.8842e-01, -1.0882e+01, -1.0786e+00,  5.3799e+00,\n",
      "         -8.9670e-01, -4.6844e+00,  1.0156e+01, -1.7543e+00,  1.1307e+01,\n",
      "         -1.4863e+00,  7.7030e+00,  2.4528e+00,  4.5908e+00, -7.7660e+00],\n",
      "        [ 1.2414e+01, -5.6854e+00,  1.4581e+00, -4.7167e+00,  5.8520e+00,\n",
      "         -2.6922e+00,  1.2068e+00,  6.6702e+00,  4.8333e+00,  2.4790e-01,\n",
      "          9.9190e+00, -1.1301e+00, -5.9674e+00,  7.7012e+00,  4.4467e+00],\n",
      "        [-1.2084e+00,  7.4482e+00,  2.8145e+00,  3.6707e+00, -1.8675e+00,\n",
      "         -8.9810e-01, -6.2028e+00, -6.2880e-01,  6.0977e+00,  2.4882e+00,\n",
      "          3.6093e+00, -6.9051e+00, -9.9673e-01,  7.7882e+00, -4.9591e+00],\n",
      "        [-3.4850e+00, -1.6255e+00,  4.2854e+00, -9.2074e+00, -4.5840e+00,\n",
      "          2.8245e-01, -7.6399e+00, -1.3532e+00,  1.3784e+00, -8.6875e+00,\n",
      "          1.8162e+00,  1.4476e+00, -2.3885e+00, -2.5302e+00,  6.7763e+00],\n",
      "        [ 9.8903e+00,  3.2121e+00, -8.1524e+00, -5.1191e+00,  1.0298e+01,\n",
      "          6.7281e+00, -1.6185e+00, -2.2468e+00,  1.9142e+00,  6.4727e+00,\n",
      "          4.0223e+00,  5.5564e+00,  3.9324e+00,  6.5164e+00, -7.3435e+00],\n",
      "        [ 3.2628e+00,  6.9066e+00,  7.8398e+00, -5.3974e-01, -2.3806e+00,\n",
      "          4.6236e+00,  3.5632e+00,  3.3432e+00,  1.9404e+00, -5.7011e+00,\n",
      "          1.1274e+01, -1.0647e+01, -8.6094e+00,  1.1520e+01,  1.6049e+00],\n",
      "        [ 6.4003e+00,  1.6006e+00, -1.1955e+01,  1.4713e+00,  1.1942e+01,\n",
      "          1.1371e+00,  2.8201e+00, -8.5067e+00,  7.5077e+00, -4.4492e+00,\n",
      "         -5.2503e+00,  8.0193e+00,  5.5288e+00,  2.3283e+00, -1.0157e+01],\n",
      "        [ 7.4001e+00,  1.4084e+00,  7.4475e+00, -3.2007e+00, -6.1135e-01,\n",
      "          1.0072e+01,  1.3643e+00,  2.6651e+00,  4.4532e+00,  1.1356e+01,\n",
      "         -5.5317e+00, -8.4098e+00, -7.5230e+00,  1.0610e+01,  4.3934e+00],\n",
      "        [ 1.1101e+00, -3.1103e+00, -1.1706e+01, -4.3712e+00,  7.6961e+00,\n",
      "         -1.8006e+00, -5.0830e+00, -1.1299e+00,  5.6162e+00, -1.1090e+01,\n",
      "          8.2231e+00, -8.9338e+00,  1.0045e+01, -6.8899e+00, -5.6098e+00],\n",
      "        [-1.6492e+00,  3.0035e+00, -1.0023e+01, -1.7198e+00,  4.3316e+00,\n",
      "         -5.3018e+00, -7.7661e-01, -4.6752e+00,  6.6527e+00, -8.3328e+00,\n",
      "          6.9958e+00, -7.0081e+00,  1.0249e+01, -5.4568e+00, -8.8366e+00],\n",
      "        [ 8.3050e+00,  5.5745e+00,  2.6608e+00, -1.2787e+00,  3.9391e+00,\n",
      "          8.1201e+00,  4.9338e+00, -4.9052e-01,  5.9218e+00,  1.1690e+01,\n",
      "          8.6250e-01,  1.0427e+01, -6.8535e+00, -7.1324e+00, -1.7710e+00],\n",
      "        [ 2.8656e-01, -9.1347e+00,  1.0293e+01, -1.8425e+00, -6.4383e+00,\n",
      "          5.2493e+00, -5.9833e+00,  7.6485e+00, -6.9581e+00,  1.6889e+00,\n",
      "         -9.5072e+00,  5.1227e+00, -4.8321e+00, -7.8833e+00, -2.2450e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0064, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 2: 0.05260756239295006\n",
      "Batch 3/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0627, -0.0064,  0.1297,  ...,  0.0440,  0.0400,  0.0633],\n",
      "        [-0.0814,  0.0606,  0.0806,  ...,  0.0163,  0.3048, -0.0186],\n",
      "        [-0.0182, -0.0172, -0.1772,  ..., -0.0210, -0.0710, -0.1156],\n",
      "        ...,\n",
      "        [-0.0253, -0.0197,  0.0560,  ...,  0.1058,  0.0343, -0.0426],\n",
      "        [-0.0931,  0.0082, -0.0671,  ..., -0.0461,  0.2348, -0.0259],\n",
      "        [-0.0183, -0.0046,  0.0014,  ...,  0.0396,  0.0557, -0.0801]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0556, -0.0100,  0.1223,  ...,  0.0366,  0.1082,  0.0887],\n",
      "        [-0.0664,  0.0282,  0.0847,  ...,  0.0128,  0.3138, -0.0124],\n",
      "        [-0.0018, -0.0274, -0.1674,  ...,  0.0095, -0.1237, -0.0866],\n",
      "        ...,\n",
      "        [-0.0540, -0.0551,  0.0466,  ...,  0.0784, -0.0074, -0.0271],\n",
      "        [-0.0377, -0.0126, -0.1233,  ..., -0.0812,  0.2275, -0.0170],\n",
      "        [-0.0218, -0.0295,  0.0128,  ...,  0.0229,  0.0128, -0.0649]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.6158,   7.9401, -12.6091,   3.7553,   2.2713,  -0.1650,   1.8293,\n",
      "           8.4039,  -5.9244,   9.5281,   0.6149,  -1.1340,  10.8488,   1.6412,\n",
      "          -4.1168,  -0.6271],\n",
      "        [  8.8371,  13.8269,  -8.8683,  -6.1578,  -5.6681,  -4.8736,  -1.4349,\n",
      "          10.8720, -10.3553,   8.0627,   7.5849,   9.2996,   9.0685,  -1.6009,\n",
      "           3.7895,  -2.3022],\n",
      "        [-12.4086,  -7.7794,  13.5304,  -1.3380,   1.5380,   4.0875,  -0.7666,\n",
      "          -5.8817,   2.4951,  -8.7744,   1.6687,  -0.5692,  -7.5339,   2.3869,\n",
      "           8.0744,   4.8548],\n",
      "        [  1.9982,  -6.1087,  -0.3030,  13.6022,  13.1402,  11.6732,  -2.3989,\n",
      "           1.9297,  -0.9822,   3.2662,   0.8268, -12.1932,   1.5403,  10.2309,\n",
      "          -1.1440,   8.8840],\n",
      "        [  1.3754,  -5.1924,   1.0915,  12.2223,  13.3965,  13.1469,  -3.6216,\n",
      "           3.9991,  -3.8910,   3.8860,   3.8499, -11.1095,   2.1311,  12.4076,\n",
      "           2.4034,  11.3515],\n",
      "        [ -0.7213,  -3.9453,   2.9344,   9.8110,  11.7714,  13.3997,  -7.2330,\n",
      "           5.6514,  -5.7352,   4.7715,   7.5477,  -8.6344,   0.1338,  13.3904,\n",
      "           4.9783,  12.4280],\n",
      "        [  1.1433,  -1.1009,   0.1131,  -0.5395,  -1.0497,  -4.7869,  13.8691,\n",
      "          -6.0182,   3.1195,  -8.7193,  -8.8331,   0.8160,   5.8773,  -6.6879,\n",
      "           1.0561,  -4.9888],\n",
      "        [  9.8101,  10.2447,  -8.7024,   1.2032,   2.2024,   3.4369,  -6.1319,\n",
      "          13.8284, -11.8676,  12.1746,   9.9613,   2.2054,   8.3143,   6.4479,\n",
      "           3.2224,   4.8355],\n",
      "        [ -6.1738,  -8.7739,   5.1931,  -0.5047,  -2.7201,  -4.1977,   3.8102,\n",
      "         -12.0660,  13.8169,  -7.8408, -10.6017,  -2.1413,  -8.5378,  -6.7809,\n",
      "          -8.3765,  -7.3422],\n",
      "        [ 10.3445,   8.3978,  -9.9198,   2.3870,   2.1746,   2.9594,  -7.5908,\n",
      "          11.8638,  -8.4837,  13.6657,   8.0544,  -0.1906,   6.0205,   6.2223,\n",
      "          -2.2102,   3.1274],\n",
      "        [  1.3909,   7.2457,  -0.9417,  -1.4291,   1.1115,   4.3432,  -9.1976,\n",
      "          10.7317, -11.2075,   7.9700,  13.8397,   3.1495,   2.7086,   7.4052,\n",
      "           7.9435,   6.5049],\n",
      "        [  1.4371,  10.4227,  -2.1572, -11.6072, -10.6022,  -8.8886,   0.9459,\n",
      "           4.1999,  -5.2000,   0.4330,   4.0504,  13.5336,   3.5315,  -6.7869,\n",
      "           5.4485,  -5.9026],\n",
      "        [ 11.5123,   9.2929,  -9.7902,   2.2625,   2.4223,  -0.0825,   4.7854,\n",
      "           8.8021,  -9.0945,   5.7026,   2.8829,   1.2642,  13.7993,   1.4949,\n",
      "           2.7698,   0.1915],\n",
      "        [  2.6162,  -0.5354,  -0.0830,   8.0822,  10.2135,  12.0186,  -7.6995,\n",
      "           7.9466,  -7.2616,   7.8165,   9.0550,  -6.6510,   2.3752,  13.5804,\n",
      "           4.0149,  11.1178],\n",
      "        [ -2.5119,   4.6377,   4.0841,  -3.2036,   0.3865,   2.9785,  -1.5597,\n",
      "           6.2582,  -9.8772,  -0.7490,   9.5024,   5.2142,   3.7142,   3.9057,\n",
      "          13.5272,   5.7880],\n",
      "        [ -0.6308,  -2.1151,   2.9292,   6.9832,   9.7846,  12.0836,  -6.2596,\n",
      "           6.5196,  -8.1211,   4.5667,   8.4939,  -6.3493,   1.0679,  12.7416,\n",
      "           7.3161,  13.6786]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6158, 13.8269, 13.5304, 13.6022, 13.3965, 13.3997, 13.8691, 13.8284,\n",
      "        13.8169, 13.6657, 13.8397, 13.5336, 13.7993, 13.5804, 13.5272, 13.6786],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.2572, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  7.9401, -12.6091,   3.7553,   2.2713,  -0.1650,   1.8293,   8.4039,\n",
      "          -5.9244,   9.5281,   0.6149,  -1.1340,  10.8488,   1.6412,  -4.1168,\n",
      "          -0.6271],\n",
      "        [  8.8371,  -8.8683,  -6.1578,  -5.6681,  -4.8736,  -1.4349,  10.8720,\n",
      "         -10.3553,   8.0627,   7.5849,   9.2996,   9.0685,  -1.6009,   3.7895,\n",
      "          -2.3022],\n",
      "        [-12.4086,  -7.7794,  -1.3380,   1.5380,   4.0875,  -0.7666,  -5.8817,\n",
      "           2.4951,  -8.7744,   1.6687,  -0.5692,  -7.5339,   2.3869,   8.0744,\n",
      "           4.8548],\n",
      "        [  1.9982,  -6.1087,  -0.3030,  13.1402,  11.6732,  -2.3989,   1.9297,\n",
      "          -0.9822,   3.2662,   0.8268, -12.1932,   1.5403,  10.2309,  -1.1440,\n",
      "           8.8840],\n",
      "        [  1.3754,  -5.1924,   1.0915,  12.2223,  13.1469,  -3.6216,   3.9991,\n",
      "          -3.8910,   3.8860,   3.8499, -11.1095,   2.1311,  12.4076,   2.4034,\n",
      "          11.3515],\n",
      "        [ -0.7213,  -3.9453,   2.9344,   9.8110,  11.7714,  -7.2330,   5.6514,\n",
      "          -5.7352,   4.7715,   7.5477,  -8.6344,   0.1338,  13.3904,   4.9783,\n",
      "          12.4280],\n",
      "        [  1.1433,  -1.1009,   0.1131,  -0.5395,  -1.0497,  -4.7869,  -6.0182,\n",
      "           3.1195,  -8.7193,  -8.8331,   0.8160,   5.8773,  -6.6879,   1.0561,\n",
      "          -4.9888],\n",
      "        [  9.8101,  10.2447,  -8.7024,   1.2032,   2.2024,   3.4369,  -6.1319,\n",
      "         -11.8676,  12.1746,   9.9613,   2.2054,   8.3143,   6.4479,   3.2224,\n",
      "           4.8355],\n",
      "        [ -6.1738,  -8.7739,   5.1931,  -0.5047,  -2.7201,  -4.1977,   3.8102,\n",
      "         -12.0660,  -7.8408, -10.6017,  -2.1413,  -8.5378,  -6.7809,  -8.3765,\n",
      "          -7.3422],\n",
      "        [ 10.3445,   8.3978,  -9.9198,   2.3870,   2.1746,   2.9594,  -7.5908,\n",
      "          11.8638,  -8.4837,   8.0544,  -0.1906,   6.0205,   6.2223,  -2.2102,\n",
      "           3.1274],\n",
      "        [  1.3909,   7.2457,  -0.9417,  -1.4291,   1.1115,   4.3432,  -9.1976,\n",
      "          10.7317, -11.2075,   7.9700,   3.1495,   2.7086,   7.4052,   7.9435,\n",
      "           6.5049],\n",
      "        [  1.4371,  10.4227,  -2.1572, -11.6072, -10.6022,  -8.8886,   0.9459,\n",
      "           4.1999,  -5.2000,   0.4330,   4.0504,   3.5315,  -6.7869,   5.4485,\n",
      "          -5.9026],\n",
      "        [ 11.5123,   9.2929,  -9.7902,   2.2625,   2.4223,  -0.0825,   4.7854,\n",
      "           8.8021,  -9.0945,   5.7026,   2.8829,   1.2642,   1.4949,   2.7698,\n",
      "           0.1915],\n",
      "        [  2.6162,  -0.5354,  -0.0830,   8.0822,  10.2135,  12.0186,  -7.6995,\n",
      "           7.9466,  -7.2616,   7.8165,   9.0550,  -6.6510,   2.3752,   4.0149,\n",
      "          11.1178],\n",
      "        [ -2.5119,   4.6377,   4.0841,  -3.2036,   0.3865,   2.9785,  -1.5597,\n",
      "           6.2582,  -9.8772,  -0.7490,   9.5024,   5.2142,   3.7142,   3.9057,\n",
      "           5.7880],\n",
      "        [ -0.6308,  -2.1151,   2.9292,   6.9832,   9.7846,  12.0836,  -6.2596,\n",
      "           6.5196,  -8.1211,   4.5667,   8.4939,  -6.3493,   1.0679,  12.7416,\n",
      "           7.3161]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0144, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 3: 0.13577818870544434\n",
      "Batch 4/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.1543,  0.0223, -0.0486,  ..., -0.0005,  0.2185, -0.0500],\n",
      "        [-0.0802,  0.0581,  0.1182,  ...,  0.0388,  0.0707, -0.0158],\n",
      "        [ 0.2070, -0.0521, -0.0243,  ..., -0.0233, -0.1554,  0.0617],\n",
      "        ...,\n",
      "        [-0.0832,  0.0471,  0.1377,  ...,  0.0256,  0.0613,  0.0226],\n",
      "        [ 0.1638, -0.0469, -0.0456,  ..., -0.0230, -0.2849,  0.0398],\n",
      "        [ 0.0854, -0.0136,  0.0420,  ..., -0.0172,  0.1400,  0.0145]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.1185,  0.0171, -0.0818,  ..., -0.0137,  0.2549, -0.0485],\n",
      "        [-0.1648,  0.0390,  0.1277,  ...,  0.0420,  0.1071, -0.0790],\n",
      "        [ 0.2332, -0.0683, -0.0252,  ..., -0.0586, -0.1637,  0.0781],\n",
      "        ...,\n",
      "        [-0.0388,  0.0235,  0.1154,  ...,  0.0388,  0.0292,  0.0520],\n",
      "        [ 0.1761, -0.0390, -0.0604,  ..., -0.0246, -0.2595,  0.0306],\n",
      "        [ 0.0674, -0.0514, -0.0085,  ..., -0.0258,  0.1452,  0.0158]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.9080,   2.0211,  -8.6346,   3.5338,   6.2169,   0.8421,   2.3246,\n",
      "          -5.6836,  10.0012,   6.6962,  -3.8019,   1.1515,  13.5280,  -4.2611,\n",
      "         -12.2636,  -1.2699],\n",
      "        [  0.2516,  13.6214,  -8.1346,  -4.5157,   5.5353,  -9.5262,  -6.8690,\n",
      "          -8.1951,  -3.5975,   0.7095,  -8.3074,   9.9219,   3.7718,   8.7855,\n",
      "          -5.2328,   5.3187],\n",
      "        [ -6.8055,  -9.0527,  13.6310,   0.4268,  -8.6095,   6.6897,   7.1777,\n",
      "          12.2084,   0.0528,  -0.1995,   7.7847, -10.4023,  -8.3171,  -4.6054,\n",
      "           8.9615,   1.4935],\n",
      "        [  7.4014,  -3.4194,  -1.4028,  13.2127,   9.7063,  10.3406,   9.6943,\n",
      "          -2.6634,  10.3768,  -4.4962,  -2.2261,   1.0450,   7.0455,  -5.8636,\n",
      "          -1.8625,   0.7076],\n",
      "        [  8.4623,   6.0433,  -9.9885,   7.4443,  13.2732,   0.6992,   0.3863,\n",
      "         -10.9064,   5.2914,  -3.3844,  -8.8941,   9.6449,   9.8523,   1.7106,\n",
      "          -6.6427,   1.7409],\n",
      "        [  2.4979, -10.0559,   6.4873,  11.2741,   1.5861,  13.9449,  12.1745,\n",
      "           5.3439,   8.8950,  -3.5899,   4.3673,  -6.8863,   0.5273,  -9.5599,\n",
      "           3.6797,  -0.4642],\n",
      "        [  5.0347,  -6.1048,   5.4045,   9.9076,   1.8758,  11.2975,  13.7887,\n",
      "           5.0154,  12.0855,   0.6660,   2.4229,  -6.9431,   4.8864,  -7.9997,\n",
      "          -0.7258,   3.5848],\n",
      "        [ -3.0277,  -8.8722,  11.5136,  -0.7445,  -9.8210,   6.2761,   6.7907,\n",
      "          13.5538,   2.2075,   4.6895,  10.6937, -12.0761,  -5.5062,  -8.4781,\n",
      "           4.4795,  -2.8877],\n",
      "        [ 11.3779,  -2.6767,  -1.4647,   7.5543,   3.7823,   7.2380,  10.0732,\n",
      "           0.3377,  13.8048,   5.4098,  -0.2477,  -4.4962,  11.1458,  -7.5733,\n",
      "          -8.1646,   1.7271],\n",
      "        [  5.5735,   2.0355,  -1.4540,  -7.9315,  -7.2568,  -4.7566,  -1.2373,\n",
      "           4.2563,   3.2933,  13.7089,   4.3557,  -6.1678,   5.0682,  -3.5416,\n",
      "          -9.0166,  -1.9868],\n",
      "        [ -1.2866,  -6.3092,   6.1247,  -2.8347,  -9.9174,   2.7947,   2.2391,\n",
      "          11.5565,   0.8925,   7.0899,  13.4845,  -9.7322,  -3.9536,  -8.7210,\n",
      "           0.7203,  -8.7271],\n",
      "        [  1.6075,  10.5130, -10.4009,   1.2644,  10.8795,  -6.1696,  -6.6023,\n",
      "         -12.5436,  -3.1905,  -5.6661, -10.4071,  13.4923,   4.3306,   8.9500,\n",
      "          -3.1732,   3.2231],\n",
      "        [ 12.9403,   4.6451,  -9.2530,   2.8801,   6.4214,  -0.6711,   2.2718,\n",
      "          -6.5217,   9.9158,   6.6900,  -5.0436,   2.1396,  13.8952,  -2.0501,\n",
      "         -12.7073,   1.3908],\n",
      "        [ -3.4188,  10.5365,  -5.3868,  -6.2233,   2.7688, -10.7462,  -8.1643,\n",
      "          -8.3633,  -6.8110,  -1.8523,  -9.1125,   9.1235,   0.2997,  13.1306,\n",
      "          -0.8028,   7.8409],\n",
      "        [-11.5225,  -5.5840,   9.7743,   2.2336,  -2.5398,   4.3072,   1.7844,\n",
      "           4.8112,  -6.6510,  -9.9253,   2.2319,  -1.3044, -11.8648,   2.4583,\n",
      "          13.7800,   2.3634],\n",
      "        [ -1.8715,   4.2221,   2.1257,  -0.4264,   1.0694,  -1.1529,   3.3368,\n",
      "          -2.2070,   1.5870,  -1.0681,  -7.3005,   0.6476,   1.5352,   6.7143,\n",
      "           0.7700,  13.3214]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.9080, 13.6214, 13.6310, 13.2127, 13.2732, 13.9449, 13.7887, 13.5538,\n",
      "        13.8048, 13.7089, 13.4845, 13.4923, 13.8952, 13.1306, 13.7800, 13.3214],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1602, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  2.0211,  -8.6346,   3.5338,   6.2169,   0.8421,   2.3246,  -5.6836,\n",
      "          10.0012,   6.6962,  -3.8019,   1.1515,  13.5280,  -4.2611, -12.2636,\n",
      "          -1.2699],\n",
      "        [  0.2516,  -8.1346,  -4.5157,   5.5353,  -9.5262,  -6.8690,  -8.1951,\n",
      "          -3.5975,   0.7095,  -8.3074,   9.9219,   3.7718,   8.7855,  -5.2328,\n",
      "           5.3187],\n",
      "        [ -6.8055,  -9.0527,   0.4268,  -8.6095,   6.6897,   7.1777,  12.2084,\n",
      "           0.0528,  -0.1995,   7.7847, -10.4023,  -8.3171,  -4.6054,   8.9615,\n",
      "           1.4935],\n",
      "        [  7.4014,  -3.4194,  -1.4028,   9.7063,  10.3406,   9.6943,  -2.6634,\n",
      "          10.3768,  -4.4962,  -2.2261,   1.0450,   7.0455,  -5.8636,  -1.8625,\n",
      "           0.7076],\n",
      "        [  8.4623,   6.0433,  -9.9885,   7.4443,   0.6992,   0.3863, -10.9064,\n",
      "           5.2914,  -3.3844,  -8.8941,   9.6449,   9.8523,   1.7106,  -6.6427,\n",
      "           1.7409],\n",
      "        [  2.4979, -10.0559,   6.4873,  11.2741,   1.5861,  12.1745,   5.3439,\n",
      "           8.8950,  -3.5899,   4.3673,  -6.8863,   0.5273,  -9.5599,   3.6797,\n",
      "          -0.4642],\n",
      "        [  5.0347,  -6.1048,   5.4045,   9.9076,   1.8758,  11.2975,   5.0154,\n",
      "          12.0855,   0.6660,   2.4229,  -6.9431,   4.8864,  -7.9997,  -0.7258,\n",
      "           3.5848],\n",
      "        [ -3.0277,  -8.8722,  11.5136,  -0.7445,  -9.8210,   6.2761,   6.7907,\n",
      "           2.2075,   4.6895,  10.6937, -12.0761,  -5.5062,  -8.4781,   4.4795,\n",
      "          -2.8877],\n",
      "        [ 11.3779,  -2.6767,  -1.4647,   7.5543,   3.7823,   7.2380,  10.0732,\n",
      "           0.3377,   5.4098,  -0.2477,  -4.4962,  11.1458,  -7.5733,  -8.1646,\n",
      "           1.7271],\n",
      "        [  5.5735,   2.0355,  -1.4540,  -7.9315,  -7.2568,  -4.7566,  -1.2373,\n",
      "           4.2563,   3.2933,   4.3557,  -6.1678,   5.0682,  -3.5416,  -9.0166,\n",
      "          -1.9868],\n",
      "        [ -1.2866,  -6.3092,   6.1247,  -2.8347,  -9.9174,   2.7947,   2.2391,\n",
      "          11.5565,   0.8925,   7.0899,  -9.7322,  -3.9536,  -8.7210,   0.7203,\n",
      "          -8.7271],\n",
      "        [  1.6075,  10.5130, -10.4009,   1.2644,  10.8795,  -6.1696,  -6.6023,\n",
      "         -12.5436,  -3.1905,  -5.6661, -10.4071,   4.3306,   8.9500,  -3.1732,\n",
      "           3.2231],\n",
      "        [ 12.9403,   4.6451,  -9.2530,   2.8801,   6.4214,  -0.6711,   2.2718,\n",
      "          -6.5217,   9.9158,   6.6900,  -5.0436,   2.1396,  -2.0501, -12.7073,\n",
      "           1.3908],\n",
      "        [ -3.4188,  10.5365,  -5.3868,  -6.2233,   2.7688, -10.7462,  -8.1643,\n",
      "          -8.3633,  -6.8110,  -1.8523,  -9.1125,   9.1235,   0.2997,  -0.8028,\n",
      "           7.8409],\n",
      "        [-11.5225,  -5.5840,   9.7743,   2.2336,  -2.5398,   4.3072,   1.7844,\n",
      "           4.8112,  -6.6510,  -9.9253,   2.2319,  -1.3044, -11.8648,   2.4583,\n",
      "           2.3634],\n",
      "        [ -1.8715,   4.2221,   2.1257,  -0.4264,   1.0694,  -1.1529,   3.3368,\n",
      "          -2.2070,   1.5870,  -1.0681,  -7.3005,   0.6476,   1.5352,   6.7143,\n",
      "           0.7700]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0104, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 4: 0.08528868108987808\n",
      "Batch 5/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0369, -0.0046,  0.1048,  ...,  0.0850, -0.2240, -0.0173],\n",
      "        [ 0.1545, -0.0555,  0.1123,  ...,  0.0229, -0.1338,  0.0442],\n",
      "        [ 0.0593, -0.0220,  0.2107,  ...,  0.0820, -0.0999,  0.0212],\n",
      "        ...,\n",
      "        [ 0.1613, -0.0551,  0.0546,  ...,  0.0410, -0.1892,  0.0583],\n",
      "        [ 0.0173,  0.0010,  0.0190,  ..., -0.0526,  0.2294, -0.0084],\n",
      "        [ 0.0013,  0.0267,  0.0098,  ..., -0.0401,  0.2251,  0.0243]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0458, -0.0195,  0.1180,  ...,  0.0660, -0.2337, -0.0360],\n",
      "        [ 0.1133, -0.0428,  0.1008,  ...,  0.0372, -0.0649,  0.0546],\n",
      "        [ 0.0442, -0.0461,  0.1985,  ...,  0.0866, -0.1189, -0.0098],\n",
      "        ...,\n",
      "        [ 0.1514, -0.0476,  0.0161,  ...,  0.0387, -0.2403,  0.0868],\n",
      "        [-0.0011, -0.0011, -0.0023,  ..., -0.0649,  0.2293, -0.0206],\n",
      "        [ 0.0084,  0.0163,  0.0505,  ..., -0.0662,  0.2046,  0.0588]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.7340,   6.7640,   9.8397,   3.1013,  -6.8598,  -2.3182,  -1.2795,\n",
      "           5.1847,   1.6053,  -3.7226,  -8.5175, -10.0262,  -6.2887,   7.3702,\n",
      "          -7.0483,  -6.8019],\n",
      "        [  7.6171,  13.5580,  11.6663,  10.3073, -10.1077, -10.4389,  -6.6886,\n",
      "           4.4610,   0.7779, -10.8684,   1.3841, -10.4929, -11.8027,  10.0330,\n",
      "           1.6787,   2.4696],\n",
      "        [  9.5316,  12.1807,  13.7389,  11.0208,  -7.9966,  -5.1261,  -6.6421,\n",
      "           9.9453,   6.3014,  -6.0397,  -2.6798,  -8.3629,  -8.1319,   9.3234,\n",
      "           0.3982,   0.7438],\n",
      "        [  1.9489,  12.1121,   9.7604,  13.4295,  -8.0021,  -8.5062,  -4.7152,\n",
      "           7.3153,   2.8059,  -8.4482,   3.6238,  -3.7133,  -8.9871,   5.8754,\n",
      "           7.9706,   8.8129],\n",
      "        [ -7.1249, -10.0215,  -9.4172,  -8.3204,  13.6927,  10.2916,   1.6399,\n",
      "          -4.5132,   0.1211,  10.9929,   3.6137,   9.4510,  12.5528,  -9.1310,\n",
      "           0.9647,  -0.6416],\n",
      "        [ -4.7512, -10.8889,  -7.1365,  -6.6161,  10.0321,  12.9146,   6.6543,\n",
      "           0.7975,   3.5346,  13.1537,  -4.4869,  11.2308,  12.8990, -10.1232,\n",
      "          -0.4789,  -1.7687],\n",
      "        [ -4.4849,  -5.5038,  -6.7660,  -1.8393,   1.4446,   2.9258,  13.2737,\n",
      "          -3.2273,  -5.8327,   4.1772,  -4.3315,   8.8716,   4.2891, -11.1445,\n",
      "           4.8791,   4.8410],\n",
      "        [  4.8199,   6.0628,  10.0120,   9.4853,  -3.4031,   2.1236,  -3.8868,\n",
      "          13.6079,  10.9846,   0.8713,  -4.2931,  -0.3602,  -1.3946,   4.3841,\n",
      "           1.7625,   1.9295],\n",
      "        [  1.3218,   2.3089,   6.6832,   5.6845,   0.4804,   5.1160,  -6.4829,\n",
      "          11.8111,  13.6985,   4.3860,  -2.0757,   1.4137,   2.4101,   4.7413,\n",
      "          -0.4565,  -0.4305],\n",
      "        [ -5.1767, -10.2220,  -7.1061,  -6.3796,  10.3558,  12.4549,   5.8084,\n",
      "           0.3559,   4.2697,  13.5865,  -3.7190,  10.9806,  13.2457,  -9.4283,\n",
      "          -0.4490,  -1.7358],\n",
      "        [ -7.4903,   1.9975,  -3.7289,   1.5642,   3.2817,  -5.5950,  -4.9025,\n",
      "          -5.7844,  -4.9551,  -4.4851,  13.6039,   1.4577,  -1.6610,  -0.8722,\n",
      "           7.9184,   7.7585],\n",
      "        [-10.4712,  -8.2208,  -8.5661,  -2.3922,   8.5612,   8.0990,   7.2462,\n",
      "          -0.9039,   0.5251,   9.2870,   1.4309,  13.9098,  10.3626, -11.9598,\n",
      "           7.3568,   6.3769],\n",
      "        [ -7.4968, -10.8558,  -8.8158,  -6.8673,  11.9761,  12.1125,   5.2233,\n",
      "          -1.4399,   2.4594,  13.0595,  -0.6391,  12.2983,  13.7570, -10.8730,\n",
      "           1.6515,   0.0380],\n",
      "        [  8.7172,   9.1919,  10.3970,   5.5546,  -8.9395,  -7.3927,  -9.7840,\n",
      "           5.2207,   4.3891,  -8.7791,  -0.2295, -12.1598, -10.1669,  13.7548,\n",
      "          -5.6274,  -4.4123],\n",
      "        [ -7.7577,   4.2595,  -0.3527,   8.1300,   0.4761,  -3.6219,   1.0636,\n",
      "           0.9965,  -1.6192,  -2.3182,   7.7968,   6.5546,  -0.8848,  -5.0538,\n",
      "          13.8114,  13.4788],\n",
      "        [ -7.8775,   4.1288,  -0.6796,   8.4063,  -1.0439,  -4.6152,   2.1197,\n",
      "           0.9241,  -2.1118,  -3.1354,   7.1425,   6.2796,  -1.9295,  -4.7299,\n",
      "          13.4442,  13.6600]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7340, 13.5580, 13.7389, 13.4295, 13.6927, 12.9146, 13.2737, 13.6079,\n",
      "        13.6985, 13.5865, 13.6039, 13.9098, 13.7570, 13.7548, 13.8114, 13.6600],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.3377, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  6.7640,   9.8397,   3.1013,  -6.8598,  -2.3182,  -1.2795,   5.1847,\n",
      "           1.6053,  -3.7226,  -8.5175, -10.0262,  -6.2887,   7.3702,  -7.0483,\n",
      "          -6.8019],\n",
      "        [  7.6171,  11.6663,  10.3073, -10.1077, -10.4389,  -6.6886,   4.4610,\n",
      "           0.7779, -10.8684,   1.3841, -10.4929, -11.8027,  10.0330,   1.6787,\n",
      "           2.4696],\n",
      "        [  9.5316,  12.1807,  11.0208,  -7.9966,  -5.1261,  -6.6421,   9.9453,\n",
      "           6.3014,  -6.0397,  -2.6798,  -8.3629,  -8.1319,   9.3234,   0.3982,\n",
      "           0.7438],\n",
      "        [  1.9489,  12.1121,   9.7604,  -8.0021,  -8.5062,  -4.7152,   7.3153,\n",
      "           2.8059,  -8.4482,   3.6238,  -3.7133,  -8.9871,   5.8754,   7.9706,\n",
      "           8.8129],\n",
      "        [ -7.1249, -10.0215,  -9.4172,  -8.3204,  10.2916,   1.6399,  -4.5132,\n",
      "           0.1211,  10.9929,   3.6137,   9.4510,  12.5528,  -9.1310,   0.9647,\n",
      "          -0.6416],\n",
      "        [ -4.7512, -10.8889,  -7.1365,  -6.6161,  10.0321,   6.6543,   0.7975,\n",
      "           3.5346,  13.1537,  -4.4869,  11.2308,  12.8990, -10.1232,  -0.4789,\n",
      "          -1.7687],\n",
      "        [ -4.4849,  -5.5038,  -6.7660,  -1.8393,   1.4446,   2.9258,  -3.2273,\n",
      "          -5.8327,   4.1772,  -4.3315,   8.8716,   4.2891, -11.1445,   4.8791,\n",
      "           4.8410],\n",
      "        [  4.8199,   6.0628,  10.0120,   9.4853,  -3.4031,   2.1236,  -3.8868,\n",
      "          10.9846,   0.8713,  -4.2931,  -0.3602,  -1.3946,   4.3841,   1.7625,\n",
      "           1.9295],\n",
      "        [  1.3218,   2.3089,   6.6832,   5.6845,   0.4804,   5.1160,  -6.4829,\n",
      "          11.8111,   4.3860,  -2.0757,   1.4137,   2.4101,   4.7413,  -0.4565,\n",
      "          -0.4305],\n",
      "        [ -5.1767, -10.2220,  -7.1061,  -6.3796,  10.3558,  12.4549,   5.8084,\n",
      "           0.3559,   4.2697,  -3.7190,  10.9806,  13.2457,  -9.4283,  -0.4490,\n",
      "          -1.7358],\n",
      "        [ -7.4903,   1.9975,  -3.7289,   1.5642,   3.2817,  -5.5950,  -4.9025,\n",
      "          -5.7844,  -4.9551,  -4.4851,   1.4577,  -1.6610,  -0.8722,   7.9184,\n",
      "           7.7585],\n",
      "        [-10.4712,  -8.2208,  -8.5661,  -2.3922,   8.5612,   8.0990,   7.2462,\n",
      "          -0.9039,   0.5251,   9.2870,   1.4309,  10.3626, -11.9598,   7.3568,\n",
      "           6.3769],\n",
      "        [ -7.4968, -10.8558,  -8.8158,  -6.8673,  11.9761,  12.1125,   5.2233,\n",
      "          -1.4399,   2.4594,  13.0595,  -0.6391,  12.2983, -10.8730,   1.6515,\n",
      "           0.0380],\n",
      "        [  8.7172,   9.1919,  10.3970,   5.5546,  -8.9395,  -7.3927,  -9.7840,\n",
      "           5.2207,   4.3891,  -8.7791,  -0.2295, -12.1598, -10.1669,  -5.6274,\n",
      "          -4.4123],\n",
      "        [ -7.7577,   4.2595,  -0.3527,   8.1300,   0.4761,  -3.6219,   1.0636,\n",
      "           0.9965,  -1.6192,  -2.3182,   7.7968,   6.5546,  -0.8848,  -5.0538,\n",
      "          13.4788],\n",
      "        [ -7.8775,   4.1288,  -0.6796,   8.4063,  -1.0439,  -4.6152,   2.1197,\n",
      "           0.9241,  -2.1118,  -3.1354,   7.1425,   6.2796,  -1.9295,  -4.7299,\n",
      "          13.4442]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0192, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 5: 0.17846599221229553\n",
      "Batch 6/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.0543,  0.0490,  0.1472,  ...,  0.0281,  0.1006,  0.0664],\n",
      "        [-0.0841,  0.0499,  0.1658,  ...,  0.0876, -0.0896, -0.0368],\n",
      "        [-0.1481, -0.0239, -0.0811,  ...,  0.0308,  0.2136, -0.0847],\n",
      "        ...,\n",
      "        [-0.0194,  0.0315, -0.1715,  ..., -0.0759,  0.1421, -0.0180],\n",
      "        [-0.1630,  0.0367,  0.0976,  ...,  0.0731,  0.1681, -0.0337],\n",
      "        [-0.0802,  0.0021, -0.0167,  ...,  0.0578,  0.2223, -0.0142]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0809,  0.0281,  0.1909,  ...,  0.0207,  0.1239,  0.0760],\n",
      "        [-0.0801,  0.0467,  0.1623,  ...,  0.0527, -0.1641, -0.0555],\n",
      "        [-0.1273,  0.0128, -0.0796,  ...,  0.0418,  0.2525, -0.0842],\n",
      "        ...,\n",
      "        [-0.0234, -0.0122, -0.1620,  ..., -0.1197,  0.0756,  0.0297],\n",
      "        [-0.1637,  0.0067,  0.0934,  ...,  0.0797,  0.0993, -0.0377],\n",
      "        [-0.1060, -0.0268,  0.0179,  ...,  0.0236,  0.2711, -0.0697]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.4732,  -2.5297,  -2.6679,  -1.5947,  -3.5066,  -6.0804,   2.5165,\n",
      "          -7.9980,  -4.1613,  12.0314,   7.8679,   0.6186,   1.1799,  -2.1158,\n",
      "          10.9717,   2.1296],\n",
      "        [ -1.2127,  13.5820,  -1.3530,   1.5312,   6.7027,   1.5782,   7.6512,\n",
      "          -6.0539,  -1.6399,   1.6701,   0.6808,   5.2183,   3.8248,  -8.8827,\n",
      "          -0.3183,  -0.9612],\n",
      "        [ -1.3081,  -4.1341,  13.5715,  -7.8425,  10.3147,  11.8451,  -0.9564,\n",
      "          -2.3927, -10.8689,  -4.4647,   9.1829, -10.3813,  11.9928,   6.7850,\n",
      "           2.7464,  10.0358],\n",
      "        [  0.5961,   2.7313,  -7.2108,  13.7466,  -8.1323,  -9.7216,   2.8612,\n",
      "           2.3678,   6.5675,  -0.0623,  -9.3655,   7.5561,  -9.1704,  -0.0494,\n",
      "           0.1550, -10.9147],\n",
      "        [ -2.1366,   3.3996,  10.4972,  -7.8573,  13.8580,  11.2212,   0.8075,\n",
      "          -2.7943, -10.5410,  -2.2100,   8.7972,  -8.8232,  11.7862,   2.3913,\n",
      "           2.5055,   7.1211],\n",
      "        [ -4.8273,   0.0412,  11.5213,  -9.9000,  12.4224,  13.6841,   0.2501,\n",
      "          -1.6394,  -8.8279,  -5.0218,   7.5324,  -8.3581,  11.4593,   2.7204,\n",
      "          -1.4909,   9.9733],\n",
      "        [  2.1253,   7.0597,   2.4501,  -1.5859,   5.7354,   4.4244,  11.9922,\n",
      "         -10.5600,  -5.7474,   3.1668,   4.0353,   4.8399,   6.4123,  -8.2592,\n",
      "           1.7207,   6.0265],\n",
      "        [ -7.1919,  -4.3269,  -0.2113,  -0.6306,  -0.0529,   1.5538,  -8.7906,\n",
      "          12.9532,   4.5068,  -6.7322,  -4.5072,  -6.5630,  -4.8226,   8.8091,\n",
      "          -6.1137,  -4.8290],\n",
      "        [ -5.2637,   0.4748, -10.2676,   6.3236, -10.1863,  -7.6498,  -3.5620,\n",
      "           7.4194,  13.8948,  -2.6523, -11.2145,   8.5068, -11.5628,  -3.0804,\n",
      "          -8.8438,  -7.5346],\n",
      "        [ 12.3955,   0.1919,  -5.9484,   0.4704,  -4.4154,  -8.3432,   2.6609,\n",
      "          -7.3847,  -1.5194,  13.6115,   4.8744,   3.5727,  -1.5839,  -4.9075,\n",
      "          10.2701,  -0.5294],\n",
      "        [  8.0998,  -2.6799,   7.6352,  -9.9420,   7.1667,   5.5631,   0.2886,\n",
      "          -7.7540, -10.9675,   6.0533,  13.9237,  -7.5857,  11.0537,   1.4022,\n",
      "           8.9574,  10.0142],\n",
      "        [ -0.7335,   5.9871,  -9.0138,   8.1677,  -7.8966,  -7.4159,   5.9592,\n",
      "          -3.3775,   8.6920,   1.7544,  -8.1399,  13.7615,  -6.9891,  -9.9519,\n",
      "          -4.1019,  -4.1745],\n",
      "        [  2.2891,   0.3697,  11.1170,  -9.2938,  10.6750,  10.1772,   1.9540,\n",
      "          -7.9084, -11.3958,   0.3173,  12.1668,  -6.9321,  13.8779,   0.6360,\n",
      "           4.8565,  11.5261],\n",
      "        [  0.2801,  -9.2184,   7.1834,  -2.1845,   2.2470,   3.5179,  -7.0089,\n",
      "           6.4883,  -4.7708,  -3.6884,   3.6115, -11.7281,   2.2072,  13.5113,\n",
      "           3.0817,   0.4755],\n",
      "        [ 11.9991,  -2.1617,   3.1368,  -2.8030,   2.7375,  -1.5281,   1.6791,\n",
      "          -7.7001,  -9.5528,  10.2382,  10.4510,  -4.5485,   5.7895,   1.4050,\n",
      "          13.6119,   3.5920],\n",
      "        [  1.2648,  -4.4636,   9.1332, -11.2136,   6.2841,   9.5527,   0.0670,\n",
      "          -6.4338,  -7.8340,   0.3706,   9.9716,  -4.9118,  10.7228,  -0.3829,\n",
      "           1.8701,  13.6651]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.4732, 13.5820, 13.5715, 13.7466, 13.8580, 13.6841, 11.9922, 12.9532,\n",
      "        13.8948, 13.6115, 13.9237, 13.7615, 13.8779, 13.5113, 13.6119, 13.6651],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1513, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ -2.5297,  -2.6679,  -1.5947,  -3.5066,  -6.0804,   2.5165,  -7.9980,\n",
      "          -4.1613,  12.0314,   7.8679,   0.6186,   1.1799,  -2.1158,  10.9717,\n",
      "           2.1296],\n",
      "        [ -1.2127,  -1.3530,   1.5312,   6.7027,   1.5782,   7.6512,  -6.0539,\n",
      "          -1.6399,   1.6701,   0.6808,   5.2183,   3.8248,  -8.8827,  -0.3183,\n",
      "          -0.9612],\n",
      "        [ -1.3081,  -4.1341,  -7.8425,  10.3147,  11.8451,  -0.9564,  -2.3927,\n",
      "         -10.8689,  -4.4647,   9.1829, -10.3813,  11.9928,   6.7850,   2.7464,\n",
      "          10.0358],\n",
      "        [  0.5961,   2.7313,  -7.2108,  -8.1323,  -9.7216,   2.8612,   2.3678,\n",
      "           6.5675,  -0.0623,  -9.3655,   7.5561,  -9.1704,  -0.0494,   0.1550,\n",
      "         -10.9147],\n",
      "        [ -2.1366,   3.3996,  10.4972,  -7.8573,  11.2212,   0.8075,  -2.7943,\n",
      "         -10.5410,  -2.2100,   8.7972,  -8.8232,  11.7862,   2.3913,   2.5055,\n",
      "           7.1211],\n",
      "        [ -4.8273,   0.0412,  11.5213,  -9.9000,  12.4224,   0.2501,  -1.6394,\n",
      "          -8.8279,  -5.0218,   7.5324,  -8.3581,  11.4593,   2.7204,  -1.4909,\n",
      "           9.9733],\n",
      "        [  2.1253,   7.0597,   2.4501,  -1.5859,   5.7354,   4.4244, -10.5600,\n",
      "          -5.7474,   3.1668,   4.0353,   4.8399,   6.4123,  -8.2592,   1.7207,\n",
      "           6.0265],\n",
      "        [ -7.1919,  -4.3269,  -0.2113,  -0.6306,  -0.0529,   1.5538,  -8.7906,\n",
      "           4.5068,  -6.7322,  -4.5072,  -6.5630,  -4.8226,   8.8091,  -6.1137,\n",
      "          -4.8290],\n",
      "        [ -5.2637,   0.4748, -10.2676,   6.3236, -10.1863,  -7.6498,  -3.5620,\n",
      "           7.4194,  -2.6523, -11.2145,   8.5068, -11.5628,  -3.0804,  -8.8438,\n",
      "          -7.5346],\n",
      "        [ 12.3955,   0.1919,  -5.9484,   0.4704,  -4.4154,  -8.3432,   2.6609,\n",
      "          -7.3847,  -1.5194,   4.8744,   3.5727,  -1.5839,  -4.9075,  10.2701,\n",
      "          -0.5294],\n",
      "        [  8.0998,  -2.6799,   7.6352,  -9.9420,   7.1667,   5.5631,   0.2886,\n",
      "          -7.7540, -10.9675,   6.0533,  -7.5857,  11.0537,   1.4022,   8.9574,\n",
      "          10.0142],\n",
      "        [ -0.7335,   5.9871,  -9.0138,   8.1677,  -7.8966,  -7.4159,   5.9592,\n",
      "          -3.3775,   8.6920,   1.7544,  -8.1399,  -6.9891,  -9.9519,  -4.1019,\n",
      "          -4.1745],\n",
      "        [  2.2891,   0.3697,  11.1170,  -9.2938,  10.6750,  10.1772,   1.9540,\n",
      "          -7.9084, -11.3958,   0.3173,  12.1668,  -6.9321,   0.6360,   4.8565,\n",
      "          11.5261],\n",
      "        [  0.2801,  -9.2184,   7.1834,  -2.1845,   2.2470,   3.5179,  -7.0089,\n",
      "           6.4883,  -4.7708,  -3.6884,   3.6115, -11.7281,   2.2072,   3.0817,\n",
      "           0.4755],\n",
      "        [ 11.9991,  -2.1617,   3.1368,  -2.8030,   2.7375,  -1.5281,   1.6791,\n",
      "          -7.7001,  -9.5528,  10.2382,  10.4510,  -4.5485,   5.7895,   1.4050,\n",
      "           3.5920],\n",
      "        [  1.2648,  -4.4636,   9.1332, -11.2136,   6.2841,   9.5527,   0.0670,\n",
      "          -6.4338,  -7.8340,   0.3706,   9.9716,  -4.9118,  10.7228,  -0.3829,\n",
      "           1.8701]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0093, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 6: 0.08029883354902267\n",
      "Batch 7/7: Matrix features: torch.Size([4, 128]), Vector features: torch.Size([4, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1779, -0.0646, -0.0683, -0.0121, -0.1077,  0.0298,  0.0336, -0.1227,\n",
      "          0.0400, -0.0697,  0.0808, -0.0020, -0.0534,  0.0365, -0.0513,  0.1494,\n",
      "          0.0069,  0.0163,  0.0548, -0.0086,  0.0068, -0.0841,  0.0012, -0.1250,\n",
      "         -0.1182,  0.0078,  0.0068, -0.0132, -0.1256,  0.0762, -0.0705, -0.0584,\n",
      "          0.1709,  0.0357, -0.0015,  0.0554,  0.1250,  0.0153, -0.1932, -0.1688,\n",
      "          0.0503,  0.1218, -0.1628, -0.1130, -0.0083,  0.0479,  0.0350, -0.0109,\n",
      "         -0.0339,  0.1049, -0.0688,  0.0747,  0.0538, -0.0440,  0.0622, -0.0374,\n",
      "          0.0017, -0.0252,  0.0087,  0.0269, -0.0024, -0.0153, -0.0057, -0.1461,\n",
      "          0.2746, -0.0535, -0.0774,  0.0266,  0.0440, -0.0839, -0.0499,  0.1354,\n",
      "         -0.0796,  0.1782,  0.0042,  0.1157,  0.0162, -0.1534,  0.0628,  0.0202,\n",
      "         -0.0350, -0.0336, -0.0845,  0.0891,  0.1361,  0.1549,  0.0053, -0.0392,\n",
      "          0.0904, -0.1238,  0.0692,  0.0501,  0.1107,  0.1182,  0.0363, -0.0943,\n",
      "          0.0806,  0.1150,  0.0911,  0.0031, -0.1788,  0.0349, -0.0141,  0.0238,\n",
      "          0.0406,  0.1081,  0.0350, -0.0062, -0.0481, -0.1476, -0.0907, -0.0465,\n",
      "         -0.2162, -0.0460, -0.0265, -0.0873,  0.0696,  0.0130,  0.0617,  0.1084,\n",
      "         -0.0708, -0.0456,  0.0020,  0.0736,  0.0528, -0.0304, -0.2411,  0.0250],\n",
      "        [-0.0173,  0.0023, -0.1741, -0.0645, -0.0525, -0.1925,  0.0260, -0.0505,\n",
      "         -0.0328, -0.1085,  0.0737, -0.0551, -0.0572,  0.0717,  0.0209,  0.0411,\n",
      "          0.0984,  0.1776,  0.1192, -0.1515, -0.1170,  0.0117, -0.0318,  0.0226,\n",
      "          0.1613, -0.0702,  0.0237, -0.0802,  0.0772, -0.0141,  0.0448,  0.1031,\n",
      "          0.0371, -0.2384,  0.0304,  0.1308, -0.0572,  0.0353, -0.0080, -0.2014,\n",
      "         -0.0928, -0.0338, -0.0128, -0.0278,  0.0147,  0.1193, -0.0242,  0.0885,\n",
      "          0.0054,  0.0491, -0.1065,  0.1130,  0.0756, -0.1845, -0.0068,  0.0231,\n",
      "         -0.0453, -0.0788, -0.1048,  0.0679,  0.0993, -0.0675, -0.0265,  0.0593,\n",
      "         -0.0363,  0.0444,  0.0527,  0.1107,  0.0625, -0.1131,  0.0710,  0.0698,\n",
      "          0.0286, -0.1038,  0.0616,  0.0503,  0.0936,  0.0811, -0.0769,  0.0996,\n",
      "         -0.1471,  0.0420, -0.1364, -0.1057,  0.0503,  0.0993, -0.1061,  0.0139,\n",
      "          0.2025, -0.1380,  0.0315,  0.0622,  0.0254,  0.0283, -0.0415, -0.0521,\n",
      "          0.0626, -0.0741, -0.0552,  0.0093, -0.0154,  0.0699,  0.0726,  0.0077,\n",
      "         -0.0250,  0.0745,  0.1209, -0.0457,  0.0088,  0.0909,  0.0489, -0.0843,\n",
      "          0.0640, -0.0247,  0.1672,  0.0090,  0.1331, -0.0437,  0.0389, -0.0262,\n",
      "          0.1594, -0.0954, -0.0858,  0.0991, -0.1937, -0.0204, -0.1437, -0.0713],\n",
      "        [-0.1587,  0.0662,  0.1864,  0.0622, -0.0128, -0.0100,  0.0328, -0.0303,\n",
      "         -0.1333, -0.0864, -0.1384,  0.0781,  0.0444,  0.0950, -0.1727, -0.1053,\n",
      "          0.1049, -0.0088, -0.0149,  0.0684, -0.0451,  0.0642, -0.1023,  0.1169,\n",
      "         -0.1296,  0.2007, -0.0801,  0.0018, -0.0061,  0.0639,  0.2085,  0.0045,\n",
      "         -0.0712, -0.0558,  0.0660, -0.0145, -0.0825,  0.1775,  0.0725,  0.1150,\n",
      "         -0.0435, -0.0725,  0.1667,  0.0192,  0.0480,  0.0077,  0.0718, -0.0233,\n",
      "         -0.1093, -0.1046,  0.0864, -0.0883,  0.0060,  0.0206,  0.1475,  0.0621,\n",
      "          0.0312, -0.0077,  0.0661, -0.1200, -0.1104,  0.0715, -0.0554,  0.1175,\n",
      "         -0.0679, -0.1644,  0.0633,  0.0263, -0.0447, -0.0348, -0.0285, -0.0529,\n",
      "         -0.0349, -0.1373,  0.0475, -0.0903, -0.0153,  0.1057,  0.0561,  0.0512,\n",
      "          0.0890,  0.0601,  0.0394, -0.0014, -0.0180, -0.2180,  0.0583,  0.0718,\n",
      "         -0.2190, -0.0508, -0.1523, -0.0141,  0.0140, -0.0772, -0.0131,  0.0739,\n",
      "          0.0931,  0.0917, -0.1760,  0.0555,  0.1335,  0.0312, -0.0624, -0.1211,\n",
      "         -0.0954, -0.0566,  0.0244,  0.1000, -0.0685,  0.0641,  0.0315, -0.0027,\n",
      "          0.0421,  0.0373, -0.0396, -0.0728, -0.1358, -0.0597,  0.0058,  0.0807,\n",
      "          0.0023,  0.0388,  0.0884, -0.0165,  0.0851,  0.0887,  0.0140, -0.0894],\n",
      "        [-0.1222,  0.0461,  0.1797,  0.0042,  0.0666,  0.0944,  0.0454, -0.0062,\n",
      "         -0.0917, -0.0462, -0.0746,  0.1112,  0.0496,  0.1054, -0.0936, -0.1909,\n",
      "          0.0602,  0.0153, -0.0658,  0.0141,  0.1016,  0.1168, -0.0497,  0.0703,\n",
      "         -0.0934,  0.2460, -0.0347,  0.0122, -0.1084,  0.0846,  0.1207,  0.0706,\n",
      "         -0.0436, -0.0035,  0.0624,  0.0105, -0.0886,  0.2072,  0.0724,  0.1192,\n",
      "          0.0127, -0.0503,  0.0711, -0.0289,  0.0463, -0.0593,  0.1169, -0.0133,\n",
      "         -0.1131, -0.1797,  0.0622, -0.0824, -0.0547,  0.0800,  0.1506,  0.0684,\n",
      "          0.0033,  0.0519,  0.0863, -0.1409, -0.0481,  0.1144, -0.0707,  0.0643,\n",
      "          0.0437, -0.1159,  0.0447, -0.0133,  0.0285, -0.0943, -0.0753, -0.0418,\n",
      "         -0.0356, -0.1184,  0.0121, -0.1062, -0.0234,  0.0442,  0.0933,  0.0476,\n",
      "          0.0697, -0.0546, -0.0325,  0.0395, -0.0526, -0.2052,  0.0552,  0.0229,\n",
      "         -0.2066,  0.0555, -0.1082, -0.0424, -0.0202, -0.1641, -0.0197,  0.1194,\n",
      "          0.0795,  0.1520, -0.1318,  0.0888,  0.1212, -0.0423, -0.0685, -0.0761,\n",
      "         -0.1344, -0.1446,  0.0259,  0.0058, -0.0859,  0.0327,  0.0339, -0.0280,\n",
      "         -0.0364,  0.0242, -0.0917, -0.0580, -0.0904, -0.0536, -0.0367, -0.0162,\n",
      "         -0.0114,  0.0915,  0.0777, -0.1004,  0.1248,  0.1111,  0.0434, -0.0218]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1081, -0.0659, -0.0677, -0.0331, -0.1028,  0.0525,  0.0593, -0.0862,\n",
      "          0.0200, -0.0275,  0.1279,  0.0049, -0.0694,  0.0192, -0.0888,  0.1359,\n",
      "         -0.0280,  0.0172,  0.0656, -0.0073,  0.0114, -0.0728, -0.0274, -0.1217,\n",
      "         -0.0726,  0.0259, -0.0418, -0.0368, -0.1487,  0.0457, -0.0548, -0.0492,\n",
      "          0.1907,  0.0107,  0.0008,  0.0157,  0.0895,  0.0218, -0.1909, -0.2064,\n",
      "          0.0503,  0.1106, -0.1445, -0.1434, -0.0508,  0.0457,  0.0522, -0.0474,\n",
      "         -0.0602,  0.1056, -0.0873,  0.0334,  0.0441, -0.0279,  0.0504, -0.0439,\n",
      "          0.0060,  0.0308, -0.0111, -0.0026, -0.0255,  0.0133,  0.0275, -0.1098,\n",
      "          0.2598, -0.0114, -0.1038,  0.0204,  0.0606, -0.0959, -0.1072,  0.1293,\n",
      "         -0.1000,  0.1784, -0.0545,  0.1795,  0.0344, -0.1592,  0.0672,  0.0163,\n",
      "          0.0332, -0.0076, -0.0598,  0.1666,  0.1066,  0.1489,  0.0391, -0.0774,\n",
      "          0.1217, -0.0961,  0.0964,  0.0504,  0.1057,  0.1121,  0.0607, -0.1364,\n",
      "          0.0636,  0.1477,  0.0795, -0.0187, -0.2053,  0.0577, -0.0426,  0.0731,\n",
      "          0.0106,  0.0989,  0.0294,  0.0029, -0.0209, -0.1183, -0.0748, -0.0312,\n",
      "         -0.2195,  0.0121, -0.0433, -0.1086,  0.0688, -0.0004,  0.0237,  0.0813,\n",
      "         -0.0528, -0.0861,  0.0358,  0.0799,  0.0617, -0.0360, -0.0824, -0.0027],\n",
      "        [-0.0064, -0.0219, -0.1576, -0.0643, -0.0825, -0.1246,  0.0332, -0.1044,\n",
      "         -0.0285, -0.0987,  0.0823, -0.0936, -0.0449,  0.0724,  0.0193,  0.0655,\n",
      "          0.0820,  0.2252,  0.1167, -0.1865, -0.1286, -0.0127, -0.0262,  0.0075,\n",
      "          0.1733, -0.1406,  0.0167, -0.0578,  0.0451, -0.0215,  0.0093,  0.1220,\n",
      "          0.0492, -0.2092,  0.0583,  0.1076, -0.0519, -0.0208, -0.0348, -0.2007,\n",
      "         -0.0932, -0.0253, -0.0246,  0.0244,  0.0130,  0.1421, -0.0400,  0.0823,\n",
      "          0.0049,  0.0914, -0.0888,  0.0711,  0.0647, -0.1064, -0.0082,  0.0014,\n",
      "         -0.0523, -0.0552, -0.1533,  0.0749,  0.0812, -0.0733,  0.0150,  0.0532,\n",
      "         -0.0365,  0.0647,  0.0271,  0.1039,  0.0985, -0.1229,  0.0658,  0.0759,\n",
      "          0.0734, -0.0641,  0.0438,  0.0856,  0.0710,  0.0956, -0.0470,  0.0999,\n",
      "         -0.0969,  0.0486, -0.1288, -0.0744,  0.0643,  0.1588, -0.0974, -0.0105,\n",
      "          0.2180, -0.0674,  0.0697,  0.0502,  0.0259,  0.0182, -0.0485, -0.0553,\n",
      "          0.0693, -0.0504, -0.0399,  0.0049, -0.0475,  0.0792,  0.0290,  0.0113,\n",
      "         -0.0243,  0.1094,  0.0808, -0.0458,  0.0374,  0.0842,  0.0099, -0.0646,\n",
      "          0.0261, -0.0926,  0.1590, -0.0533,  0.1473, -0.0241,  0.0291, -0.0486,\n",
      "          0.1352, -0.1456, -0.1110,  0.0873, -0.1814, -0.0513, -0.1552, -0.0451],\n",
      "        [-0.1769,  0.0630,  0.1823,  0.0432, -0.0250, -0.0343,  0.0363, -0.0754,\n",
      "         -0.1445, -0.0955, -0.1455,  0.0869,  0.0933,  0.0479, -0.1652, -0.0726,\n",
      "          0.0987, -0.0220, -0.0202,  0.0464, -0.0775,  0.0347, -0.0909,  0.0666,\n",
      "         -0.1532,  0.1558, -0.0659,  0.0193, -0.0232,  0.1084,  0.1941,  0.0513,\n",
      "         -0.0128, -0.0784,  0.0943, -0.0143, -0.0917,  0.2066,  0.0456,  0.0961,\n",
      "         -0.1041, -0.0710,  0.1719,  0.0182,  0.0542,  0.0721,  0.0162, -0.0280,\n",
      "         -0.1387, -0.0517,  0.0736, -0.0966,  0.0105,  0.0464,  0.2038,  0.0568,\n",
      "          0.0065, -0.0348,  0.0506, -0.0962, -0.1472,  0.0521, -0.0442,  0.1214,\n",
      "         -0.0080, -0.1334,  0.0734,  0.0168, -0.0235, -0.0919, -0.0506, -0.0080,\n",
      "          0.0095, -0.1345,  0.0579, -0.0307, -0.0316,  0.1032,  0.0549,  0.0562,\n",
      "          0.1182,  0.0878,  0.0184,  0.0254, -0.0116, -0.2265,  0.0170,  0.1024,\n",
      "         -0.1416, -0.0591, -0.1426, -0.0030,  0.0600, -0.0663,  0.0104,  0.0533,\n",
      "          0.0971,  0.0896, -0.1643,  0.0545,  0.1127,  0.0315, -0.1149, -0.1354,\n",
      "         -0.0721, -0.0640,  0.0177,  0.1019, -0.1172,  0.0725,  0.0055,  0.0092,\n",
      "          0.0339,  0.0258, -0.0107, -0.1175, -0.1384, -0.0420,  0.0374,  0.0503,\n",
      "          0.0081,  0.0335,  0.0453,  0.0526,  0.0747,  0.0779, -0.0262, -0.0659],\n",
      "        [-0.1673,  0.0264,  0.1613, -0.0122,  0.0684,  0.0970,  0.0515, -0.0284,\n",
      "         -0.1093, -0.0328, -0.0927,  0.1148,  0.0712,  0.0921, -0.0678, -0.2164,\n",
      "          0.0709,  0.0232, -0.0500, -0.0124,  0.0511,  0.0978, -0.0732,  0.0808,\n",
      "         -0.0390,  0.2232, -0.0433,  0.0313, -0.1006,  0.0957,  0.1108,  0.0746,\n",
      "         -0.0080, -0.0098,  0.0584, -0.0049, -0.1073,  0.2481,  0.1036,  0.1094,\n",
      "         -0.0200, -0.0506,  0.0723, -0.0244,  0.0744, -0.0389,  0.1027, -0.0447,\n",
      "         -0.1222, -0.2044,  0.0577, -0.1328, -0.0480,  0.0713,  0.1350,  0.0729,\n",
      "         -0.0093,  0.0097,  0.0969, -0.0895, -0.0682,  0.0881, -0.0678,  0.0855,\n",
      "          0.0281, -0.0772,  0.0357,  0.0071,  0.0014, -0.0969, -0.1086, -0.0325,\n",
      "         -0.0083, -0.1400,  0.0277, -0.0891, -0.0212,  0.0559,  0.0738,  0.0534,\n",
      "          0.0848, -0.0218, -0.0428,  0.0194, -0.0590, -0.2256,  0.0191,  0.0144,\n",
      "         -0.1619,  0.0553, -0.0968, -0.0367,  0.0045, -0.1785, -0.0009,  0.1215,\n",
      "          0.0912,  0.1140, -0.1312,  0.0965,  0.1234, -0.0179, -0.0706, -0.0754,\n",
      "         -0.1177, -0.1212,  0.0472,  0.0340, -0.1122,  0.0719,  0.0327, -0.0319,\n",
      "         -0.0407,  0.0271, -0.0573, -0.0793, -0.0915, -0.0363, -0.0233, -0.0462,\n",
      "          0.0066,  0.0723,  0.0833, -0.0778,  0.1066,  0.1313,  0.0772, -0.0299]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.3862,  3.0203, -4.0162, -5.4576],\n",
      "        [ 1.0519, 13.5615, -1.9412, -4.4031],\n",
      "        [-5.5053, -4.7805, 13.5291, 12.0103],\n",
      "        [-4.2159, -6.7815, 10.9316, 13.8603]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.3862, 13.5615, 13.5291, 13.8603], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0625, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 3.0203, -4.0162, -5.4576],\n",
      "        [ 1.0519, -1.9412, -4.4031],\n",
      "        [-5.5053, -4.7805, 12.0103],\n",
      "        [-4.2159, -6.7815, 10.9316]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0208, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 7: 0.04168684780597687\n",
      "Epoch [7/10], Loss: 0.0911\n",
      "Batch 1/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.1007,  0.0463,  0.0284,  ..., -0.0187,  0.0588, -0.0173],\n",
      "        [ 0.0515, -0.0639, -0.2240,  ...,  0.0153, -0.1194, -0.0274],\n",
      "        [ 0.2064, -0.0643, -0.0348,  ..., -0.0395, -0.2311,  0.0805],\n",
      "        ...,\n",
      "        [-0.1118, -0.0283, -0.1003,  ...,  0.0561,  0.1623, -0.0523],\n",
      "        [-0.0924,  0.0333,  0.0728,  ...,  0.0078,  0.3104, -0.0855],\n",
      "        [-0.0085, -0.0030, -0.1694,  ...,  0.0023, -0.0700, -0.0917]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0957,  0.0229,  0.0457,  ...,  0.0202,  0.0381, -0.0011],\n",
      "        [ 0.0500, -0.0753, -0.1845,  ..., -0.0056, -0.1998, -0.0362],\n",
      "        [ 0.2272, -0.0549, -0.0166,  ..., -0.0578, -0.2047,  0.0618],\n",
      "        ...,\n",
      "        [-0.1400, -0.0297, -0.0981,  ...,  0.0614,  0.1751, -0.0906],\n",
      "        [-0.0919,  0.0072,  0.0461,  ...,  0.0157,  0.3441, -0.1062],\n",
      "        [-0.0291, -0.0390, -0.1409,  ..., -0.0133, -0.1027, -0.1184]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3494e+01, -5.3443e+00, -6.9224e+00,  1.1242e+01,  1.1788e+00,\n",
      "          1.0329e+01,  1.0591e+01, -2.9759e+00, -3.7171e+00,  9.5812e-01,\n",
      "          1.5173e-01,  9.6073e+00,  2.0956e+00, -1.8752e+00,  7.7250e+00,\n",
      "         -1.0864e+00],\n",
      "        [-3.7708e+00,  1.3286e+01,  2.2031e+00, -1.2131e+00,  3.0368e+00,\n",
      "         -4.6538e+00, -8.4211e-01,  5.0336e+00,  6.5518e+00, -7.8235e-01,\n",
      "         -3.4405e-01, -9.5110e+00,  6.6368e+00,  7.6650e+00, -8.4028e+00,\n",
      "          1.1361e+01],\n",
      "        [-6.0628e+00,  4.1094e+00,  1.3862e+01, -1.5810e+00,  1.0064e+01,\n",
      "         -3.4076e+00, -3.2082e+00, -4.6800e+00, -6.9999e+00, -1.1782e+01,\n",
      "         -1.1305e+01, -2.9185e+00,  6.3509e+00, -7.0861e+00, -7.5956e+00,\n",
      "         -2.4234e+00],\n",
      "        [ 1.2071e+01, -2.4880e+00, -2.9986e+00,  1.3582e+01,  5.6079e+00,\n",
      "          8.9093e+00,  9.3959e+00, -1.9725e+00, -3.5887e+00, -3.1775e+00,\n",
      "         -3.2709e+00,  7.8804e+00,  3.3792e+00, -2.4853e+00,  4.4866e+00,\n",
      "         -3.8607e-01],\n",
      "        [ 4.8135e-01,  3.8922e+00,  9.4945e+00,  5.3421e+00,  1.3699e+01,\n",
      "         -1.4145e-01,  7.0549e-02, -6.7748e-01, -5.0841e+00, -1.1443e+01,\n",
      "         -9.0527e+00, -1.7777e+00,  7.2265e+00, -5.5577e+00, -3.3434e+00,\n",
      "          9.8631e-01],\n",
      "        [ 1.0404e+01, -7.2049e+00, -5.0112e+00,  8.5814e+00,  6.3144e-01,\n",
      "          1.3532e+01,  8.3621e+00, -4.9482e+00, -5.3216e+00,  2.3122e+00,\n",
      "         -6.5586e-01,  1.2621e+01,  3.3613e-01, -5.0606e-01,  1.0109e+01,\n",
      "         -6.3533e+00],\n",
      "        [ 1.2406e+01, -2.0800e+00, -3.6550e+00,  9.3714e+00,  1.1035e+00,\n",
      "          9.9660e+00,  1.3641e+01, -8.5134e+00, -7.0430e+00, -1.5919e+00,\n",
      "         -4.4678e+00,  9.3244e+00,  6.7520e+00, -3.6805e+00,  2.8993e+00,\n",
      "         -1.0830e-02],\n",
      "        [-3.3501e+00,  1.8218e+00, -6.5506e+00, -1.3796e+00, -4.2458e+00,\n",
      "         -4.3960e+00, -7.3167e+00,  1.3714e+01,  1.2779e+01,  8.0624e+00,\n",
      "          1.1340e+01, -6.0947e+00, -7.7371e+00,  9.4189e+00,  1.9291e+00,\n",
      "          5.0251e+00],\n",
      "        [-4.2215e+00,  4.0653e+00, -7.8863e+00, -3.4968e+00, -7.2737e+00,\n",
      "         -5.3843e+00, -6.2596e+00,  1.2131e+01,  1.3873e+01,  1.0064e+01,\n",
      "          1.1852e+01, -7.2540e+00, -7.2988e+00,  1.1557e+01,  1.4919e-01,\n",
      "          6.9489e+00],\n",
      "        [-1.1748e-01, -2.6472e+00, -1.2007e+01, -4.0060e+00, -1.2021e+01,\n",
      "          6.7149e-01, -2.1225e+00,  6.3545e+00,  9.2875e+00,  1.3961e+01,\n",
      "          1.2944e+01,  7.9963e-02, -8.3524e+00,  1.0006e+01,  6.3186e+00,\n",
      "          1.5777e+00],\n",
      "        [-1.5686e+00, -2.7975e+00, -1.0832e+01, -3.2120e+00, -9.7618e+00,\n",
      "         -2.1101e+00, -5.2701e+00,  1.0295e+01,  1.1360e+01,  1.2359e+01,\n",
      "          1.3770e+01, -2.2140e+00, -1.0594e+01,  9.1730e+00,  5.9366e+00,\n",
      "          1.9996e+00],\n",
      "        [ 8.9037e+00, -1.0423e+01, -2.6359e+00,  7.2448e+00,  5.4797e-01,\n",
      "          1.2062e+01,  6.8836e+00, -7.0238e+00, -7.9821e+00,  1.6275e-01,\n",
      "         -2.3567e+00,  1.3627e+01, -1.4514e+00, -4.7305e+00,  9.8212e+00,\n",
      "         -1.0166e+01],\n",
      "        [ 3.8870e+00,  8.0059e+00,  5.7366e+00,  3.3245e+00,  7.1694e+00,\n",
      "          2.1687e+00,  8.3407e+00, -6.9721e+00, -6.4960e+00, -7.6411e+00,\n",
      "         -9.3426e+00, -7.6707e-01,  1.3772e+01, -3.1409e+00, -6.9035e+00,\n",
      "          5.9402e+00],\n",
      "        [-2.1928e+00,  4.8106e+00, -8.0075e+00, -1.9816e+00, -6.0098e+00,\n",
      "          4.7067e-01, -3.1086e+00,  8.8930e+00,  1.1417e+01,  1.0614e+01,\n",
      "          9.7883e+00, -3.5236e+00, -4.2688e+00,  1.3870e+01,  2.4082e+00,\n",
      "          5.5741e+00],\n",
      "        [ 5.9187e+00, -1.0501e+01, -7.9116e+00,  3.5258e+00, -3.4217e+00,\n",
      "          8.6844e+00,  9.0355e-01,  4.7969e-01, -4.1661e-01,  6.8747e+00,\n",
      "          5.8668e+00,  9.3832e+00, -7.6519e+00,  1.8467e+00,  1.3756e+01,\n",
      "         -7.8252e+00],\n",
      "        [ 7.5262e-01,  9.8728e+00, -4.4293e+00,  2.1278e-01, -1.5671e+00,\n",
      "         -5.3602e+00,  2.0026e+00,  6.6262e+00,  8.4675e+00,  2.8654e+00,\n",
      "          4.6433e+00, -8.6204e+00,  3.9153e+00,  6.7914e+00, -5.9852e+00,\n",
      "          1.3571e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.4944, 13.2855, 13.8615, 13.5815, 13.6992, 13.5321, 13.6408, 13.7137,\n",
      "        13.8728, 13.9608, 13.7697, 13.6268, 13.7716, 13.8697, 13.7557, 13.5714],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1960, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[-5.3443e+00, -6.9224e+00,  1.1242e+01,  1.1788e+00,  1.0329e+01,\n",
      "          1.0591e+01, -2.9759e+00, -3.7171e+00,  9.5812e-01,  1.5173e-01,\n",
      "          9.6073e+00,  2.0956e+00, -1.8752e+00,  7.7250e+00, -1.0864e+00],\n",
      "        [-3.7708e+00,  2.2031e+00, -1.2131e+00,  3.0368e+00, -4.6538e+00,\n",
      "         -8.4211e-01,  5.0336e+00,  6.5518e+00, -7.8235e-01, -3.4405e-01,\n",
      "         -9.5110e+00,  6.6368e+00,  7.6650e+00, -8.4028e+00,  1.1361e+01],\n",
      "        [-6.0628e+00,  4.1094e+00, -1.5810e+00,  1.0064e+01, -3.4076e+00,\n",
      "         -3.2082e+00, -4.6800e+00, -6.9999e+00, -1.1782e+01, -1.1305e+01,\n",
      "         -2.9185e+00,  6.3509e+00, -7.0861e+00, -7.5956e+00, -2.4234e+00],\n",
      "        [ 1.2071e+01, -2.4880e+00, -2.9986e+00,  5.6079e+00,  8.9093e+00,\n",
      "          9.3959e+00, -1.9725e+00, -3.5887e+00, -3.1775e+00, -3.2709e+00,\n",
      "          7.8804e+00,  3.3792e+00, -2.4853e+00,  4.4866e+00, -3.8607e-01],\n",
      "        [ 4.8135e-01,  3.8922e+00,  9.4945e+00,  5.3421e+00, -1.4145e-01,\n",
      "          7.0549e-02, -6.7748e-01, -5.0841e+00, -1.1443e+01, -9.0527e+00,\n",
      "         -1.7777e+00,  7.2265e+00, -5.5577e+00, -3.3434e+00,  9.8631e-01],\n",
      "        [ 1.0404e+01, -7.2049e+00, -5.0112e+00,  8.5814e+00,  6.3144e-01,\n",
      "          8.3621e+00, -4.9482e+00, -5.3216e+00,  2.3122e+00, -6.5586e-01,\n",
      "          1.2621e+01,  3.3613e-01, -5.0606e-01,  1.0109e+01, -6.3533e+00],\n",
      "        [ 1.2406e+01, -2.0800e+00, -3.6550e+00,  9.3714e+00,  1.1035e+00,\n",
      "          9.9660e+00, -8.5134e+00, -7.0430e+00, -1.5919e+00, -4.4678e+00,\n",
      "          9.3244e+00,  6.7520e+00, -3.6805e+00,  2.8993e+00, -1.0830e-02],\n",
      "        [-3.3501e+00,  1.8218e+00, -6.5506e+00, -1.3796e+00, -4.2458e+00,\n",
      "         -4.3960e+00, -7.3167e+00,  1.2779e+01,  8.0624e+00,  1.1340e+01,\n",
      "         -6.0947e+00, -7.7371e+00,  9.4189e+00,  1.9291e+00,  5.0251e+00],\n",
      "        [-4.2215e+00,  4.0653e+00, -7.8863e+00, -3.4968e+00, -7.2737e+00,\n",
      "         -5.3843e+00, -6.2596e+00,  1.2131e+01,  1.0064e+01,  1.1852e+01,\n",
      "         -7.2540e+00, -7.2988e+00,  1.1557e+01,  1.4919e-01,  6.9489e+00],\n",
      "        [-1.1748e-01, -2.6472e+00, -1.2007e+01, -4.0060e+00, -1.2021e+01,\n",
      "          6.7149e-01, -2.1225e+00,  6.3545e+00,  9.2875e+00,  1.2944e+01,\n",
      "          7.9963e-02, -8.3524e+00,  1.0006e+01,  6.3186e+00,  1.5777e+00],\n",
      "        [-1.5686e+00, -2.7975e+00, -1.0832e+01, -3.2120e+00, -9.7618e+00,\n",
      "         -2.1101e+00, -5.2701e+00,  1.0295e+01,  1.1360e+01,  1.2359e+01,\n",
      "         -2.2140e+00, -1.0594e+01,  9.1730e+00,  5.9366e+00,  1.9996e+00],\n",
      "        [ 8.9037e+00, -1.0423e+01, -2.6359e+00,  7.2448e+00,  5.4797e-01,\n",
      "          1.2062e+01,  6.8836e+00, -7.0238e+00, -7.9821e+00,  1.6275e-01,\n",
      "         -2.3567e+00, -1.4514e+00, -4.7305e+00,  9.8212e+00, -1.0166e+01],\n",
      "        [ 3.8870e+00,  8.0059e+00,  5.7366e+00,  3.3245e+00,  7.1694e+00,\n",
      "          2.1687e+00,  8.3407e+00, -6.9721e+00, -6.4960e+00, -7.6411e+00,\n",
      "         -9.3426e+00, -7.6707e-01, -3.1409e+00, -6.9035e+00,  5.9402e+00],\n",
      "        [-2.1928e+00,  4.8106e+00, -8.0075e+00, -1.9816e+00, -6.0098e+00,\n",
      "          4.7067e-01, -3.1086e+00,  8.8930e+00,  1.1417e+01,  1.0614e+01,\n",
      "          9.7883e+00, -3.5236e+00, -4.2688e+00,  2.4082e+00,  5.5741e+00],\n",
      "        [ 5.9187e+00, -1.0501e+01, -7.9116e+00,  3.5258e+00, -3.4217e+00,\n",
      "          8.6844e+00,  9.0355e-01,  4.7969e-01, -4.1661e-01,  6.8747e+00,\n",
      "          5.8668e+00,  9.3832e+00, -7.6519e+00,  1.8467e+00, -7.8252e+00],\n",
      "        [ 7.5262e-01,  9.8728e+00, -4.4293e+00,  2.1278e-01, -1.5671e+00,\n",
      "         -5.3602e+00,  2.0026e+00,  6.6262e+00,  8.4675e+00,  2.8654e+00,\n",
      "          4.6433e+00, -8.6204e+00,  3.9153e+00,  6.7914e+00, -5.9852e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0123, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 1: 0.10418141633272171\n",
      "Batch 2/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0932,  0.0060, -0.2118,  ..., -0.1243, -0.0190,  0.0180],\n",
      "        [-0.1405,  0.0431, -0.0667,  ..., -0.0219,  0.2439, -0.0634],\n",
      "        [ 0.1941, -0.0262,  0.0471,  ..., -0.0465, -0.1309,  0.0249],\n",
      "        ...,\n",
      "        [ 0.0386,  0.0009,  0.0048,  ..., -0.0826,  0.1650, -0.0409],\n",
      "        [-0.1234,  0.0247, -0.1112,  ..., -0.0351,  0.1034, -0.1040],\n",
      "        [ 0.1607, -0.0594, -0.1885,  ..., -0.0967,  0.0231, -0.0279]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1197, -0.0158, -0.1825,  ..., -0.1633, -0.0050, -0.0008],\n",
      "        [-0.1267,  0.0136, -0.0760,  ..., -0.0261,  0.2326, -0.0561],\n",
      "        [ 0.1510, -0.0361,  0.0140,  ..., -0.0674, -0.1478,  0.0885],\n",
      "        ...,\n",
      "        [ 0.0137, -0.0111, -0.0263,  ..., -0.0696,  0.1835, -0.0438],\n",
      "        [-0.0740, -0.0046, -0.0784,  ..., -0.0680,  0.0261, -0.1174],\n",
      "        [ 0.1717, -0.0936, -0.2277,  ..., -0.1076, -0.0165, -0.0068]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.5537,   4.8045,   0.5729,  -0.2321,   4.3184,   2.2028,   6.0233,\n",
      "          -8.6748,   4.9871,  -3.4508,   4.2687,   9.6704,   3.8387,   3.4771,\n",
      "           6.9648,  10.3958],\n",
      "        [  3.9128,  13.9934, -10.5681,   5.4651,   9.7491,   7.3883,   8.6005,\n",
      "          -3.0202,   4.5497,  -9.7427,  12.8571,   6.2581,  -5.3445,   6.5366,\n",
      "           6.0374,  -1.2365],\n",
      "        [  0.3233, -10.6477,  13.6554,  -7.6002, -10.3411,  -8.6624,  -1.3415,\n",
      "           5.5170,  -1.7345,   6.0705, -11.6938,   0.0210,   2.7590,   1.5376,\n",
      "          -2.9786,   4.1808],\n",
      "        [ -0.6885,   6.5368,  -7.7444,  13.7751,   8.6264,   7.7561,  -2.5489,\n",
      "          -0.0643,  -8.5916, -11.1605,   7.9383,  -3.9423, -10.0466,  -3.6639,\n",
      "          10.8680,  -2.8596],\n",
      "        [  3.7164,  10.8900, -10.6252,   8.7380,  13.6594,  12.7988,   1.2410,\n",
      "          -6.6433,  -0.3660,  -8.4389,   9.7243,   2.4501,  -4.1790,   0.5367,\n",
      "           8.5355,  -3.4568],\n",
      "        [  1.5316,   8.9197,  -9.9347,   9.2311,  13.5634,  13.5934,  -1.6085,\n",
      "          -5.7493,  -2.6949,  -7.8730,   7.4389,   0.6186,  -4.4985,  -0.7201,\n",
      "           8.7208,  -5.2048],\n",
      "        [  5.5132,   9.0165,  -1.5797,  -3.2596,  -0.2238,  -2.7579,  13.6720,\n",
      "           1.6911,   8.7658,  -5.5049,   7.4924,  10.2846,  -2.1896,  11.9814,\n",
      "           1.1533,   4.4870],\n",
      "        [ -9.7642,  -3.9586,   5.2235,  -2.6487,  -7.9929,  -6.4611,   0.9877,\n",
      "          13.4812,  -3.4586,   0.4398,  -5.0917,  -4.2664,  -6.8230,   4.2186,\n",
      "          -4.4224,  -6.2856],\n",
      "        [  4.7227,   5.2807,  -1.5495,  -8.9681,  -0.9787,  -2.4565,  10.1164,\n",
      "          -3.3835,  13.5268,   3.3597,   3.7235,   9.8847,   6.8926,   8.8818,\n",
      "          -5.8784,   3.5693],\n",
      "        [ -1.7724,  -9.8331,   5.8057,  -8.9792,  -7.4427,  -5.9155,  -4.9376,\n",
      "          -2.1149,   3.8283,  13.6723,  -8.8092,  -3.5005,  10.6306,  -4.8353,\n",
      "         -10.4387,   1.7455],\n",
      "        [  3.6600,  13.2294, -11.4212,   6.6877,   9.0810,   6.1919,   7.3695,\n",
      "          -3.7287,   4.0414,  -9.3382,  13.8513,   5.0274,  -4.5014,   3.5905,\n",
      "           5.5066,   0.0901],\n",
      "        [  9.5854,   6.0256,   1.1925,  -4.9947,   2.3680,   0.7958,   9.6619,\n",
      "          -4.2722,   8.8234,  -3.3465,   3.4699,  13.6967,   3.7673,   9.9281,\n",
      "           2.9543,   6.2314],\n",
      "        [  3.8623,  -6.4954,   4.1407,  -8.7867,  -3.6809,  -3.2008,  -2.7256,\n",
      "          -7.3443,   6.7998,  10.9380,  -5.7529,   2.8324,  13.7561,  -3.2506,\n",
      "          -7.4278,   5.3181],\n",
      "        [  3.2632,   6.6362,   1.0343,  -6.1193,  -0.6259,  -1.4374,  11.8913,\n",
      "           2.9988,   8.6320,  -3.2386,   2.9398,  10.6495,  -1.3070,  13.7702,\n",
      "          -0.2742,   1.0292],\n",
      "        [  5.6061,   7.6700,  -3.8205,  10.2308,   7.8038,   6.5110,   2.4696,\n",
      "          -1.7189,  -5.1739, -12.4551,   7.4230,   2.9536,  -8.4469,   2.3110,\n",
      "          13.4740,   2.6261],\n",
      "        [ 11.1499,   0.0720,   5.2010,  -3.1318,  -4.0028,  -6.2057,   6.2352,\n",
      "          -3.8396,   4.7667,  -0.6098,   1.3887,   7.7775,   4.3721,   3.2852,\n",
      "           3.1073,  13.5633]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.5537, 13.9934, 13.6554, 13.7751, 13.6594, 13.5934, 13.6720, 13.4812,\n",
      "        13.5268, 13.6723, 13.8513, 13.6967, 13.7561, 13.7702, 13.4740, 13.5633],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1718, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  4.8045,   0.5729,  -0.2321,   4.3184,   2.2028,   6.0233,  -8.6748,\n",
      "           4.9871,  -3.4508,   4.2687,   9.6704,   3.8387,   3.4771,   6.9648,\n",
      "          10.3958],\n",
      "        [  3.9128, -10.5681,   5.4651,   9.7491,   7.3883,   8.6005,  -3.0202,\n",
      "           4.5497,  -9.7427,  12.8571,   6.2581,  -5.3445,   6.5366,   6.0374,\n",
      "          -1.2365],\n",
      "        [  0.3233, -10.6477,  -7.6002, -10.3411,  -8.6624,  -1.3415,   5.5170,\n",
      "          -1.7345,   6.0705, -11.6938,   0.0210,   2.7590,   1.5376,  -2.9786,\n",
      "           4.1808],\n",
      "        [ -0.6885,   6.5368,  -7.7444,   8.6264,   7.7561,  -2.5489,  -0.0643,\n",
      "          -8.5916, -11.1605,   7.9383,  -3.9423, -10.0466,  -3.6639,  10.8680,\n",
      "          -2.8596],\n",
      "        [  3.7164,  10.8900, -10.6252,   8.7380,  12.7988,   1.2410,  -6.6433,\n",
      "          -0.3660,  -8.4389,   9.7243,   2.4501,  -4.1790,   0.5367,   8.5355,\n",
      "          -3.4568],\n",
      "        [  1.5316,   8.9197,  -9.9347,   9.2311,  13.5634,  -1.6085,  -5.7493,\n",
      "          -2.6949,  -7.8730,   7.4389,   0.6186,  -4.4985,  -0.7201,   8.7208,\n",
      "          -5.2048],\n",
      "        [  5.5132,   9.0165,  -1.5797,  -3.2596,  -0.2238,  -2.7579,   1.6911,\n",
      "           8.7658,  -5.5049,   7.4924,  10.2846,  -2.1896,  11.9814,   1.1533,\n",
      "           4.4870],\n",
      "        [ -9.7642,  -3.9586,   5.2235,  -2.6487,  -7.9929,  -6.4611,   0.9877,\n",
      "          -3.4586,   0.4398,  -5.0917,  -4.2664,  -6.8230,   4.2186,  -4.4224,\n",
      "          -6.2856],\n",
      "        [  4.7227,   5.2807,  -1.5495,  -8.9681,  -0.9787,  -2.4565,  10.1164,\n",
      "          -3.3835,   3.3597,   3.7235,   9.8847,   6.8926,   8.8818,  -5.8784,\n",
      "           3.5693],\n",
      "        [ -1.7724,  -9.8331,   5.8057,  -8.9792,  -7.4427,  -5.9155,  -4.9376,\n",
      "          -2.1149,   3.8283,  -8.8092,  -3.5005,  10.6306,  -4.8353, -10.4387,\n",
      "           1.7455],\n",
      "        [  3.6600,  13.2294, -11.4212,   6.6877,   9.0810,   6.1919,   7.3695,\n",
      "          -3.7287,   4.0414,  -9.3382,   5.0274,  -4.5014,   3.5905,   5.5066,\n",
      "           0.0901],\n",
      "        [  9.5854,   6.0256,   1.1925,  -4.9947,   2.3680,   0.7958,   9.6619,\n",
      "          -4.2722,   8.8234,  -3.3465,   3.4699,   3.7673,   9.9281,   2.9543,\n",
      "           6.2314],\n",
      "        [  3.8623,  -6.4954,   4.1407,  -8.7867,  -3.6809,  -3.2008,  -2.7256,\n",
      "          -7.3443,   6.7998,  10.9380,  -5.7529,   2.8324,  -3.2506,  -7.4278,\n",
      "           5.3181],\n",
      "        [  3.2632,   6.6362,   1.0343,  -6.1193,  -0.6259,  -1.4374,  11.8913,\n",
      "           2.9988,   8.6320,  -3.2386,   2.9398,  10.6495,  -1.3070,  -0.2742,\n",
      "           1.0292],\n",
      "        [  5.6061,   7.6700,  -3.8205,  10.2308,   7.8038,   6.5110,   2.4696,\n",
      "          -1.7189,  -5.1739, -12.4551,   7.4230,   2.9536,  -8.4469,   2.3110,\n",
      "           2.6261],\n",
      "        [ 11.1499,   0.0720,   5.2010,  -3.1318,  -4.0028,  -6.2057,   6.2352,\n",
      "          -3.8396,   4.7667,  -0.6098,   1.3887,   7.7775,   4.3721,   3.2852,\n",
      "           3.1073]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0111, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 2: 0.09145808964967728\n",
      "Batch 3/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1852, -0.0281, -0.0515,  ..., -0.0790, -0.0420,  0.0318],\n",
      "        [ 0.0103,  0.0048,  0.1825,  ...,  0.0431,  0.0308,  0.0107],\n",
      "        [ 0.2143, -0.0322, -0.0726,  ..., -0.0399, -0.2499,  0.0303],\n",
      "        ...,\n",
      "        [-0.1645,  0.0163,  0.0093,  ...,  0.0799,  0.2604, -0.0892],\n",
      "        [ 0.0205, -0.0110, -0.1399,  ..., -0.0384, -0.2023, -0.0617],\n",
      "        [-0.1023,  0.0445,  0.0692,  ...,  0.0268,  0.3208, -0.0584]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1702, -0.0354, -0.0607,  ..., -0.0414, -0.0948, -0.0145],\n",
      "        [-0.0017,  0.0177,  0.2384,  ...,  0.0343,  0.0043,  0.0729],\n",
      "        [ 0.1829, -0.0431, -0.0471,  ..., -0.0236, -0.2471,  0.0360],\n",
      "        ...,\n",
      "        [-0.1838, -0.0137,  0.0187,  ...,  0.0600,  0.2339, -0.1032],\n",
      "        [ 0.0357, -0.0019, -0.1378,  ..., -0.0543, -0.1703, -0.0767],\n",
      "        [-0.1517,  0.0264,  0.0761,  ...,  0.0265,  0.2877, -0.0548]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.4175,   1.9452,   8.7594,  -7.6400,   7.3363,   1.6853,   1.2745,\n",
      "           7.3890,  -0.0867,  -1.9864, -10.4507,   5.8810,   5.7231,  -9.8447,\n",
      "          -0.8891,  -2.4259],\n",
      "        [  2.9045,  13.5936,  -0.0890,   1.1540,  -7.4400,   7.1833,   4.3328,\n",
      "           2.5729,   3.5539,  -2.5928,   0.9926,   3.0614,  -7.9159,  -2.3326,\n",
      "         -11.1233,   3.9496],\n",
      "        [  9.2664,  -1.8976,  13.8402,   1.5819,  11.0874,   8.3511,   7.9785,\n",
      "          11.8705,  -7.8646,   5.7106, -11.2546,   0.2157,   8.6137, -10.6651,\n",
      "           7.2109, -10.9886],\n",
      "        [ -4.7697,   2.5357,   1.5550,  13.8420,  -1.6440,   7.8864,   6.5744,\n",
      "           2.1872,   0.0497,   1.3252,   3.6580,  -7.2916,  -4.3561,  -0.4982,\n",
      "           3.0572,  -5.2655],\n",
      "        [  6.7764,  -8.6606,  10.6244,  -0.0790,  13.8354,   1.6375,   2.1668,\n",
      "           8.7389,  -6.7930,   5.1669, -10.6399,   0.1138,  12.0051,  -8.4888,\n",
      "          11.2065, -10.5410],\n",
      "        [  3.0504,   6.6047,   8.5524,   7.2554,   1.6884,  14.0006,  10.2385,\n",
      "          10.4334,  -6.7901,   7.0002,  -4.9637,   0.9887,   0.4756,  -7.6435,\n",
      "          -0.3001,  -8.8864],\n",
      "        [  1.8439,   4.9561,   7.9208,   6.6836,   0.9043,  10.5709,  13.5995,\n",
      "           5.5698,  -3.6845,   3.3835,  -1.6875,  -5.4824,  -3.0432,  -5.0569,\n",
      "           1.7750,  -5.7340],\n",
      "        [  7.8293,   1.4110,  12.0299,   1.7152,   9.1520,  10.2231,   6.8731,\n",
      "          13.8203,  -9.3561,   8.7020, -11.9283,   4.4529,   8.4921, -11.4173,\n",
      "           3.4849, -11.0967],\n",
      "        [ -0.0189,   2.9274,  -6.8614,  -0.0550,  -5.8633,  -6.4158,  -4.8876,\n",
      "          -8.1662,  13.7731, -12.7414,   6.9765,  -3.0740,  -8.3757,   3.2220,\n",
      "          -4.7067,   8.4364],\n",
      "        [ -3.0328,  -1.1564,   3.5618,   2.4269,   3.4581,   6.5698,   3.8853,\n",
      "           7.6621, -12.1591,  13.7662,  -5.0747,   4.8106,   6.9013,  -3.1348,\n",
      "           2.8253,  -8.0627],\n",
      "        [-10.5841,   1.7110, -11.3540,   4.2230, -11.5607,  -4.5909,  -3.3145,\n",
      "         -11.8354,   7.1903,  -5.9199,  13.9079,  -6.1578, -10.6695,  12.1357,\n",
      "          -4.1049,   9.2543],\n",
      "        [  5.4023,   3.5709,   0.9850,  -7.4356,   1.3866,   1.8839,  -4.3511,\n",
      "           6.3632,  -3.8689,   4.7608,  -7.0058,  13.8510,   5.9339,  -5.7016,\n",
      "          -5.9535,  -1.3736],\n",
      "        [  6.1884,  -8.3627,   7.6004,  -4.4225,  12.0835,  -0.7804,  -2.2508,\n",
      "           7.9426,  -8.0434,   6.9029, -10.7615,   5.4306,  13.8274,  -6.7419,\n",
      "           8.0104,  -8.0939],\n",
      "        [-10.3463,  -1.2974, -11.6083,  -0.8400,  -9.7267,  -7.9197,  -6.1635,\n",
      "         -11.8910,   3.7911,  -3.3448,  11.8159,  -3.4880,  -6.7541,  13.8946,\n",
      "          -3.5806,  10.7264],\n",
      "        [  0.3413, -11.7905,   5.4196,   3.7418,  10.1665,  -2.0172,   1.2204,\n",
      "           1.4933,  -3.2461,   2.0938,  -3.0828,  -6.1498,   7.6449,  -2.2091,\n",
      "          13.7473,  -8.0062],\n",
      "        [ -3.3457,   3.9297, -10.4518,  -5.1154,  -9.6052,  -8.7142,  -6.9925,\n",
      "         -10.5894,  10.0244,  -9.3924,   8.7742,  -0.2016,  -8.7327,   8.9985,\n",
      "          -8.7654,  13.8072]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.4175, 13.5936, 13.8402, 13.8420, 13.8354, 14.0006, 13.5995, 13.8203,\n",
      "        13.7731, 13.7662, 13.9079, 13.8510, 13.8274, 13.8946, 13.7473, 13.8072],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0842, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  1.9452,   8.7594,  -7.6400,   7.3363,   1.6853,   1.2745,   7.3890,\n",
      "          -0.0867,  -1.9864, -10.4507,   5.8810,   5.7231,  -9.8447,  -0.8891,\n",
      "          -2.4259],\n",
      "        [  2.9045,  -0.0890,   1.1540,  -7.4400,   7.1833,   4.3328,   2.5729,\n",
      "           3.5539,  -2.5928,   0.9926,   3.0614,  -7.9159,  -2.3326, -11.1233,\n",
      "           3.9496],\n",
      "        [  9.2664,  -1.8976,   1.5819,  11.0874,   8.3511,   7.9785,  11.8705,\n",
      "          -7.8646,   5.7106, -11.2546,   0.2157,   8.6137, -10.6651,   7.2109,\n",
      "         -10.9886],\n",
      "        [ -4.7697,   2.5357,   1.5550,  -1.6440,   7.8864,   6.5744,   2.1872,\n",
      "           0.0497,   1.3252,   3.6580,  -7.2916,  -4.3561,  -0.4982,   3.0572,\n",
      "          -5.2655],\n",
      "        [  6.7764,  -8.6606,  10.6244,  -0.0790,   1.6375,   2.1668,   8.7389,\n",
      "          -6.7930,   5.1669, -10.6399,   0.1138,  12.0051,  -8.4888,  11.2065,\n",
      "         -10.5410],\n",
      "        [  3.0504,   6.6047,   8.5524,   7.2554,   1.6884,  10.2385,  10.4334,\n",
      "          -6.7901,   7.0002,  -4.9637,   0.9887,   0.4756,  -7.6435,  -0.3001,\n",
      "          -8.8864],\n",
      "        [  1.8439,   4.9561,   7.9208,   6.6836,   0.9043,  10.5709,   5.5698,\n",
      "          -3.6845,   3.3835,  -1.6875,  -5.4824,  -3.0432,  -5.0569,   1.7750,\n",
      "          -5.7340],\n",
      "        [  7.8293,   1.4110,  12.0299,   1.7152,   9.1520,  10.2231,   6.8731,\n",
      "          -9.3561,   8.7020, -11.9283,   4.4529,   8.4921, -11.4173,   3.4849,\n",
      "         -11.0967],\n",
      "        [ -0.0189,   2.9274,  -6.8614,  -0.0550,  -5.8633,  -6.4158,  -4.8876,\n",
      "          -8.1662, -12.7414,   6.9765,  -3.0740,  -8.3757,   3.2220,  -4.7067,\n",
      "           8.4364],\n",
      "        [ -3.0328,  -1.1564,   3.5618,   2.4269,   3.4581,   6.5698,   3.8853,\n",
      "           7.6621, -12.1591,  -5.0747,   4.8106,   6.9013,  -3.1348,   2.8253,\n",
      "          -8.0627],\n",
      "        [-10.5841,   1.7110, -11.3540,   4.2230, -11.5607,  -4.5909,  -3.3145,\n",
      "         -11.8354,   7.1903,  -5.9199,  -6.1578, -10.6695,  12.1357,  -4.1049,\n",
      "           9.2543],\n",
      "        [  5.4023,   3.5709,   0.9850,  -7.4356,   1.3866,   1.8839,  -4.3511,\n",
      "           6.3632,  -3.8689,   4.7608,  -7.0058,   5.9339,  -5.7016,  -5.9535,\n",
      "          -1.3736],\n",
      "        [  6.1884,  -8.3627,   7.6004,  -4.4225,  12.0835,  -0.7804,  -2.2508,\n",
      "           7.9426,  -8.0434,   6.9029, -10.7615,   5.4306,  -6.7419,   8.0104,\n",
      "          -8.0939],\n",
      "        [-10.3463,  -1.2974, -11.6083,  -0.8400,  -9.7267,  -7.9197,  -6.1635,\n",
      "         -11.8910,   3.7911,  -3.3448,  11.8159,  -3.4880,  -6.7541,  -3.5806,\n",
      "          10.7264],\n",
      "        [  0.3413, -11.7905,   5.4196,   3.7418,  10.1665,  -2.0172,   1.2204,\n",
      "           1.4933,  -3.2461,   2.0938,  -3.0828,  -6.1498,   7.6449,  -2.2091,\n",
      "          -8.0062],\n",
      "        [ -3.3457,   3.9297, -10.4518,  -5.1154,  -9.6052,  -8.7142,  -6.9925,\n",
      "         -10.5894,  10.0244,  -9.3924,   8.7742,  -0.2016,  -8.7327,   8.9985,\n",
      "          -8.7654]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0054, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 3: 0.04479210078716278\n",
      "Batch 4/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.0733,  0.0496,  0.0605,  ..., -0.0530,  0.3676, -0.0138],\n",
      "        [ 0.0827, -0.0075, -0.1475,  ..., -0.1371,  0.1415, -0.0247],\n",
      "        [-0.0332, -0.0182,  0.1787,  ...,  0.0755,  0.2195, -0.0261],\n",
      "        ...,\n",
      "        [-0.1468, -0.0060, -0.0910,  ..., -0.0023,  0.2410, -0.0542],\n",
      "        [ 0.0641,  0.0171, -0.0695,  ..., -0.0823, -0.0058,  0.0413],\n",
      "        [ 0.1081, -0.0582, -0.0486,  ...,  0.0436,  0.0812,  0.0162]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0650,  0.0461,  0.0359,  ..., -0.0910,  0.2947,  0.0273],\n",
      "        [ 0.0599, -0.0111, -0.1284,  ..., -0.1648,  0.2021, -0.0066],\n",
      "        [-0.0741, -0.0078,  0.1905,  ...,  0.0205,  0.2528, -0.0110],\n",
      "        ...,\n",
      "        [-0.1495,  0.0123, -0.0597,  ..., -0.0140,  0.2428, -0.0290],\n",
      "        [ 0.0307,  0.0163, -0.0590,  ..., -0.0686, -0.0105,  0.0396],\n",
      "        [ 0.0775, -0.0888, -0.0196,  ...,  0.0355,  0.1101,  0.0321]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.4954,   7.7208,   8.7422,  -7.2556,  -3.1251, -10.4387,  10.1627,\n",
      "           9.4750,  11.1487,   3.8142,  -1.3439,   0.2557,  -3.2873,   6.9444,\n",
      "          -0.4844,   3.5065],\n",
      "        [  8.2948,  14.0414,  -0.9692,  -9.7616,  -3.0532,  -4.2316,   3.6533,\n",
      "           3.9136,   3.0126,  -8.1920,   1.9103,  -4.4758, -10.1207,   6.7132,\n",
      "           0.8864,   3.9561],\n",
      "        [  7.2412,  -0.8000,  13.4836,  -0.7462,   1.1825,  -8.0552,   7.2980,\n",
      "           8.9373,  10.0981,  10.9345,  -1.2567,   7.0073,   1.0420,  -0.4297,\n",
      "          -3.5976,   6.7964],\n",
      "        [ -8.5345,  -9.3689,  -1.5463,  13.4767,  -1.9724,  10.6296,   0.5955,\n",
      "         -10.3523,  -5.6840,   3.2230,  -8.5205,   7.8393,   2.9342, -10.8058,\n",
      "           7.7439,  -1.2358],\n",
      "        [ -1.0653,  -2.2767,   2.0569,  -2.4975,  13.2446,  -3.0915,  -6.5095,\n",
      "           3.6349,  -0.7106,   2.6145,   9.9493,  -5.7654,  -0.5816,  -0.1832,\n",
      "          -9.7049,   5.9402],\n",
      "        [-10.3692,  -3.6594,  -9.6214,   8.2478,  -2.6484,  13.6067,  -5.0737,\n",
      "         -12.6031, -11.4116,  -6.5454,  -4.5105,   2.2601,  -0.3572,  -8.7839,\n",
      "           7.2795,  -3.7541],\n",
      "        [  9.2376,   3.8378,   7.7662,   0.5567,  -6.2876,  -5.2598,  13.6566,\n",
      "           3.4610,   9.8613,   4.8745,  -8.1674,   4.3029,  -3.8696,   3.7364,\n",
      "           6.0648,   4.3932],\n",
      "        [  9.6006,   3.1967,  10.6496,  -8.2336,   1.8821, -13.0325,   3.9711,\n",
      "          13.5491,  10.7756,   7.1350,   4.5747,   0.6577,   2.0453,   7.0637,\n",
      "          -8.1952,   3.2934],\n",
      "        [ 10.2674,   2.0544,  11.0916,  -1.8943,  -1.2360,  -9.4394,  10.4938,\n",
      "           8.5870,  13.5559,   9.0643,  -1.7857,   4.3584,  -1.5331,   5.1083,\n",
      "           0.1472,   6.4297],\n",
      "        [  3.8635,  -7.0883,  11.6240,   2.8158,   1.9227,  -6.0210,   4.8633,\n",
      "           6.3939,   7.9634,  13.3894,  -1.7807,   6.8819,   6.6723,  -2.3378,\n",
      "          -3.6828,   2.3410],\n",
      "        [  1.5680,   1.7955,  -0.0325,  -8.6180,   9.8651,  -6.8724,  -8.0755,\n",
      "           7.5448,   1.6689,  -0.3397,  13.5612,  -7.5356,   0.5157,   5.5202,\n",
      "         -11.4758,   2.3891],\n",
      "        [ -2.9759,  -5.9603,   5.6537,   9.2783,  -4.0558,   5.0069,   3.8477,\n",
      "          -3.0001,   0.5292,   6.6740,  -7.7160,  13.3500,   2.5857,  -9.9018,\n",
      "           5.0721,   1.5820],\n",
      "        [ -2.9149, -10.2456,   2.8444,   4.4126,  -2.4204,  -0.9611,  -1.3179,\n",
      "           1.4668,  -0.0592,   7.8780,  -2.7132,   5.2827,  13.5583,  -2.5122,\n",
      "          -2.0619,  -9.0970],\n",
      "        [  7.3295,   8.0113,  -0.7876,  -9.1621,  -1.3861,  -9.2557,   3.3867,\n",
      "           6.8616,   6.2707,  -3.5415,   3.6022,  -8.0669,  -2.8285,  13.8819,\n",
      "          -1.8792,  -0.3378],\n",
      "        [ -0.3205,   2.1308,  -4.0390,   6.8144,  -8.8177,   7.4162,   7.6982,\n",
      "          -9.1581,  -2.0256,  -4.2336, -11.0594,   3.8871,  -4.9951,  -2.5935,\n",
      "          13.6732,  -1.2585],\n",
      "        [  4.4425,   5.0473,   5.5538,  -1.9350,   5.8046,  -2.2426,   3.5559,\n",
      "           2.9936,   5.2276,   1.7312,   2.8494,   0.2398,  -9.9364,  -0.1958,\n",
      "          -1.5691,  13.6188]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.4954, 14.0414, 13.4836, 13.4767, 13.2446, 13.6067, 13.6566, 13.5491,\n",
      "        13.5559, 13.3894, 13.5612, 13.3500, 13.5583, 13.8819, 13.6732, 13.6188],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0595, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  7.7208,   8.7422,  -7.2556,  -3.1251, -10.4387,  10.1627,   9.4750,\n",
      "          11.1487,   3.8142,  -1.3439,   0.2557,  -3.2873,   6.9444,  -0.4844,\n",
      "           3.5065],\n",
      "        [  8.2948,  -0.9692,  -9.7616,  -3.0532,  -4.2316,   3.6533,   3.9136,\n",
      "           3.0126,  -8.1920,   1.9103,  -4.4758, -10.1207,   6.7132,   0.8864,\n",
      "           3.9561],\n",
      "        [  7.2412,  -0.8000,  -0.7462,   1.1825,  -8.0552,   7.2980,   8.9373,\n",
      "          10.0981,  10.9345,  -1.2567,   7.0073,   1.0420,  -0.4297,  -3.5976,\n",
      "           6.7964],\n",
      "        [ -8.5345,  -9.3689,  -1.5463,  -1.9724,  10.6296,   0.5955, -10.3523,\n",
      "          -5.6840,   3.2230,  -8.5205,   7.8393,   2.9342, -10.8058,   7.7439,\n",
      "          -1.2358],\n",
      "        [ -1.0653,  -2.2767,   2.0569,  -2.4975,  -3.0915,  -6.5095,   3.6349,\n",
      "          -0.7106,   2.6145,   9.9493,  -5.7654,  -0.5816,  -0.1832,  -9.7049,\n",
      "           5.9402],\n",
      "        [-10.3692,  -3.6594,  -9.6214,   8.2478,  -2.6484,  -5.0737, -12.6031,\n",
      "         -11.4116,  -6.5454,  -4.5105,   2.2601,  -0.3572,  -8.7839,   7.2795,\n",
      "          -3.7541],\n",
      "        [  9.2376,   3.8378,   7.7662,   0.5567,  -6.2876,  -5.2598,   3.4610,\n",
      "           9.8613,   4.8745,  -8.1674,   4.3029,  -3.8696,   3.7364,   6.0648,\n",
      "           4.3932],\n",
      "        [  9.6006,   3.1967,  10.6496,  -8.2336,   1.8821, -13.0325,   3.9711,\n",
      "          10.7756,   7.1350,   4.5747,   0.6577,   2.0453,   7.0637,  -8.1952,\n",
      "           3.2934],\n",
      "        [ 10.2674,   2.0544,  11.0916,  -1.8943,  -1.2360,  -9.4394,  10.4938,\n",
      "           8.5870,   9.0643,  -1.7857,   4.3584,  -1.5331,   5.1083,   0.1472,\n",
      "           6.4297],\n",
      "        [  3.8635,  -7.0883,  11.6240,   2.8158,   1.9227,  -6.0210,   4.8633,\n",
      "           6.3939,   7.9634,  -1.7807,   6.8819,   6.6723,  -2.3378,  -3.6828,\n",
      "           2.3410],\n",
      "        [  1.5680,   1.7955,  -0.0325,  -8.6180,   9.8651,  -6.8724,  -8.0755,\n",
      "           7.5448,   1.6689,  -0.3397,  -7.5356,   0.5157,   5.5202, -11.4758,\n",
      "           2.3891],\n",
      "        [ -2.9759,  -5.9603,   5.6537,   9.2783,  -4.0558,   5.0069,   3.8477,\n",
      "          -3.0001,   0.5292,   6.6740,  -7.7160,   2.5857,  -9.9018,   5.0721,\n",
      "           1.5820],\n",
      "        [ -2.9149, -10.2456,   2.8444,   4.4126,  -2.4204,  -0.9611,  -1.3179,\n",
      "           1.4668,  -0.0592,   7.8780,  -2.7132,   5.2827,  -2.5122,  -2.0619,\n",
      "          -9.0970],\n",
      "        [  7.3295,   8.0113,  -0.7876,  -9.1621,  -1.3861,  -9.2557,   3.3867,\n",
      "           6.8616,   6.2707,  -3.5415,   3.6022,  -8.0669,  -2.8285,  -1.8792,\n",
      "          -0.3378],\n",
      "        [ -0.3205,   2.1308,  -4.0390,   6.8144,  -8.8177,   7.4162,   7.6982,\n",
      "          -9.1581,  -2.0256,  -4.2336, -11.0594,   3.8871,  -4.9951,  -2.5935,\n",
      "          -1.2585],\n",
      "        [  4.4425,   5.0473,   5.5538,  -1.9350,   5.8046,  -2.2426,   3.5559,\n",
      "           2.9936,   5.2276,   1.7312,   2.8494,   0.2398,  -9.9364,  -0.1958,\n",
      "          -1.5691]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0038, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 4: 0.0316777378320694\n",
      "Batch 5/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 1.7151e-01, -5.7859e-02,  6.3104e-02,  ...,  3.4555e-02,\n",
      "         -1.0289e-01,  4.9265e-02],\n",
      "        [ 1.7396e-01, -2.3382e-02, -1.2235e-01,  ..., -1.3499e-01,\n",
      "         -2.9531e-02, -5.0514e-05],\n",
      "        [ 3.8208e-02, -1.5396e-02,  1.1968e-01,  ...,  6.1940e-03,\n",
      "         -5.8343e-02, -7.3269e-02],\n",
      "        ...,\n",
      "        [ 1.7016e-01, -4.1796e-02, -1.9025e-01,  ..., -9.3052e-02,\n",
      "         -1.8287e-01,  4.2428e-03],\n",
      "        [ 1.3013e-01, -1.1214e-02,  8.2189e-02,  ...,  4.5973e-03,\n",
      "         -2.0750e-01,  6.6868e-02],\n",
      "        [-5.2150e-02, -1.0790e-03,  1.4456e-01,  ...,  1.4211e-01,\n",
      "         -5.8121e-02,  5.2439e-02]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1254, -0.0565,  0.1019,  ...,  0.0493, -0.1145,  0.0432],\n",
      "        [ 0.1514, -0.0102, -0.1526,  ..., -0.1489, -0.0330,  0.0003],\n",
      "        [ 0.0274, -0.0291,  0.1202,  ...,  0.0173, -0.0125, -0.0402],\n",
      "        ...,\n",
      "        [ 0.1222, -0.0335, -0.2189,  ..., -0.1129, -0.1438, -0.0200],\n",
      "        [ 0.1232, -0.0271,  0.0624,  ..., -0.0047, -0.1130,  0.0949],\n",
      "        [-0.1014, -0.0031,  0.2182,  ...,  0.1505, -0.0520,  0.0209]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.7170,   3.6111,   6.4801,  -9.8689,  -9.2080,  -0.4661,   8.5313,\n",
      "          -0.8066,   8.3381,   9.3502,   4.2671,   9.7624,   5.2869,  -0.8218,\n",
      "           9.2298,   3.9205],\n",
      "        [  3.2059,  13.8407,   2.2885,  -4.0630,   4.3717,  -1.5206,  12.1147,\n",
      "           0.8881,   1.9889,   8.6926,  -6.7674,  -0.7313,  -5.8184,  10.6989,\n",
      "          -0.3522, -10.0933],\n",
      "        [  6.4170,   1.5951,  13.7275,   0.3475,  -5.7259,   6.8494,   1.8862,\n",
      "          -1.2780,   8.8202,   4.0888,   7.0471,   9.2696,  10.0351,  -2.0701,\n",
      "           3.7881,   5.6470],\n",
      "        [-10.3583,  -3.6328,  -0.8361,  13.7367,   8.2269,   4.5511,  -9.2307,\n",
      "          -0.2585,  -4.0058,  -6.7878,   1.0564,  -6.0701,  -1.2468,   0.7071,\n",
      "          -8.7800,  -0.0426],\n",
      "        [ -9.2180,   3.7940,  -4.9376,   8.5525,  13.5862,   2.8051,  -2.7173,\n",
      "          -3.4588,  -7.1743,  -4.7950,  -3.0147,  -9.5779,  -6.4552,   5.2359,\n",
      "         -11.6617,  -7.3309],\n",
      "        [  0.0221,  -0.8275,   7.8309,   4.7637,   2.0636,  13.8020,  -4.5787,\n",
      "         -11.2315,   6.1999,  -5.9963,   7.3642,   6.0032,   8.5849,  -1.7620,\n",
      "          -4.9076,   5.7839],\n",
      "        [  7.7825,  11.9017,   2.3983,  -9.0757,  -1.6486,  -4.7450,  13.8474,\n",
      "           3.2454,   3.8631,  11.4104,  -6.0103,   2.5049,  -4.1945,   8.2899,\n",
      "           5.3144,  -7.5189],\n",
      "        [ -0.9431,   0.7503,  -2.4113,  -0.2156,  -2.9715, -10.9770,   3.5353,\n",
      "          13.8530,  -1.6909,   7.5265,  -5.9248,  -3.1871,  -6.3375,   3.8670,\n",
      "           6.0550,  -4.3008],\n",
      "        [  7.0847,   2.1823,   8.8539,  -2.3958,  -6.2783,   5.0422,   3.6010,\n",
      "          -1.1048,  13.8126,   5.1197,   4.0037,  12.3869,   5.6572,   3.5946,\n",
      "           8.4040,   4.7694],\n",
      "        [  9.1459,   8.6018,   3.4912,  -6.3918,  -4.1198,  -6.6276,  11.7649,\n",
      "           6.9669,   4.7801,  13.7628,  -2.7071,   3.4729,  -3.0427,   6.4988,\n",
      "           8.1908,  -4.2883],\n",
      "        [  5.8315,  -6.5185,   7.5633,   0.9256,  -5.2629,   7.4133,  -5.3743,\n",
      "          -5.9633,   4.4548,  -2.0454,  13.6238,   7.3530,  12.0318,  -9.4675,\n",
      "           1.6350,  11.4963],\n",
      "        [  8.8647,  -0.8993,   9.7735,  -4.3853,  -9.3935,   5.0627,   2.0840,\n",
      "          -1.8311,  13.1583,   3.9495,   6.7605,  13.7781,   9.1357,  -1.2769,\n",
      "           9.6954,   8.0445],\n",
      "        [  6.2284,  -5.4526,  10.5170,  -0.7102,  -7.6389,   8.7986,  -3.9150,\n",
      "          -6.2541,   6.4923,  -2.4026,  10.9518,   9.5680,  13.5580,  -9.2568,\n",
      "           2.5395,  11.2133],\n",
      "        [ -1.5996,  10.4671,  -1.8846,   0.7213,   6.0747,  -2.6676,   8.0221,\n",
      "           3.6845,   2.8992,   6.4666,  -8.7899,  -1.9137,  -9.5951,  13.9094,\n",
      "          -0.0508, -10.0759],\n",
      "        [  8.6743,  -1.3961,   2.8857,  -7.2942, -10.8806,  -5.9649,   4.5741,\n",
      "           6.9780,   7.7354,   8.1834,   1.9928,   8.7083,   2.5303,  -0.7152,\n",
      "          13.7461,   4.3653],\n",
      "        [  6.3287,  -8.9414,   6.2082,  -1.3160,  -9.0971,   6.9440,  -5.9673,\n",
      "          -5.6700,   7.2697,  -3.3024,  11.6297,  10.1562,  12.1567,  -9.5939,\n",
      "           4.8444,  13.4977]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7170, 13.8407, 13.7275, 13.7367, 13.5862, 13.8020, 13.8474, 13.8530,\n",
      "        13.8126, 13.7628, 13.6238, 13.7781, 13.5580, 13.9094, 13.7461, 13.4977],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1447, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  3.6111,   6.4801,  -9.8689,  -9.2080,  -0.4661,   8.5313,  -0.8066,\n",
      "           8.3381,   9.3502,   4.2671,   9.7624,   5.2869,  -0.8218,   9.2298,\n",
      "           3.9205],\n",
      "        [  3.2059,   2.2885,  -4.0630,   4.3717,  -1.5206,  12.1147,   0.8881,\n",
      "           1.9889,   8.6926,  -6.7674,  -0.7313,  -5.8184,  10.6989,  -0.3522,\n",
      "         -10.0933],\n",
      "        [  6.4170,   1.5951,   0.3475,  -5.7259,   6.8494,   1.8862,  -1.2780,\n",
      "           8.8202,   4.0888,   7.0471,   9.2696,  10.0351,  -2.0701,   3.7881,\n",
      "           5.6470],\n",
      "        [-10.3583,  -3.6328,  -0.8361,   8.2269,   4.5511,  -9.2307,  -0.2585,\n",
      "          -4.0058,  -6.7878,   1.0564,  -6.0701,  -1.2468,   0.7071,  -8.7800,\n",
      "          -0.0426],\n",
      "        [ -9.2180,   3.7940,  -4.9376,   8.5525,   2.8051,  -2.7173,  -3.4588,\n",
      "          -7.1743,  -4.7950,  -3.0147,  -9.5779,  -6.4552,   5.2359, -11.6617,\n",
      "          -7.3309],\n",
      "        [  0.0221,  -0.8275,   7.8309,   4.7637,   2.0636,  -4.5787, -11.2315,\n",
      "           6.1999,  -5.9963,   7.3642,   6.0032,   8.5849,  -1.7620,  -4.9076,\n",
      "           5.7839],\n",
      "        [  7.7825,  11.9017,   2.3983,  -9.0757,  -1.6486,  -4.7450,   3.2454,\n",
      "           3.8631,  11.4104,  -6.0103,   2.5049,  -4.1945,   8.2899,   5.3144,\n",
      "          -7.5189],\n",
      "        [ -0.9431,   0.7503,  -2.4113,  -0.2156,  -2.9715, -10.9770,   3.5353,\n",
      "          -1.6909,   7.5265,  -5.9248,  -3.1871,  -6.3375,   3.8670,   6.0550,\n",
      "          -4.3008],\n",
      "        [  7.0847,   2.1823,   8.8539,  -2.3958,  -6.2783,   5.0422,   3.6010,\n",
      "          -1.1048,   5.1197,   4.0037,  12.3869,   5.6572,   3.5946,   8.4040,\n",
      "           4.7694],\n",
      "        [  9.1459,   8.6018,   3.4912,  -6.3918,  -4.1198,  -6.6276,  11.7649,\n",
      "           6.9669,   4.7801,  -2.7071,   3.4729,  -3.0427,   6.4988,   8.1908,\n",
      "          -4.2883],\n",
      "        [  5.8315,  -6.5185,   7.5633,   0.9256,  -5.2629,   7.4133,  -5.3743,\n",
      "          -5.9633,   4.4548,  -2.0454,   7.3530,  12.0318,  -9.4675,   1.6350,\n",
      "          11.4963],\n",
      "        [  8.8647,  -0.8993,   9.7735,  -4.3853,  -9.3935,   5.0627,   2.0840,\n",
      "          -1.8311,  13.1583,   3.9495,   6.7605,   9.1357,  -1.2769,   9.6954,\n",
      "           8.0445],\n",
      "        [  6.2284,  -5.4526,  10.5170,  -0.7102,  -7.6389,   8.7986,  -3.9150,\n",
      "          -6.2541,   6.4923,  -2.4026,  10.9518,   9.5680,  -9.2568,   2.5395,\n",
      "          11.2133],\n",
      "        [ -1.5996,  10.4671,  -1.8846,   0.7213,   6.0747,  -2.6676,   8.0221,\n",
      "           3.6845,   2.8992,   6.4666,  -8.7899,  -1.9137,  -9.5951,  -0.0508,\n",
      "         -10.0759],\n",
      "        [  8.6743,  -1.3961,   2.8857,  -7.2942, -10.8806,  -5.9649,   4.5741,\n",
      "           6.9780,   7.7354,   8.1834,   1.9928,   8.7083,   2.5303,  -0.7152,\n",
      "           4.3653],\n",
      "        [  6.3287,  -8.9414,   6.2082,  -1.3160,  -9.0971,   6.9440,  -5.9673,\n",
      "          -5.6700,   7.2697,  -3.3024,  11.6297,  10.1562,  12.1567,  -9.5939,\n",
      "           4.8444]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0092, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 5: 0.07692814618349075\n",
      "Batch 6/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0404,  0.0103,  0.0362,  ...,  0.0861, -0.1289,  0.0612],\n",
      "        [-0.1208,  0.0209,  0.1375,  ...,  0.1209, -0.0464,  0.0407],\n",
      "        [ 0.2031, -0.0176, -0.1015,  ..., -0.0576,  0.0238,  0.0920],\n",
      "        ...,\n",
      "        [ 0.1546, -0.0783, -0.0012,  ...,  0.0159,  0.0126, -0.0052],\n",
      "        [ 0.0563, -0.0459, -0.0455,  ...,  0.0168,  0.1529,  0.0437],\n",
      "        [ 0.0941,  0.0006,  0.1231,  ...,  0.0710, -0.2814, -0.0115]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-4.6817e-02,  1.5255e-02,  9.4422e-02,  ...,  8.7841e-02,\n",
      "         -7.0064e-02,  7.6012e-02],\n",
      "        [-1.5292e-01,  3.3388e-03,  1.2913e-01,  ...,  1.0987e-01,\n",
      "         -3.3677e-03,  5.8019e-04],\n",
      "        [ 1.8752e-01, -5.7478e-02, -1.0660e-01,  ..., -6.5852e-02,\n",
      "         -6.1426e-03,  1.2863e-01],\n",
      "        ...,\n",
      "        [ 1.3899e-01, -9.3970e-02,  1.6265e-02,  ..., -3.3980e-05,\n",
      "          5.9879e-02,  6.2001e-03],\n",
      "        [ 5.3607e-02, -3.7612e-02, -4.7247e-02,  ...,  1.7077e-02,\n",
      "          2.2971e-01,  2.8914e-02],\n",
      "        [ 4.7179e-02, -1.2167e-02,  1.1684e-01,  ...,  6.7867e-02,\n",
      "         -2.8204e-01, -1.9312e-02]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3575e+01,  7.5993e+00,  3.8184e+00,  2.8491e+00, -8.1683e+00,\n",
      "          1.0227e+01,  9.0465e+00,  7.7257e+00, -2.4525e+00, -5.0630e+00,\n",
      "         -4.1833e+00,  1.2368e+01, -2.9653e+00,  4.8542e+00,  1.1196e+00,\n",
      "          3.4930e+00],\n",
      "        [ 1.1476e+01,  1.3492e+01, -4.0916e+00,  1.4343e+00, -6.2180e+00,\n",
      "          4.2451e+00,  5.9477e+00,  6.0191e+00, -3.6708e-03, -1.1396e+00,\n",
      "         -5.3068e+00,  6.5120e+00, -1.1126e+01, -5.2159e-01, -9.1268e-01,\n",
      "          3.4671e+00],\n",
      "        [ 1.6449e+00, -5.7828e+00,  1.3780e+01,  8.6049e+00, -1.5227e+00,\n",
      "          1.2287e+00,  9.0846e+00,  1.3024e+00,  3.0287e-01, -5.2307e-01,\n",
      "         -2.6601e+00,  3.3923e+00,  9.0714e+00,  1.0822e+01,  1.0385e+01,\n",
      "         -4.6994e+00],\n",
      "        [ 2.9996e+00, -8.2629e-01,  9.3305e+00,  1.3409e+01,  1.6780e+00,\n",
      "         -1.7846e+00,  1.1276e+01,  7.6548e+00,  8.2026e+00, -2.7315e+00,\n",
      "         -2.7410e+00,  3.3803e+00,  2.6678e+00,  1.1601e+01,  8.9323e+00,\n",
      "          3.0176e-01],\n",
      "        [-7.7527e+00, -3.9440e+00, -2.6393e+00,  1.6965e+00,  1.3461e+01,\n",
      "         -4.0140e+00, -4.3533e+00,  3.2638e+00,  1.0563e+01, -5.3726e+00,\n",
      "          5.3335e+00, -3.7190e+00,  2.1041e+00, -1.0845e+00, -4.2693e+00,\n",
      "          6.4412e+00],\n",
      "        [ 9.3195e+00,  1.3836e+00,  2.4136e+00, -3.1263e+00, -5.2204e+00,\n",
      "          1.3756e+01,  2.8453e+00,  6.6876e+00, -3.9200e+00, -9.0629e+00,\n",
      "         -7.3518e-01,  1.2168e+01,  1.5044e+00,  2.3905e+00, -4.4671e+00,\n",
      "          6.9066e+00],\n",
      "        [ 9.2179e+00,  3.0584e+00,  9.8457e+00,  1.0771e+01, -4.2115e+00,\n",
      "          4.3335e+00,  1.3566e+01,  8.2643e+00,  3.2402e+00, -3.8642e+00,\n",
      "         -6.7605e+00,  8.2004e+00,  5.7873e-01,  1.1563e+01,  8.5478e+00,\n",
      "          7.0083e-01],\n",
      "        [ 7.5459e+00,  2.6831e+00,  1.9258e+00,  5.7227e+00,  1.9435e+00,\n",
      "          7.9735e+00,  6.9461e+00,  1.3605e+01,  7.7657e+00, -1.2066e+01,\n",
      "         -1.0450e+00,  1.0197e+01, -1.5040e+00,  7.0660e+00, -2.2241e+00,\n",
      "          1.1220e+01],\n",
      "        [-7.2675e-01,  6.9814e-01,  5.6967e-01,  8.6793e+00,  9.1339e+00,\n",
      "         -2.1681e+00,  4.7447e+00,  9.8086e+00,  1.3711e+01, -7.6156e+00,\n",
      "         -1.4602e+00,  6.0702e-01, -2.1184e+00,  5.7971e+00,  5.8559e-01,\n",
      "          8.3770e+00],\n",
      "        [-3.3170e+00,  1.9516e+00, -1.2897e+00, -1.2260e+00, -4.6894e+00,\n",
      "         -9.0554e+00, -2.3204e+00, -1.1132e+01, -6.6658e+00,  1.3932e+01,\n",
      "          6.3837e-01, -7.9984e+00, -1.4318e+00, -5.1662e+00,  4.9948e+00,\n",
      "         -1.2221e+01],\n",
      "        [-3.3584e+00, -4.1533e+00, -2.7792e+00, -2.7793e+00,  4.0096e+00,\n",
      "         -3.3371e-01, -7.1904e+00, -1.1815e+00, -5.8223e-01, -2.8838e-01,\n",
      "          1.3661e+01,  1.5178e+00,  5.4928e+00, -5.6138e+00, -6.9021e+00,\n",
      "          1.3825e+00],\n",
      "        [ 1.0572e+01,  2.4870e+00,  3.8836e+00,  1.0137e+00, -4.3079e+00,\n",
      "          1.1996e+01,  5.4596e+00,  8.6316e+00, -1.6860e+00, -8.5991e+00,\n",
      "          1.3360e+00,  1.3747e+01,  1.9036e+00,  3.8134e+00, -2.8883e+00,\n",
      "          6.2909e+00],\n",
      "        [-5.4921e+00, -1.1849e+01,  8.1772e+00, -2.4968e-01,  3.5945e+00,\n",
      "          1.8093e+00, -2.3450e+00, -3.1348e+00, -2.2815e+00, -1.5424e+00,\n",
      "          6.9200e+00,  1.1023e+00,  1.3789e+01,  2.5873e+00,  1.0795e+00,\n",
      "         -2.6626e+00],\n",
      "        [ 3.7855e+00, -3.2207e+00,  1.0981e+01,  1.0307e+01, -1.0801e+00,\n",
      "          2.5500e+00,  1.0939e+01,  7.3410e+00,  4.3062e+00, -4.8286e+00,\n",
      "         -4.3516e+00,  5.1189e+00,  4.7858e+00,  1.3714e+01,  9.0815e+00,\n",
      "          3.9239e-01],\n",
      "        [ 1.6688e+00, -3.5483e-01,  1.0349e+01,  9.6258e+00, -3.5201e+00,\n",
      "         -3.8462e+00,  1.0322e+01, -6.8038e-01,  6.9773e-01,  4.5212e+00,\n",
      "         -7.5149e+00, -1.4178e+00,  2.2715e+00,  9.6858e+00,  1.3412e+01,\n",
      "         -7.6466e+00],\n",
      "        [ 3.6778e+00,  7.0549e-01, -3.0301e+00, -3.9344e-01,  4.4315e+00,\n",
      "          8.1672e+00,  1.2555e-01,  1.1052e+01,  6.9479e+00, -1.2910e+01,\n",
      "          1.2091e+00,  7.4359e+00, -1.7310e+00,  1.6896e+00, -7.8596e+00,\n",
      "          1.3713e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.5752, 13.4922, 13.7798, 13.4091, 13.4614, 13.7556, 13.5655, 13.6052,\n",
      "        13.7106, 13.9317, 13.6612, 13.7467, 13.7895, 13.7144, 13.4123, 13.7127],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1265, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 7.5993e+00,  3.8184e+00,  2.8491e+00, -8.1683e+00,  1.0227e+01,\n",
      "          9.0465e+00,  7.7257e+00, -2.4525e+00, -5.0630e+00, -4.1833e+00,\n",
      "          1.2368e+01, -2.9653e+00,  4.8542e+00,  1.1196e+00,  3.4930e+00],\n",
      "        [ 1.1476e+01, -4.0916e+00,  1.4343e+00, -6.2180e+00,  4.2451e+00,\n",
      "          5.9477e+00,  6.0191e+00, -3.6708e-03, -1.1396e+00, -5.3068e+00,\n",
      "          6.5120e+00, -1.1126e+01, -5.2159e-01, -9.1268e-01,  3.4671e+00],\n",
      "        [ 1.6449e+00, -5.7828e+00,  8.6049e+00, -1.5227e+00,  1.2287e+00,\n",
      "          9.0846e+00,  1.3024e+00,  3.0287e-01, -5.2307e-01, -2.6601e+00,\n",
      "          3.3923e+00,  9.0714e+00,  1.0822e+01,  1.0385e+01, -4.6994e+00],\n",
      "        [ 2.9996e+00, -8.2629e-01,  9.3305e+00,  1.6780e+00, -1.7846e+00,\n",
      "          1.1276e+01,  7.6548e+00,  8.2026e+00, -2.7315e+00, -2.7410e+00,\n",
      "          3.3803e+00,  2.6678e+00,  1.1601e+01,  8.9323e+00,  3.0176e-01],\n",
      "        [-7.7527e+00, -3.9440e+00, -2.6393e+00,  1.6965e+00, -4.0140e+00,\n",
      "         -4.3533e+00,  3.2638e+00,  1.0563e+01, -5.3726e+00,  5.3335e+00,\n",
      "         -3.7190e+00,  2.1041e+00, -1.0845e+00, -4.2693e+00,  6.4412e+00],\n",
      "        [ 9.3195e+00,  1.3836e+00,  2.4136e+00, -3.1263e+00, -5.2204e+00,\n",
      "          2.8453e+00,  6.6876e+00, -3.9200e+00, -9.0629e+00, -7.3518e-01,\n",
      "          1.2168e+01,  1.5044e+00,  2.3905e+00, -4.4671e+00,  6.9066e+00],\n",
      "        [ 9.2179e+00,  3.0584e+00,  9.8457e+00,  1.0771e+01, -4.2115e+00,\n",
      "          4.3335e+00,  8.2643e+00,  3.2402e+00, -3.8642e+00, -6.7605e+00,\n",
      "          8.2004e+00,  5.7873e-01,  1.1563e+01,  8.5478e+00,  7.0083e-01],\n",
      "        [ 7.5459e+00,  2.6831e+00,  1.9258e+00,  5.7227e+00,  1.9435e+00,\n",
      "          7.9735e+00,  6.9461e+00,  7.7657e+00, -1.2066e+01, -1.0450e+00,\n",
      "          1.0197e+01, -1.5040e+00,  7.0660e+00, -2.2241e+00,  1.1220e+01],\n",
      "        [-7.2675e-01,  6.9814e-01,  5.6967e-01,  8.6793e+00,  9.1339e+00,\n",
      "         -2.1681e+00,  4.7447e+00,  9.8086e+00, -7.6156e+00, -1.4602e+00,\n",
      "          6.0702e-01, -2.1184e+00,  5.7971e+00,  5.8559e-01,  8.3770e+00],\n",
      "        [-3.3170e+00,  1.9516e+00, -1.2897e+00, -1.2260e+00, -4.6894e+00,\n",
      "         -9.0554e+00, -2.3204e+00, -1.1132e+01, -6.6658e+00,  6.3837e-01,\n",
      "         -7.9984e+00, -1.4318e+00, -5.1662e+00,  4.9948e+00, -1.2221e+01],\n",
      "        [-3.3584e+00, -4.1533e+00, -2.7792e+00, -2.7793e+00,  4.0096e+00,\n",
      "         -3.3371e-01, -7.1904e+00, -1.1815e+00, -5.8223e-01, -2.8838e-01,\n",
      "          1.5178e+00,  5.4928e+00, -5.6138e+00, -6.9021e+00,  1.3825e+00],\n",
      "        [ 1.0572e+01,  2.4870e+00,  3.8836e+00,  1.0137e+00, -4.3079e+00,\n",
      "          1.1996e+01,  5.4596e+00,  8.6316e+00, -1.6860e+00, -8.5991e+00,\n",
      "          1.3360e+00,  1.9036e+00,  3.8134e+00, -2.8883e+00,  6.2909e+00],\n",
      "        [-5.4921e+00, -1.1849e+01,  8.1772e+00, -2.4968e-01,  3.5945e+00,\n",
      "          1.8093e+00, -2.3450e+00, -3.1348e+00, -2.2815e+00, -1.5424e+00,\n",
      "          6.9200e+00,  1.1023e+00,  2.5873e+00,  1.0795e+00, -2.6626e+00],\n",
      "        [ 3.7855e+00, -3.2207e+00,  1.0981e+01,  1.0307e+01, -1.0801e+00,\n",
      "          2.5500e+00,  1.0939e+01,  7.3410e+00,  4.3062e+00, -4.8286e+00,\n",
      "         -4.3516e+00,  5.1189e+00,  4.7858e+00,  9.0815e+00,  3.9239e-01],\n",
      "        [ 1.6688e+00, -3.5483e-01,  1.0349e+01,  9.6258e+00, -3.5201e+00,\n",
      "         -3.8462e+00,  1.0322e+01, -6.8038e-01,  6.9773e-01,  4.5212e+00,\n",
      "         -7.5149e+00, -1.4178e+00,  2.2715e+00,  9.6858e+00, -7.6466e+00],\n",
      "        [ 3.6778e+00,  7.0549e-01, -3.0301e+00, -3.9344e-01,  4.4315e+00,\n",
      "          8.1672e+00,  1.2555e-01,  1.1052e+01,  6.9479e+00, -1.2910e+01,\n",
      "          1.2091e+00,  7.4359e+00, -1.7310e+00,  1.6896e+00, -7.8596e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0081, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 6: 0.06727376580238342\n",
      "Batch 7/7: Matrix features: torch.Size([4, 128]), Vector features: torch.Size([4, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 1.2222e-01, -1.9783e-02, -1.5721e-01, -3.6754e-03, -4.0515e-02,\n",
      "          4.5640e-02, -1.3946e-02, -8.4128e-02,  4.0611e-02, -9.7164e-03,\n",
      "          2.0918e-01, -7.9112e-02, -1.5080e-01,  1.8582e-02,  2.4395e-02,\n",
      "          1.2778e-01,  2.2547e-02,  1.3684e-01,  1.0825e-01, -2.8746e-02,\n",
      "          2.6002e-02, -2.3391e-02,  1.1380e-02, -1.1028e-01,  6.5194e-02,\n",
      "         -6.1358e-02,  1.6235e-02, -9.0854e-02, -3.3232e-02, -2.1832e-02,\n",
      "         -3.2358e-02, -3.8966e-02,  6.5780e-02, -4.6087e-02, -2.0657e-02,\n",
      "          9.4731e-02,  6.7956e-02, -3.4793e-03, -7.3391e-02, -1.9268e-01,\n",
      "          1.9042e-02,  1.3311e-01, -1.9029e-01, -1.8604e-01, -1.5286e-01,\n",
      "          1.4596e-02,  2.9945e-02, -2.6206e-04, -2.3624e-02,  7.5738e-02,\n",
      "         -1.4031e-01,  8.3570e-02, -2.3765e-02, -1.2649e-01, -5.9182e-02,\n",
      "         -6.8140e-02,  2.7812e-02,  5.4765e-02, -7.6076e-02, -4.6129e-05,\n",
      "          1.1637e-01,  1.1581e-03,  2.4704e-02, -1.3362e-01,  9.9619e-02,\n",
      "          8.2220e-02, -8.9017e-02,  1.5433e-02,  8.9972e-02, -7.8160e-02,\n",
      "         -1.3899e-02,  1.3854e-01, -9.2223e-02,  1.1747e-01, -5.7218e-02,\n",
      "          8.7124e-02,  1.6959e-01, -1.4940e-02, -1.5795e-02,  7.6112e-02,\n",
      "         -1.0281e-01,  5.2171e-03, -1.5366e-01,  5.0638e-02,  1.0219e-01,\n",
      "          2.0183e-01, -8.4626e-02, -1.2095e-01,  1.6119e-01, -1.0174e-01,\n",
      "          1.0296e-01,  5.9232e-02, -1.8877e-02,  9.0243e-02, -2.6897e-02,\n",
      "         -6.5585e-02,  8.1228e-02, -2.3685e-02,  8.9511e-02, -4.2585e-02,\n",
      "         -1.7936e-01,  3.5723e-02,  9.3263e-02,  1.2309e-01, -1.5754e-02,\n",
      "          1.8199e-01,  4.1527e-02, -7.5570e-02,  3.6721e-02,  4.0859e-03,\n",
      "          1.3905e-02, -1.1073e-01, -6.0132e-02,  2.8444e-02,  5.7524e-02,\n",
      "          3.9234e-02,  1.4878e-01, -4.7107e-02, -7.9954e-02,  3.6319e-02,\n",
      "          8.7642e-02, -6.7844e-02, -1.5102e-02,  3.8257e-02, -8.2270e-02,\n",
      "         -1.0642e-01, -1.1372e-01,  1.9175e-03],\n",
      "        [ 1.7720e-02, -3.0113e-02, -1.7778e-01, -1.0231e-02,  6.3458e-02,\n",
      "         -1.3134e-02, -4.5022e-02,  5.6224e-02,  7.2990e-02,  7.3423e-02,\n",
      "          1.3354e-01, -1.0117e-01, -1.3744e-01, -3.4065e-02,  1.9595e-01,\n",
      "         -8.9662e-03, -3.5858e-03,  1.6850e-01,  7.5963e-02, -8.7869e-02,\n",
      "          6.7423e-02,  1.6664e-02,  5.8997e-02,  2.4681e-02,  2.2988e-01,\n",
      "         -1.0542e-01,  1.4284e-02, -5.9485e-02,  1.0105e-01, -1.2074e-01,\n",
      "         -4.7816e-02,  3.2319e-02, -9.7631e-03, -5.3974e-02, -9.6415e-02,\n",
      "          4.5308e-02, -6.3020e-02, -5.5992e-02,  1.9738e-02, -6.7777e-02,\n",
      "         -1.6880e-02,  2.0683e-02, -8.3078e-02, -8.7697e-02, -1.2147e-01,\n",
      "         -5.6522e-02, -2.9015e-02,  2.9635e-02,  5.5091e-02, -3.5537e-02,\n",
      "         -8.5931e-02,  4.5359e-02, -8.8271e-02, -1.0232e-01, -1.2367e-01,\n",
      "         -4.5307e-02,  1.3707e-02,  6.5944e-02, -8.5865e-02,  3.5693e-02,\n",
      "          2.0526e-01,  8.4121e-03,  6.9251e-03, -2.8842e-02, -7.5805e-02,\n",
      "          1.7418e-01, -3.1715e-03, -6.8985e-03,  6.9112e-02,  4.4421e-02,\n",
      "          7.2364e-02,  3.5551e-02,  7.4842e-03, -1.5792e-02, -7.1942e-02,\n",
      "         -1.1046e-01,  1.9572e-01,  7.2426e-02, -1.2003e-01,  4.1202e-02,\n",
      "         -9.0097e-02, -4.5636e-02, -9.1182e-02, -1.1101e-01, -4.5832e-02,\n",
      "          1.3129e-01, -1.2811e-01, -1.0942e-01,  1.7432e-01,  1.7977e-02,\n",
      "          9.4297e-02,  1.1994e-02, -1.6546e-01, -1.1931e-02, -6.4471e-02,\n",
      "          1.0996e-02, -2.5680e-02, -1.4226e-01,  7.2546e-02, -4.4014e-02,\n",
      "         -1.5747e-02, -2.8973e-02,  1.3655e-01,  1.3146e-01,  1.5420e-02,\n",
      "          7.8603e-02,  5.5327e-02, -1.0037e-01,  9.9173e-02,  1.1037e-01,\n",
      "          9.7318e-02, -9.3686e-02,  6.6938e-03,  2.4847e-02,  9.0164e-02,\n",
      "          1.6736e-01,  1.0944e-01, -1.6170e-02, -1.1496e-01, -9.8755e-02,\n",
      "          1.2507e-01,  2.0060e-02, -7.5178e-03, -5.1465e-02, -1.8649e-01,\n",
      "         -6.3245e-02,  1.2405e-01,  4.2122e-03],\n",
      "        [-1.1714e-01,  4.0537e-02,  1.5082e-01,  3.2363e-02, -6.2306e-02,\n",
      "         -1.4775e-01,  1.0275e-02, -2.7041e-02, -6.0806e-02, -6.9928e-02,\n",
      "         -1.3485e-01,  7.7926e-02,  6.4490e-02,  3.5781e-02, -1.2992e-01,\n",
      "          4.0762e-02,  1.2655e-01,  2.5897e-02,  3.2135e-02,  6.6186e-02,\n",
      "         -1.9335e-01, -5.1066e-02, -5.3526e-02,  1.2820e-01, -1.6520e-01,\n",
      "          3.0229e-02, -4.7236e-02,  1.7438e-02,  6.9410e-02, -5.2251e-03,\n",
      "          2.3056e-01, -4.7218e-02, -6.5995e-02, -7.3510e-02,  3.7899e-02,\n",
      "         -2.5498e-02, -7.9971e-02,  1.4814e-01,  6.1166e-02,  5.5008e-02,\n",
      "         -1.4642e-01, -7.9999e-02,  1.3263e-01,  2.0422e-02,  6.0845e-02,\n",
      "          1.1918e-01,  3.6148e-02, -5.5073e-03, -9.4896e-02, -2.0560e-02,\n",
      "         -4.2150e-03, -4.4482e-02,  3.4169e-02, -2.6723e-02,  1.9802e-01,\n",
      "          4.3211e-02, -8.9577e-03, -1.1305e-01,  6.8894e-02, -2.1687e-02,\n",
      "         -1.1118e-01, -5.7234e-03, -6.4636e-02,  1.4110e-01, -1.6937e-01,\n",
      "         -1.8168e-01,  8.9173e-02,  2.3785e-02, -1.0656e-01, -1.8496e-02,\n",
      "          3.7630e-02, -6.9525e-02,  3.3872e-02, -1.6700e-01,  4.6781e-02,\n",
      "         -7.7581e-02,  1.5003e-02,  1.6918e-01,  6.1493e-04,  2.7977e-02,\n",
      "          2.6246e-02,  6.3050e-02,  1.0083e-01, -7.6585e-02,  2.0505e-02,\n",
      "         -1.7873e-01,  1.2520e-04,  1.0392e-01, -8.2310e-02, -1.1351e-01,\n",
      "         -1.7618e-01,  2.9054e-02,  5.3981e-02,  8.9911e-02,  2.9680e-02,\n",
      "          5.3760e-02,  9.0739e-02, -3.6169e-02, -1.4212e-01,  1.8300e-02,\n",
      "          1.5907e-01,  5.9970e-02, -2.9330e-02, -1.5691e-01, -1.3485e-02,\n",
      "         -4.0487e-02,  5.4756e-02,  1.4811e-01, -3.9888e-02,  8.3601e-02,\n",
      "          7.8344e-02, -2.2370e-02,  1.2244e-01,  2.1596e-02, -7.5482e-04,\n",
      "         -2.9537e-02, -7.9104e-02, -5.4031e-02,  8.6686e-02,  6.4795e-02,\n",
      "          7.0257e-02,  5.6264e-03,  4.1922e-03,  1.0679e-01, -3.4667e-02,\n",
      "          4.2177e-02, -6.1088e-02, -1.1029e-01],\n",
      "        [-8.3355e-02,  6.4848e-02,  3.9949e-02, -1.4138e-02, -5.9931e-02,\n",
      "         -1.8046e-01, -7.4102e-03, -2.6891e-02, -6.8526e-02, -9.4597e-02,\n",
      "         -9.2997e-02,  6.5778e-02,  8.8657e-02,  1.3498e-02, -1.8630e-02,\n",
      "         -3.1575e-02,  8.3351e-02,  4.4927e-02, -5.5943e-02, -5.6421e-02,\n",
      "         -1.2968e-01, -1.3425e-02, -4.5333e-02,  1.1213e-01,  1.5664e-02,\n",
      "         -6.3599e-02, -2.2469e-02,  4.7897e-02,  1.5072e-01, -4.3670e-02,\n",
      "          7.5058e-02,  6.2688e-02, -7.9571e-02, -1.3998e-01,  5.8960e-02,\n",
      "          1.1519e-02, -7.6893e-02,  1.2549e-02,  1.1983e-01,  2.7530e-02,\n",
      "         -1.2356e-01, -1.7292e-01,  1.2327e-01,  1.2915e-01,  1.1216e-01,\n",
      "          1.1281e-01, -8.8498e-03,  7.2937e-02, -2.3435e-02, -2.8664e-02,\n",
      "          3.3991e-02, -2.4256e-02,  1.0171e-01, -8.4935e-02,  7.7906e-02,\n",
      "         -6.1854e-03, -1.3371e-02, -5.5552e-02, -3.3154e-02,  7.9193e-02,\n",
      "         -7.2943e-02, -6.3476e-02, -3.9741e-02,  1.9554e-01, -2.1878e-01,\n",
      "         -7.9362e-02,  1.3839e-01,  2.0864e-02, -8.6086e-02,  1.1083e-02,\n",
      "          1.4914e-01, -1.0537e-01,  1.8008e-01, -2.0070e-01,  5.8847e-02,\n",
      "         -1.2513e-01,  8.6928e-03,  2.1200e-01, -7.3488e-02,  3.6552e-02,\n",
      "         -6.7996e-02,  7.3064e-03,  2.5281e-02, -1.7457e-01,  5.0051e-03,\n",
      "         -7.4028e-02, -7.7592e-02,  1.1514e-01, -6.4291e-03, -6.7899e-02,\n",
      "         -9.2389e-02,  2.1752e-04,  5.3665e-02, -3.2092e-02, -1.9149e-03,\n",
      "          6.6793e-03,  1.5878e-02, -1.1928e-01, -9.8316e-02,  2.2010e-02,\n",
      "          1.3704e-01, -5.2325e-03,  3.8364e-02, -1.0910e-01,  6.0722e-02,\n",
      "         -7.6343e-02,  1.0943e-01,  1.3345e-01,  2.8328e-02,  1.5479e-01,\n",
      "          5.3091e-02, -4.2558e-02,  1.8486e-01, -1.5960e-02,  7.7282e-02,\n",
      "         -3.2999e-03,  1.9525e-02, -6.4324e-03,  1.3652e-01, -4.9365e-02,\n",
      "          7.0581e-02,  6.0376e-03, -1.4905e-01,  9.4096e-02, -9.9850e-02,\n",
      "          1.8240e-02, -1.0508e-01, -9.7511e-03]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 7.2056e-02, -1.8909e-02, -1.8511e-01, -3.3929e-02, -4.1007e-02,\n",
      "          2.6176e-02, -2.1479e-03, -8.9567e-02,  5.7812e-02,  2.9013e-02,\n",
      "          2.3817e-01, -9.8844e-02, -1.1514e-01,  1.8114e-02,  5.4618e-02,\n",
      "          8.7860e-02,  6.8903e-03,  1.8375e-01,  1.1071e-01, -8.4653e-02,\n",
      "          5.3646e-02, -3.2241e-02,  2.7815e-02, -7.1272e-02,  9.3612e-02,\n",
      "         -2.4346e-02,  3.1719e-03, -5.7491e-02, -2.0267e-02, -2.0852e-02,\n",
      "         -6.1514e-02,  1.8425e-02,  7.0133e-02, -7.2099e-02, -3.2658e-03,\n",
      "          8.1943e-02, -2.7655e-02,  3.3338e-02, -9.8388e-02, -2.2239e-01,\n",
      "          2.2858e-02,  1.0654e-01, -1.3770e-01, -1.2449e-01, -1.4828e-01,\n",
      "          4.3840e-02,  1.4818e-02, -2.4132e-02, -2.4011e-02,  4.9498e-02,\n",
      "         -1.4022e-01,  6.1657e-02, -2.4992e-02, -1.3385e-01, -1.0932e-01,\n",
      "         -4.3373e-02,  5.4015e-03,  5.9915e-02, -4.8034e-02,  3.0428e-02,\n",
      "          1.4834e-01, -1.9667e-02,  3.7339e-02, -9.5222e-02,  1.5454e-01,\n",
      "          7.7440e-02, -8.6237e-02,  2.3499e-02,  9.0722e-02, -5.7996e-02,\n",
      "         -1.7323e-02,  1.3122e-01, -5.5200e-02,  6.2400e-02, -7.1142e-02,\n",
      "          6.4284e-02,  1.5178e-01, -3.2787e-02,  1.4606e-02,  8.8991e-02,\n",
      "         -7.2446e-02, -2.5528e-02, -1.5756e-01,  3.3504e-02,  1.0945e-01,\n",
      "          2.0415e-01, -7.5162e-02, -1.7633e-01,  2.1209e-01, -1.0933e-01,\n",
      "          1.4188e-01,  3.2037e-02, -1.0579e-02,  7.6552e-02, -3.2810e-02,\n",
      "         -6.8444e-02,  7.5751e-02, -7.0949e-02,  8.9594e-02, -4.8636e-02,\n",
      "         -1.3793e-01, -8.1733e-03,  5.8706e-02,  1.5159e-01,  6.7129e-03,\n",
      "          1.3199e-01,  4.1498e-02, -6.6835e-02,  2.9023e-02,  2.3916e-02,\n",
      "          2.4959e-02, -1.0796e-01, -1.2982e-01,  1.4590e-02,  3.8221e-02,\n",
      "          1.3374e-02,  1.6850e-01, -3.6261e-02, -8.5384e-02,  4.6715e-02,\n",
      "          7.4294e-02, -7.5591e-02, -1.2886e-02,  8.8507e-03, -1.0377e-01,\n",
      "         -9.1368e-02, -6.8285e-02,  3.0835e-02],\n",
      "        [-2.4668e-02, -1.6253e-02, -1.7732e-01, -4.8151e-02,  5.6917e-02,\n",
      "         -5.4406e-02, -4.4481e-02,  7.1569e-02,  6.4459e-02,  9.8488e-02,\n",
      "          1.3432e-01, -1.0283e-01, -9.6249e-02, -4.1996e-02,  1.9111e-01,\n",
      "         -1.0992e-02,  8.2193e-04,  1.4313e-01,  4.1733e-02, -9.3388e-02,\n",
      "          5.8777e-02,  2.3844e-02,  5.2706e-02,  1.6759e-02,  2.7082e-01,\n",
      "         -1.1491e-01, -9.7416e-03, -5.4342e-02,  9.8507e-02, -1.0835e-01,\n",
      "         -6.3102e-02,  2.9907e-02, -4.1052e-02, -6.9700e-02, -7.7977e-02,\n",
      "          4.6012e-02, -6.8206e-02, -8.9299e-02,  6.4767e-02, -4.6407e-02,\n",
      "         -6.7604e-03,  3.9852e-03, -6.0514e-02, -2.2881e-02, -1.1113e-01,\n",
      "         -2.6498e-02, -1.4081e-02,  3.1587e-02,  4.9186e-02, -4.3735e-02,\n",
      "         -9.8658e-02,  1.2889e-02, -7.7128e-02, -8.3260e-02, -1.7735e-01,\n",
      "         -5.2521e-02,  3.9172e-02,  6.7567e-02, -5.2155e-02,  4.0520e-02,\n",
      "          2.1753e-01, -2.3656e-02,  2.2394e-02, -2.5253e-02, -1.0274e-01,\n",
      "          1.5362e-01, -1.9692e-02,  1.7256e-03,  5.8951e-02,  7.0848e-02,\n",
      "          9.3311e-02,  3.7018e-02,  3.1520e-02, -2.9844e-02, -4.0023e-02,\n",
      "         -1.0300e-01,  1.6417e-01,  6.1403e-02, -9.2258e-02, -6.3779e-03,\n",
      "         -8.7734e-02, -4.4424e-02, -6.3301e-02, -1.3033e-01, -5.1026e-02,\n",
      "          1.0169e-01, -1.4048e-01, -1.1263e-01,  1.8917e-01,  3.6267e-02,\n",
      "          8.7599e-02, -2.6618e-03, -8.2706e-02, -3.5087e-02, -7.0088e-02,\n",
      "          2.6294e-02, -3.5108e-02, -1.8866e-01,  6.4421e-02, -6.3419e-02,\n",
      "          7.6577e-03, -4.3358e-02,  1.3413e-01,  8.2634e-02,  2.7613e-02,\n",
      "          7.5863e-02,  3.5100e-02, -7.2997e-02,  1.1502e-01,  1.0619e-01,\n",
      "          1.0034e-01, -1.2823e-01,  7.4279e-02,  3.9834e-02,  9.1297e-02,\n",
      "          1.5781e-01,  1.5901e-01,  4.6445e-03, -8.1264e-02, -9.7152e-02,\n",
      "          1.4246e-01,  1.4329e-02, -1.7307e-02, -4.0960e-02, -1.8239e-01,\n",
      "         -9.5079e-02,  1.0699e-01, -1.4645e-02],\n",
      "        [-1.3386e-01,  7.1074e-02,  1.4022e-01,  4.7313e-02, -7.4616e-02,\n",
      "         -1.4029e-01, -4.5889e-03, -3.6273e-02, -7.4338e-02, -6.0605e-02,\n",
      "         -1.0797e-01,  5.0682e-02,  5.1284e-02,  7.8355e-03, -1.2771e-01,\n",
      "          6.3295e-02,  9.6249e-02,  1.2846e-03,  2.4073e-02,  8.3406e-02,\n",
      "         -1.8543e-01, -4.9564e-02, -7.1546e-02,  1.0465e-01, -1.5590e-01,\n",
      "          3.0646e-03, -7.6668e-02,  1.6260e-02,  7.0366e-02,  1.7641e-02,\n",
      "          1.6361e-01, -3.4310e-02, -4.4463e-02, -8.0573e-02,  2.7630e-02,\n",
      "         -1.3165e-02, -6.1754e-02,  1.2037e-01,  6.1533e-02,  5.3217e-02,\n",
      "         -1.7692e-01, -9.9892e-02,  1.5772e-01,  3.9831e-02,  4.0552e-02,\n",
      "          1.3395e-01, -2.5103e-04, -2.5804e-02, -8.7689e-02, -2.0237e-02,\n",
      "          1.1750e-02, -4.6663e-02,  2.0249e-02, -3.1630e-02,  1.9819e-01,\n",
      "          1.2623e-02, -6.5347e-03, -1.2398e-01,  4.2117e-02, -1.5383e-02,\n",
      "         -1.3533e-01, -2.7071e-02, -5.8623e-02,  1.4263e-01, -1.5528e-01,\n",
      "         -1.6947e-01,  7.6464e-02,  3.2079e-02, -1.2186e-01,  9.9617e-03,\n",
      "          6.4207e-02, -7.6114e-02,  3.9544e-02, -1.7911e-01,  6.0532e-02,\n",
      "         -5.4449e-02,  3.9629e-02,  2.4520e-01, -1.0121e-02,  5.8959e-02,\n",
      "          3.4347e-02,  9.6948e-02,  8.6522e-02, -6.3899e-02,  6.1259e-02,\n",
      "         -1.7715e-01, -1.9024e-02,  1.0818e-01, -1.0852e-01, -1.2074e-01,\n",
      "         -1.6194e-01,  4.6480e-02,  5.9542e-02,  1.0137e-01,  4.0944e-03,\n",
      "          7.4297e-02,  6.5511e-02, -3.8093e-02, -1.4697e-01, -1.9321e-02,\n",
      "          1.5226e-01,  6.3214e-02, -3.8780e-02, -9.9031e-02, -1.0059e-02,\n",
      "         -1.2740e-02,  3.1126e-02,  1.4983e-01, -4.5865e-02,  9.7131e-02,\n",
      "          8.2033e-02, -2.2215e-02,  1.1731e-01,  5.0806e-02,  4.5018e-03,\n",
      "         -8.6636e-03, -1.0559e-01, -4.2580e-02,  6.5508e-02,  9.4658e-02,\n",
      "          8.3536e-02, -8.4339e-04,  1.0321e-02,  1.0771e-01, -3.1476e-02,\n",
      "          1.3602e-02, -4.6015e-02, -8.9729e-02],\n",
      "        [-1.2263e-01,  3.5323e-02,  2.0339e-02, -3.3831e-02, -3.3590e-02,\n",
      "         -1.7219e-01, -1.9902e-02,  1.4233e-02, -4.6858e-02, -1.0029e-01,\n",
      "         -4.6337e-02,  5.8640e-02,  1.1872e-01, -3.6819e-03,  3.1769e-02,\n",
      "         -5.9314e-02,  7.9589e-02,  5.4821e-02, -3.1763e-02, -9.4339e-02,\n",
      "         -1.5921e-01,  2.0389e-02, -3.3950e-02,  1.1798e-01,  4.8634e-02,\n",
      "         -7.8183e-02, -7.6816e-03,  4.2087e-02,  1.6415e-01, -4.1769e-02,\n",
      "          3.2484e-02,  8.6478e-02, -1.0722e-01, -1.2611e-01,  3.7738e-02,\n",
      "          2.7766e-02, -9.8629e-02, -4.7653e-03,  1.2894e-01,  3.8738e-02,\n",
      "         -1.1462e-01, -1.4381e-01,  1.2690e-01,  1.2220e-01,  9.0085e-02,\n",
      "          1.3119e-01,  6.4850e-03,  9.8389e-02, -2.6401e-02, -9.8562e-03,\n",
      "          3.7155e-02, -3.5309e-02,  1.0272e-01, -5.5078e-02,  5.2339e-02,\n",
      "          2.4887e-02, -1.1118e-02, -8.0468e-02, -6.7796e-02,  9.2273e-02,\n",
      "         -2.0720e-02, -3.7096e-02, -7.6977e-03,  2.0651e-01, -2.7014e-01,\n",
      "         -4.7862e-02,  1.3388e-01,  3.5550e-02, -2.9421e-02,  3.5902e-02,\n",
      "          1.5222e-01, -8.4558e-02,  1.3379e-01, -2.1474e-01,  9.9266e-02,\n",
      "         -1.1164e-01,  1.2737e-02,  2.1730e-01, -1.1361e-01,  1.1850e-02,\n",
      "         -6.4383e-02,  2.0882e-02,  2.1335e-02, -1.7468e-01, -3.5830e-02,\n",
      "         -7.4620e-02, -7.2975e-02,  1.0228e-01,  2.9979e-02, -3.6174e-02,\n",
      "         -5.6019e-02, -1.8713e-02,  2.6628e-02, -8.9034e-02, -2.3877e-02,\n",
      "         -8.4854e-03,  1.2535e-02, -1.7583e-01, -1.1687e-01, -1.4519e-03,\n",
      "          1.0155e-01,  3.5108e-02,  1.7050e-02, -1.0257e-01,  5.2210e-03,\n",
      "         -4.2632e-02,  9.3128e-02,  9.2744e-02,  4.7034e-02,  1.6282e-01,\n",
      "          5.0817e-02, -2.8991e-02,  1.9240e-01, -5.1059e-02,  8.1379e-02,\n",
      "          3.3382e-03,  3.4566e-02, -1.3905e-04,  7.5880e-02, -4.8840e-02,\n",
      "          6.9253e-02, -1.0137e-02, -1.5057e-01,  6.7624e-02, -9.3568e-02,\n",
      "          1.8283e-02, -3.3449e-02, -3.9726e-02]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.5470,  6.8172, -6.6512, -5.6917],\n",
      "        [ 8.8493, 13.7755, -5.6926,  1.1402],\n",
      "        [-7.5723, -5.4282, 13.8985,  9.0622],\n",
      "        [-5.6441,  0.8757, 10.3443, 13.6552]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.5470, 13.7755, 13.8985, 13.6552], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0130, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 6.8172, -6.6512, -5.6917],\n",
      "        [ 8.8493, -5.6926,  1.1402],\n",
      "        [-7.5723, -5.4282,  9.0622],\n",
      "        [-5.6441,  0.8757, 10.3443]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0043, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 7: 0.008694525808095932\n",
      "Epoch [8/10], Loss: 0.0607\n",
      "Batch 1/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1822, -0.0412, -0.0754,  ..., -0.0111, -0.1469,  0.0348],\n",
      "        [ 0.1137,  0.0207,  0.0435,  ..., -0.0677, -0.1707, -0.0760],\n",
      "        [ 0.1472, -0.0220,  0.0899,  ...,  0.0437, -0.2733,  0.0733],\n",
      "        ...,\n",
      "        [ 0.1458, -0.0527,  0.0331,  ...,  0.0054,  0.0116,  0.0844],\n",
      "        [ 0.1735, -0.0512, -0.1115,  ..., -0.0603,  0.0367,  0.0581],\n",
      "        [ 0.1432, -0.0319, -0.0945,  ..., -0.0683,  0.0494,  0.0377]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1436, -0.0663, -0.0805,  ..., -0.0540, -0.1657,  0.0856],\n",
      "        [ 0.0658,  0.0175,  0.0482,  ..., -0.0804, -0.1912, -0.0385],\n",
      "        [ 0.0625, -0.0303,  0.1032,  ...,  0.0960, -0.2298,  0.0554],\n",
      "        ...,\n",
      "        [ 0.0943, -0.0569,  0.0279,  ...,  0.0392,  0.0780,  0.1100],\n",
      "        [ 0.1085, -0.0442, -0.1396,  ..., -0.0620,  0.1335,  0.0669],\n",
      "        [ 0.0766, -0.0403, -0.1083,  ..., -0.0797,  0.1382,  0.0199]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3808e+01,  7.7375e+00,  7.2766e+00, -4.0128e+00, -1.2802e+00,\n",
      "         -9.3980e+00,  1.1676e+00, -6.5974e+00,  3.6965e+00,  2.4139e+00,\n",
      "          5.5061e+00, -1.7481e+00,  5.8450e+00,  2.9579e-01,  3.9904e+00,\n",
      "         -3.4466e+00],\n",
      "        [ 6.4139e+00,  1.3911e+01,  6.3739e+00, -1.8780e+00, -3.9378e+00,\n",
      "         -7.7021e+00, -3.9703e+00, -7.0616e+00, -1.3144e+00,  1.2617e+00,\n",
      "          7.4272e-01, -5.0612e+00,  5.7815e-01, -7.0382e+00, -6.3730e+00,\n",
      "         -7.0863e+00],\n",
      "        [ 8.0762e+00,  6.8311e+00,  1.3701e+01, -6.0406e+00, -1.0785e+01,\n",
      "         -2.0454e+00, -4.0034e+00, -6.5894e+00,  1.1922e+00,  6.0301e+00,\n",
      "         -5.0508e+00, -7.6053e+00,  7.8361e+00,  3.2513e+00, -2.9353e+00,\n",
      "         -4.6298e+00],\n",
      "        [-5.2304e+00, -4.8841e-01, -4.1706e+00,  1.3180e+01,  9.1292e-01,\n",
      "          5.4384e+00, -9.6726e+00, -3.3705e+00, -9.8471e+00, -2.6566e+00,\n",
      "          9.5911e-01,  9.1940e+00, -1.2562e+00, -4.8538e+00, -6.6410e+00,\n",
      "         -5.1432e+00],\n",
      "        [-2.6692e+00, -3.1240e+00, -1.1289e+01,  3.5565e+00,  1.3872e+01,\n",
      "         -7.7939e-01,  3.5657e+00,  3.5159e+00, -1.4832e+00, -4.5090e+00,\n",
      "          1.0716e+01,  6.8394e+00, -5.2561e+00, -6.7181e+00,  2.7521e+00,\n",
      "          4.8580e-01],\n",
      "        [-9.0753e+00, -8.2770e+00, -8.3081e-01,  4.9404e+00, -1.4780e+00,\n",
      "          1.3872e+01, -6.7644e+00,  2.6544e+00, -7.1824e+00,  1.2452e+00,\n",
      "         -4.7652e+00,  3.0924e+00,  3.5515e+00,  1.9588e+00, -5.0962e+00,\n",
      "         -1.6881e+00],\n",
      "        [ 1.4237e+00, -2.6773e+00, -4.1999e+00, -7.5134e+00,  2.9160e+00,\n",
      "         -6.7689e+00,  1.3763e+01,  6.1611e+00,  1.0704e+01, -7.8777e-01,\n",
      "         -3.7130e-01, -3.0566e+00, -5.8646e+00,  5.6386e+00,  1.0979e+01,\n",
      "          1.0524e+01],\n",
      "        [-4.9057e+00, -6.3217e+00, -5.1778e+00, -4.1693e+00,  1.1434e-01,\n",
      "          2.1578e+00,  4.8728e+00,  1.3560e+01,  8.9988e+00, -9.9893e+00,\n",
      "         -3.1090e+00, -5.1084e+00, -1.2384e-01,  3.7824e+00,  4.3716e+00,\n",
      "          1.0737e+01],\n",
      "        [ 4.7585e+00,  1.4491e-01,  5.6607e-01, -9.2079e+00, -2.1717e+00,\n",
      "         -7.8888e+00,  9.7605e+00,  7.2058e+00,  1.3781e+01, -5.2042e+00,\n",
      "         -1.3653e+00, -7.6238e+00, -1.0151e+00,  5.5806e+00,  8.9665e+00,\n",
      "          1.0156e+01],\n",
      "        [ 4.3146e+00,  1.9540e+00,  9.1689e+00, -2.7620e+00, -6.0798e+00,\n",
      "          3.1117e-01,  1.5518e-01, -9.3993e+00, -3.1948e+00,  1.3290e+01,\n",
      "         -4.6566e+00, -4.8455e-01,  2.3946e+00,  5.5462e+00,  2.0989e-01,\n",
      "         -4.3473e+00],\n",
      "        [ 3.6827e+00,  1.1424e+00, -5.7838e+00,  4.3920e+00,  1.1764e+01,\n",
      "         -2.8150e+00, -1.1045e+00, -1.9121e+00, -3.1160e+00, -3.3464e+00,\n",
      "          1.3791e+01,  7.1448e+00, -1.8065e-01, -8.3924e+00,  8.9686e-01,\n",
      "         -4.9781e+00],\n",
      "        [-1.5903e+00, -4.6772e+00, -6.7543e+00,  1.1753e+01,  5.7975e+00,\n",
      "          2.6197e+00, -2.2753e+00, -3.6284e+00, -6.7856e+00,  8.3769e-01,\n",
      "          5.1881e+00,  1.3680e+01, -2.6090e+00, -3.3950e-01,  2.3124e+00,\n",
      "         -1.4905e+00],\n",
      "        [ 6.9473e+00,  1.0045e+00,  8.4353e+00, -1.8968e+00, -5.6416e+00,\n",
      "          3.0161e+00, -6.2586e+00, -8.6759e-01,  1.7762e-01, -6.4918e-01,\n",
      "         -5.0230e-01, -3.2443e+00,  1.3462e+01,  3.1364e+00, -1.1460e+00,\n",
      "         -3.2207e+00],\n",
      "        [ 2.3090e+00, -6.2204e+00,  3.8395e+00, -5.3055e+00, -6.8924e+00,\n",
      "          2.3753e-03,  7.0430e+00,  3.4846e+00,  8.3559e+00,  2.6560e+00,\n",
      "         -7.4370e+00, -2.8604e+00,  2.2527e+00,  1.3269e+01,  9.2998e+00,\n",
      "          9.2590e+00],\n",
      "        [ 6.0751e+00, -4.2925e+00, -2.2195e+00, -4.2942e+00,  1.2090e+00,\n",
      "         -6.6291e+00,  1.0924e+01,  4.4771e+00,  1.0943e+01, -2.0902e+00,\n",
      "          1.4245e+00,  5.0467e-01, -6.7709e-01,  8.7757e+00,  1.3614e+01,\n",
      "          1.0201e+01],\n",
      "        [-1.0381e+00, -5.5048e+00, -3.1345e+00, -5.4039e+00, -2.5002e+00,\n",
      "         -3.1306e+00,  9.9656e+00,  9.7307e+00,  1.2018e+01, -5.3213e+00,\n",
      "         -5.0897e+00, -4.1672e+00, -3.0010e+00,  9.0003e+00,  9.7364e+00,\n",
      "          1.3538e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.8078, 13.9108, 13.7013, 13.1804, 13.8722, 13.8721, 13.7629, 13.5605,\n",
      "        13.7806, 13.2901, 13.7906, 13.6797, 13.4622, 13.2691, 13.6143, 13.5376],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0684, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 7.7375e+00,  7.2766e+00, -4.0128e+00, -1.2802e+00, -9.3980e+00,\n",
      "          1.1676e+00, -6.5974e+00,  3.6965e+00,  2.4139e+00,  5.5061e+00,\n",
      "         -1.7481e+00,  5.8450e+00,  2.9579e-01,  3.9904e+00, -3.4466e+00],\n",
      "        [ 6.4139e+00,  6.3739e+00, -1.8780e+00, -3.9378e+00, -7.7021e+00,\n",
      "         -3.9703e+00, -7.0616e+00, -1.3144e+00,  1.2617e+00,  7.4272e-01,\n",
      "         -5.0612e+00,  5.7815e-01, -7.0382e+00, -6.3730e+00, -7.0863e+00],\n",
      "        [ 8.0762e+00,  6.8311e+00, -6.0406e+00, -1.0785e+01, -2.0454e+00,\n",
      "         -4.0034e+00, -6.5894e+00,  1.1922e+00,  6.0301e+00, -5.0508e+00,\n",
      "         -7.6053e+00,  7.8361e+00,  3.2513e+00, -2.9353e+00, -4.6298e+00],\n",
      "        [-5.2304e+00, -4.8841e-01, -4.1706e+00,  9.1292e-01,  5.4384e+00,\n",
      "         -9.6726e+00, -3.3705e+00, -9.8471e+00, -2.6566e+00,  9.5911e-01,\n",
      "          9.1940e+00, -1.2562e+00, -4.8538e+00, -6.6410e+00, -5.1432e+00],\n",
      "        [-2.6692e+00, -3.1240e+00, -1.1289e+01,  3.5565e+00, -7.7939e-01,\n",
      "          3.5657e+00,  3.5159e+00, -1.4832e+00, -4.5090e+00,  1.0716e+01,\n",
      "          6.8394e+00, -5.2561e+00, -6.7181e+00,  2.7521e+00,  4.8580e-01],\n",
      "        [-9.0753e+00, -8.2770e+00, -8.3081e-01,  4.9404e+00, -1.4780e+00,\n",
      "         -6.7644e+00,  2.6544e+00, -7.1824e+00,  1.2452e+00, -4.7652e+00,\n",
      "          3.0924e+00,  3.5515e+00,  1.9588e+00, -5.0962e+00, -1.6881e+00],\n",
      "        [ 1.4237e+00, -2.6773e+00, -4.1999e+00, -7.5134e+00,  2.9160e+00,\n",
      "         -6.7689e+00,  6.1611e+00,  1.0704e+01, -7.8777e-01, -3.7130e-01,\n",
      "         -3.0566e+00, -5.8646e+00,  5.6386e+00,  1.0979e+01,  1.0524e+01],\n",
      "        [-4.9057e+00, -6.3217e+00, -5.1778e+00, -4.1693e+00,  1.1434e-01,\n",
      "          2.1578e+00,  4.8728e+00,  8.9988e+00, -9.9893e+00, -3.1090e+00,\n",
      "         -5.1084e+00, -1.2384e-01,  3.7824e+00,  4.3716e+00,  1.0737e+01],\n",
      "        [ 4.7585e+00,  1.4491e-01,  5.6607e-01, -9.2079e+00, -2.1717e+00,\n",
      "         -7.8888e+00,  9.7605e+00,  7.2058e+00, -5.2042e+00, -1.3653e+00,\n",
      "         -7.6238e+00, -1.0151e+00,  5.5806e+00,  8.9665e+00,  1.0156e+01],\n",
      "        [ 4.3146e+00,  1.9540e+00,  9.1689e+00, -2.7620e+00, -6.0798e+00,\n",
      "          3.1117e-01,  1.5518e-01, -9.3993e+00, -3.1948e+00, -4.6566e+00,\n",
      "         -4.8455e-01,  2.3946e+00,  5.5462e+00,  2.0989e-01, -4.3473e+00],\n",
      "        [ 3.6827e+00,  1.1424e+00, -5.7838e+00,  4.3920e+00,  1.1764e+01,\n",
      "         -2.8150e+00, -1.1045e+00, -1.9121e+00, -3.1160e+00, -3.3464e+00,\n",
      "          7.1448e+00, -1.8065e-01, -8.3924e+00,  8.9686e-01, -4.9781e+00],\n",
      "        [-1.5903e+00, -4.6772e+00, -6.7543e+00,  1.1753e+01,  5.7975e+00,\n",
      "          2.6197e+00, -2.2753e+00, -3.6284e+00, -6.7856e+00,  8.3769e-01,\n",
      "          5.1881e+00, -2.6090e+00, -3.3950e-01,  2.3124e+00, -1.4905e+00],\n",
      "        [ 6.9473e+00,  1.0045e+00,  8.4353e+00, -1.8968e+00, -5.6416e+00,\n",
      "          3.0161e+00, -6.2586e+00, -8.6759e-01,  1.7762e-01, -6.4918e-01,\n",
      "         -5.0230e-01, -3.2443e+00,  3.1364e+00, -1.1460e+00, -3.2207e+00],\n",
      "        [ 2.3090e+00, -6.2204e+00,  3.8395e+00, -5.3055e+00, -6.8924e+00,\n",
      "          2.3753e-03,  7.0430e+00,  3.4846e+00,  8.3559e+00,  2.6560e+00,\n",
      "         -7.4370e+00, -2.8604e+00,  2.2527e+00,  9.2998e+00,  9.2590e+00],\n",
      "        [ 6.0751e+00, -4.2925e+00, -2.2195e+00, -4.2942e+00,  1.2090e+00,\n",
      "         -6.6291e+00,  1.0924e+01,  4.4771e+00,  1.0943e+01, -2.0902e+00,\n",
      "          1.4245e+00,  5.0467e-01, -6.7709e-01,  8.7757e+00,  1.0201e+01],\n",
      "        [-1.0381e+00, -5.5048e+00, -3.1345e+00, -5.4039e+00, -2.5002e+00,\n",
      "         -3.1306e+00,  9.9656e+00,  9.7307e+00,  1.2018e+01, -5.3213e+00,\n",
      "         -5.0897e+00, -4.1672e+00, -3.0010e+00,  9.0003e+00,  9.7364e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0044, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 1: 0.036424510180950165\n",
      "Batch 2/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.0738,  0.0761,  0.0925,  ...,  0.0248, -0.0876, -0.0979],\n",
      "        [ 0.1103, -0.0167, -0.2227,  ..., -0.1495,  0.0017, -0.0267],\n",
      "        [ 0.1184,  0.0039, -0.1504,  ..., -0.1046, -0.2317,  0.0070],\n",
      "        ...,\n",
      "        [ 0.0873,  0.0212,  0.1572,  ...,  0.0088, -0.1114,  0.0173],\n",
      "        [ 0.0893,  0.0120, -0.0099,  ..., -0.0227, -0.2279, -0.0151],\n",
      "        [-0.0012,  0.0230,  0.1726,  ...,  0.0656,  0.0905, -0.0231]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-1.0210e-01,  7.6994e-02,  1.3297e-01,  ...,  7.1877e-03,\n",
      "         -9.2151e-02, -7.2829e-02],\n",
      "        [ 8.1293e-02, -3.2564e-02, -1.9415e-01,  ..., -1.2925e-01,\n",
      "          2.1788e-02,  2.2187e-02],\n",
      "        [ 1.1965e-01, -1.8489e-02, -1.3692e-01,  ..., -8.2175e-02,\n",
      "         -2.3287e-01, -1.7476e-02],\n",
      "        ...,\n",
      "        [ 4.7107e-02,  2.9026e-02,  1.3142e-01,  ...,  5.4389e-03,\n",
      "         -9.5434e-02,  1.8434e-02],\n",
      "        [ 4.8482e-02,  1.5216e-04, -4.8819e-03,  ..., -3.1416e-02,\n",
      "         -1.7344e-01, -2.3514e-02],\n",
      "        [-4.4219e-02, -8.4777e-03,  1.3968e-01,  ...,  3.8991e-02,\n",
      "          4.8192e-02,  3.9459e-02]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3867e+01, -3.4674e+00, -8.8732e-01,  3.1812e+00,  1.1659e+01,\n",
      "          9.6096e+00, -7.7387e-01, -2.5146e+00, -2.5371e+00, -5.6243e+00,\n",
      "         -5.1419e+00, -3.3710e+00, -2.4848e+00,  4.0433e+00,  8.5540e+00,\n",
      "          6.5048e+00],\n",
      "        [-1.7452e+00,  1.3866e+01,  7.3810e+00,  3.7475e+00, -7.7580e+00,\n",
      "         -4.4608e+00, -1.5686e+00, -2.5452e+00,  5.3590e-01,  9.0767e+00,\n",
      "          7.9669e+00,  6.7567e-01,  9.6669e+00, -4.9702e+00,  4.8878e+00,\n",
      "         -2.4430e+00],\n",
      "        [ 6.0163e-01,  7.2741e+00,  1.3933e+01,  7.9050e+00,  5.4717e-01,\n",
      "          1.6685e+00, -6.5212e-01, -9.2440e+00,  1.0869e+01,  6.5962e+00,\n",
      "          8.0729e+00,  1.1025e+01,  1.3341e+01, -4.8010e-01,  4.9177e+00,\n",
      "         -8.3672e+00],\n",
      "        [ 5.1049e+00,  2.3666e+00,  7.0951e+00,  1.3800e+01,  3.8827e+00,\n",
      "         -2.0377e+00, -7.5523e+00, -1.3084e+00,  4.4464e+00, -3.6838e+00,\n",
      "          1.0008e+01,  4.8713e+00,  7.6684e+00,  5.9109e-01,  2.3363e+00,\n",
      "         -7.8113e+00],\n",
      "        [ 1.1440e+01, -8.2394e+00,  9.7840e-01,  3.1242e+00,  1.3899e+01,\n",
      "          1.1265e+01,  2.8368e-01, -4.9239e+00,  3.0237e+00, -6.9139e+00,\n",
      "         -5.7125e+00,  2.1638e+00, -1.9700e+00,  5.6035e+00,  5.5902e+00,\n",
      "          2.8304e+00],\n",
      "        [ 9.1399e+00, -5.6229e+00,  2.3139e+00, -2.3078e+00,  1.1591e+01,\n",
      "          1.3677e+01,  4.4622e+00, -8.3309e+00,  4.1436e+00, -1.8642e+00,\n",
      "         -8.4278e+00,  2.9324e+00, -9.9618e-01,  4.3377e+00,  7.3682e+00,\n",
      "          5.4818e+00],\n",
      "        [-1.9067e+00,  3.7711e-01,  2.1448e+00, -5.5559e+00, -3.3018e-01,\n",
      "          5.1787e+00,  1.3619e+01, -7.9824e+00,  6.9664e-01,  9.2867e+00,\n",
      "         -4.7954e+00,  3.7732e+00,  4.4081e-01,  8.8350e+00,  4.4605e+00,\n",
      "          3.2345e+00],\n",
      "        [-3.8154e+00, -1.4234e+00, -9.0828e+00, -1.9021e+00, -5.7657e+00,\n",
      "         -9.0728e+00, -5.9547e+00,  1.3894e+01, -8.2253e+00, -4.0729e+00,\n",
      "          5.7773e-01, -8.7129e+00, -6.5227e+00, -2.9024e+00, -9.9214e+00,\n",
      "          4.3952e-02],\n",
      "        [-1.8340e+00, -2.6186e-01,  1.1079e+01,  4.3938e+00,  2.7419e+00,\n",
      "          2.9459e+00, -1.3961e+00, -7.9014e+00,  1.3875e+01,  1.6344e+00,\n",
      "          4.4281e+00,  1.2564e+01,  9.1221e+00, -1.6407e+00, -2.6577e-01,\n",
      "         -9.2337e+00],\n",
      "        [-5.3579e+00,  9.1404e+00,  7.5328e+00, -2.1384e+00, -6.6400e+00,\n",
      "         -5.3797e-01,  7.9937e+00, -6.3047e+00,  3.3059e+00,  1.3964e+01,\n",
      "          2.4262e+00,  5.1795e+00,  7.9204e+00,  2.3308e+00,  2.9207e+00,\n",
      "         -2.2317e+00],\n",
      "        [-3.8333e+00,  7.4568e+00,  8.2648e+00,  1.0745e+01, -5.4616e+00,\n",
      "         -8.5367e+00, -6.0837e+00, -3.3953e-01,  5.0785e+00,  2.0263e+00,\n",
      "          1.3742e+01,  6.2809e+00,  1.0126e+01, -2.8025e+00, -1.2865e+00,\n",
      "         -1.0689e+01],\n",
      "        [-2.3986e+00,  1.3170e-02,  1.1733e+01,  5.5603e+00,  2.3231e+00,\n",
      "          2.3816e+00,  1.1274e+00, -8.8704e+00,  1.3279e+01,  3.2559e+00,\n",
      "          5.6018e+00,  1.3840e+01,  9.7960e+00,  1.8201e+00,  2.0181e-01,\n",
      "         -9.8697e+00],\n",
      "        [ 1.0577e+00,  8.1849e+00,  1.3775e+01,  8.3360e+00,  1.1856e-01,\n",
      "          1.2687e+00, -1.1264e+00, -8.5809e+00,  1.0000e+01,  6.8393e+00,\n",
      "          8.5218e+00,  1.0159e+01,  1.3545e+01, -6.2979e-01,  5.2437e+00,\n",
      "         -7.9831e+00],\n",
      "        [ 2.8782e+00, -5.9777e+00,  8.2299e-01,  4.1361e-01,  6.2172e+00,\n",
      "          5.6951e+00,  9.1562e+00, -3.4801e+00,  8.3003e-01,  2.4559e+00,\n",
      "         -3.9789e+00,  4.2990e+00, -1.3101e+00,  1.3614e+01,  7.0708e-01,\n",
      "          9.7399e-02],\n",
      "        [ 9.2587e+00,  4.4211e+00,  5.4146e+00,  2.6542e+00,  5.8773e+00,\n",
      "          8.7060e+00,  4.4813e+00, -1.0441e+01,  5.7788e-01,  3.0617e+00,\n",
      "         -1.4090e+00,  1.1372e+00,  4.0529e+00,  2.8798e+00,  1.3823e+01,\n",
      "          5.3731e+00],\n",
      "        [ 6.1352e+00, -3.5406e+00, -8.9939e+00, -9.1072e+00,  4.0350e+00,\n",
      "          7.2373e+00,  5.9844e+00,  8.1701e-01, -9.2741e+00, -1.2314e+00,\n",
      "         -1.1882e+01, -9.4334e+00, -9.6337e+00,  2.9341e+00,  4.9986e+00,\n",
      "          1.3524e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.8671, 13.8665, 13.9331, 13.8000, 13.8987, 13.6765, 13.6188, 13.8945,\n",
      "        13.8750, 13.9636, 13.7416, 13.8397, 13.5450, 13.6142, 13.8235, 13.5244],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1742, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[-3.4674e+00, -8.8732e-01,  3.1812e+00,  1.1659e+01,  9.6096e+00,\n",
      "         -7.7387e-01, -2.5146e+00, -2.5371e+00, -5.6243e+00, -5.1419e+00,\n",
      "         -3.3710e+00, -2.4848e+00,  4.0433e+00,  8.5540e+00,  6.5048e+00],\n",
      "        [-1.7452e+00,  7.3810e+00,  3.7475e+00, -7.7580e+00, -4.4608e+00,\n",
      "         -1.5686e+00, -2.5452e+00,  5.3590e-01,  9.0767e+00,  7.9669e+00,\n",
      "          6.7567e-01,  9.6669e+00, -4.9702e+00,  4.8878e+00, -2.4430e+00],\n",
      "        [ 6.0163e-01,  7.2741e+00,  7.9050e+00,  5.4717e-01,  1.6685e+00,\n",
      "         -6.5212e-01, -9.2440e+00,  1.0869e+01,  6.5962e+00,  8.0729e+00,\n",
      "          1.1025e+01,  1.3341e+01, -4.8010e-01,  4.9177e+00, -8.3672e+00],\n",
      "        [ 5.1049e+00,  2.3666e+00,  7.0951e+00,  3.8827e+00, -2.0377e+00,\n",
      "         -7.5523e+00, -1.3084e+00,  4.4464e+00, -3.6838e+00,  1.0008e+01,\n",
      "          4.8713e+00,  7.6684e+00,  5.9109e-01,  2.3363e+00, -7.8113e+00],\n",
      "        [ 1.1440e+01, -8.2394e+00,  9.7840e-01,  3.1242e+00,  1.1265e+01,\n",
      "          2.8368e-01, -4.9239e+00,  3.0237e+00, -6.9139e+00, -5.7125e+00,\n",
      "          2.1638e+00, -1.9700e+00,  5.6035e+00,  5.5902e+00,  2.8304e+00],\n",
      "        [ 9.1399e+00, -5.6229e+00,  2.3139e+00, -2.3078e+00,  1.1591e+01,\n",
      "          4.4622e+00, -8.3309e+00,  4.1436e+00, -1.8642e+00, -8.4278e+00,\n",
      "          2.9324e+00, -9.9618e-01,  4.3377e+00,  7.3682e+00,  5.4818e+00],\n",
      "        [-1.9067e+00,  3.7711e-01,  2.1448e+00, -5.5559e+00, -3.3018e-01,\n",
      "          5.1787e+00, -7.9824e+00,  6.9664e-01,  9.2867e+00, -4.7954e+00,\n",
      "          3.7732e+00,  4.4081e-01,  8.8350e+00,  4.4605e+00,  3.2345e+00],\n",
      "        [-3.8154e+00, -1.4234e+00, -9.0828e+00, -1.9021e+00, -5.7657e+00,\n",
      "         -9.0728e+00, -5.9547e+00, -8.2253e+00, -4.0729e+00,  5.7773e-01,\n",
      "         -8.7129e+00, -6.5227e+00, -2.9024e+00, -9.9214e+00,  4.3952e-02],\n",
      "        [-1.8340e+00, -2.6186e-01,  1.1079e+01,  4.3938e+00,  2.7419e+00,\n",
      "          2.9459e+00, -1.3961e+00, -7.9014e+00,  1.6344e+00,  4.4281e+00,\n",
      "          1.2564e+01,  9.1221e+00, -1.6407e+00, -2.6577e-01, -9.2337e+00],\n",
      "        [-5.3579e+00,  9.1404e+00,  7.5328e+00, -2.1384e+00, -6.6400e+00,\n",
      "         -5.3797e-01,  7.9937e+00, -6.3047e+00,  3.3059e+00,  2.4262e+00,\n",
      "          5.1795e+00,  7.9204e+00,  2.3308e+00,  2.9207e+00, -2.2317e+00],\n",
      "        [-3.8333e+00,  7.4568e+00,  8.2648e+00,  1.0745e+01, -5.4616e+00,\n",
      "         -8.5367e+00, -6.0837e+00, -3.3953e-01,  5.0785e+00,  2.0263e+00,\n",
      "          6.2809e+00,  1.0126e+01, -2.8025e+00, -1.2865e+00, -1.0689e+01],\n",
      "        [-2.3986e+00,  1.3170e-02,  1.1733e+01,  5.5603e+00,  2.3231e+00,\n",
      "          2.3816e+00,  1.1274e+00, -8.8704e+00,  1.3279e+01,  3.2559e+00,\n",
      "          5.6018e+00,  9.7960e+00,  1.8201e+00,  2.0181e-01, -9.8697e+00],\n",
      "        [ 1.0577e+00,  8.1849e+00,  1.3775e+01,  8.3360e+00,  1.1856e-01,\n",
      "          1.2687e+00, -1.1264e+00, -8.5809e+00,  1.0000e+01,  6.8393e+00,\n",
      "          8.5218e+00,  1.0159e+01, -6.2979e-01,  5.2437e+00, -7.9831e+00],\n",
      "        [ 2.8782e+00, -5.9777e+00,  8.2299e-01,  4.1361e-01,  6.2172e+00,\n",
      "          5.6951e+00,  9.1562e+00, -3.4801e+00,  8.3003e-01,  2.4559e+00,\n",
      "         -3.9789e+00,  4.2990e+00, -1.3101e+00,  7.0708e-01,  9.7399e-02],\n",
      "        [ 9.2587e+00,  4.4211e+00,  5.4146e+00,  2.6542e+00,  5.8773e+00,\n",
      "          8.7060e+00,  4.4813e+00, -1.0441e+01,  5.7788e-01,  3.0617e+00,\n",
      "         -1.4090e+00,  1.1372e+00,  4.0529e+00,  2.8798e+00,  5.3731e+00],\n",
      "        [ 6.1352e+00, -3.5406e+00, -8.9939e+00, -9.1072e+00,  4.0350e+00,\n",
      "          7.2373e+00,  5.9844e+00,  8.1701e-01, -9.2741e+00, -1.2314e+00,\n",
      "         -1.1882e+01, -9.4334e+00, -9.6337e+00,  2.9341e+00,  4.9986e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0110, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 2: 0.09259456396102905\n",
      "Batch 3/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.2026, -0.0128, -0.0290,  ..., -0.0812, -0.2053, -0.0445],\n",
      "        [-0.0193,  0.0394,  0.0166,  ...,  0.0070, -0.1836,  0.0110],\n",
      "        [ 0.1813, -0.0110, -0.0251,  ..., -0.0674, -0.2868,  0.0264],\n",
      "        ...,\n",
      "        [ 0.0692, -0.0651, -0.0927,  ...,  0.0708, -0.2085,  0.0297],\n",
      "        [ 0.0914, -0.0300,  0.1740,  ...,  0.0339, -0.1757, -0.0376],\n",
      "        [ 0.0838,  0.0019, -0.1148,  ..., -0.0639, -0.2078,  0.1044]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0987, -0.0091, -0.0244,  ..., -0.0825, -0.1950, -0.0529],\n",
      "        [-0.0286,  0.0129,  0.0270,  ...,  0.0200, -0.0986, -0.0058],\n",
      "        [ 0.1063, -0.0090, -0.0235,  ..., -0.0798, -0.2589,  0.0051],\n",
      "        ...,\n",
      "        [ 0.0227, -0.0528, -0.0428,  ...,  0.0751, -0.1545, -0.0198],\n",
      "        [ 0.0428, -0.0480,  0.1770,  ...,  0.0816, -0.1866, -0.0748],\n",
      "        [ 0.0640, -0.0027, -0.0924,  ..., -0.0716, -0.1373,  0.0980]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3734e+01,  6.1271e-01,  1.3319e+01,  7.5421e+00,  2.5103e+00,\n",
      "         -5.7924e+00, -4.1539e+00, -7.6431e+00,  7.5568e+00, -4.7507e-01,\n",
      "          7.0267e+00,  6.4324e+00, -4.4378e+00, -1.8050e+00,  6.9496e+00,\n",
      "          2.9298e+00],\n",
      "        [ 1.7642e+00,  1.3785e+01,  2.7919e+00, -1.8005e+00, -8.9423e+00,\n",
      "          1.5036e+00,  2.2858e+00, -3.6614e+00,  3.5787e+00,  8.6321e-01,\n",
      "          2.9713e+00, -5.8779e+00,  8.4297e+00,  4.0755e+00,  3.1463e+00,\n",
      "          7.4710e+00],\n",
      "        [ 1.2925e+01,  1.5620e+00,  1.3751e+01,  8.1266e+00,  3.2001e+00,\n",
      "         -6.2675e+00, -5.5455e+00, -6.3361e+00,  7.9742e+00,  2.2340e+00,\n",
      "          5.2675e+00,  4.5286e+00, -1.5954e+00,  1.3035e+00,  7.2235e+00,\n",
      "          4.8226e+00],\n",
      "        [ 7.8588e+00, -1.3585e+00,  8.2110e+00,  1.3908e+01,  8.6031e+00,\n",
      "         -1.0426e+01, -4.4530e+00,  3.9683e+00,  1.2107e+01,  7.7932e+00,\n",
      "          7.3140e+00,  5.5275e+00, -7.2248e+00,  3.2534e+00, -2.4263e+00,\n",
      "          5.1832e+00],\n",
      "        [ 4.0239e+00, -8.4192e+00,  4.4169e+00,  9.9850e+00,  1.3650e+01,\n",
      "         -9.2040e+00, -7.6779e+00,  4.6622e+00,  6.2304e+00,  4.1364e+00,\n",
      "          9.9713e-01,  9.8045e+00, -8.6224e+00, -6.7844e-01, -2.7965e+00,\n",
      "          2.6163e+00],\n",
      "        [-5.1525e+00,  2.3806e+00, -5.3043e+00, -1.0358e+01, -9.0051e+00,\n",
      "          1.3829e+01,  8.7601e+00, -2.2143e+00, -9.3205e+00, -1.4044e+00,\n",
      "         -2.5931e+00, -9.4895e+00,  8.4630e+00,  3.8332e+00,  6.5948e+00,\n",
      "         -8.0466e+00],\n",
      "        [-4.7572e+00,  3.7717e+00, -5.8689e+00, -5.1657e+00, -8.6080e+00,\n",
      "          1.0332e+01,  1.3797e+01,  2.4037e+00, -1.8716e+00,  2.3413e+00,\n",
      "          6.2477e+00, -8.9838e+00,  3.1811e+00,  3.4171e+00, -7.2551e-01,\n",
      "         -5.6592e+00],\n",
      "        [-8.0817e+00, -2.4842e+00, -7.5203e+00,  4.9002e+00,  5.6984e+00,\n",
      "         -1.1043e+00,  3.4716e+00,  1.3900e+01,  3.6005e+00,  1.0019e+01,\n",
      "          1.4953e+00, -3.1866e+00, -2.2395e+00,  6.9677e+00, -9.5621e+00,\n",
      "          6.6112e-02],\n",
      "        [ 6.7322e+00,  4.1552e+00,  7.4076e+00,  1.1863e+01,  4.4042e+00,\n",
      "         -8.9411e+00, -1.1959e+00,  3.7155e+00,  1.3795e+01,  8.1967e+00,\n",
      "          9.8258e+00,  2.7925e+00, -4.0917e+00,  3.8107e+00, -3.6076e+00,\n",
      "          8.6952e+00],\n",
      "        [-8.8255e-01,  1.1147e+00,  5.9696e-01,  8.4509e+00,  5.0930e+00,\n",
      "         -1.8034e+00,  3.0573e+00,  1.0203e+01,  8.2713e+00,  1.3788e+01,\n",
      "          5.6874e+00, -4.4761e+00,  3.6657e-01,  1.1168e+01, -3.0509e+00,\n",
      "          2.9036e+00],\n",
      "        [ 5.8218e+00,  8.8992e-01,  4.3741e+00,  8.1131e+00,  1.5075e+00,\n",
      "         -3.2772e+00,  5.9891e+00,  2.5894e+00,  1.0529e+01,  5.1610e+00,\n",
      "          1.3638e+01,  2.3745e+00, -7.0441e+00,  2.3010e-01, -3.4350e+00,\n",
      "          1.8487e+00],\n",
      "        [ 6.7798e+00, -6.1517e+00,  5.8290e+00,  6.5882e+00,  8.6426e+00,\n",
      "         -9.7966e+00, -8.2283e+00, -2.6432e+00,  4.8258e+00, -4.4940e+00,\n",
      "          1.8604e+00,  1.3831e+01, -1.0099e+01, -9.1042e+00, -2.2873e+00,\n",
      "          3.7848e+00],\n",
      "        [-2.0111e+00,  9.4138e+00, -1.4041e-03, -7.6585e+00, -9.4380e+00,\n",
      "          8.0205e+00,  2.2843e+00, -4.5746e+00, -4.8593e+00,  3.7581e-01,\n",
      "         -4.2076e+00, -9.9473e+00,  1.3445e+01,  6.5392e+00,  7.8124e+00,\n",
      "          1.3698e+00],\n",
      "        [-1.2238e+00,  4.3910e+00,  1.1718e+00,  4.6447e+00,  1.5933e+00,\n",
      "          1.1959e+00,  1.3521e+00,  6.9774e+00,  4.2201e+00,  1.2135e+01,\n",
      "          7.8824e-01, -8.0094e+00,  6.0696e+00,  1.3707e+01,  1.8261e+00,\n",
      "          2.4673e+00],\n",
      "        [ 7.0928e+00,  2.4679e+00,  7.8677e+00, -2.7865e+00, -3.1921e+00,\n",
      "          4.3774e+00, -2.1738e+00, -9.2415e+00, -3.3628e+00, -2.1131e+00,\n",
      "         -2.1461e+00, -1.9871e+00,  5.6868e+00,  2.7082e+00,  1.3764e+01,\n",
      "         -2.0996e+00],\n",
      "        [ 3.3678e+00,  7.9084e+00,  5.6797e+00,  6.1585e+00,  2.0626e+00,\n",
      "         -8.6008e+00, -6.0120e+00,  6.7050e-01,  9.2198e+00,  4.1311e+00,\n",
      "          2.0708e+00,  2.5432e+00,  2.5378e+00,  2.3539e+00, -2.6009e+00,\n",
      "          1.3603e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7337, 13.7854, 13.7510, 13.9081, 13.6500, 13.8294, 13.7973, 13.8997,\n",
      "        13.7948, 13.7880, 13.6376, 13.8312, 13.4450, 13.7068, 13.7641, 13.6034],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1078, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 6.1271e-01,  1.3319e+01,  7.5421e+00,  2.5103e+00, -5.7924e+00,\n",
      "         -4.1539e+00, -7.6431e+00,  7.5568e+00, -4.7507e-01,  7.0267e+00,\n",
      "          6.4324e+00, -4.4378e+00, -1.8050e+00,  6.9496e+00,  2.9298e+00],\n",
      "        [ 1.7642e+00,  2.7919e+00, -1.8005e+00, -8.9423e+00,  1.5036e+00,\n",
      "          2.2858e+00, -3.6614e+00,  3.5787e+00,  8.6321e-01,  2.9713e+00,\n",
      "         -5.8779e+00,  8.4297e+00,  4.0755e+00,  3.1463e+00,  7.4710e+00],\n",
      "        [ 1.2925e+01,  1.5620e+00,  8.1266e+00,  3.2001e+00, -6.2675e+00,\n",
      "         -5.5455e+00, -6.3361e+00,  7.9742e+00,  2.2340e+00,  5.2675e+00,\n",
      "          4.5286e+00, -1.5954e+00,  1.3035e+00,  7.2235e+00,  4.8226e+00],\n",
      "        [ 7.8588e+00, -1.3585e+00,  8.2110e+00,  8.6031e+00, -1.0426e+01,\n",
      "         -4.4530e+00,  3.9683e+00,  1.2107e+01,  7.7932e+00,  7.3140e+00,\n",
      "          5.5275e+00, -7.2248e+00,  3.2534e+00, -2.4263e+00,  5.1832e+00],\n",
      "        [ 4.0239e+00, -8.4192e+00,  4.4169e+00,  9.9850e+00, -9.2040e+00,\n",
      "         -7.6779e+00,  4.6622e+00,  6.2304e+00,  4.1364e+00,  9.9713e-01,\n",
      "          9.8045e+00, -8.6224e+00, -6.7844e-01, -2.7965e+00,  2.6163e+00],\n",
      "        [-5.1525e+00,  2.3806e+00, -5.3043e+00, -1.0358e+01, -9.0051e+00,\n",
      "          8.7601e+00, -2.2143e+00, -9.3205e+00, -1.4044e+00, -2.5931e+00,\n",
      "         -9.4895e+00,  8.4630e+00,  3.8332e+00,  6.5948e+00, -8.0466e+00],\n",
      "        [-4.7572e+00,  3.7717e+00, -5.8689e+00, -5.1657e+00, -8.6080e+00,\n",
      "          1.0332e+01,  2.4037e+00, -1.8716e+00,  2.3413e+00,  6.2477e+00,\n",
      "         -8.9838e+00,  3.1811e+00,  3.4171e+00, -7.2551e-01, -5.6592e+00],\n",
      "        [-8.0817e+00, -2.4842e+00, -7.5203e+00,  4.9002e+00,  5.6984e+00,\n",
      "         -1.1043e+00,  3.4716e+00,  3.6005e+00,  1.0019e+01,  1.4953e+00,\n",
      "         -3.1866e+00, -2.2395e+00,  6.9677e+00, -9.5621e+00,  6.6112e-02],\n",
      "        [ 6.7322e+00,  4.1552e+00,  7.4076e+00,  1.1863e+01,  4.4042e+00,\n",
      "         -8.9411e+00, -1.1959e+00,  3.7155e+00,  8.1967e+00,  9.8258e+00,\n",
      "          2.7925e+00, -4.0917e+00,  3.8107e+00, -3.6076e+00,  8.6952e+00],\n",
      "        [-8.8255e-01,  1.1147e+00,  5.9696e-01,  8.4509e+00,  5.0930e+00,\n",
      "         -1.8034e+00,  3.0573e+00,  1.0203e+01,  8.2713e+00,  5.6874e+00,\n",
      "         -4.4761e+00,  3.6657e-01,  1.1168e+01, -3.0509e+00,  2.9036e+00],\n",
      "        [ 5.8218e+00,  8.8992e-01,  4.3741e+00,  8.1131e+00,  1.5075e+00,\n",
      "         -3.2772e+00,  5.9891e+00,  2.5894e+00,  1.0529e+01,  5.1610e+00,\n",
      "          2.3745e+00, -7.0441e+00,  2.3010e-01, -3.4350e+00,  1.8487e+00],\n",
      "        [ 6.7798e+00, -6.1517e+00,  5.8290e+00,  6.5882e+00,  8.6426e+00,\n",
      "         -9.7966e+00, -8.2283e+00, -2.6432e+00,  4.8258e+00, -4.4940e+00,\n",
      "          1.8604e+00, -1.0099e+01, -9.1042e+00, -2.2873e+00,  3.7848e+00],\n",
      "        [-2.0111e+00,  9.4138e+00, -1.4041e-03, -7.6585e+00, -9.4380e+00,\n",
      "          8.0205e+00,  2.2843e+00, -4.5746e+00, -4.8593e+00,  3.7581e-01,\n",
      "         -4.2076e+00, -9.9473e+00,  6.5392e+00,  7.8124e+00,  1.3698e+00],\n",
      "        [-1.2238e+00,  4.3910e+00,  1.1718e+00,  4.6447e+00,  1.5933e+00,\n",
      "          1.1959e+00,  1.3521e+00,  6.9774e+00,  4.2201e+00,  1.2135e+01,\n",
      "          7.8824e-01, -8.0094e+00,  6.0696e+00,  1.8261e+00,  2.4673e+00],\n",
      "        [ 7.0928e+00,  2.4679e+00,  7.8677e+00, -2.7865e+00, -3.1921e+00,\n",
      "          4.3774e+00, -2.1738e+00, -9.2415e+00, -3.3628e+00, -2.1131e+00,\n",
      "         -2.1461e+00, -1.9871e+00,  5.6868e+00,  2.7082e+00, -2.0996e+00],\n",
      "        [ 3.3678e+00,  7.9084e+00,  5.6797e+00,  6.1585e+00,  2.0626e+00,\n",
      "         -8.6008e+00, -6.0120e+00,  6.7050e-01,  9.2198e+00,  4.1311e+00,\n",
      "          2.0708e+00,  2.5432e+00,  2.5378e+00,  2.3539e+00, -2.6009e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0071, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 3: 0.05747365951538086\n",
      "Batch 4/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1241, -0.0531, -0.0462,  ...,  0.0342, -0.1887,  0.0169],\n",
      "        [ 0.1590, -0.0055, -0.0937,  ..., -0.1389, -0.0241, -0.0811],\n",
      "        [-0.0905,  0.0428,  0.0925,  ...,  0.0570,  0.2485,  0.0517],\n",
      "        ...,\n",
      "        [-0.0035, -0.0062,  0.1449,  ...,  0.1147, -0.0301, -0.0355],\n",
      "        [-0.0470, -0.0041,  0.1287,  ...,  0.1713, -0.0594,  0.0582],\n",
      "        [-0.0143,  0.0517, -0.0176,  ...,  0.0060, -0.2580, -0.0804]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.1073, -0.0559, -0.0031,  ...,  0.0531, -0.2094,  0.0037],\n",
      "        [ 0.1094, -0.0083, -0.1118,  ..., -0.1741, -0.0308, -0.0900],\n",
      "        [-0.1174,  0.0376,  0.0810,  ...,  0.0484,  0.2717,  0.0848],\n",
      "        ...,\n",
      "        [-0.0806,  0.0048,  0.1576,  ...,  0.0854,  0.0322, -0.0171],\n",
      "        [-0.0953, -0.0452,  0.1357,  ...,  0.1099, -0.0817,  0.0647],\n",
      "        [-0.0482,  0.0300,  0.0056,  ...,  0.0455, -0.2095, -0.0908]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3746e+01,  1.7412e+00, -9.1033e+00, -1.1382e+01,  2.9035e+00,\n",
      "          1.3097e+01, -5.5044e+00,  4.9402e+00,  3.5570e+00,  2.7529e+00,\n",
      "          4.6795e+00,  4.1438e+00,  6.0747e+00,  3.8407e+00,  1.5415e+00,\n",
      "          4.4126e+00],\n",
      "        [ 1.3825e+00,  1.3652e+01, -6.8668e+00,  2.7624e+00,  1.2127e+01,\n",
      "          3.3626e+00,  8.7905e+00,  5.1238e+00,  1.6568e+00,  1.3049e+01,\n",
      "         -2.5677e-01,  3.0020e+00, -7.6552e+00, -6.0027e+00, -1.2760e+01,\n",
      "          2.3526e+00],\n",
      "        [-8.0143e+00, -6.8466e+00,  1.3834e+01,  5.3479e+00, -9.8131e+00,\n",
      "         -1.0312e+01,  5.6072e-01, -5.5992e+00, -7.3282e+00, -5.3632e+00,\n",
      "          3.6763e+00, -8.8659e+00,  6.9135e-01,  3.0873e+00,  4.7958e+00,\n",
      "         -8.9409e+00],\n",
      "        [-1.1262e+01,  1.6933e+00,  5.9016e+00,  1.3798e+01,  1.7939e+00,\n",
      "         -1.0973e+01,  7.5692e+00, -3.1562e+00, -1.4891e-01,  1.3229e+00,\n",
      "         -5.4352e+00,  7.2810e-02, -8.2466e+00, -4.4589e+00, -5.6650e+00,\n",
      "         -2.8851e+00],\n",
      "        [ 3.0437e+00,  1.0524e+01, -1.0275e+01,  1.3213e+00,  1.3595e+01,\n",
      "          5.1148e+00,  4.8854e+00,  3.9888e+00,  8.0697e+00,  9.3241e+00,\n",
      "         -3.2386e+00,  8.3547e+00, -8.0414e+00, -6.7747e+00, -1.0691e+01,\n",
      "          8.8987e+00],\n",
      "        [ 1.2764e+01,  2.6320e+00, -1.0707e+01, -1.0568e+01,  4.4840e+00,\n",
      "          1.3642e+01, -4.0015e+00,  4.6508e+00,  4.7386e+00,  3.3235e+00,\n",
      "          1.8942e+00,  6.6747e+00,  5.1962e+00,  1.8381e+00,  4.7595e-01,\n",
      "          5.1255e+00],\n",
      "        [-4.5411e+00,  1.0080e+01, -1.3445e+00,  7.2705e+00,  7.4915e+00,\n",
      "         -1.9489e+00,  1.3722e+01, -2.6703e+00, -4.5450e+00,  1.1398e+01,\n",
      "         -5.4985e+00,  3.9796e+00, -9.1059e+00, -9.8965e+00, -1.1134e+01,\n",
      "         -4.0013e+00],\n",
      "        [ 5.3629e+00,  5.7048e+00, -6.6267e+00, -3.4726e+00,  4.6839e+00,\n",
      "          6.1259e+00, -4.2302e+00,  1.3695e+01,  4.4126e+00,  3.0374e+00,\n",
      "          4.9725e+00, -3.3779e+00,  4.7832e+00,  7.4799e+00, -2.0223e+00,\n",
      "          2.7124e+00],\n",
      "        [ 1.8114e+00,  1.3592e-01, -5.9606e+00,  8.4864e-01,  6.8410e+00,\n",
      "          1.6739e+00, -5.0751e+00,  3.5998e+00,  1.3635e+01, -2.2840e+00,\n",
      "         -1.5989e+00,  6.1750e+00, -3.1096e+00, -1.2919e-02, -1.8495e+00,\n",
      "          1.1999e+01],\n",
      "        [ 1.7996e+00,  1.2869e+01, -5.8178e+00,  2.4000e+00,  1.0666e+01,\n",
      "          3.8729e+00,  1.0439e+01,  2.8707e+00, -1.2079e+00,  1.3856e+01,\n",
      "         -6.7492e-01,  3.5761e+00, -7.1242e+00, -6.6481e+00, -1.2190e+01,\n",
      "         -6.6805e-01],\n",
      "        [ 4.8706e+00,  2.0781e+00,  3.5744e+00, -4.2217e+00, -1.9391e+00,\n",
      "          2.4393e+00, -2.7766e+00,  6.3748e+00, -2.5710e+00,  2.5842e+00,\n",
      "          1.3284e+01, -9.0639e+00,  4.2795e+00,  8.4478e+00,  1.4359e-01,\n",
      "         -4.2639e+00],\n",
      "        [ 2.7096e+00,  2.3302e+00, -8.7133e+00,  6.1528e-01,  7.8789e+00,\n",
      "          4.6702e+00,  2.7992e+00, -3.9052e+00,  7.6841e+00,  2.6155e+00,\n",
      "         -8.8347e+00,  1.3809e+01, -5.2902e+00, -8.1726e+00, -4.2218e+00,\n",
      "          8.1199e+00],\n",
      "        [ 8.1091e+00, -5.3940e+00, -2.5732e+00, -9.4557e+00, -6.0995e+00,\n",
      "          7.6414e+00, -1.0233e+01,  7.0666e+00,  6.5185e-01, -6.2243e+00,\n",
      "          4.7989e+00, -3.2053e+00,  1.3285e+01,  1.0884e+01,  9.2195e+00,\n",
      "         -1.0853e+00],\n",
      "        [ 7.3355e+00, -5.0067e+00, -1.1632e-02, -7.6363e+00, -6.0027e+00,\n",
      "          5.1232e+00, -1.1202e+01,  8.5345e+00,  1.2699e+00, -5.9388e+00,\n",
      "          8.8268e+00, -6.4346e+00,  1.1806e+01,  1.3414e+01,  8.4187e+00,\n",
      "         -8.4807e-01],\n",
      "        [ 2.5560e+00, -1.2019e+01,  3.9005e+00, -6.9422e+00, -1.1361e+01,\n",
      "          7.3731e-01, -1.0732e+01, -1.5950e+00, -2.2458e+00, -1.1675e+01,\n",
      "          1.7795e+00, -3.9090e+00,  1.0629e+01,  7.8937e+00,  1.3528e+01,\n",
      "         -1.5373e+00],\n",
      "        [ 4.1663e+00,  2.4751e+00, -9.9511e+00, -2.2511e+00,  8.8598e+00,\n",
      "          4.7555e+00, -4.0822e+00,  2.9608e+00,  1.1735e+01,  2.3129e-01,\n",
      "         -3.7356e+00,  8.1303e+00, -3.9375e+00, -2.9877e+00, -2.9128e+00,\n",
      "          1.3699e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7457, 13.6520, 13.8341, 13.7983, 13.5951, 13.6416, 13.7216, 13.6951,\n",
      "        13.6353, 13.8560, 13.2842, 13.8094, 13.2850, 13.4135, 13.5275, 13.6990],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.1643, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 1.7412e+00, -9.1033e+00, -1.1382e+01,  2.9035e+00,  1.3097e+01,\n",
      "         -5.5044e+00,  4.9402e+00,  3.5570e+00,  2.7529e+00,  4.6795e+00,\n",
      "          4.1438e+00,  6.0747e+00,  3.8407e+00,  1.5415e+00,  4.4126e+00],\n",
      "        [ 1.3825e+00, -6.8668e+00,  2.7624e+00,  1.2127e+01,  3.3626e+00,\n",
      "          8.7905e+00,  5.1238e+00,  1.6568e+00,  1.3049e+01, -2.5677e-01,\n",
      "          3.0020e+00, -7.6552e+00, -6.0027e+00, -1.2760e+01,  2.3526e+00],\n",
      "        [-8.0143e+00, -6.8466e+00,  5.3479e+00, -9.8131e+00, -1.0312e+01,\n",
      "          5.6072e-01, -5.5992e+00, -7.3282e+00, -5.3632e+00,  3.6763e+00,\n",
      "         -8.8659e+00,  6.9135e-01,  3.0873e+00,  4.7958e+00, -8.9409e+00],\n",
      "        [-1.1262e+01,  1.6933e+00,  5.9016e+00,  1.7939e+00, -1.0973e+01,\n",
      "          7.5692e+00, -3.1562e+00, -1.4891e-01,  1.3229e+00, -5.4352e+00,\n",
      "          7.2810e-02, -8.2466e+00, -4.4589e+00, -5.6650e+00, -2.8851e+00],\n",
      "        [ 3.0437e+00,  1.0524e+01, -1.0275e+01,  1.3213e+00,  5.1148e+00,\n",
      "          4.8854e+00,  3.9888e+00,  8.0697e+00,  9.3241e+00, -3.2386e+00,\n",
      "          8.3547e+00, -8.0414e+00, -6.7747e+00, -1.0691e+01,  8.8987e+00],\n",
      "        [ 1.2764e+01,  2.6320e+00, -1.0707e+01, -1.0568e+01,  4.4840e+00,\n",
      "         -4.0015e+00,  4.6508e+00,  4.7386e+00,  3.3235e+00,  1.8942e+00,\n",
      "          6.6747e+00,  5.1962e+00,  1.8381e+00,  4.7595e-01,  5.1255e+00],\n",
      "        [-4.5411e+00,  1.0080e+01, -1.3445e+00,  7.2705e+00,  7.4915e+00,\n",
      "         -1.9489e+00, -2.6703e+00, -4.5450e+00,  1.1398e+01, -5.4985e+00,\n",
      "          3.9796e+00, -9.1059e+00, -9.8965e+00, -1.1134e+01, -4.0013e+00],\n",
      "        [ 5.3629e+00,  5.7048e+00, -6.6267e+00, -3.4726e+00,  4.6839e+00,\n",
      "          6.1259e+00, -4.2302e+00,  4.4126e+00,  3.0374e+00,  4.9725e+00,\n",
      "         -3.3779e+00,  4.7832e+00,  7.4799e+00, -2.0223e+00,  2.7124e+00],\n",
      "        [ 1.8114e+00,  1.3592e-01, -5.9606e+00,  8.4864e-01,  6.8410e+00,\n",
      "          1.6739e+00, -5.0751e+00,  3.5998e+00, -2.2840e+00, -1.5989e+00,\n",
      "          6.1750e+00, -3.1096e+00, -1.2919e-02, -1.8495e+00,  1.1999e+01],\n",
      "        [ 1.7996e+00,  1.2869e+01, -5.8178e+00,  2.4000e+00,  1.0666e+01,\n",
      "          3.8729e+00,  1.0439e+01,  2.8707e+00, -1.2079e+00, -6.7492e-01,\n",
      "          3.5761e+00, -7.1242e+00, -6.6481e+00, -1.2190e+01, -6.6805e-01],\n",
      "        [ 4.8706e+00,  2.0781e+00,  3.5744e+00, -4.2217e+00, -1.9391e+00,\n",
      "          2.4393e+00, -2.7766e+00,  6.3748e+00, -2.5710e+00,  2.5842e+00,\n",
      "         -9.0639e+00,  4.2795e+00,  8.4478e+00,  1.4359e-01, -4.2639e+00],\n",
      "        [ 2.7096e+00,  2.3302e+00, -8.7133e+00,  6.1528e-01,  7.8789e+00,\n",
      "          4.6702e+00,  2.7992e+00, -3.9052e+00,  7.6841e+00,  2.6155e+00,\n",
      "         -8.8347e+00, -5.2902e+00, -8.1726e+00, -4.2218e+00,  8.1199e+00],\n",
      "        [ 8.1091e+00, -5.3940e+00, -2.5732e+00, -9.4557e+00, -6.0995e+00,\n",
      "          7.6414e+00, -1.0233e+01,  7.0666e+00,  6.5185e-01, -6.2243e+00,\n",
      "          4.7989e+00, -3.2053e+00,  1.0884e+01,  9.2195e+00, -1.0853e+00],\n",
      "        [ 7.3355e+00, -5.0067e+00, -1.1632e-02, -7.6363e+00, -6.0027e+00,\n",
      "          5.1232e+00, -1.1202e+01,  8.5345e+00,  1.2699e+00, -5.9388e+00,\n",
      "          8.8268e+00, -6.4346e+00,  1.1806e+01,  8.4187e+00, -8.4807e-01],\n",
      "        [ 2.5560e+00, -1.2019e+01,  3.9005e+00, -6.9422e+00, -1.1361e+01,\n",
      "          7.3731e-01, -1.0732e+01, -1.5950e+00, -2.2458e+00, -1.1675e+01,\n",
      "          1.7795e+00, -3.9090e+00,  1.0629e+01,  7.8937e+00, -1.5373e+00],\n",
      "        [ 4.1663e+00,  2.4751e+00, -9.9511e+00, -2.2511e+00,  8.8598e+00,\n",
      "          4.7555e+00, -4.0822e+00,  2.9608e+00,  1.1735e+01,  2.3129e-01,\n",
      "         -3.7356e+00,  8.1303e+00, -3.9375e+00, -2.9877e+00, -2.9128e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0105, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 4: 0.08739792555570602\n",
      "Batch 5/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0656, -0.0165, -0.2119,  ..., -0.0956,  0.0984,  0.0181],\n",
      "        [ 0.0662, -0.0075, -0.0503,  ...,  0.0011, -0.1016,  0.0233],\n",
      "        [-0.0022, -0.0058, -0.0042,  ...,  0.0357, -0.0217,  0.0136],\n",
      "        ...,\n",
      "        [-0.0646, -0.0206,  0.0379,  ...,  0.0259,  0.2937, -0.1144],\n",
      "        [ 0.1758, -0.0306, -0.0013,  ...,  0.0052, -0.2249,  0.0659],\n",
      "        [-0.0904, -0.0226, -0.0639,  ...,  0.0917,  0.0923, -0.0350]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 4.2200e-02, -2.9548e-02, -1.9359e-01,  ..., -1.2437e-01,\n",
      "          1.2833e-01,  4.7171e-02],\n",
      "        [ 3.4730e-02, -2.0601e-02, -5.7545e-02,  ..., -3.0004e-02,\n",
      "         -1.2508e-01,  2.2371e-02],\n",
      "        [-1.0761e-04, -1.6129e-02,  1.8037e-02,  ...,  3.6542e-02,\n",
      "          2.3034e-02,  1.5383e-02],\n",
      "        ...,\n",
      "        [-6.9463e-02, -3.3024e-02,  3.5422e-02,  ...,  2.9212e-02,\n",
      "          2.9482e-01, -1.0894e-01],\n",
      "        [ 1.5152e-01, -3.2259e-02, -1.0917e-03,  ..., -1.9612e-02,\n",
      "         -1.1327e-01,  6.9065e-02],\n",
      "        [-1.0163e-01, -5.7560e-02, -6.1402e-02,  ...,  8.6690e-02,\n",
      "          9.2008e-02, -5.3177e-02]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3693e+01,  4.3689e+00, -3.4125e+00,  7.6811e+00,  5.9780e+00,\n",
      "         -5.3498e+00,  9.5893e+00, -6.0750e+00, -3.6382e+00,  7.7818e+00,\n",
      "         -2.8292e-01,  1.1346e+00, -8.8128e+00, -2.0295e+00, -2.5510e-01,\n",
      "         -9.5206e-01],\n",
      "        [ 4.7106e+00,  1.3678e+01, -1.0161e+01, -5.2928e-01, -7.3558e+00,\n",
      "         -8.2326e+00, -3.9276e+00,  7.2109e+00, -2.8732e-01, -2.0384e+00,\n",
      "          9.7695e+00, -5.1953e+00, -1.1606e+01, -1.0912e+01,  9.1607e+00,\n",
      "         -9.9077e+00],\n",
      "        [-4.0641e+00, -8.8519e+00,  1.3500e+01, -2.1176e+00,  4.5927e-01,\n",
      "          1.1846e+01,  6.1231e+00, -9.2610e+00, -2.9728e+00, -1.6062e+00,\n",
      "         -8.8163e+00,  7.1926e+00,  7.5846e+00,  5.2268e+00, -3.3259e+00,\n",
      "          1.0400e+01],\n",
      "        [ 8.3197e+00, -2.8917e-03, -1.2476e+00,  1.3883e+01,  7.4847e+00,\n",
      "         -4.0047e+00,  3.7542e+00, -2.3212e+00,  5.8848e+00,  9.0860e+00,\n",
      "         -2.4480e+00, -4.0248e+00, -4.0563e+00,  6.5338e+00, -2.2191e+00,\n",
      "          2.4346e+00],\n",
      "        [ 5.1330e+00, -7.5691e+00,  1.5508e+00,  7.2606e+00,  1.3802e+01,\n",
      "         -6.5687e-02,  5.8016e+00, -6.1278e+00,  1.4759e+00,  1.1135e+01,\n",
      "         -8.6625e+00, -1.2752e+00,  4.2536e+00,  9.2296e+00, -1.1311e+01,\n",
      "          6.0456e+00],\n",
      "        [-5.5385e+00, -7.6706e+00,  1.2465e+01, -4.2644e+00,  3.4950e-01,\n",
      "          1.3914e+01,  3.5661e+00, -7.6759e+00, -4.2093e+00, -7.4559e-01,\n",
      "         -9.6820e+00,  4.1847e+00,  8.2630e+00,  3.2499e+00, -5.3880e+00,\n",
      "          1.1491e+01],\n",
      "        [ 8.5292e+00, -3.5419e+00,  6.7977e+00,  3.4889e+00,  5.5497e+00,\n",
      "          4.1217e+00,  1.3684e+01, -1.2502e+01, -7.7807e+00,  3.7928e+00,\n",
      "         -6.0864e+00,  8.7139e+00, -1.5651e+00,  1.2945e+00, -2.8567e+00,\n",
      "          6.4163e+00],\n",
      "        [-6.4052e+00,  5.7988e+00, -8.7939e+00, -2.1753e+00, -6.9272e+00,\n",
      "         -6.9861e+00, -1.2321e+01,  1.3721e+01,  6.4138e+00, -6.1098e+00,\n",
      "          9.9565e+00, -6.9046e+00, -1.6870e+00, -3.3877e+00,  6.2691e+00,\n",
      "         -9.5823e+00],\n",
      "        [-5.2688e+00,  1.3902e-01, -3.2699e+00,  4.0624e+00, -3.7142e-01,\n",
      "         -3.8571e+00, -9.9611e+00,  8.2520e+00,  1.3330e+01,  2.2212e+00,\n",
      "          7.6442e-01, -9.9940e+00,  2.4348e+00,  6.1785e+00,  4.9916e-02,\n",
      "         -2.1600e+00],\n",
      "        [ 7.8135e+00, -2.7915e+00,  8.1658e-02,  7.6463e+00,  1.1917e+01,\n",
      "         -5.1165e-01,  5.2318e+00, -5.8826e+00,  2.0359e+00,  1.3536e+01,\n",
      "         -8.5465e+00, -4.9068e+00,  4.1580e-01,  6.0903e+00, -9.6785e+00,\n",
      "          5.4992e+00],\n",
      "        [ 1.0005e+00,  9.6282e+00, -9.5684e+00, -2.4760e+00, -8.9329e+00,\n",
      "         -9.2227e+00, -4.5753e+00,  8.8982e+00, -1.4423e+00, -8.2396e+00,\n",
      "          1.3750e+01,  5.7030e-01, -8.2616e+00, -9.6838e+00,  1.1532e+01,\n",
      "         -1.2330e+01],\n",
      "        [-5.4784e-01, -3.8062e+00,  5.6622e+00, -6.1290e+00, -3.0655e+00,\n",
      "          4.4943e+00,  7.7372e+00, -6.9217e+00, -1.0435e+01, -7.9042e+00,\n",
      "          6.7776e-01,  1.3498e+01,  1.2167e+00, -2.7315e+00,  2.5721e+00,\n",
      "          1.8233e+00],\n",
      "        [-8.3363e+00, -1.2331e+01,  1.0046e+01, -3.3338e+00,  4.2848e+00,\n",
      "          1.0669e+01, -1.3344e-02, -4.5065e+00, -5.7065e-02,  3.8035e-01,\n",
      "         -9.2777e+00,  2.6222e+00,  1.3181e+01,  8.5223e+00, -8.7452e+00,\n",
      "          9.8890e+00],\n",
      "        [-2.1027e+00, -1.0663e+01,  6.3560e+00,  7.1496e+00,  9.1677e+00,\n",
      "          4.0845e+00,  1.2474e+00, -4.3513e+00,  6.8210e+00,  6.8365e+00,\n",
      "         -9.5576e+00, -1.3707e+00,  8.3005e+00,  1.3691e+01, -9.3047e+00,\n",
      "          9.0247e+00],\n",
      "        [-7.7879e-01,  8.9013e+00, -3.8638e+00, -4.2120e+00, -1.2430e+01,\n",
      "         -4.0218e+00, -2.9268e+00,  5.7059e+00, -2.0777e+00, -1.0370e+01,\n",
      "          1.1412e+01,  3.0264e+00, -7.0190e+00, -9.8040e+00,  1.3626e+01,\n",
      "         -8.8998e+00],\n",
      "        [-4.5527e-01, -9.3318e+00,  1.1488e+01,  2.4855e+00,  7.0147e+00,\n",
      "          1.1300e+01,  6.7761e+00, -1.0570e+01, -1.5073e+00,  5.9837e+00,\n",
      "         -1.3021e+01,  2.5303e+00,  7.1986e+00,  8.2700e+00, -9.4561e+00,\n",
      "          1.3698e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6930, 13.6777, 13.4998, 13.8828, 13.8021, 13.9145, 13.6843, 13.7207,\n",
      "        13.3303, 13.5358, 13.7504, 13.4977, 13.1805, 13.6907, 13.6259, 13.6980],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0936, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 4.3689e+00, -3.4125e+00,  7.6811e+00,  5.9780e+00, -5.3498e+00,\n",
      "          9.5893e+00, -6.0750e+00, -3.6382e+00,  7.7818e+00, -2.8292e-01,\n",
      "          1.1346e+00, -8.8128e+00, -2.0295e+00, -2.5510e-01, -9.5206e-01],\n",
      "        [ 4.7106e+00, -1.0161e+01, -5.2928e-01, -7.3558e+00, -8.2326e+00,\n",
      "         -3.9276e+00,  7.2109e+00, -2.8732e-01, -2.0384e+00,  9.7695e+00,\n",
      "         -5.1953e+00, -1.1606e+01, -1.0912e+01,  9.1607e+00, -9.9077e+00],\n",
      "        [-4.0641e+00, -8.8519e+00, -2.1176e+00,  4.5927e-01,  1.1846e+01,\n",
      "          6.1231e+00, -9.2610e+00, -2.9728e+00, -1.6062e+00, -8.8163e+00,\n",
      "          7.1926e+00,  7.5846e+00,  5.2268e+00, -3.3259e+00,  1.0400e+01],\n",
      "        [ 8.3197e+00, -2.8917e-03, -1.2476e+00,  7.4847e+00, -4.0047e+00,\n",
      "          3.7542e+00, -2.3212e+00,  5.8848e+00,  9.0860e+00, -2.4480e+00,\n",
      "         -4.0248e+00, -4.0563e+00,  6.5338e+00, -2.2191e+00,  2.4346e+00],\n",
      "        [ 5.1330e+00, -7.5691e+00,  1.5508e+00,  7.2606e+00, -6.5687e-02,\n",
      "          5.8016e+00, -6.1278e+00,  1.4759e+00,  1.1135e+01, -8.6625e+00,\n",
      "         -1.2752e+00,  4.2536e+00,  9.2296e+00, -1.1311e+01,  6.0456e+00],\n",
      "        [-5.5385e+00, -7.6706e+00,  1.2465e+01, -4.2644e+00,  3.4950e-01,\n",
      "          3.5661e+00, -7.6759e+00, -4.2093e+00, -7.4559e-01, -9.6820e+00,\n",
      "          4.1847e+00,  8.2630e+00,  3.2499e+00, -5.3880e+00,  1.1491e+01],\n",
      "        [ 8.5292e+00, -3.5419e+00,  6.7977e+00,  3.4889e+00,  5.5497e+00,\n",
      "          4.1217e+00, -1.2502e+01, -7.7807e+00,  3.7928e+00, -6.0864e+00,\n",
      "          8.7139e+00, -1.5651e+00,  1.2945e+00, -2.8567e+00,  6.4163e+00],\n",
      "        [-6.4052e+00,  5.7988e+00, -8.7939e+00, -2.1753e+00, -6.9272e+00,\n",
      "         -6.9861e+00, -1.2321e+01,  6.4138e+00, -6.1098e+00,  9.9565e+00,\n",
      "         -6.9046e+00, -1.6870e+00, -3.3877e+00,  6.2691e+00, -9.5823e+00],\n",
      "        [-5.2688e+00,  1.3902e-01, -3.2699e+00,  4.0624e+00, -3.7142e-01,\n",
      "         -3.8571e+00, -9.9611e+00,  8.2520e+00,  2.2212e+00,  7.6442e-01,\n",
      "         -9.9940e+00,  2.4348e+00,  6.1785e+00,  4.9916e-02, -2.1600e+00],\n",
      "        [ 7.8135e+00, -2.7915e+00,  8.1658e-02,  7.6463e+00,  1.1917e+01,\n",
      "         -5.1165e-01,  5.2318e+00, -5.8826e+00,  2.0359e+00, -8.5465e+00,\n",
      "         -4.9068e+00,  4.1580e-01,  6.0903e+00, -9.6785e+00,  5.4992e+00],\n",
      "        [ 1.0005e+00,  9.6282e+00, -9.5684e+00, -2.4760e+00, -8.9329e+00,\n",
      "         -9.2227e+00, -4.5753e+00,  8.8982e+00, -1.4423e+00, -8.2396e+00,\n",
      "          5.7030e-01, -8.2616e+00, -9.6838e+00,  1.1532e+01, -1.2330e+01],\n",
      "        [-5.4784e-01, -3.8062e+00,  5.6622e+00, -6.1290e+00, -3.0655e+00,\n",
      "          4.4943e+00,  7.7372e+00, -6.9217e+00, -1.0435e+01, -7.9042e+00,\n",
      "          6.7776e-01,  1.2167e+00, -2.7315e+00,  2.5721e+00,  1.8233e+00],\n",
      "        [-8.3363e+00, -1.2331e+01,  1.0046e+01, -3.3338e+00,  4.2848e+00,\n",
      "          1.0669e+01, -1.3344e-02, -4.5065e+00, -5.7065e-02,  3.8035e-01,\n",
      "         -9.2777e+00,  2.6222e+00,  8.5223e+00, -8.7452e+00,  9.8890e+00],\n",
      "        [-2.1027e+00, -1.0663e+01,  6.3560e+00,  7.1496e+00,  9.1677e+00,\n",
      "          4.0845e+00,  1.2474e+00, -4.3513e+00,  6.8210e+00,  6.8365e+00,\n",
      "         -9.5576e+00, -1.3707e+00,  8.3005e+00, -9.3047e+00,  9.0247e+00],\n",
      "        [-7.7879e-01,  8.9013e+00, -3.8638e+00, -4.2120e+00, -1.2430e+01,\n",
      "         -4.0218e+00, -2.9268e+00,  5.7059e+00, -2.0777e+00, -1.0370e+01,\n",
      "          1.1412e+01,  3.0264e+00, -7.0190e+00, -9.8040e+00, -8.8998e+00],\n",
      "        [-4.5527e-01, -9.3318e+00,  1.1488e+01,  2.4855e+00,  7.0147e+00,\n",
      "          1.1300e+01,  6.7761e+00, -1.0570e+01, -1.5073e+00,  5.9837e+00,\n",
      "         -1.3021e+01,  2.5303e+00,  7.1986e+00,  8.2700e+00, -9.4561e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0060, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 5: 0.04982082173228264\n",
      "Batch 6/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.0245,  0.0490,  0.0955,  ...,  0.0591, -0.1819, -0.0722],\n",
      "        [ 0.1099, -0.1047, -0.0791,  ...,  0.0436,  0.1087, -0.0843],\n",
      "        [ 0.0725,  0.0085,  0.0999,  ..., -0.0773,  0.1542,  0.0022],\n",
      "        ...,\n",
      "        [ 0.0150, -0.0482, -0.0278,  ...,  0.1224, -0.0461, -0.0280],\n",
      "        [-0.0476, -0.0474, -0.1583,  ...,  0.0058,  0.1001, -0.0775],\n",
      "        [-0.0185,  0.0510,  0.0050,  ...,  0.0301, -0.0705,  0.0555]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.0708,  0.0492,  0.1095,  ...,  0.0368, -0.1739, -0.0776],\n",
      "        [ 0.0806, -0.0654, -0.1101,  ...,  0.0112,  0.1447, -0.0425],\n",
      "        [ 0.0660,  0.0246,  0.0777,  ..., -0.1193,  0.1596,  0.0309],\n",
      "        ...,\n",
      "        [ 0.0095, -0.0829, -0.0348,  ...,  0.1060, -0.0589,  0.0088],\n",
      "        [-0.0776, -0.0541, -0.1705,  ...,  0.0195,  0.1591, -0.0462],\n",
      "        [-0.0280, -0.0008,  0.0008,  ..., -0.0119, -0.0788,  0.0600]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.8168,  -8.4758,  -5.5101,  -5.1425,  -8.1882,  -0.8714,   5.6865,\n",
      "           4.5269,   2.4853,  -2.6923,   4.4943,  -4.8238,  -1.7774,   1.0152,\n",
      "          -5.7412,   6.1866],\n",
      "        [ -7.9801,  13.7172,   0.5357,   3.5701,   1.6531,   3.8289,  -9.4314,\n",
      "          -1.7042,  -3.1100,  -3.6178,  -5.7146,   4.7052,   7.3835,   6.8501,\n",
      "           6.5470,  -4.7729],\n",
      "        [ -5.1961,   1.5283,  13.7895,   6.8874,  11.7134,   0.9631,   5.6205,\n",
      "          -9.3380,   9.7227,   4.4458,  -8.5190,   0.1934,  -6.4078,  -5.5202,\n",
      "          -7.1605,  -4.6810],\n",
      "        [ -5.0685,   5.0881,   7.9323,  13.6530,   6.1520,  -0.1387,  -3.4750,\n",
      "          -2.8458,  -0.0167,  -4.9051, -12.3312,   4.9071,  -4.4759,   0.7384,\n",
      "           2.7268,   2.5695],\n",
      "        [ -8.3368,   2.9243,  11.6697,   6.1361,  13.5592,   0.3145,   3.6011,\n",
      "          -5.4550,   4.1303,   6.9812,  -6.7081,   5.1593,  -5.9188,  -6.5982,\n",
      "          -3.0382,  -5.9463],\n",
      "        [ -1.5163,   4.5366,   1.5015,  -1.0522,   1.5556,  13.5435,  -5.9277,\n",
      "           4.9467,  -0.3378,   2.0160,  -1.1150,   8.4319,   8.2320,   2.9951,\n",
      "          -3.7042,   0.1864],\n",
      "        [  5.2126,  -9.6513,   5.2055,  -2.9596,   4.5649,  -6.0865,  13.8084,\n",
      "          -4.4660,   8.2782,   7.4049,   2.6871,  -5.6504,  -9.7647,  -9.5153,\n",
      "          -8.8509,  -2.6956],\n",
      "        [  6.0056,  -3.5428,  -8.4735,  -3.0629,  -5.7447,   3.7900,  -3.6241,\n",
      "          13.7292,  -9.5353,  -0.3053,   5.3642,   7.9393,   3.3052,   1.3495,\n",
      "           2.8980,   6.4179],\n",
      "        [  2.9852,  -2.6814,   8.6584,  -0.3498,   4.2743,  -0.0255,   9.1571,\n",
      "          -9.9287,  13.5676,   1.9228,  -3.4882,  -7.7915,  -5.0408,  -2.6890,\n",
      "         -11.2063,  -2.6545],\n",
      "        [ -1.5154,  -4.5125,   3.6417,  -6.5898,   6.4376,   0.7529,   7.8335,\n",
      "          -0.2844,   2.8190,  13.6633,   7.0506,   2.0547,  -1.3223, -10.3462,\n",
      "          -5.3659,  -8.3922],\n",
      "        [  3.8513,  -6.3004,  -8.4795, -11.8351,  -5.9920,  -0.9752,   2.8508,\n",
      "           5.6815,  -3.8339,   6.9458,  13.8832,  -1.9149,   4.3114,  -4.2783,\n",
      "           0.3914,  -2.9875],\n",
      "        [ -4.1660,   4.6520,   0.0749,   3.1765,   3.6936,   7.0609,  -6.6123,\n",
      "           9.0850,  -8.1809,   3.2993,  -1.2511,  13.8375,   4.0934,  -0.2486,\n",
      "           3.9345,   0.0772],\n",
      "        [ -0.6103,   6.5269,  -6.6897,  -5.1098,  -7.2167,   8.6353,  -9.0043,\n",
      "           5.0410,  -4.4016,  -1.3909,   4.6148,   2.9054,  13.8525,   5.2354,\n",
      "           3.4511,  -2.4953],\n",
      "        [  2.0988,   6.3985,  -5.6062,   0.2486,  -6.7387,   3.6816,  -8.3704,\n",
      "           1.4921,  -2.3210, -10.8956,  -3.6173,  -0.8659,   5.0869,  13.7978,\n",
      "           2.9986,   6.8376],\n",
      "        [ -4.9800,   5.9543,  -7.0699,   1.9738,  -4.0289,  -4.2427,  -8.1779,\n",
      "           4.5419, -11.5088,  -2.8800,   2.0462,   3.8627,   4.6193,   2.2895,\n",
      "          13.7099,  -1.5081],\n",
      "        [  8.0792,  -5.7101,  -4.5231,   2.2802,  -6.3875,   0.5708,  -1.7017,\n",
      "           5.7872,  -2.4466,  -8.6729,  -1.6380,  -0.7755,  -3.0767,   6.1554,\n",
      "          -0.6496,  13.5252]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.8168, 13.7172, 13.7895, 13.6530, 13.5592, 13.5435, 13.8084, 13.7292,\n",
      "        13.5676, 13.6633, 13.8832, 13.8375, 13.8525, 13.7978, 13.7099, 13.5252],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0224, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ -8.4758,  -5.5101,  -5.1425,  -8.1882,  -0.8714,   5.6865,   4.5269,\n",
      "           2.4853,  -2.6923,   4.4943,  -4.8238,  -1.7774,   1.0152,  -5.7412,\n",
      "           6.1866],\n",
      "        [ -7.9801,   0.5357,   3.5701,   1.6531,   3.8289,  -9.4314,  -1.7042,\n",
      "          -3.1100,  -3.6178,  -5.7146,   4.7052,   7.3835,   6.8501,   6.5470,\n",
      "          -4.7729],\n",
      "        [ -5.1961,   1.5283,   6.8874,  11.7134,   0.9631,   5.6205,  -9.3380,\n",
      "           9.7227,   4.4458,  -8.5190,   0.1934,  -6.4078,  -5.5202,  -7.1605,\n",
      "          -4.6810],\n",
      "        [ -5.0685,   5.0881,   7.9323,   6.1520,  -0.1387,  -3.4750,  -2.8458,\n",
      "          -0.0167,  -4.9051, -12.3312,   4.9071,  -4.4759,   0.7384,   2.7268,\n",
      "           2.5695],\n",
      "        [ -8.3368,   2.9243,  11.6697,   6.1361,   0.3145,   3.6011,  -5.4550,\n",
      "           4.1303,   6.9812,  -6.7081,   5.1593,  -5.9188,  -6.5982,  -3.0382,\n",
      "          -5.9463],\n",
      "        [ -1.5163,   4.5366,   1.5015,  -1.0522,   1.5556,  -5.9277,   4.9467,\n",
      "          -0.3378,   2.0160,  -1.1150,   8.4319,   8.2320,   2.9951,  -3.7042,\n",
      "           0.1864],\n",
      "        [  5.2126,  -9.6513,   5.2055,  -2.9596,   4.5649,  -6.0865,  -4.4660,\n",
      "           8.2782,   7.4049,   2.6871,  -5.6504,  -9.7647,  -9.5153,  -8.8509,\n",
      "          -2.6956],\n",
      "        [  6.0056,  -3.5428,  -8.4735,  -3.0629,  -5.7447,   3.7900,  -3.6241,\n",
      "          -9.5353,  -0.3053,   5.3642,   7.9393,   3.3052,   1.3495,   2.8980,\n",
      "           6.4179],\n",
      "        [  2.9852,  -2.6814,   8.6584,  -0.3498,   4.2743,  -0.0255,   9.1571,\n",
      "          -9.9287,   1.9228,  -3.4882,  -7.7915,  -5.0408,  -2.6890, -11.2063,\n",
      "          -2.6545],\n",
      "        [ -1.5154,  -4.5125,   3.6417,  -6.5898,   6.4376,   0.7529,   7.8335,\n",
      "          -0.2844,   2.8190,   7.0506,   2.0547,  -1.3223, -10.3462,  -5.3659,\n",
      "          -8.3922],\n",
      "        [  3.8513,  -6.3004,  -8.4795, -11.8351,  -5.9920,  -0.9752,   2.8508,\n",
      "           5.6815,  -3.8339,   6.9458,  -1.9149,   4.3114,  -4.2783,   0.3914,\n",
      "          -2.9875],\n",
      "        [ -4.1660,   4.6520,   0.0749,   3.1765,   3.6936,   7.0609,  -6.6123,\n",
      "           9.0850,  -8.1809,   3.2993,  -1.2511,   4.0934,  -0.2486,   3.9345,\n",
      "           0.0772],\n",
      "        [ -0.6103,   6.5269,  -6.6897,  -5.1098,  -7.2167,   8.6353,  -9.0043,\n",
      "           5.0410,  -4.4016,  -1.3909,   4.6148,   2.9054,   5.2354,   3.4511,\n",
      "          -2.4953],\n",
      "        [  2.0988,   6.3985,  -5.6062,   0.2486,  -6.7387,   3.6816,  -8.3704,\n",
      "           1.4921,  -2.3210, -10.8956,  -3.6173,  -0.8659,   5.0869,   2.9986,\n",
      "           6.8376],\n",
      "        [ -4.9800,   5.9543,  -7.0699,   1.9738,  -4.0289,  -4.2427,  -8.1779,\n",
      "           4.5419, -11.5088,  -2.8800,   2.0462,   3.8627,   4.6193,   2.2895,\n",
      "          -1.5081],\n",
      "        [  8.0792,  -5.7101,  -4.5231,   2.2802,  -6.3875,   0.5708,  -1.7017,\n",
      "           5.7872,  -2.4466,  -8.6729,  -1.6380,  -0.7755,  -3.0767,   6.1554,\n",
      "          -0.6496]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0015, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 6: 0.011944061145186424\n",
      "Batch 7/7: Matrix features: torch.Size([4, 128]), Vector features: torch.Size([4, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 1.3660e-01, -5.4305e-02, -1.5834e-02, -1.3485e-01, -2.5755e-02,\n",
      "         -1.5951e-02,  8.2970e-02, -5.4852e-02, -1.8077e-03, -1.0758e-01,\n",
      "          6.7068e-02,  4.8371e-02,  6.0512e-02, -3.5123e-02,  3.9245e-02,\n",
      "         -3.4830e-02, -7.3989e-02, -1.1615e-02, -9.4322e-02, -9.2482e-02,\n",
      "          3.7224e-02,  5.6195e-03,  2.4590e-02, -7.8372e-02, -1.4050e-02,\n",
      "         -3.8642e-02,  9.5638e-02,  4.3839e-02, -1.3469e-01,  4.5835e-02,\n",
      "         -1.2406e-01,  9.7188e-02,  1.4790e-01,  8.4186e-03,  9.2240e-02,\n",
      "          8.1424e-02,  1.2718e-01, -2.2050e-02, -1.1138e-01, -1.2710e-01,\n",
      "          8.8742e-02,  7.6285e-03, -1.3600e-01,  3.3535e-02,  1.6052e-01,\n",
      "          6.8178e-03,  2.6927e-02,  8.7881e-02,  9.7697e-02, -5.2265e-03,\n",
      "          2.8626e-02,  8.0125e-02,  1.4251e-01,  3.2365e-02, -3.2682e-02,\n",
      "          1.6009e-03, -4.7949e-02, -6.7685e-02, -8.0917e-02,  9.3444e-02,\n",
      "          3.8186e-02, -3.7515e-02, -1.5800e-02, -4.6437e-02,  1.8702e-01,\n",
      "          4.8135e-02, -4.8519e-03, -6.3406e-03,  8.4119e-02, -1.0904e-01,\n",
      "         -2.4870e-02,  6.2726e-02,  2.5691e-02,  1.0183e-01,  1.3692e-01,\n",
      "          1.4275e-01, -2.0626e-01, -1.8063e-01, -8.0422e-03, -4.2920e-02,\n",
      "         -5.4050e-02, -1.0680e-01, -9.4032e-02, -2.0697e-02,  6.1284e-02,\n",
      "          1.1005e-01,  2.4756e-02,  4.5994e-02,  3.9523e-02,  2.0413e-02,\n",
      "          1.4774e-01, -2.7459e-02,  1.2709e-01, -1.1535e-01,  8.7856e-03,\n",
      "         -1.0010e-01, -1.9913e-02,  9.4964e-02,  1.1980e-01,  1.6260e-01,\n",
      "         -5.8329e-02, -4.7806e-03, -1.4582e-02, -4.3102e-02,  8.5509e-05,\n",
      "         -6.7285e-02,  1.8224e-02, -1.0371e-01, -5.0020e-03, -7.0110e-02,\n",
      "         -7.7125e-02,  3.0853e-02, -7.3610e-02, -1.7761e-01,  5.9682e-03,\n",
      "         -1.1870e-01,  9.4594e-02,  5.8653e-02,  1.3289e-01, -7.7975e-02,\n",
      "         -1.5128e-01, -2.1357e-02, -1.8967e-01,  1.4925e-03,  8.8450e-02,\n",
      "          9.2733e-02, -2.7971e-01,  6.6856e-02],\n",
      "        [ 2.2325e-01, -1.5049e-02, -1.5764e-01,  1.5227e-02, -8.7158e-02,\n",
      "         -5.8565e-02, -5.0539e-02,  8.2368e-03,  1.4217e-01,  4.8523e-02,\n",
      "          1.2215e-01, -6.7734e-02, -5.3596e-02, -1.1121e-01,  4.5706e-02,\n",
      "          1.8754e-01, -4.5618e-02, -5.4351e-03,  6.3912e-02,  6.8724e-02,\n",
      "         -3.5543e-02, -1.3963e-01,  5.3608e-02, -7.5883e-02, -9.0989e-03,\n",
      "         -2.1130e-01,  8.1648e-03, -3.0463e-02,  5.2781e-02, -6.3089e-02,\n",
      "         -7.5502e-02, -1.0024e-01,  7.2236e-02,  3.8132e-02, -6.5968e-02,\n",
      "         -5.0552e-03,  1.2787e-01, -1.7116e-01, -7.3407e-02, -1.5411e-01,\n",
      "         -4.6287e-03,  6.4953e-02, -1.4224e-01, -8.0179e-02, -4.8756e-02,\n",
      "          7.3475e-02, -1.9856e-02,  2.6285e-02,  6.2272e-02,  1.1070e-01,\n",
      "         -8.7508e-02,  7.9481e-02,  6.0810e-02, -1.0337e-01, -8.8243e-02,\n",
      "         -1.4176e-01,  9.9606e-04, -3.6783e-02, -4.8777e-02,  1.1073e-01,\n",
      "          2.4551e-02, -6.8251e-02,  1.4192e-03, -6.9907e-02, -5.8353e-03,\n",
      "          3.3373e-02, -4.5911e-02, -3.4298e-02, -4.0400e-02,  9.7584e-02,\n",
      "          8.9407e-02,  3.3521e-02, -1.0499e-02,  1.3588e-01, -3.9980e-02,\n",
      "          1.5097e-02,  1.1114e-01, -1.4409e-02, -7.7342e-02, -5.1181e-03,\n",
      "         -1.2929e-01, -2.4423e-02,  1.8988e-02, -5.8684e-02,  1.3895e-01,\n",
      "          1.7522e-01, -1.0451e-01, -7.4031e-02,  1.4614e-01, -1.3201e-01,\n",
      "          4.7339e-02,  4.2515e-02, -1.7421e-03,  2.1039e-01,  3.4298e-02,\n",
      "         -1.0854e-01, -5.7418e-02, -1.3834e-01,  1.8352e-01, -9.3180e-02,\n",
      "         -7.9871e-02,  1.7603e-02,  1.2118e-01,  5.6186e-02,  9.1690e-02,\n",
      "          1.7286e-01,  1.2012e-02,  3.1041e-02,  5.1969e-02, -5.0152e-02,\n",
      "          3.3904e-02, -5.4906e-02,  1.7255e-02,  7.5152e-03, -1.9302e-02,\n",
      "          1.6045e-01,  1.1692e-01,  5.5760e-03,  4.1848e-02,  7.3400e-02,\n",
      "          3.7174e-02, -1.6174e-02, -5.6161e-02,  1.1703e-01, -7.8931e-02,\n",
      "         -1.2151e-01, -8.7966e-02, -8.3736e-03],\n",
      "        [-5.8982e-02,  1.4031e-02,  1.7601e-01, -8.9310e-02,  4.6246e-02,\n",
      "          4.7181e-02,  9.6041e-02,  1.0319e-02, -1.3814e-01, -8.2058e-02,\n",
      "         -8.9988e-02,  7.0970e-02,  5.2477e-02,  5.2249e-02, -3.5681e-02,\n",
      "         -1.9743e-01, -2.7207e-02, -5.7228e-02, -1.0553e-01,  1.9734e-02,\n",
      "          3.1991e-02,  1.6829e-01, -3.2167e-02,  4.0366e-02, -1.0359e-01,\n",
      "          1.7187e-01,  4.7485e-02,  1.6504e-02, -8.5286e-02,  9.6519e-02,\n",
      "          4.7682e-02,  3.5531e-02,  1.5226e-02,  4.0725e-02,  7.0238e-02,\n",
      "         -2.4961e-02,  1.0856e-02,  9.1757e-02,  2.4348e-03,  1.0979e-01,\n",
      "          4.6251e-02, -5.1764e-02,  6.4853e-02,  4.6056e-02,  1.5001e-01,\n",
      "         -8.4594e-02, -3.1022e-03,  2.8151e-02,  3.0240e-02, -7.2770e-02,\n",
      "          1.2915e-01,  8.9454e-03,  1.0638e-02,  1.5118e-01,  9.1463e-02,\n",
      "          1.1897e-01, -5.2197e-03,  5.1691e-03, -9.5795e-03, -9.2652e-02,\n",
      "         -6.7968e-02,  3.0816e-02, -2.3410e-02,  9.5036e-02,  8.1074e-02,\n",
      "         -5.8511e-02,  4.6975e-02,  1.8378e-02,  2.9679e-02, -8.0568e-02,\n",
      "         -9.1845e-02,  1.5946e-02, -1.4774e-02,  2.1634e-02,  1.1209e-01,\n",
      "         -1.0372e-03, -2.2575e-01, -1.2793e-01,  4.5529e-02, -4.2000e-02,\n",
      "          9.2318e-02,  2.2884e-02, -1.1712e-03,  2.0011e-02, -8.4027e-02,\n",
      "         -1.5343e-01,  9.8797e-02,  1.1959e-01, -2.0763e-01,  1.3340e-01,\n",
      "         -3.3782e-02, -4.4627e-02, -2.9324e-03, -1.8983e-01, -5.9881e-03,\n",
      "          9.8160e-02, -1.7740e-03,  1.9301e-01, -1.1769e-01,  1.6078e-01,\n",
      "          1.0211e-01, -9.6729e-03, -7.4199e-02, -9.4653e-02, -1.3290e-01,\n",
      "         -1.7501e-01, -2.9000e-02, -3.0235e-02, -5.8676e-02, -4.6161e-02,\n",
      "         -7.0407e-02,  1.2474e-01, -6.1255e-02, -1.2784e-01, -2.9793e-02,\n",
      "         -1.4625e-01, -1.1944e-01,  1.4475e-02,  1.2723e-02, -6.1003e-02,\n",
      "         -1.0877e-01,  3.7009e-02, -1.5766e-03, -8.7998e-02,  1.3233e-01,\n",
      "          1.4842e-01,  1.4440e-02, -1.1763e-02],\n",
      "        [ 6.5844e-03, -3.3360e-02,  5.5471e-02, -6.4797e-02, -3.7304e-03,\n",
      "          3.0503e-02,  8.0129e-02, -1.1473e-01, -5.3594e-02, -1.0064e-01,\n",
      "          1.9920e-02,  1.2053e-01,  4.1419e-02,  8.2749e-02, -1.3229e-01,\n",
      "         -4.6495e-02,  6.3007e-02,  9.8023e-02, -2.6766e-02, -5.0298e-02,\n",
      "          9.7755e-03, -2.2329e-02, -3.0668e-02, -1.6149e-02, -8.5408e-02,\n",
      "          1.6630e-01,  1.7817e-02,  4.6154e-02, -2.3423e-01,  1.7695e-01,\n",
      "          5.2823e-03,  7.9194e-02,  1.1634e-01, -2.2614e-02,  2.6648e-02,\n",
      "          9.4312e-02,  2.0387e-04,  2.4466e-01, -7.8771e-02, -1.0967e-01,\n",
      "          1.2981e-02,  3.5200e-02, -1.1629e-01, -1.2570e-01,  9.8707e-02,\n",
      "          4.5516e-02,  1.3492e-01, -1.4945e-02, -5.3201e-02, -5.1045e-02,\n",
      "         -9.4329e-02,  1.8721e-02,  3.8596e-02, -8.4612e-04,  1.4812e-01,\n",
      "          2.4487e-02, -8.3104e-02, -4.4146e-02,  3.3700e-02, -2.8051e-02,\n",
      "         -2.5332e-02,  5.6566e-02, -7.5590e-02, -6.8791e-02,  2.4536e-01,\n",
      "         -6.4885e-02, -4.1490e-02,  1.7934e-02,  9.9622e-02, -2.0372e-01,\n",
      "         -1.5091e-01,  5.6907e-02, -1.7074e-02, -2.6979e-02,  7.1109e-02,\n",
      "          7.7627e-02, -2.3331e-02, -7.6656e-02,  1.4811e-01,  3.5261e-02,\n",
      "          5.6027e-02, -6.7600e-02, -1.2297e-01,  1.1320e-01,  1.1408e-01,\n",
      "         -1.8864e-02,  5.0237e-02, -1.3323e-03, -8.3375e-03, -9.2672e-02,\n",
      "          3.0652e-02,  1.9978e-02,  8.1098e-02, -3.9982e-02, -1.4517e-03,\n",
      "          1.1814e-02,  1.3157e-01,  1.8695e-01,  4.2931e-02,  1.2107e-01,\n",
      "         -5.2874e-02,  3.0180e-02, -6.9820e-02, -4.2849e-02, -1.0107e-01,\n",
      "         -5.3929e-02,  8.3340e-02, -6.3188e-02, -1.2422e-01, -7.2352e-02,\n",
      "         -7.7428e-03, -2.0566e-02, -2.3444e-01, -4.0489e-02, -6.3212e-02,\n",
      "         -1.2816e-01,  6.9262e-02, -2.9191e-02,  6.9494e-02,  1.1465e-02,\n",
      "         -4.7516e-02, -2.7574e-02, -1.5235e-02, -1.3086e-02,  6.5440e-02,\n",
      "          1.0196e-01, -2.3206e-01,  2.1877e-02]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 1.2241e-01, -6.7686e-02, -1.0058e-02, -1.1970e-01, -6.1736e-02,\n",
      "          1.9223e-02,  8.4965e-02, -2.6382e-02,  5.2969e-03, -8.7144e-02,\n",
      "          5.5158e-02,  4.0783e-02,  8.6915e-02, -3.3602e-02,  1.9957e-02,\n",
      "         -4.1618e-02, -7.3393e-02, -3.2295e-02, -7.3232e-02, -9.2950e-02,\n",
      "          3.5480e-05,  6.1648e-03,  1.5947e-02, -7.6118e-02, -3.3784e-02,\n",
      "         -2.3851e-03,  7.8006e-02,  6.3534e-02, -1.2007e-01,  8.1360e-02,\n",
      "         -1.2376e-01,  8.3373e-02,  1.5920e-01,  2.4674e-02,  5.3158e-02,\n",
      "          6.2183e-02,  1.3793e-01,  2.2481e-02, -9.6837e-02, -1.0621e-01,\n",
      "          6.9559e-02,  1.9680e-02, -1.4028e-01,  5.8157e-02,  1.8954e-01,\n",
      "          2.4931e-02,  3.8498e-02,  8.5792e-02,  9.5198e-02,  1.3803e-02,\n",
      "          5.1442e-02,  4.5184e-02,  1.1323e-01,  5.2573e-02, -3.1398e-02,\n",
      "         -3.8277e-03, -4.4124e-02, -7.2190e-02, -5.8175e-02,  1.0037e-01,\n",
      "          5.9346e-03, -4.6833e-02, -2.1267e-03, -2.0875e-02,  2.0909e-01,\n",
      "          5.2935e-02,  5.1911e-03,  4.8286e-03,  5.7724e-02, -8.8255e-02,\n",
      "         -2.2103e-02,  6.6688e-02,  7.8354e-02,  1.0655e-01,  7.6477e-02,\n",
      "          1.5863e-01, -2.2619e-01, -2.1339e-01, -1.0627e-02, -4.4806e-02,\n",
      "         -5.1653e-02, -1.1234e-01, -7.4957e-02, -2.2588e-03,  6.7176e-02,\n",
      "          7.8927e-02,  3.8861e-02,  1.1247e-02,  1.2963e-02,  4.1797e-02,\n",
      "          1.5948e-01, -2.9313e-03,  1.1875e-01, -1.1244e-01,  2.7161e-03,\n",
      "         -8.7391e-02, -2.4925e-03,  9.1603e-02,  1.0634e-01,  1.3499e-01,\n",
      "         -7.2813e-02, -1.0396e-02, -4.4626e-02, -4.7785e-02, -6.9209e-03,\n",
      "         -7.8808e-02,  1.4738e-02, -8.0726e-02,  3.5542e-03, -7.2754e-02,\n",
      "         -8.6640e-02,  2.5267e-02, -1.4994e-01, -1.8573e-01, -3.7275e-02,\n",
      "         -2.0539e-01,  7.3203e-02,  6.1120e-02,  9.7517e-02, -6.7806e-02,\n",
      "         -1.4505e-01, -5.7563e-02, -1.6407e-01,  2.0964e-02,  1.2027e-01,\n",
      "          9.5542e-02, -2.4338e-01,  1.0964e-01],\n",
      "        [ 1.9507e-01, -3.4508e-02, -1.6556e-01,  2.6911e-02, -6.6227e-02,\n",
      "         -2.8438e-02, -4.5554e-02, -5.6556e-03,  1.2337e-01,  4.6975e-02,\n",
      "          1.4334e-01, -8.4658e-02, -6.7000e-02, -1.1655e-01,  6.6849e-02,\n",
      "          2.4961e-01, -5.8746e-02, -4.0568e-02,  3.0266e-02,  3.4719e-02,\n",
      "         -3.2887e-02, -1.6669e-01,  7.5128e-02, -7.5975e-02, -7.1786e-03,\n",
      "         -1.6177e-01, -2.5386e-03, -3.0799e-02,  4.7787e-02, -6.3460e-02,\n",
      "         -8.2884e-02, -1.1370e-01,  4.5317e-02,  5.9779e-02, -6.7752e-02,\n",
      "         -1.6571e-02,  1.3417e-01, -2.1416e-01, -3.8775e-02, -1.2262e-01,\n",
      "          1.4578e-02,  9.0589e-02, -1.4273e-01, -7.3872e-02, -8.9472e-02,\n",
      "          5.5778e-02, -2.6962e-02, -1.7943e-02,  5.5984e-02,  4.7368e-02,\n",
      "         -1.0904e-01,  4.6600e-02,  3.9042e-02, -5.2695e-02, -1.0275e-01,\n",
      "         -1.6213e-01,  1.9134e-02,  2.9719e-02, -1.1613e-02,  1.1419e-01,\n",
      "          3.2854e-02, -4.9260e-02,  1.9675e-02, -9.1884e-02,  1.6978e-02,\n",
      "          7.0842e-02, -7.6701e-02, -3.1519e-02, -3.6040e-02,  1.1718e-01,\n",
      "          4.6008e-02,  3.4773e-02, -4.9161e-03,  1.2980e-01, -7.6878e-02,\n",
      "          4.8435e-02,  9.9474e-02, -4.0251e-02, -5.3403e-02, -1.3901e-02,\n",
      "         -7.8947e-02, -4.8395e-02,  7.8823e-03, -7.3261e-03,  1.3827e-01,\n",
      "          2.2260e-01, -5.8315e-02, -7.2242e-02,  1.5887e-01, -8.0977e-02,\n",
      "          1.0775e-01,  3.2003e-02, -1.1502e-02,  1.4998e-01,  2.6778e-02,\n",
      "         -1.3570e-01, -6.0425e-02, -1.1962e-01,  1.8530e-01, -9.9290e-02,\n",
      "         -9.4217e-02,  1.5977e-02,  9.4769e-02,  8.7238e-02,  1.6385e-01,\n",
      "          1.7463e-01,  2.5171e-04,  2.8375e-02,  1.0001e-01, -3.3727e-02,\n",
      "          2.0685e-02, -4.5394e-02, -2.5442e-02,  2.8714e-02, -3.1807e-02,\n",
      "          8.1321e-02,  1.1111e-01,  1.2730e-02,  9.4221e-03,  4.8943e-02,\n",
      "          1.8181e-02, -1.9831e-02, -7.0809e-02,  1.0177e-01, -6.5593e-02,\n",
      "         -1.3029e-01, -7.9655e-02,  6.1745e-03],\n",
      "        [-1.1144e-01, -1.4874e-03,  1.9618e-01, -8.6671e-03,  4.5788e-02,\n",
      "          4.8405e-02,  7.3126e-02, -2.8502e-02, -1.4914e-01, -6.0532e-02,\n",
      "         -6.4212e-02,  8.5598e-02,  5.0560e-02,  7.2564e-02, -7.0877e-02,\n",
      "         -1.9122e-01, -4.1836e-02, -8.1039e-02, -9.5549e-02,  4.8197e-02,\n",
      "          2.1048e-02,  1.1261e-01,  4.9392e-03,  1.4982e-02, -8.1007e-02,\n",
      "          1.5445e-01,  3.8319e-02,  3.8493e-02, -4.9111e-02,  7.6366e-02,\n",
      "          5.6323e-02,  4.5039e-02,  7.3200e-03,  5.6921e-02,  7.2194e-02,\n",
      "         -8.3751e-03,  1.9541e-02,  1.0655e-01,  2.8019e-02,  1.4792e-01,\n",
      "          6.6684e-02, -5.9455e-02,  5.5170e-02,  8.8021e-02,  1.1987e-01,\n",
      "         -6.6470e-02,  1.3700e-02, -1.9886e-02,  1.7212e-02, -7.9684e-02,\n",
      "          1.3214e-01, -7.9918e-02,  3.4114e-02,  1.4615e-01,  5.5965e-03,\n",
      "          1.0799e-01, -2.3375e-02, -3.0417e-02,  2.3092e-02, -4.5300e-02,\n",
      "         -1.1038e-01,  4.2256e-02, -1.3601e-02,  9.1979e-02,  9.0466e-02,\n",
      "         -8.2468e-02,  2.4552e-02,  1.9339e-02,  2.1049e-02, -8.1517e-02,\n",
      "         -8.4409e-02, -1.4668e-03, -2.8430e-02,  1.3479e-02,  1.0255e-01,\n",
      "          2.5558e-02, -2.1402e-01, -8.0849e-02,  4.5877e-02, -8.8686e-03,\n",
      "          1.1890e-01,  2.3419e-03,  2.7201e-02,  2.0155e-02, -1.0376e-01,\n",
      "         -2.0196e-01,  1.1103e-01,  8.8879e-02, -1.8975e-01,  1.3184e-01,\n",
      "         -3.7472e-02, -4.5767e-02,  3.2987e-02, -2.2138e-01,  3.0206e-02,\n",
      "          4.9182e-02, -2.5936e-02,  2.0906e-01, -1.4150e-01,  1.0911e-01,\n",
      "          7.2038e-02,  3.0138e-03, -1.2030e-01, -1.2708e-01, -1.0857e-01,\n",
      "         -1.6273e-01, -3.5856e-02, -2.4483e-03, -5.2206e-02, -1.1118e-02,\n",
      "         -7.0563e-02,  9.1224e-02, -4.1317e-02, -7.6999e-02, -2.5132e-02,\n",
      "         -1.8491e-01, -1.2541e-01,  1.9136e-02,  3.8737e-03, -3.8525e-02,\n",
      "         -1.2321e-01,  5.0509e-02,  2.2752e-02, -5.9508e-02,  1.6684e-01,\n",
      "          1.6190e-01,  3.4523e-02,  5.6857e-03],\n",
      "        [-6.6967e-03, -3.7107e-02,  2.9550e-02, -7.4575e-02,  1.7172e-02,\n",
      "          5.7549e-02,  1.0061e-01, -8.6854e-02, -4.5042e-02, -4.6488e-02,\n",
      "          6.5447e-02,  1.0114e-01,  7.7988e-02,  8.2251e-02, -8.8722e-02,\n",
      "         -8.3678e-02,  4.0919e-02,  9.0273e-02,  8.3956e-03, -9.0387e-02,\n",
      "          1.7702e-03, -4.2618e-02, -3.6293e-02,  1.9556e-02, -8.4757e-02,\n",
      "          6.7381e-02,  2.0895e-02,  6.4403e-02, -1.6943e-01,  1.6733e-01,\n",
      "          1.1686e-02,  7.8254e-02,  1.5151e-01, -1.8871e-02,  2.0882e-02,\n",
      "          5.8600e-02, -2.7505e-02,  3.4352e-01, -2.2810e-03, -8.5700e-02,\n",
      "         -1.3135e-02,  1.3241e-02, -1.2994e-01, -1.4764e-01,  7.1692e-02,\n",
      "          3.2059e-02,  1.4404e-01, -4.5543e-02, -7.5695e-02, -9.1759e-02,\n",
      "         -8.2733e-02, -2.7950e-02,  1.3589e-02, -1.3254e-02,  8.7221e-02,\n",
      "          1.8287e-02, -1.0827e-01, -4.9128e-02,  5.0434e-02,  1.4807e-02,\n",
      "         -7.2944e-03,  1.9517e-02, -1.0065e-01, -7.8786e-02,  2.5210e-01,\n",
      "         -1.9653e-02, -8.2193e-02,  4.0343e-02,  6.9185e-02, -1.8318e-01,\n",
      "         -1.6420e-01,  4.5405e-02,  6.6416e-04, -6.1253e-02,  6.8897e-02,\n",
      "          1.2554e-01, -7.3544e-02, -8.5880e-02,  8.7821e-02,  6.2416e-02,\n",
      "          7.8442e-02, -3.2433e-02, -1.5432e-01,  6.6669e-02,  1.0779e-01,\n",
      "         -8.1358e-02,  5.8364e-02, -4.3023e-02,  1.1616e-02, -1.3661e-02,\n",
      "          8.7678e-02, -1.9507e-03,  1.0302e-01, -4.3531e-02, -3.1254e-02,\n",
      "          2.7103e-03,  1.8305e-01,  1.5252e-01,  5.6462e-02,  1.3258e-01,\n",
      "          3.0606e-03,  2.5658e-02, -5.1388e-02, -2.5737e-02, -9.7661e-02,\n",
      "         -5.3331e-02,  7.2180e-02, -8.1158e-02, -1.3791e-01, -3.1695e-02,\n",
      "          5.9073e-03, -3.5814e-02, -1.9351e-01, -1.5278e-02, -7.0695e-02,\n",
      "         -1.9692e-01,  6.1114e-02, -1.5213e-02,  6.5936e-02, -2.1865e-02,\n",
      "         -4.0043e-03, -4.1941e-02, -2.3109e-02, -2.5645e-02,  7.8637e-02,\n",
      "          1.1687e-01, -1.7176e-01, -1.1842e-02]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.7998,   1.7913,   3.0421,   6.8254],\n",
      "        [  0.6755,  13.5993, -11.9329,  -4.4154],\n",
      "        [  4.8046, -11.4507,  13.5923,   5.1149],\n",
      "        [  7.7451,  -3.8651,   4.8229,  13.3122]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7998, 13.5993, 13.5923, 13.3122], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0013, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  1.7913,   3.0421,   6.8254],\n",
      "        [  0.6755, -11.9329,  -4.4154],\n",
      "        [  4.8046, -11.4507,   5.1149],\n",
      "        [  7.7451,  -3.8651,   4.8229]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0004, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 7: 0.0008907857118174434\n",
      "Epoch [9/10], Loss: 0.0481\n",
      "Batch 1/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-1.2105e-01, -4.6350e-03,  9.3434e-02,  ...,  1.8968e-01,\n",
      "         -3.4912e-03, -1.2416e-02],\n",
      "        [-3.0202e-02,  4.3585e-03,  8.9696e-02,  ...,  5.1087e-02,\n",
      "          8.8487e-02, -3.0352e-02],\n",
      "        [ 1.0540e-01, -2.0855e-02, -7.0789e-02,  ..., -8.2794e-02,\n",
      "          1.4324e-01, -3.6755e-03],\n",
      "        ...,\n",
      "        [ 3.6489e-02, -4.9636e-03, -1.6329e-01,  ..., -7.4121e-02,\n",
      "          9.2712e-05, -2.8198e-02],\n",
      "        [-4.5012e-02,  3.2700e-02,  9.4211e-02,  ...,  6.4011e-02,\n",
      "         -1.8779e-01, -9.3491e-02],\n",
      "        [ 1.4299e-01, -4.7524e-02, -1.7981e-01,  ..., -1.2120e-01,\n",
      "         -8.9538e-02, -6.0747e-02]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.1315, -0.0202,  0.0909,  ...,  0.1276, -0.0221,  0.0003],\n",
      "        [-0.0504,  0.0048,  0.0846,  ...,  0.0124,  0.0919,  0.0013],\n",
      "        [ 0.0635, -0.0287, -0.0876,  ..., -0.0586,  0.1576, -0.0339],\n",
      "        ...,\n",
      "        [ 0.0133,  0.0004, -0.1718,  ..., -0.1144,  0.0163,  0.0041],\n",
      "        [-0.0411,  0.0300,  0.1300,  ...,  0.0411, -0.1879, -0.0947],\n",
      "        [ 0.1612, -0.0647, -0.1948,  ..., -0.1363, -0.0754, -0.0272]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.7639,   2.8504,  -6.4881,   0.7561,   4.9686, -10.2301,   2.1420,\n",
      "           1.1036,   0.7691,   0.6890,  -0.3001,   5.5703,  -6.8611,  -4.6380,\n",
      "           2.6255,  -9.7488],\n",
      "        [  3.1576,  13.6612,   5.4636,   1.2616,   1.7653,   1.7214,   7.5118,\n",
      "           5.1712,   3.0641,  -8.6943,  -4.1363,  -2.2207,   2.0371, -11.1253,\n",
      "           6.3207,  -2.0763],\n",
      "        [ -8.0304,   5.4837,  13.8900,   4.8496,  -6.0426,  11.7254,   1.1680,\n",
      "           0.2595,   6.3647,  -9.7371,  -4.4195,  -7.7190,  11.3492,  -0.9435,\n",
      "          -6.0790,   7.4773],\n",
      "        [ -1.2187,   4.1070,   6.2998,  13.7942,  -5.0289,   0.7638,  -6.6632,\n",
      "          -4.0998,  -1.7788,  -4.0939,   5.1998,  -9.5749,   7.1291,   4.0642,\n",
      "          -4.3737,   3.2477],\n",
      "        [  6.9613,   0.1036,  -7.6407,  -6.8040,  13.5582,  -9.4671,   8.5829,\n",
      "          -0.4808,  -7.7077,   7.8918,  -2.2174,   4.9292, -11.5588,  -7.6728,\n",
      "           7.9728, -10.0051],\n",
      "        [ -9.8917,   2.4248,  10.6762,  -0.3214,  -7.6232,  13.7910,  -0.5686,\n",
      "           5.1394,   8.0394,  -7.9546,  -2.6701,  -5.6375,   9.9639,   1.0582,\n",
      "          -4.0031,  11.0060],\n",
      "        [  3.0565,   6.5437,   0.9784,  -7.4841,   8.5835,  -1.2209,  13.6690,\n",
      "           1.2396,   0.5250,  -2.1834,  -9.8876,   5.0622,  -3.8804, -12.2170,\n",
      "           5.9146,  -7.7305],\n",
      "        [  1.9380,   5.6233,   0.2997,  -3.2611,   0.1868,   3.6341,   1.0276,\n",
      "          13.6317,   4.4979,  -4.0629,   0.9699,  -1.8522,   0.0358,  -4.8336,\n",
      "           5.3515,   4.2619],\n",
      "        [  0.7536,   2.3601,   5.2025,  -1.9881,  -7.7263,   7.2129,   0.6028,\n",
      "           5.0245,  13.8373,  -9.6028,  -6.2176,   3.8771,   6.1969,  -0.8384,\n",
      "          -5.3610,   2.8532],\n",
      "        [  1.4232,  -9.1100,  -9.9431,  -4.1838,   6.7559,  -7.8279,  -2.6964,\n",
      "          -3.7867,  -9.9578,  13.8648,   7.5257,   1.1636, -10.6893,   3.9338,\n",
      "           4.7500,  -2.1504],\n",
      "        [ -0.7840,  -3.5706,  -4.3585,   5.2517,  -1.9877,  -3.1906, -10.1567,\n",
      "          -0.6724,  -7.0114,   7.1339,  13.7475,  -7.0175,  -3.0810,   7.1033,\n",
      "           3.6589,   5.4292],\n",
      "        [  7.6584,  -2.1134,  -7.4562,  -7.7111,   3.4108,  -6.4056,   5.7396,\n",
      "          -1.2555,   3.2982,   1.0868,  -7.0791,  13.3400,  -6.0510,  -3.2367,\n",
      "           1.1983,  -9.8392],\n",
      "        [ -8.1774,   2.9317,  11.5446,   7.3499,  -9.7512,  10.3207,  -3.0776,\n",
      "          -1.4124,   6.8453, -10.3442,  -3.8108,  -5.1156,  13.6022,   4.0739,\n",
      "          -9.2325,   6.9969],\n",
      "        [ -5.2413, -10.0260,  -2.2090,   4.2750,  -8.0499,   1.1919, -11.8958,\n",
      "          -4.7059,  -0.8053,   4.0396,   6.7791,  -1.0384,   3.4630,  13.7246,\n",
      "          -7.0018,   6.1461],\n",
      "        [  3.6850,   5.1905,  -5.5022,  -5.6687,   7.6654,  -4.9571,   5.7529,\n",
      "           2.9262,  -6.1979,   4.8883,   3.3882,   0.4066,  -9.2415,  -8.0962,\n",
      "          13.8532,  -3.3332],\n",
      "        [ -9.7548,  -1.0204,   7.0093,   3.4296,  -9.4638,  10.8843,  -8.0943,\n",
      "           3.8612,   3.6955,  -3.0382,   6.2084,  -9.0009,   8.0219,   6.8030,\n",
      "          -2.9164,  13.8996]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7639, 13.6612, 13.8900, 13.7942, 13.5582, 13.7910, 13.6690, 13.6317,\n",
      "        13.8373, 13.8648, 13.7475, 13.3400, 13.6022, 13.7246, 13.8532, 13.8996],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0349, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  2.8504,  -6.4881,   0.7561,   4.9686, -10.2301,   2.1420,   1.1036,\n",
      "           0.7691,   0.6890,  -0.3001,   5.5703,  -6.8611,  -4.6380,   2.6255,\n",
      "          -9.7488],\n",
      "        [  3.1576,   5.4636,   1.2616,   1.7653,   1.7214,   7.5118,   5.1712,\n",
      "           3.0641,  -8.6943,  -4.1363,  -2.2207,   2.0371, -11.1253,   6.3207,\n",
      "          -2.0763],\n",
      "        [ -8.0304,   5.4837,   4.8496,  -6.0426,  11.7254,   1.1680,   0.2595,\n",
      "           6.3647,  -9.7371,  -4.4195,  -7.7190,  11.3492,  -0.9435,  -6.0790,\n",
      "           7.4773],\n",
      "        [ -1.2187,   4.1070,   6.2998,  -5.0289,   0.7638,  -6.6632,  -4.0998,\n",
      "          -1.7788,  -4.0939,   5.1998,  -9.5749,   7.1291,   4.0642,  -4.3737,\n",
      "           3.2477],\n",
      "        [  6.9613,   0.1036,  -7.6407,  -6.8040,  -9.4671,   8.5829,  -0.4808,\n",
      "          -7.7077,   7.8918,  -2.2174,   4.9292, -11.5588,  -7.6728,   7.9728,\n",
      "         -10.0051],\n",
      "        [ -9.8917,   2.4248,  10.6762,  -0.3214,  -7.6232,  -0.5686,   5.1394,\n",
      "           8.0394,  -7.9546,  -2.6701,  -5.6375,   9.9639,   1.0582,  -4.0031,\n",
      "          11.0060],\n",
      "        [  3.0565,   6.5437,   0.9784,  -7.4841,   8.5835,  -1.2209,   1.2396,\n",
      "           0.5250,  -2.1834,  -9.8876,   5.0622,  -3.8804, -12.2170,   5.9146,\n",
      "          -7.7305],\n",
      "        [  1.9380,   5.6233,   0.2997,  -3.2611,   0.1868,   3.6341,   1.0276,\n",
      "           4.4979,  -4.0629,   0.9699,  -1.8522,   0.0358,  -4.8336,   5.3515,\n",
      "           4.2619],\n",
      "        [  0.7536,   2.3601,   5.2025,  -1.9881,  -7.7263,   7.2129,   0.6028,\n",
      "           5.0245,  -9.6028,  -6.2176,   3.8771,   6.1969,  -0.8384,  -5.3610,\n",
      "           2.8532],\n",
      "        [  1.4232,  -9.1100,  -9.9431,  -4.1838,   6.7559,  -7.8279,  -2.6964,\n",
      "          -3.7867,  -9.9578,   7.5257,   1.1636, -10.6893,   3.9338,   4.7500,\n",
      "          -2.1504],\n",
      "        [ -0.7840,  -3.5706,  -4.3585,   5.2517,  -1.9877,  -3.1906, -10.1567,\n",
      "          -0.6724,  -7.0114,   7.1339,  -7.0175,  -3.0810,   7.1033,   3.6589,\n",
      "           5.4292],\n",
      "        [  7.6584,  -2.1134,  -7.4562,  -7.7111,   3.4108,  -6.4056,   5.7396,\n",
      "          -1.2555,   3.2982,   1.0868,  -7.0791,  -6.0510,  -3.2367,   1.1983,\n",
      "          -9.8392],\n",
      "        [ -8.1774,   2.9317,  11.5446,   7.3499,  -9.7512,  10.3207,  -3.0776,\n",
      "          -1.4124,   6.8453, -10.3442,  -3.8108,  -5.1156,   4.0739,  -9.2325,\n",
      "           6.9969],\n",
      "        [ -5.2413, -10.0260,  -2.2090,   4.2750,  -8.0499,   1.1919, -11.8958,\n",
      "          -4.7059,  -0.8053,   4.0396,   6.7791,  -1.0384,   3.4630,  -7.0018,\n",
      "           6.1461],\n",
      "        [  3.6850,   5.1905,  -5.5022,  -5.6687,   7.6654,  -4.9571,   5.7529,\n",
      "           2.9262,  -6.1979,   4.8883,   3.3882,   0.4066,  -9.2415,  -8.0962,\n",
      "          -3.3332],\n",
      "        [ -9.7548,  -1.0204,   7.0093,   3.4296,  -9.4638,  10.8843,  -8.0943,\n",
      "           3.8612,   3.6955,  -3.0382,   6.2084,  -9.0009,   8.0219,   6.8030,\n",
      "          -2.9164]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0023, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 1: 0.018583040684461594\n",
      "Batch 2/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.1192, -0.0042, -0.1251,  ..., -0.0482,  0.1403,  0.0187],\n",
      "        [ 0.1197, -0.0543, -0.0514,  ...,  0.0384, -0.1802,  0.0544],\n",
      "        [ 0.0631,  0.0162, -0.0142,  ..., -0.0519, -0.0744, -0.0433],\n",
      "        ...,\n",
      "        [ 0.0555, -0.0961, -0.0673,  ...,  0.0550,  0.0216, -0.0227],\n",
      "        [ 0.0277, -0.0179, -0.1961,  ..., -0.0935,  0.1208,  0.0326],\n",
      "        [ 0.1141, -0.0455,  0.1334,  ...,  0.0108, -0.0710,  0.0103]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0348, -0.0526, -0.1382,  ..., -0.0309,  0.1891, -0.0106],\n",
      "        [ 0.1169, -0.0608, -0.0700,  ...,  0.0412, -0.1980,  0.0816],\n",
      "        [ 0.0360,  0.0085, -0.0025,  ..., -0.0590, -0.0545, -0.0721],\n",
      "        ...,\n",
      "        [ 0.0380, -0.0717, -0.0594,  ...,  0.0418, -0.0021,  0.0417],\n",
      "        [ 0.0036, -0.0305, -0.1794,  ..., -0.0847,  0.0721,  0.0213],\n",
      "        [ 0.0683, -0.0507,  0.1161,  ...,  0.0681, -0.0622,  0.0074]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.6413,   2.4506,  -7.2140,   1.9424,  -3.3398,   2.4183,  -2.3970,\n",
      "           1.1218, -10.1994, -10.7642,   2.2399,   1.8005, -10.5462,  -0.8809,\n",
      "           3.3138,  -2.7820],\n",
      "        [  2.0450,  13.8172,  -7.3926,   7.8223,  -7.4410,  -5.2869,  11.1700,\n",
      "           7.5660,  -8.0752,   1.8990,  -8.2017,   7.3344,  -0.2513,   5.3627,\n",
      "          -2.4104,  -1.7821],\n",
      "        [ -7.9749,  -6.4060,  13.8433,   3.2198,   8.6764,   5.2345,  -6.3288,\n",
      "         -11.1924,   9.7304,   8.1756,  -2.8989,  -8.3426,   7.6145,   2.0445,\n",
      "           3.7480,   5.1984],\n",
      "        [  0.5615,   8.9552,   3.2460,  13.7722,  -0.8951,   1.6620,   2.4216,\n",
      "          -4.1291,  -4.1324,   4.8144, -10.8853,  -0.1571,   2.7347,   7.1518,\n",
      "           3.0152,   3.7493],\n",
      "        [ -4.7355,  -7.4597,   9.1212,  -0.3114,  13.7534,   2.0472,  -5.6589,\n",
      "          -8.4038,  10.4993,   5.4272,   0.1275,  -4.6965,   1.6655,  -6.9400,\n",
      "           2.2558,  -0.1226],\n",
      "        [  2.4708,  -6.3558,   5.7605,   0.7325,   3.3600,  13.6442,  -9.7704,\n",
      "         -10.7066,   1.9098,  -0.5053,   3.8539, -12.3506,  -2.0079,   2.1189,\n",
      "           5.3830,   1.6175],\n",
      "        [ -2.2297,  10.5152,  -7.0138,   1.6685,  -4.8579,  -8.5305,  13.8312,\n",
      "          10.3796,  -3.2685,   3.4818,  -5.9507,   7.8452,   1.8625,   2.9446,\n",
      "          -3.1841,  -5.6087],\n",
      "        [  2.1466,   5.9988, -11.1369,  -4.7394,  -8.7365,  -8.9535,   9.7756,\n",
      "          13.7489,  -6.1659,  -4.8053,  -0.2458,   9.1391,  -0.5732,   0.0822,\n",
      "          -3.3299,  -6.2722],\n",
      "        [-11.2745,  -8.0105,   9.4302,  -4.2333,  10.0664,   1.2900,  -3.5270,\n",
      "          -6.1862,  13.8576,   9.8001,   2.7451,  -4.8728,   5.3874,  -4.9802,\n",
      "          -3.1751,   3.1521],\n",
      "        [-12.5310,   0.8928,   7.3024,   2.6752,   5.6702,  -1.2485,   2.7356,\n",
      "          -3.6123,  10.0487,  13.8250,  -3.7920,  -1.2740,   7.4080,  -0.4390,\n",
      "          -5.3906,   4.7437],\n",
      "        [  2.2411,  -9.0046,  -2.1055, -10.7772,   0.8576,   2.8791,  -7.1172,\n",
      "          -0.9472,   2.8307,  -4.9929,  13.7589,  -2.0849,  -7.3655,  -6.7712,\n",
      "          -4.7992,   2.3321],\n",
      "        [  2.5822,   6.7882,  -9.3187,  -0.8455,  -4.1784, -11.9926,   7.9064,\n",
      "          10.6552,  -5.0421,  -3.0299,  -0.6074,  13.5263,  -4.1069,  -4.1639,\n",
      "          -6.7949,  -1.2227],\n",
      "        [-10.7625,  -1.5331,   7.4546,   0.9323,   0.6786,  -1.2122,   1.8717,\n",
      "          -0.7381,   6.4518,   7.5636,  -6.6940,  -3.0370,  13.7803,   4.9157,\n",
      "           2.6606,   0.5632],\n",
      "        [  1.0583,   6.3758,   1.5353,   6.7876,  -7.7613,   3.1117,   4.2894,\n",
      "          -0.3699,  -6.1954,   0.8821,  -6.5636,  -3.1819,   4.3453,  13.7463,\n",
      "           5.2617,   0.8300],\n",
      "        [  4.6107,  -2.9317,   4.1642,   2.3592,   2.3296,   6.1350,  -2.7287,\n",
      "          -4.4077,  -2.1508,  -4.4589,  -4.3139,  -7.7761,   2.4667,   5.3150,\n",
      "          13.6941,  -7.3599],\n",
      "        [ -2.7704,   0.0942,   5.3450,   4.9491,  -1.6600,   2.4294,  -5.2944,\n",
      "          -6.2837,   1.0561,   4.2066,   1.0183,  -0.5407,   0.5511,   2.8838,\n",
      "          -5.7078,  13.6487]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6413, 13.8172, 13.8433, 13.7722, 13.7534, 13.6442, 13.8312, 13.7489,\n",
      "        13.8576, 13.8250, 13.7589, 13.5263, 13.7803, 13.7463, 13.6941, 13.6487],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0251, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  2.4506,  -7.2140,   1.9424,  -3.3398,   2.4183,  -2.3970,   1.1218,\n",
      "         -10.1994, -10.7642,   2.2399,   1.8005, -10.5462,  -0.8809,   3.3138,\n",
      "          -2.7820],\n",
      "        [  2.0450,  -7.3926,   7.8223,  -7.4410,  -5.2869,  11.1700,   7.5660,\n",
      "          -8.0752,   1.8990,  -8.2017,   7.3344,  -0.2513,   5.3627,  -2.4104,\n",
      "          -1.7821],\n",
      "        [ -7.9749,  -6.4060,   3.2198,   8.6764,   5.2345,  -6.3288, -11.1924,\n",
      "           9.7304,   8.1756,  -2.8989,  -8.3426,   7.6145,   2.0445,   3.7480,\n",
      "           5.1984],\n",
      "        [  0.5615,   8.9552,   3.2460,  -0.8951,   1.6620,   2.4216,  -4.1291,\n",
      "          -4.1324,   4.8144, -10.8853,  -0.1571,   2.7347,   7.1518,   3.0152,\n",
      "           3.7493],\n",
      "        [ -4.7355,  -7.4597,   9.1212,  -0.3114,   2.0472,  -5.6589,  -8.4038,\n",
      "          10.4993,   5.4272,   0.1275,  -4.6965,   1.6655,  -6.9400,   2.2558,\n",
      "          -0.1226],\n",
      "        [  2.4708,  -6.3558,   5.7605,   0.7325,   3.3600,  -9.7704, -10.7066,\n",
      "           1.9098,  -0.5053,   3.8539, -12.3506,  -2.0079,   2.1189,   5.3830,\n",
      "           1.6175],\n",
      "        [ -2.2297,  10.5152,  -7.0138,   1.6685,  -4.8579,  -8.5305,  10.3796,\n",
      "          -3.2685,   3.4818,  -5.9507,   7.8452,   1.8625,   2.9446,  -3.1841,\n",
      "          -5.6087],\n",
      "        [  2.1466,   5.9988, -11.1369,  -4.7394,  -8.7365,  -8.9535,   9.7756,\n",
      "          -6.1659,  -4.8053,  -0.2458,   9.1391,  -0.5732,   0.0822,  -3.3299,\n",
      "          -6.2722],\n",
      "        [-11.2745,  -8.0105,   9.4302,  -4.2333,  10.0664,   1.2900,  -3.5270,\n",
      "          -6.1862,   9.8001,   2.7451,  -4.8728,   5.3874,  -4.9802,  -3.1751,\n",
      "           3.1521],\n",
      "        [-12.5310,   0.8928,   7.3024,   2.6752,   5.6702,  -1.2485,   2.7356,\n",
      "          -3.6123,  10.0487,  -3.7920,  -1.2740,   7.4080,  -0.4390,  -5.3906,\n",
      "           4.7437],\n",
      "        [  2.2411,  -9.0046,  -2.1055, -10.7772,   0.8576,   2.8791,  -7.1172,\n",
      "          -0.9472,   2.8307,  -4.9929,  -2.0849,  -7.3655,  -6.7712,  -4.7992,\n",
      "           2.3321],\n",
      "        [  2.5822,   6.7882,  -9.3187,  -0.8455,  -4.1784, -11.9926,   7.9064,\n",
      "          10.6552,  -5.0421,  -3.0299,  -0.6074,  -4.1069,  -4.1639,  -6.7949,\n",
      "          -1.2227],\n",
      "        [-10.7625,  -1.5331,   7.4546,   0.9323,   0.6786,  -1.2122,   1.8717,\n",
      "          -0.7381,   6.4518,   7.5636,  -6.6940,  -3.0370,   4.9157,   2.6606,\n",
      "           0.5632],\n",
      "        [  1.0583,   6.3758,   1.5353,   6.7876,  -7.7613,   3.1117,   4.2894,\n",
      "          -0.3699,  -6.1954,   0.8821,  -6.5636,  -3.1819,   4.3453,   5.2617,\n",
      "           0.8300],\n",
      "        [  4.6107,  -2.9317,   4.1642,   2.3592,   2.3296,   6.1350,  -2.7287,\n",
      "          -4.4077,  -2.1508,  -4.4589,  -4.3139,  -7.7761,   2.4667,   5.3150,\n",
      "          -7.3599],\n",
      "        [ -2.7704,   0.0942,   5.3450,   4.9491,  -1.6600,   2.4294,  -5.2944,\n",
      "          -6.2837,   1.0561,   4.2066,   1.0183,  -0.5407,   0.5511,   2.8838,\n",
      "          -5.7078]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0017, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 2: 0.013370743952691555\n",
      "Batch 3/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.0806,  0.0423,  0.0118,  ...,  0.0436, -0.1225, -0.1019],\n",
      "        [ 0.0011, -0.0243,  0.1889,  ...,  0.0966, -0.1349, -0.0899],\n",
      "        [-0.0382,  0.0026, -0.0026,  ..., -0.0535,  0.2482, -0.1203],\n",
      "        ...,\n",
      "        [ 0.1170,  0.0083, -0.1288,  ..., -0.1528,  0.0749, -0.0392],\n",
      "        [ 0.1096,  0.0318, -0.1284,  ..., -0.1586, -0.1363, -0.0179],\n",
      "        [ 0.1079, -0.0314, -0.1448,  ..., -0.0451,  0.1117,  0.0648]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.1254,  0.0302,  0.0014,  ...,  0.0213, -0.1037, -0.0775],\n",
      "        [-0.0191, -0.0346,  0.2303,  ...,  0.0736, -0.0874, -0.1128],\n",
      "        [-0.0564,  0.0071, -0.0364,  ..., -0.0687,  0.2319, -0.1198],\n",
      "        ...,\n",
      "        [ 0.0943, -0.0024, -0.1444,  ..., -0.1638,  0.0796, -0.0474],\n",
      "        [ 0.0730,  0.0286, -0.1087,  ..., -0.1372, -0.1140, -0.0102],\n",
      "        [ 0.0759, -0.0670, -0.1517,  ..., -0.0338,  0.1233,  0.0945]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.8600,   1.1998,   2.6253,   8.3260,  -7.4579,   0.6487,   1.6350,\n",
      "           8.2166,  -1.3378,   4.6741,   2.6287,   3.1426,   3.9096,  -4.7287,\n",
      "           2.4643,  -8.9577],\n",
      "        [  2.0809,  13.5305,  -2.6872,   7.3239,  -6.2948,   4.2523,  -7.2265,\n",
      "          -0.0357,   1.6248,   1.9306,   8.4485,  -8.8230,   4.3689,  -5.4705,\n",
      "          -4.5772,  -9.4668],\n",
      "        [  2.4608,  -1.9175,  13.8375,   1.2840,  -4.5484,   4.8234,  -0.4970,\n",
      "          -7.0478,  -4.1831,   0.2897,   0.3729,   2.6777,  -6.9418,   5.4358,\n",
      "           1.1271,   0.5134],\n",
      "        [  8.9709,   6.8067,   1.5374,  13.8959, -11.7276,  -4.8226,  -8.4671,\n",
      "           1.2096,  -7.9453,  -4.6330,  -0.0744,  -4.9221,  -2.5336, -10.4088,\n",
      "          -8.3097,  -7.7925],\n",
      "        [ -6.8947,  -6.4006,  -4.7725, -11.2764,  13.7499,   1.9406,  10.2878,\n",
      "           2.5707,   8.3430,   5.0933,  -2.6616,   4.0353,   4.8308,   9.0461,\n",
      "           7.4097,   7.6555],\n",
      "        [ -0.3850,   3.4343,   5.7028,  -4.4917,   2.1867,  13.7112,   4.7084,\n",
      "          -3.1287,   5.9990,  10.4008,   7.9990,   3.4802,   5.6545,   9.3218,\n",
      "           8.8078,  -5.0082],\n",
      "        [  1.1119,  -8.7933,  -1.4417,  -9.0450,  10.2057,   3.8824,  13.7097,\n",
      "           6.8478,   7.2145,   9.2516,  -2.0590,   9.5558,   7.2725,   8.4844,\n",
      "          11.9486,   3.2439],\n",
      "        [  8.3150,   0.6842,  -7.6818,   2.1350,   0.7976,  -1.6769,   4.9569,\n",
      "          13.6919,   6.1526,   5.7945,   2.8986,   0.3761,   8.7689,  -4.9152,\n",
      "           3.2955,  -4.5000],\n",
      "        [ -1.3068,   2.2103,  -4.4387,  -7.1576,   7.7411,   7.8314,   7.1466,\n",
      "           6.4624,  13.5310,   9.8293,   8.7355,  -0.6589,   8.8010,   5.7909,\n",
      "           7.4194,  -0.8307],\n",
      "        [  4.4335,   0.6085,   0.4399,  -4.1406,   4.4141,  10.4834,  10.0410,\n",
      "           5.4920,   7.7848,  13.6489,   4.7847,   5.6919,  11.4108,   6.7814,\n",
      "          11.6568,  -5.3728],\n",
      "        [  2.5458,   8.7120,   0.5269,   1.5414,  -3.3754,   8.2963,  -2.7154,\n",
      "           1.7808,   7.5293,   5.3198,  13.7241,  -3.9717,   3.8079,   0.0857,\n",
      "           1.2420,  -8.1164],\n",
      "        [  3.4976,  -9.4020,   3.9327,  -3.9441,   3.2806,   2.3441,   8.7971,\n",
      "           0.7171,  -2.5265,   4.8275,  -5.1732,  13.6043,   2.5264,   6.1631,\n",
      "           9.4381,  -0.6840],\n",
      "        [  3.6217,   2.2049,  -6.6936,  -2.7698,   4.5777,   6.5238,   7.9394,\n",
      "           7.8900,   7.1992,  11.4952,   3.7252,   4.0794,  13.8983,   2.1050,\n",
      "           9.0403,  -6.6974],\n",
      "        [ -5.0205,  -6.6007,   6.5923, -10.2665,   8.9382,   8.0218,   9.2719,\n",
      "          -4.5149,   4.4134,   6.5153,  -0.9113,   7.4566,   0.6362,  13.6759,\n",
      "           9.3860,   5.3540],\n",
      "        [  2.6688,  -5.7715,   0.9694,  -8.0343,   7.7718,   8.3728,  12.7970,\n",
      "           5.3941,   7.4282,  12.0106,   1.5382,  10.1916,   8.8457,   9.1401,\n",
      "          13.6426,  -1.0390],\n",
      "        [ -8.3792,  -8.3941,   0.2909,  -7.7495,   7.5459,  -5.1757,   2.5264,\n",
      "          -2.7891,   1.0173,  -5.4627,  -6.6153,  -0.8087,  -6.9480,   4.3285,\n",
      "          -1.2230,  13.7978]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.8600, 13.5305, 13.8375, 13.8959, 13.7499, 13.7112, 13.7097, 13.6919,\n",
      "        13.5310, 13.6489, 13.7241, 13.6043, 13.8983, 13.6759, 13.6426, 13.7978],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0869, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[  1.1998,   2.6253,   8.3260,  -7.4579,   0.6487,   1.6350,   8.2166,\n",
      "          -1.3378,   4.6741,   2.6287,   3.1426,   3.9096,  -4.7287,   2.4643,\n",
      "          -8.9577],\n",
      "        [  2.0809,  -2.6872,   7.3239,  -6.2948,   4.2523,  -7.2265,  -0.0357,\n",
      "           1.6248,   1.9306,   8.4485,  -8.8230,   4.3689,  -5.4705,  -4.5772,\n",
      "          -9.4668],\n",
      "        [  2.4608,  -1.9175,   1.2840,  -4.5484,   4.8234,  -0.4970,  -7.0478,\n",
      "          -4.1831,   0.2897,   0.3729,   2.6777,  -6.9418,   5.4358,   1.1271,\n",
      "           0.5134],\n",
      "        [  8.9709,   6.8067,   1.5374, -11.7276,  -4.8226,  -8.4671,   1.2096,\n",
      "          -7.9453,  -4.6330,  -0.0744,  -4.9221,  -2.5336, -10.4088,  -8.3097,\n",
      "          -7.7925],\n",
      "        [ -6.8947,  -6.4006,  -4.7725, -11.2764,   1.9406,  10.2878,   2.5707,\n",
      "           8.3430,   5.0933,  -2.6616,   4.0353,   4.8308,   9.0461,   7.4097,\n",
      "           7.6555],\n",
      "        [ -0.3850,   3.4343,   5.7028,  -4.4917,   2.1867,   4.7084,  -3.1287,\n",
      "           5.9990,  10.4008,   7.9990,   3.4802,   5.6545,   9.3218,   8.8078,\n",
      "          -5.0082],\n",
      "        [  1.1119,  -8.7933,  -1.4417,  -9.0450,  10.2057,   3.8824,   6.8478,\n",
      "           7.2145,   9.2516,  -2.0590,   9.5558,   7.2725,   8.4844,  11.9486,\n",
      "           3.2439],\n",
      "        [  8.3150,   0.6842,  -7.6818,   2.1350,   0.7976,  -1.6769,   4.9569,\n",
      "           6.1526,   5.7945,   2.8986,   0.3761,   8.7689,  -4.9152,   3.2955,\n",
      "          -4.5000],\n",
      "        [ -1.3068,   2.2103,  -4.4387,  -7.1576,   7.7411,   7.8314,   7.1466,\n",
      "           6.4624,   9.8293,   8.7355,  -0.6589,   8.8010,   5.7909,   7.4194,\n",
      "          -0.8307],\n",
      "        [  4.4335,   0.6085,   0.4399,  -4.1406,   4.4141,  10.4834,  10.0410,\n",
      "           5.4920,   7.7848,   4.7847,   5.6919,  11.4108,   6.7814,  11.6568,\n",
      "          -5.3728],\n",
      "        [  2.5458,   8.7120,   0.5269,   1.5414,  -3.3754,   8.2963,  -2.7154,\n",
      "           1.7808,   7.5293,   5.3198,  -3.9717,   3.8079,   0.0857,   1.2420,\n",
      "          -8.1164],\n",
      "        [  3.4976,  -9.4020,   3.9327,  -3.9441,   3.2806,   2.3441,   8.7971,\n",
      "           0.7171,  -2.5265,   4.8275,  -5.1732,   2.5264,   6.1631,   9.4381,\n",
      "          -0.6840],\n",
      "        [  3.6217,   2.2049,  -6.6936,  -2.7698,   4.5777,   6.5238,   7.9394,\n",
      "           7.8900,   7.1992,  11.4952,   3.7252,   4.0794,   2.1050,   9.0403,\n",
      "          -6.6974],\n",
      "        [ -5.0205,  -6.6007,   6.5923, -10.2665,   8.9382,   8.0218,   9.2719,\n",
      "          -4.5149,   4.4134,   6.5153,  -0.9113,   7.4566,   0.6362,   9.3860,\n",
      "           5.3540],\n",
      "        [  2.6688,  -5.7715,   0.9694,  -8.0343,   7.7718,   8.3728,  12.7970,\n",
      "           5.3941,   7.4282,  12.0106,   1.5382,  10.1916,   8.8457,   9.1401,\n",
      "          -1.0390],\n",
      "        [ -8.3792,  -8.3941,   0.2909,  -7.7495,   7.5459,  -5.1757,   2.5264,\n",
      "          -2.7891,   1.0173,  -5.4627,  -6.6153,  -0.8087,  -6.9480,   4.3285,\n",
      "          -1.2230]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0053, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 3: 0.04610734060406685\n",
      "Batch 4/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.1060,  0.0358, -0.0443,  ..., -0.0617,  0.2263, -0.0878],\n",
      "        [ 0.1329, -0.0077, -0.0605,  ..., -0.0233, -0.2452,  0.0266],\n",
      "        [ 0.0940, -0.0540,  0.0202,  ...,  0.1346, -0.2507,  0.0758],\n",
      "        ...,\n",
      "        [-0.0141, -0.0718, -0.1869,  ...,  0.0171,  0.0919, -0.0285],\n",
      "        [-0.0489,  0.0530,  0.1858,  ...,  0.0365, -0.1682, -0.0810],\n",
      "        [ 0.0290,  0.0398,  0.1010,  ..., -0.0364, -0.1264, -0.0839]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.1221,  0.0099, -0.0766,  ..., -0.0784,  0.2135, -0.0942],\n",
      "        [ 0.1243, -0.0199, -0.0547,  ..., -0.0020, -0.2547,  0.0611],\n",
      "        [ 0.0750, -0.0625,  0.0162,  ...,  0.1367, -0.1938,  0.1524],\n",
      "        ...,\n",
      "        [-0.0448, -0.0646, -0.1664,  ...,  0.0259,  0.1290, -0.0501],\n",
      "        [-0.0701,  0.0631,  0.1577,  ...,  0.0534, -0.1372, -0.0649],\n",
      "        [ 0.0267,  0.0275,  0.0664,  ..., -0.0282, -0.0712, -0.0552]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3780e+01, -6.7371e+00, -9.8646e+00, -5.9350e+00,  3.4027e+00,\n",
      "          9.3412e-01,  6.2457e+00,  5.9167e+00, -4.7182e+00,  5.9389e+00,\n",
      "         -4.8219e+00,  8.1849e+00, -1.4260e+00,  6.8120e-01, -2.9185e+00,\n",
      "          5.1195e+00],\n",
      "        [-6.6380e+00,  1.3812e+01,  6.8500e+00, -3.6013e-01, -7.5718e+00,\n",
      "          3.4773e+00, -3.8284e-01, -5.3308e+00,  6.5249e+00, -5.0759e+00,\n",
      "         -8.1481e+00, -8.8901e+00,  4.6838e+00, -1.1890e+00,  1.6078e+00,\n",
      "          2.2048e+00],\n",
      "        [-1.0861e+01,  7.9696e+00,  1.3713e+01,  3.0170e-01, -5.5995e+00,\n",
      "         -8.3402e-01,  5.3146e-01, -7.5430e+00,  1.1182e+00, -9.1043e+00,\n",
      "          1.1696e+00, -8.8333e+00,  7.8139e+00,  1.2791e+00, -4.7177e-01,\n",
      "         -3.6678e+00],\n",
      "        [-5.2406e+00, -1.0086e+00,  3.8017e-01,  1.3839e+01,  5.6223e+00,\n",
      "          8.1937e-01, -1.7409e-01,  5.4601e+00,  9.5901e+00,  3.5485e+00,\n",
      "          7.7686e+00, -7.3981e+00, -6.3073e+00, -4.7887e+00,  2.5886e+00,\n",
      "          8.8661e-01],\n",
      "        [ 3.7656e+00, -8.1061e+00, -4.4843e+00,  6.7309e+00,  1.3704e+01,\n",
      "         -3.1791e+00,  1.0298e+00,  1.2053e+01,  4.2658e+00,  3.9981e+00,\n",
      "          8.1397e+00,  3.3321e+00, -7.4467e+00, -7.5832e+00,  6.1309e-01,\n",
      "          5.5117e+00],\n",
      "        [ 8.8119e-01,  1.7964e+00, -3.0728e+00,  1.2194e+00, -3.2911e+00,\n",
      "          1.3957e+01,  1.1738e+00,  1.4303e+00,  3.6975e+00, -5.8807e+00,\n",
      "         -1.4710e+00, -2.7622e+00,  6.3379e+00, -6.8278e+00,  1.1144e+01,\n",
      "          7.4634e+00],\n",
      "        [ 6.1565e+00,  5.2824e-01,  8.5898e-01, -1.8554e-01,  5.6735e-01,\n",
      "          1.6829e+00,  1.3686e+01,  2.1506e+00,  8.5189e-01,  2.7276e+00,\n",
      "         -4.5244e+00, -3.7138e+00,  2.3397e+00, -8.8045e-02, -4.9111e+00,\n",
      "          3.9228e+00],\n",
      "        [ 6.4730e+00, -5.7605e+00, -7.0203e+00,  5.7788e+00,  1.2032e+01,\n",
      "          6.3776e-01,  1.7866e+00,  1.3814e+01,  6.4947e+00,  4.1973e+00,\n",
      "          3.8187e+00,  2.0927e+00, -5.8571e+00, -8.7747e+00,  2.4329e+00,\n",
      "          9.8366e+00],\n",
      "        [-5.1716e+00,  6.3105e+00,  1.5722e+00,  1.0368e+01,  4.0624e+00,\n",
      "          4.6411e+00, -3.5034e-01,  6.1859e+00,  1.3849e+01, -1.1574e+00,\n",
      "          1.1113e+00, -8.5905e+00, -2.6499e+00, -9.9012e+00,  6.0729e+00,\n",
      "          7.6966e+00],\n",
      "        [ 6.9369e+00, -5.6614e+00, -7.9516e+00,  4.2275e+00,  4.4608e+00,\n",
      "         -6.0103e+00,  3.4780e+00,  4.2734e+00,  3.4857e-02,  1.3777e+01,\n",
      "         -4.9505e-01,  2.6183e+00, -1.0691e+01,  4.6987e+00, -7.8525e+00,\n",
      "         -2.7296e+00],\n",
      "        [-4.9379e+00, -7.7838e+00,  1.0365e+00,  8.1708e+00,  7.8333e+00,\n",
      "         -1.8370e+00, -4.5869e+00,  4.5436e+00,  1.3614e+00, -1.3588e+00,\n",
      "          1.3731e+01,  6.0452e-01, -3.6583e+00, -3.8138e+00,  3.7034e+00,\n",
      "         -2.0902e+00],\n",
      "        [ 7.2638e+00, -9.4152e+00, -8.2100e+00, -6.6512e+00,  3.7208e+00,\n",
      "         -3.0822e+00, -3.8095e+00,  1.3445e+00, -8.9644e+00,  3.0405e+00,\n",
      "          1.9620e+00,  1.3792e+01, -4.0326e+00,  2.0956e+00, -6.5894e-01,\n",
      "         -2.4750e+00],\n",
      "        [-2.1135e+00,  5.6371e+00,  6.1509e+00, -6.4365e+00, -7.9980e+00,\n",
      "          8.3182e+00,  2.0148e+00, -5.2952e+00, -2.1419e+00, -1.1449e+01,\n",
      "         -4.1336e+00, -3.9750e+00,  1.3715e+01, -9.2478e-01,  5.2489e+00,\n",
      "          3.4185e+00],\n",
      "        [ 6.0748e-01, -3.7699e-01,  1.4627e+00, -5.3968e+00, -7.7194e+00,\n",
      "         -7.1269e+00,  3.0192e-01, -9.1236e+00, -8.9783e+00,  4.9823e+00,\n",
      "         -3.6023e+00,  1.4084e+00,  1.0182e-03,  1.3978e+01, -1.0031e+01,\n",
      "         -1.1052e+01],\n",
      "        [-3.3525e+00,  1.2782e+00, -1.4730e+00,  3.1570e+00,  4.1793e-01,\n",
      "          1.1568e+01, -5.1013e+00,  2.9210e+00,  5.2786e+00, -8.4419e+00,\n",
      "          3.3611e+00, -1.1920e+00,  4.3077e+00, -1.0084e+01,  1.3906e+01,\n",
      "          7.2940e+00],\n",
      "        [ 3.6461e+00,  2.2659e+00, -3.7680e+00,  1.5718e+00,  4.4418e+00,\n",
      "          8.8047e+00,  1.2272e+00,  9.0381e+00,  7.9760e+00, -4.1176e+00,\n",
      "         -2.3986e+00, -1.6473e+00,  2.8846e+00, -1.1388e+01,  8.5761e+00,\n",
      "          1.3634e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7801, 13.8123, 13.7129, 13.8385, 13.7039, 13.9567, 13.6855, 13.8140,\n",
      "        13.8493, 13.7770, 13.7310, 13.7922, 13.7151, 13.9781, 13.9062, 13.6340],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0384, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[-6.7371e+00, -9.8646e+00, -5.9350e+00,  3.4027e+00,  9.3412e-01,\n",
      "          6.2457e+00,  5.9167e+00, -4.7182e+00,  5.9389e+00, -4.8219e+00,\n",
      "          8.1849e+00, -1.4260e+00,  6.8120e-01, -2.9185e+00,  5.1195e+00],\n",
      "        [-6.6380e+00,  6.8500e+00, -3.6013e-01, -7.5718e+00,  3.4773e+00,\n",
      "         -3.8284e-01, -5.3308e+00,  6.5249e+00, -5.0759e+00, -8.1481e+00,\n",
      "         -8.8901e+00,  4.6838e+00, -1.1890e+00,  1.6078e+00,  2.2048e+00],\n",
      "        [-1.0861e+01,  7.9696e+00,  3.0170e-01, -5.5995e+00, -8.3402e-01,\n",
      "          5.3146e-01, -7.5430e+00,  1.1182e+00, -9.1043e+00,  1.1696e+00,\n",
      "         -8.8333e+00,  7.8139e+00,  1.2791e+00, -4.7177e-01, -3.6678e+00],\n",
      "        [-5.2406e+00, -1.0086e+00,  3.8017e-01,  5.6223e+00,  8.1937e-01,\n",
      "         -1.7409e-01,  5.4601e+00,  9.5901e+00,  3.5485e+00,  7.7686e+00,\n",
      "         -7.3981e+00, -6.3073e+00, -4.7887e+00,  2.5886e+00,  8.8661e-01],\n",
      "        [ 3.7656e+00, -8.1061e+00, -4.4843e+00,  6.7309e+00, -3.1791e+00,\n",
      "          1.0298e+00,  1.2053e+01,  4.2658e+00,  3.9981e+00,  8.1397e+00,\n",
      "          3.3321e+00, -7.4467e+00, -7.5832e+00,  6.1309e-01,  5.5117e+00],\n",
      "        [ 8.8119e-01,  1.7964e+00, -3.0728e+00,  1.2194e+00, -3.2911e+00,\n",
      "          1.1738e+00,  1.4303e+00,  3.6975e+00, -5.8807e+00, -1.4710e+00,\n",
      "         -2.7622e+00,  6.3379e+00, -6.8278e+00,  1.1144e+01,  7.4634e+00],\n",
      "        [ 6.1565e+00,  5.2824e-01,  8.5898e-01, -1.8554e-01,  5.6735e-01,\n",
      "          1.6829e+00,  2.1506e+00,  8.5189e-01,  2.7276e+00, -4.5244e+00,\n",
      "         -3.7138e+00,  2.3397e+00, -8.8045e-02, -4.9111e+00,  3.9228e+00],\n",
      "        [ 6.4730e+00, -5.7605e+00, -7.0203e+00,  5.7788e+00,  1.2032e+01,\n",
      "          6.3776e-01,  1.7866e+00,  6.4947e+00,  4.1973e+00,  3.8187e+00,\n",
      "          2.0927e+00, -5.8571e+00, -8.7747e+00,  2.4329e+00,  9.8366e+00],\n",
      "        [-5.1716e+00,  6.3105e+00,  1.5722e+00,  1.0368e+01,  4.0624e+00,\n",
      "          4.6411e+00, -3.5034e-01,  6.1859e+00, -1.1574e+00,  1.1113e+00,\n",
      "         -8.5905e+00, -2.6499e+00, -9.9012e+00,  6.0729e+00,  7.6966e+00],\n",
      "        [ 6.9369e+00, -5.6614e+00, -7.9516e+00,  4.2275e+00,  4.4608e+00,\n",
      "         -6.0103e+00,  3.4780e+00,  4.2734e+00,  3.4857e-02, -4.9505e-01,\n",
      "          2.6183e+00, -1.0691e+01,  4.6987e+00, -7.8525e+00, -2.7296e+00],\n",
      "        [-4.9379e+00, -7.7838e+00,  1.0365e+00,  8.1708e+00,  7.8333e+00,\n",
      "         -1.8370e+00, -4.5869e+00,  4.5436e+00,  1.3614e+00, -1.3588e+00,\n",
      "          6.0452e-01, -3.6583e+00, -3.8138e+00,  3.7034e+00, -2.0902e+00],\n",
      "        [ 7.2638e+00, -9.4152e+00, -8.2100e+00, -6.6512e+00,  3.7208e+00,\n",
      "         -3.0822e+00, -3.8095e+00,  1.3445e+00, -8.9644e+00,  3.0405e+00,\n",
      "          1.9620e+00, -4.0326e+00,  2.0956e+00, -6.5894e-01, -2.4750e+00],\n",
      "        [-2.1135e+00,  5.6371e+00,  6.1509e+00, -6.4365e+00, -7.9980e+00,\n",
      "          8.3182e+00,  2.0148e+00, -5.2952e+00, -2.1419e+00, -1.1449e+01,\n",
      "         -4.1336e+00, -3.9750e+00, -9.2478e-01,  5.2489e+00,  3.4185e+00],\n",
      "        [ 6.0748e-01, -3.7699e-01,  1.4627e+00, -5.3968e+00, -7.7194e+00,\n",
      "         -7.1269e+00,  3.0192e-01, -9.1236e+00, -8.9783e+00,  4.9823e+00,\n",
      "         -3.6023e+00,  1.4084e+00,  1.0182e-03, -1.0031e+01, -1.1052e+01],\n",
      "        [-3.3525e+00,  1.2782e+00, -1.4730e+00,  3.1570e+00,  4.1793e-01,\n",
      "          1.1568e+01, -5.1013e+00,  2.9210e+00,  5.2786e+00, -8.4419e+00,\n",
      "          3.3611e+00, -1.1920e+00,  4.3077e+00, -1.0084e+01,  7.2940e+00],\n",
      "        [ 3.6461e+00,  2.2659e+00, -3.7680e+00,  1.5718e+00,  4.4418e+00,\n",
      "          8.8047e+00,  1.2272e+00,  9.0381e+00,  7.9760e+00, -4.1176e+00,\n",
      "         -2.3986e+00, -1.6473e+00,  2.8846e+00, -1.1388e+01,  8.5761e+00]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0025, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 4: 0.020475611090660095\n",
      "Batch 5/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-0.1464, -0.0010, -0.0375,  ...,  0.0844,  0.1180, -0.0543],\n",
      "        [ 0.0071, -0.0448,  0.0437,  ...,  0.1106,  0.0801,  0.0819],\n",
      "        [-0.0943,  0.0632,  0.1182,  ...,  0.0009, -0.0311, -0.1150],\n",
      "        ...,\n",
      "        [-0.0891,  0.0537,  0.1808,  ..., -0.0044,  0.0584, -0.0184],\n",
      "        [-0.0150, -0.0052, -0.0289,  ...,  0.0841, -0.1853,  0.1481],\n",
      "        [-0.1319,  0.0670, -0.0243,  ..., -0.0277,  0.1703,  0.0266]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-0.1121, -0.0365, -0.0619,  ...,  0.0650,  0.1449, -0.0665],\n",
      "        [ 0.0393, -0.0525,  0.0084,  ...,  0.1057,  0.0984,  0.0863],\n",
      "        [-0.1026,  0.0534,  0.1181,  ..., -0.0046, -0.0118, -0.1244],\n",
      "        ...,\n",
      "        [-0.0658,  0.0405,  0.1804,  ..., -0.0125,  0.0515,  0.0849],\n",
      "        [-0.0115,  0.0211, -0.0406,  ...,  0.0568, -0.1143,  0.1647],\n",
      "        [-0.1207,  0.0415, -0.0267,  ..., -0.0268,  0.3076,  0.0112]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 1.3798e+01,  6.0947e+00, -2.6595e+00,  3.5459e+00, -2.7896e-02,\n",
      "         -4.7816e+00,  9.4811e+00,  2.2097e+00,  1.0714e+00, -5.9199e+00,\n",
      "          7.2046e-01,  1.4032e+00, -1.1303e+01,  2.8701e+00,  1.3572e+00,\n",
      "          4.5853e+00],\n",
      "        [ 7.3652e+00,  1.3413e+01, -7.5029e+00, -7.5405e+00, -6.2310e+00,\n",
      "         -4.2157e+00,  8.4660e+00,  5.7932e+00,  8.4661e+00, -4.2998e+00,\n",
      "         -6.0588e-01,  7.6031e+00, -8.7463e+00,  4.5520e+00,  4.2052e+00,\n",
      "          1.5611e+00],\n",
      "        [-3.5039e+00, -6.8195e+00,  1.3759e+01,  9.8954e+00, -5.3099e+00,\n",
      "         -2.1933e+00, -7.4106e+00,  2.8219e+00, -7.6479e+00,  1.1551e+01,\n",
      "         -6.7782e+00, -4.8193e+00,  8.4498e+00,  5.0335e+00, -8.3035e+00,\n",
      "          1.7935e+00],\n",
      "        [ 3.2791e+00, -5.8235e+00,  8.6349e+00,  1.3679e+01,  1.8341e+00,\n",
      "         -1.7703e-01, -2.6643e+00, -3.3051e+00, -7.1702e+00,  3.6490e+00,\n",
      "          1.9874e-01, -4.2196e+00,  3.1484e-01,  1.2156e+00, -3.7103e+00,\n",
      "          5.2629e+00],\n",
      "        [-2.7122e-01, -6.2974e+00, -5.4900e+00,  2.0100e+00,  1.3778e+01,\n",
      "          3.3734e+00, -6.5912e-03, -8.4636e+00, -1.7411e+00, -7.3187e+00,\n",
      "          8.9048e+00, -5.1484e+00, -2.5168e+00, -1.0208e+01,  6.3781e+00,\n",
      "         -3.2086e+00],\n",
      "        [-5.2324e+00, -6.9340e+00, -8.9197e-01,  5.6895e-01,  4.5859e+00,\n",
      "          1.3746e+01, -6.9806e+00, -8.8719e+00,  2.6154e+00, -4.2254e+00,\n",
      "          8.2736e+00,  6.3676e+00,  2.9201e+00, -7.9674e+00, -1.2746e-01,\n",
      "          7.0212e+00],\n",
      "        [ 1.1482e+01,  8.2197e+00, -6.2866e+00, -1.9810e+00,  5.5946e-01,\n",
      "         -6.7706e+00,  1.3618e+01,  1.6155e+00, -6.1734e-01, -6.0734e+00,\n",
      "         -2.8033e+00, -8.2308e-01, -9.9198e+00,  5.2143e+00,  1.5953e+00,\n",
      "         -1.5347e+00],\n",
      "        [ 3.3247e+00,  7.0689e+00,  2.1097e+00, -3.1122e+00, -8.4908e+00,\n",
      "         -9.5246e+00,  1.6826e+00,  1.3697e+01,  2.5772e+00,  4.2532e+00,\n",
      "         -4.7198e+00, -7.8796e-01, -2.6732e+00,  6.0350e+00,  2.3469e+00,\n",
      "         -1.1436e+00],\n",
      "        [ 2.0301e+00,  6.9999e+00, -9.3958e+00, -8.0972e+00, -7.2920e-01,\n",
      "          5.0004e+00,  3.9593e-01,  1.5035e-01,  1.3641e+01, -7.7102e+00,\n",
      "          8.1336e+00,  1.1116e+01, -5.8516e+00, -6.3170e+00,  6.0257e+00,\n",
      "          3.7289e+00],\n",
      "        [-6.8567e+00, -2.6429e+00,  1.1121e+01,  3.7934e+00, -7.9323e+00,\n",
      "         -5.4957e+00, -6.0258e+00,  5.0884e+00, -5.8479e+00,  1.3806e+01,\n",
      "         -1.0243e+01, -5.0473e+00,  1.0426e+01,  7.2081e+00, -7.8565e+00,\n",
      "         -4.2341e+00],\n",
      "        [ 1.2469e+00, -1.9620e+00, -6.3118e+00, -1.0642e-01,  7.9079e+00,\n",
      "          8.2406e+00, -3.1050e+00, -4.7223e+00,  6.7849e+00, -9.2639e+00,\n",
      "          1.3775e+01,  4.8129e+00, -5.8026e+00, -1.1168e+01,  8.9032e+00,\n",
      "          5.9441e+00],\n",
      "        [ 2.2285e+00,  7.0317e+00, -6.3014e+00, -6.3288e+00, -4.3227e+00,\n",
      "          7.2785e+00,  5.3272e-01, -7.6494e-01,  1.1562e+01, -5.8883e+00,\n",
      "          5.4114e+00,  1.3613e+01, -4.6393e+00, -1.9925e+00,  2.1102e+00,\n",
      "          8.0929e+00],\n",
      "        [-1.2227e+01, -7.7919e+00,  8.4721e+00,  1.4867e+00, -2.6445e+00,\n",
      "          1.5777e+00, -1.0378e+01, -5.8336e-01, -4.1998e+00,  1.0760e+01,\n",
      "         -5.2205e+00, -3.7455e+00,  1.3651e+01,  1.7097e-01, -6.5480e+00,\n",
      "         -4.8079e+00],\n",
      "        [ 2.2076e+00,  3.8284e+00,  8.2730e+00,  2.8459e+00, -1.0389e+01,\n",
      "         -7.7013e+00,  3.2243e+00,  7.1995e+00, -6.2222e+00,  8.9590e+00,\n",
      "         -1.1963e+01, -2.3840e+00,  2.2869e+00,  1.3175e+01, -7.2576e+00,\n",
      "          2.4980e-01],\n",
      "        [ 3.1945e-01,  2.4612e+00, -6.7170e+00, -3.1792e+00,  5.7918e+00,\n",
      "         -6.3353e-01,  3.7635e-02,  1.8857e+00,  4.4111e+00, -5.2893e+00,\n",
      "          9.0717e+00, -9.9348e-01, -6.2454e+00, -5.9779e+00,  1.3465e+01,\n",
      "         -4.5566e-01],\n",
      "        [ 2.7790e+00,  1.0123e-01,  2.4316e+00,  4.2821e+00, -3.2205e+00,\n",
      "          7.7738e+00, -3.3630e+00, -9.4762e-01,  3.6380e+00, -2.1938e+00,\n",
      "          5.4619e+00,  8.5111e+00, -3.4028e+00, -2.5614e-01,  7.4715e-01,\n",
      "          1.3662e+01]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.7981, 13.4132, 13.7590, 13.6786, 13.7785, 13.7457, 13.6181, 13.6970,\n",
      "        13.6414, 13.8061, 13.7755, 13.6127, 13.6510, 13.1754, 13.4651, 13.6619],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0457, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 6.0947e+00, -2.6595e+00,  3.5459e+00, -2.7896e-02, -4.7816e+00,\n",
      "          9.4811e+00,  2.2097e+00,  1.0714e+00, -5.9199e+00,  7.2046e-01,\n",
      "          1.4032e+00, -1.1303e+01,  2.8701e+00,  1.3572e+00,  4.5853e+00],\n",
      "        [ 7.3652e+00, -7.5029e+00, -7.5405e+00, -6.2310e+00, -4.2157e+00,\n",
      "          8.4660e+00,  5.7932e+00,  8.4661e+00, -4.2998e+00, -6.0588e-01,\n",
      "          7.6031e+00, -8.7463e+00,  4.5520e+00,  4.2052e+00,  1.5611e+00],\n",
      "        [-3.5039e+00, -6.8195e+00,  9.8954e+00, -5.3099e+00, -2.1933e+00,\n",
      "         -7.4106e+00,  2.8219e+00, -7.6479e+00,  1.1551e+01, -6.7782e+00,\n",
      "         -4.8193e+00,  8.4498e+00,  5.0335e+00, -8.3035e+00,  1.7935e+00],\n",
      "        [ 3.2791e+00, -5.8235e+00,  8.6349e+00,  1.8341e+00, -1.7703e-01,\n",
      "         -2.6643e+00, -3.3051e+00, -7.1702e+00,  3.6490e+00,  1.9874e-01,\n",
      "         -4.2196e+00,  3.1484e-01,  1.2156e+00, -3.7103e+00,  5.2629e+00],\n",
      "        [-2.7122e-01, -6.2974e+00, -5.4900e+00,  2.0100e+00,  3.3734e+00,\n",
      "         -6.5912e-03, -8.4636e+00, -1.7411e+00, -7.3187e+00,  8.9048e+00,\n",
      "         -5.1484e+00, -2.5168e+00, -1.0208e+01,  6.3781e+00, -3.2086e+00],\n",
      "        [-5.2324e+00, -6.9340e+00, -8.9197e-01,  5.6895e-01,  4.5859e+00,\n",
      "         -6.9806e+00, -8.8719e+00,  2.6154e+00, -4.2254e+00,  8.2736e+00,\n",
      "          6.3676e+00,  2.9201e+00, -7.9674e+00, -1.2746e-01,  7.0212e+00],\n",
      "        [ 1.1482e+01,  8.2197e+00, -6.2866e+00, -1.9810e+00,  5.5946e-01,\n",
      "         -6.7706e+00,  1.6155e+00, -6.1734e-01, -6.0734e+00, -2.8033e+00,\n",
      "         -8.2308e-01, -9.9198e+00,  5.2143e+00,  1.5953e+00, -1.5347e+00],\n",
      "        [ 3.3247e+00,  7.0689e+00,  2.1097e+00, -3.1122e+00, -8.4908e+00,\n",
      "         -9.5246e+00,  1.6826e+00,  2.5772e+00,  4.2532e+00, -4.7198e+00,\n",
      "         -7.8796e-01, -2.6732e+00,  6.0350e+00,  2.3469e+00, -1.1436e+00],\n",
      "        [ 2.0301e+00,  6.9999e+00, -9.3958e+00, -8.0972e+00, -7.2920e-01,\n",
      "          5.0004e+00,  3.9593e-01,  1.5035e-01, -7.7102e+00,  8.1336e+00,\n",
      "          1.1116e+01, -5.8516e+00, -6.3170e+00,  6.0257e+00,  3.7289e+00],\n",
      "        [-6.8567e+00, -2.6429e+00,  1.1121e+01,  3.7934e+00, -7.9323e+00,\n",
      "         -5.4957e+00, -6.0258e+00,  5.0884e+00, -5.8479e+00, -1.0243e+01,\n",
      "         -5.0473e+00,  1.0426e+01,  7.2081e+00, -7.8565e+00, -4.2341e+00],\n",
      "        [ 1.2469e+00, -1.9620e+00, -6.3118e+00, -1.0642e-01,  7.9079e+00,\n",
      "          8.2406e+00, -3.1050e+00, -4.7223e+00,  6.7849e+00, -9.2639e+00,\n",
      "          4.8129e+00, -5.8026e+00, -1.1168e+01,  8.9032e+00,  5.9441e+00],\n",
      "        [ 2.2285e+00,  7.0317e+00, -6.3014e+00, -6.3288e+00, -4.3227e+00,\n",
      "          7.2785e+00,  5.3272e-01, -7.6494e-01,  1.1562e+01, -5.8883e+00,\n",
      "          5.4114e+00, -4.6393e+00, -1.9925e+00,  2.1102e+00,  8.0929e+00],\n",
      "        [-1.2227e+01, -7.7919e+00,  8.4721e+00,  1.4867e+00, -2.6445e+00,\n",
      "          1.5777e+00, -1.0378e+01, -5.8336e-01, -4.1998e+00,  1.0760e+01,\n",
      "         -5.2205e+00, -3.7455e+00,  1.7097e-01, -6.5480e+00, -4.8079e+00],\n",
      "        [ 2.2076e+00,  3.8284e+00,  8.2730e+00,  2.8459e+00, -1.0389e+01,\n",
      "         -7.7013e+00,  3.2243e+00,  7.1995e+00, -6.2222e+00,  8.9590e+00,\n",
      "         -1.1963e+01, -2.3840e+00,  2.2869e+00, -7.2576e+00,  2.4980e-01],\n",
      "        [ 3.1945e-01,  2.4612e+00, -6.7170e+00, -3.1792e+00,  5.7918e+00,\n",
      "         -6.3353e-01,  3.7635e-02,  1.8857e+00,  4.4111e+00, -5.2893e+00,\n",
      "          9.0717e+00, -9.9348e-01, -6.2454e+00, -5.9779e+00, -4.5566e-01],\n",
      "        [ 2.7790e+00,  1.0123e-01,  2.4316e+00,  4.2821e+00, -3.2205e+00,\n",
      "          7.7738e+00, -3.3630e+00, -9.4762e-01,  3.6380e+00, -2.1938e+00,\n",
      "          5.4619e+00,  8.5111e+00, -3.4028e+00, -2.5614e-01,  7.4715e-01]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0030, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 5: 0.024353155866265297\n",
      "Batch 6/7: Matrix features: torch.Size([16, 128]), Vector features: torch.Size([16, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[ 0.0268, -0.0665,  0.0190,  ...,  0.1200, -0.0160,  0.0030],\n",
      "        [ 0.0034,  0.0377,  0.0779,  ..., -0.0283, -0.1677, -0.0590],\n",
      "        [ 0.1422, -0.0766, -0.1228,  ..., -0.1035,  0.1030, -0.0509],\n",
      "        ...,\n",
      "        [-0.0731, -0.0188, -0.1424,  ..., -0.0111,  0.1749, -0.0362],\n",
      "        [-0.1580, -0.0102,  0.0818,  ...,  0.0559,  0.1899, -0.1808],\n",
      "        [-0.0562,  0.0138,  0.0036,  ...,  0.0280,  0.2344,  0.0483]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[ 0.0301, -0.0835,  0.0385,  ...,  0.1205, -0.0228,  0.0611],\n",
      "        [ 0.0188,  0.0232,  0.0660,  ..., -0.0441, -0.1718, -0.0443],\n",
      "        [ 0.1433, -0.0858, -0.1381,  ..., -0.0816,  0.0572,  0.0052],\n",
      "        ...,\n",
      "        [-0.0663, -0.0241, -0.1541,  ..., -0.0076,  0.1639, -0.0285],\n",
      "        [-0.1430, -0.0197,  0.0869,  ...,  0.0438,  0.1553, -0.1910],\n",
      "        [-0.0432,  0.0187, -0.0050,  ...,  0.0049,  0.1782,  0.0542]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[ 13.6590,  -3.2123,   1.3461,   8.0640,  -8.3424,   1.1927,   6.0405,\n",
      "          -0.8225,  -5.0281,  -5.3789,  -6.0291,   8.6927,  -7.2212,   5.2172,\n",
      "           2.6316,  -1.2960],\n",
      "        [ -2.7231,  13.8048,  -0.1613,  -4.5238,   1.7471,   4.7980,   2.1884,\n",
      "          -3.4578,   0.5633,   5.4836,   8.6330,  -1.7439,  -7.2329,  -7.7015,\n",
      "           3.8944,  -4.0770],\n",
      "        [ -0.7927,   1.8336,  13.8200,   5.3876,  -9.9158,   4.9448,   8.7382,\n",
      "         -10.7091, -11.5119,   9.7445,  -3.0860,   3.5368,  -5.6684,   6.2552,\n",
      "          -0.0509,   2.7577],\n",
      "        [  6.2562,  -3.5202,   5.3515,  13.8968,  -8.4731,   5.7663,   6.4307,\n",
      "           0.6332,  -7.4629,  -3.3236,  -4.8822,   7.8014,  -5.2415,  11.0690,\n",
      "           7.8988,   6.1441],\n",
      "        [ -8.1078,   1.7849, -10.2916,  -9.3526,  13.8408,  -3.6525,  -9.6079,\n",
      "           8.1971,  10.2310,  -1.2633,   4.2164,  -5.6055,   9.5377,  -6.5056,\n",
      "          -2.4819,  -3.0952],\n",
      "        [  1.3194,   4.3004,   4.9644,   6.2892,  -4.6349,  13.7122,  11.1484,\n",
      "           1.2859,  -7.5131,   2.1256,   3.3743,   5.9488,  -6.3130,   2.3034,\n",
      "           1.1206,   6.6738],\n",
      "        [  3.8552,   3.0741,   9.0867,   6.1729,  -9.2065,  11.8897,  13.7153,\n",
      "          -4.1311, -11.0052,   4.6668,   0.3264,   7.1104,  -8.4644,   3.1622,\n",
      "          -1.7185,   4.8951],\n",
      "        [  0.0869,  -3.6859, -11.3422,   0.0231,   8.4805,  -0.1076,  -6.0602,\n",
      "          13.7089,   8.7631, -10.4377,   2.6522,  -1.1768,   6.9074,  -0.9803,\n",
      "           2.0702,   3.0010],\n",
      "        [ -3.8584,   0.4240, -11.3490,  -7.3653,   9.8026,  -7.6651, -11.5638,\n",
      "           6.9873,  13.5067,  -7.2312,   6.5625,  -9.7627,   6.4832,  -7.5615,\n",
      "           2.5216,  -1.1448],\n",
      "        [ -6.0830,   8.0241,   8.2553,  -3.3045,  -0.8822,   4.4700,   5.2907,\n",
      "          -8.7655,  -7.3679,  13.5640,  -0.1050,   2.3889,  -3.2663,  -0.8137,\n",
      "          -3.6739,  -4.0550],\n",
      "        [ -3.3240,   8.1333,  -3.4493,  -4.3276,   1.9766,   5.2527,   0.7475,\n",
      "           2.7869,   5.3323,  -2.0120,  13.4659,  -7.0212,  -3.4819, -10.0913,\n",
      "           2.1598,   3.9004],\n",
      "        [  7.4887,  -1.4507,   3.1842,   7.6596,  -4.2868,   5.4104,   7.8232,\n",
      "           0.0730,  -9.0343,   1.7818,  -9.1556,  13.8699,  -4.4151,   7.9161,\n",
      "          -0.6179,  -3.7751],\n",
      "        [ -6.1773,  -7.4008,  -7.0214,  -5.7002,  10.0152,  -6.3985,  -9.6669,\n",
      "           8.0609,   8.1917,  -3.6474,  -1.3074,  -5.1867,  13.9146,  -0.5033,\n",
      "          -5.2143,   1.3228],\n",
      "        [  2.9288,  -6.7876,   6.1369,  11.3083,  -5.1196,   0.9819,   2.4776,\n",
      "          -0.6493,  -7.3200,   0.0332,  -9.9214,   7.0939,   1.0642,  13.9788,\n",
      "           4.4640,   3.9202],\n",
      "        [  0.9157,   2.8353,  -1.4832,   7.6704,  -0.5851,   0.6530,  -2.5708,\n",
      "           2.2411,   1.6320,  -4.3439,   1.7043,  -0.0308,  -3.4547,   4.5807,\n",
      "          13.5918,   2.6487],\n",
      "        [ -1.4135,  -4.0978,   4.0831,   6.7364,  -4.4052,   5.2746,   3.2003,\n",
      "           2.6292,  -1.3396,  -3.7737,   3.7840,  -3.5733,   1.1891,   4.5590,\n",
      "           3.2169,  13.7915]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.6590, 13.8048, 13.8200, 13.8968, 13.8408, 13.7122, 13.7153, 13.7089,\n",
      "        13.5067, 13.5640, 13.4659, 13.8699, 13.9146, 13.9788, 13.5918, 13.7915],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0342, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ -3.2123,   1.3461,   8.0640,  -8.3424,   1.1927,   6.0405,  -0.8225,\n",
      "          -5.0281,  -5.3789,  -6.0291,   8.6927,  -7.2212,   5.2172,   2.6316,\n",
      "          -1.2960],\n",
      "        [ -2.7231,  -0.1613,  -4.5238,   1.7471,   4.7980,   2.1884,  -3.4578,\n",
      "           0.5633,   5.4836,   8.6330,  -1.7439,  -7.2329,  -7.7015,   3.8944,\n",
      "          -4.0770],\n",
      "        [ -0.7927,   1.8336,   5.3876,  -9.9158,   4.9448,   8.7382, -10.7091,\n",
      "         -11.5119,   9.7445,  -3.0860,   3.5368,  -5.6684,   6.2552,  -0.0509,\n",
      "           2.7577],\n",
      "        [  6.2562,  -3.5202,   5.3515,  -8.4731,   5.7663,   6.4307,   0.6332,\n",
      "          -7.4629,  -3.3236,  -4.8822,   7.8014,  -5.2415,  11.0690,   7.8988,\n",
      "           6.1441],\n",
      "        [ -8.1078,   1.7849, -10.2916,  -9.3526,  -3.6525,  -9.6079,   8.1971,\n",
      "          10.2310,  -1.2633,   4.2164,  -5.6055,   9.5377,  -6.5056,  -2.4819,\n",
      "          -3.0952],\n",
      "        [  1.3194,   4.3004,   4.9644,   6.2892,  -4.6349,  11.1484,   1.2859,\n",
      "          -7.5131,   2.1256,   3.3743,   5.9488,  -6.3130,   2.3034,   1.1206,\n",
      "           6.6738],\n",
      "        [  3.8552,   3.0741,   9.0867,   6.1729,  -9.2065,  11.8897,  -4.1311,\n",
      "         -11.0052,   4.6668,   0.3264,   7.1104,  -8.4644,   3.1622,  -1.7185,\n",
      "           4.8951],\n",
      "        [  0.0869,  -3.6859, -11.3422,   0.0231,   8.4805,  -0.1076,  -6.0602,\n",
      "           8.7631, -10.4377,   2.6522,  -1.1768,   6.9074,  -0.9803,   2.0702,\n",
      "           3.0010],\n",
      "        [ -3.8584,   0.4240, -11.3490,  -7.3653,   9.8026,  -7.6651, -11.5638,\n",
      "           6.9873,  -7.2312,   6.5625,  -9.7627,   6.4832,  -7.5615,   2.5216,\n",
      "          -1.1448],\n",
      "        [ -6.0830,   8.0241,   8.2553,  -3.3045,  -0.8822,   4.4700,   5.2907,\n",
      "          -8.7655,  -7.3679,  -0.1050,   2.3889,  -3.2663,  -0.8137,  -3.6739,\n",
      "          -4.0550],\n",
      "        [ -3.3240,   8.1333,  -3.4493,  -4.3276,   1.9766,   5.2527,   0.7475,\n",
      "           2.7869,   5.3323,  -2.0120,  -7.0212,  -3.4819, -10.0913,   2.1598,\n",
      "           3.9004],\n",
      "        [  7.4887,  -1.4507,   3.1842,   7.6596,  -4.2868,   5.4104,   7.8232,\n",
      "           0.0730,  -9.0343,   1.7818,  -9.1556,  -4.4151,   7.9161,  -0.6179,\n",
      "          -3.7751],\n",
      "        [ -6.1773,  -7.4008,  -7.0214,  -5.7002,  10.0152,  -6.3985,  -9.6669,\n",
      "           8.0609,   8.1917,  -3.6474,  -1.3074,  -5.1867,  -0.5033,  -5.2143,\n",
      "           1.3228],\n",
      "        [  2.9288,  -6.7876,   6.1369,  11.3083,  -5.1196,   0.9819,   2.4776,\n",
      "          -0.6493,  -7.3200,   0.0332,  -9.9214,   7.0939,   1.0642,   4.4640,\n",
      "           3.9202],\n",
      "        [  0.9157,   2.8353,  -1.4832,   7.6704,  -0.5851,   0.6530,  -2.5708,\n",
      "           2.2411,   1.6320,  -4.3439,   1.7043,  -0.0308,  -3.4547,   4.5807,\n",
      "           2.6487],\n",
      "        [ -1.4135,  -4.0978,   4.0831,   6.7364,  -4.4052,   5.2746,   3.2003,\n",
      "           2.6292,  -1.3396,  -3.7737,   3.7840,  -3.5733,   1.1891,   4.5590,\n",
      "           3.2169]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0023, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 6: 0.018246334046125412\n",
      "Batch 7/7: Matrix features: torch.Size([4, 128]), Vector features: torch.Size([4, 128])\n",
      "=== Contrastive Loss Calculation ===\n",
      "Normalized Matrix Features: tensor([[-1.3476e-03, -4.9840e-02,  1.0542e-01,  5.7110e-02,  5.8292e-02,\n",
      "          3.8759e-02, -3.0948e-02,  9.7318e-02, -2.7282e-03,  6.1471e-02,\n",
      "         -1.2974e-01, -1.1034e-01, -4.2294e-02, -6.0278e-02,  3.9000e-02,\n",
      "         -9.5578e-03, -7.8631e-02, -1.7301e-01, -4.6364e-02,  1.4301e-01,\n",
      "          5.4395e-02,  1.2231e-01, -1.2957e-02, -1.2716e-02,  1.0860e-03,\n",
      "          1.2949e-02,  1.1818e-02, -8.1439e-02,  1.6419e-01, -7.2094e-02,\n",
      "          4.8880e-02, -1.1200e-01, -1.0559e-01,  1.3619e-01, -2.5390e-02,\n",
      "         -1.2102e-01,  4.1825e-02, -2.6177e-01,  2.3267e-02,  1.4181e-01,\n",
      "          4.9511e-02, -6.0289e-02,  9.9379e-02,  1.2067e-01, -3.5454e-02,\n",
      "         -1.6217e-01, -1.2262e-01, -1.5159e-02,  1.2042e-01,  7.2544e-02,\n",
      "          1.8497e-01,  9.0625e-04, -2.3045e-02,  1.2195e-01, -4.9881e-02,\n",
      "          3.4824e-02,  5.8929e-02,  4.7813e-02, -2.2119e-02, -5.7933e-02,\n",
      "          1.0053e-02,  6.1732e-02,  3.9026e-02,  6.0239e-02, -6.2891e-02,\n",
      "          4.0583e-03,  1.6228e-02, -2.7263e-02, -1.4274e-02,  8.2003e-02,\n",
      "         -2.0273e-02, -1.3386e-02, -8.3596e-02,  1.1271e-01, -2.2273e-02,\n",
      "         -5.7043e-02, -1.3777e-01, -9.5646e-02, -4.8441e-02, -9.0739e-02,\n",
      "         -2.2444e-03,  1.1608e-01,  1.5212e-01,  8.8712e-03, -1.2237e-01,\n",
      "         -3.8643e-02,  7.0701e-02,  9.2292e-02, -1.8140e-01,  1.7532e-01,\n",
      "         -6.8929e-02,  2.1195e-02, -9.6800e-02,  1.2110e-02,  6.7976e-02,\n",
      "          6.1078e-03, -1.3897e-01,  8.8981e-02, -1.0038e-01, -5.9012e-02,\n",
      "          4.6611e-02, -3.9481e-02, -1.4735e-04, -1.1461e-02,  8.3463e-03,\n",
      "         -3.8314e-02, -1.5187e-01,  1.3101e-02,  7.0958e-02, -5.6821e-02,\n",
      "         -5.8503e-02,  1.6185e-01,  9.1643e-02, -9.0712e-02, -2.4887e-03,\n",
      "          3.3218e-02, -1.5436e-01,  3.3368e-02, -8.7706e-02,  3.1073e-02,\n",
      "         -1.1439e-01,  7.0978e-02,  8.5205e-02, -5.8807e-02,  1.0490e-01,\n",
      "          3.2556e-02,  2.5742e-01, -7.6329e-02],\n",
      "        [ 5.7158e-02, -2.8653e-02,  6.0221e-02, -1.4311e-01, -3.6371e-02,\n",
      "         -1.0050e-01,  6.4608e-02,  1.5149e-02, -3.9702e-02, -8.7834e-02,\n",
      "         -8.0417e-02,  7.1740e-02,  1.5330e-01, -7.2390e-02,  9.7831e-03,\n",
      "          7.2986e-03, -6.1647e-02, -1.1876e-01, -1.1460e-01, -1.6014e-02,\n",
      "         -1.0325e-01, -3.2854e-02,  4.2472e-05,  3.0743e-02, -1.0718e-01,\n",
      "         -3.6132e-02,  1.0262e-01,  7.4916e-02, -1.0824e-02,  3.8464e-02,\n",
      "         -4.1580e-03,  1.5122e-02,  4.5593e-02,  3.8099e-02,  7.6449e-02,\n",
      "          3.6739e-02,  9.9388e-02,  8.1132e-03, -1.7711e-02,  2.0201e-02,\n",
      "         -6.7227e-03, -8.2811e-02,  7.6104e-03,  1.0936e-01,  2.2176e-01,\n",
      "          5.6359e-02, -4.1554e-02,  7.2455e-02,  1.5210e-01, -1.7391e-02,\n",
      "          1.1329e-01,  5.8775e-02,  1.2999e-01,  5.9657e-02,  4.6208e-02,\n",
      "          1.9555e-02, -5.5876e-02, -1.9730e-01, -3.7868e-02,  1.2131e-01,\n",
      "         -1.0610e-01, -8.1183e-02, -8.8859e-02,  6.4560e-02, -1.6608e-02,\n",
      "         -3.7333e-02,  4.8020e-02,  3.7624e-02, -4.0008e-02,  7.7670e-03,\n",
      "          3.7357e-02, -2.1999e-02,  1.2815e-01,  2.9575e-02,  1.5487e-01,\n",
      "          8.8252e-02, -3.1138e-01, -1.0766e-01, -3.0932e-02, -7.4669e-02,\n",
      "         -2.4732e-02, -1.0357e-02,  7.0028e-02, -3.9223e-02,  4.2711e-02,\n",
      "         -3.7476e-02,  6.2675e-02,  1.7675e-01, -1.0255e-01,  3.1185e-02,\n",
      "          3.9937e-02, -7.2334e-03,  1.4878e-01, -2.2325e-02,  1.4679e-02,\n",
      "          1.8687e-04, -3.6384e-02,  5.8080e-02,  2.8480e-02,  1.5840e-01,\n",
      "          9.6048e-02,  2.8730e-02, -5.0652e-02, -1.6421e-01,  4.7789e-02,\n",
      "         -1.0941e-01, -2.9973e-02, -2.1697e-03, -1.5566e-02, -7.0561e-02,\n",
      "         -8.6962e-02,  9.5294e-02,  2.0393e-02, -2.1370e-01, -1.3237e-02,\n",
      "         -1.3300e-01, -3.8712e-02,  4.1119e-02,  1.5975e-01, -4.1434e-02,\n",
      "         -1.5910e-01, -1.6392e-02, -1.3971e-01,  5.7977e-02,  6.9748e-02,\n",
      "          1.0311e-01, -2.4589e-01,  1.8958e-02],\n",
      "        [-1.7181e-01,  5.2235e-02,  4.0125e-02,  4.3766e-02, -5.1691e-02,\n",
      "         -1.6768e-01, -7.4076e-03, -6.3891e-02, -8.8109e-02, -7.9385e-02,\n",
      "         -8.6557e-02,  1.5569e-02, -7.8305e-03,  8.0691e-02, -1.1223e-01,\n",
      "          1.7760e-02,  1.2863e-01,  1.3304e-01,  7.5686e-02,  2.9088e-02,\n",
      "         -1.8634e-01, -3.2092e-04, -7.5772e-02,  9.7712e-02, -4.7519e-02,\n",
      "          7.4593e-03, -8.2833e-02, -1.9098e-02,  8.6686e-02,  6.6970e-03,\n",
      "          1.9774e-01,  6.9703e-03, -8.9889e-02, -1.5778e-01,  2.6331e-02,\n",
      "          3.7657e-02, -1.4321e-01,  1.0398e-01,  5.1838e-02,  2.4145e-02,\n",
      "         -1.8066e-01, -8.4041e-02,  1.3075e-01,  4.1910e-02,  1.0459e-03,\n",
      "          1.3024e-01, -1.2041e-02,  1.3948e-02, -1.0809e-01,  1.6209e-02,\n",
      "         -7.2004e-02, -1.3807e-02,  7.4230e-03, -1.1160e-01,  1.5972e-01,\n",
      "          4.5900e-02,  2.2181e-03, -4.2024e-02, -3.3933e-03, -5.4102e-02,\n",
      "         -5.8098e-02, -1.5467e-02, -6.0099e-02,  1.2082e-01, -1.6492e-01,\n",
      "         -1.1546e-01,  7.3709e-02,  6.6695e-02, -1.6723e-02, -3.5569e-02,\n",
      "          4.8332e-02, -4.7899e-04,  6.7439e-04, -1.8566e-01,  1.6743e-02,\n",
      "         -8.3418e-02,  1.0848e-01,  2.4889e-01, -6.8729e-03,  6.0664e-02,\n",
      "          1.9687e-02,  1.2399e-01,  1.9026e-02, -5.7885e-02,  1.0522e-02,\n",
      "         -7.1617e-02, -5.4623e-02,  7.2880e-02, -3.4472e-02, -1.3650e-01,\n",
      "         -1.7862e-01,  6.2773e-02, -6.6176e-03,  9.2907e-02, -1.4304e-02,\n",
      "          9.3379e-02,  1.0310e-01, -4.0739e-02, -1.8698e-01, -3.7459e-02,\n",
      "          1.1459e-01,  7.3270e-02,  1.3689e-03, -7.4531e-02, -7.0258e-02,\n",
      "         -3.2949e-03,  1.1812e-01,  8.1902e-02, -4.5012e-02,  1.3105e-01,\n",
      "          1.0505e-01, -1.7285e-02,  1.5804e-01,  5.8238e-02,  9.7752e-02,\n",
      "          1.9927e-02, -5.7778e-02, -6.0860e-02,  3.2501e-02,  4.2400e-02,\n",
      "          1.3716e-01, -1.8036e-02,  4.7490e-02,  9.1318e-02, -1.1312e-01,\n",
      "         -2.9333e-03, -7.4063e-03, -1.0977e-01],\n",
      "        [-1.3265e-02,  6.7456e-03, -6.4230e-02, -1.3737e-02, -4.0942e-02,\n",
      "         -2.3410e-01, -3.9285e-02,  2.1783e-02,  2.9616e-02, -1.2466e-02,\n",
      "         -2.6147e-03, -3.0991e-02, -8.1316e-03, -5.6666e-02,  3.7242e-02,\n",
      "          1.0959e-01,  1.0280e-01,  1.1980e-01,  8.9842e-02, -2.9612e-02,\n",
      "         -1.7903e-01, -1.0930e-01,  1.8326e-02,  1.1615e-01,  6.1346e-02,\n",
      "         -1.5362e-01,  1.5632e-02, -5.0132e-02,  1.7841e-01, -9.0600e-02,\n",
      "          1.1931e-01, -4.6896e-02, -9.2712e-02, -1.1906e-01, -4.7501e-02,\n",
      "          3.9839e-02, -8.3360e-02, -3.6278e-02,  1.0488e-01, -5.5606e-02,\n",
      "         -1.6921e-01, -1.0615e-01,  3.2137e-02,  3.7675e-04, -1.2402e-02,\n",
      "          1.4441e-01, -6.5910e-02,  3.8267e-02,  6.4095e-03,  6.2717e-02,\n",
      "         -7.3243e-02,  6.5398e-02,  2.6980e-02, -1.6088e-01,  5.8279e-03,\n",
      "         -1.6975e-02, -9.8443e-03, -9.0550e-02, -7.0367e-02,  9.0344e-02,\n",
      "          9.2998e-03, -1.0354e-01, -4.0325e-02,  5.3894e-02, -2.5267e-01,\n",
      "          1.3610e-02,  3.7218e-02,  3.3151e-02, -3.5866e-02,  3.9208e-02,\n",
      "          9.8577e-02, -2.6360e-02,  5.5429e-02, -1.1944e-01,  5.1085e-02,\n",
      "         -5.9021e-02,  1.1080e-01,  2.1289e-01, -1.1316e-01,  3.2879e-02,\n",
      "         -8.5709e-02,  1.1810e-01,  4.7565e-02, -1.2619e-01,  4.3127e-02,\n",
      "          3.9092e-02, -1.1688e-01,  3.8891e-02,  9.6919e-02, -8.7898e-02,\n",
      "         -3.5628e-02,  5.5167e-02,  1.1352e-02,  1.4937e-01, -3.3990e-02,\n",
      "          3.0458e-03,  8.9026e-03, -1.6613e-01, -2.7299e-02, -7.6853e-02,\n",
      "          7.7031e-02,  7.0805e-02,  1.0006e-01, -5.6038e-02,  3.9918e-02,\n",
      "          6.8303e-02,  8.1648e-02,  3.3708e-02,  5.7461e-02,  1.2304e-01,\n",
      "          1.1982e-01, -4.6919e-02,  1.9724e-01, -4.2837e-03,  9.4732e-02,\n",
      "          1.0393e-01,  5.6420e-02, -3.2242e-02,  5.3135e-02, -8.7961e-03,\n",
      "          1.5957e-01, -6.2578e-02, -5.0003e-02,  1.1954e-01, -1.6690e-01,\n",
      "         -7.6212e-02, -5.1611e-02, -1.1155e-01]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Normalized Vector Features: tensor([[-3.2221e-02, -5.0230e-02,  6.8387e-02,  5.3659e-02,  3.9271e-02,\n",
      "          2.9717e-02, -2.2604e-02,  1.3879e-01, -5.2970e-02,  8.9851e-02,\n",
      "         -1.0853e-01, -1.0944e-01, -5.8527e-02, -1.0166e-01,  4.1038e-02,\n",
      "         -1.6999e-02, -1.0366e-01, -1.7528e-01, -2.0302e-02,  1.8788e-01,\n",
      "         -1.9197e-02,  1.0044e-01,  8.7622e-04,  5.8232e-03,  1.7336e-02,\n",
      "         -2.3463e-03,  3.1066e-02, -1.9771e-02,  1.3771e-01, -4.0622e-02,\n",
      "          4.7896e-02, -1.2126e-01, -1.1966e-01,  1.4560e-01, -3.6069e-02,\n",
      "         -1.4962e-01,  3.3751e-02, -2.1322e-01,  3.1889e-02,  1.6802e-01,\n",
      "          3.2460e-02, -8.4155e-02,  9.3909e-02,  9.4859e-02, -4.3291e-02,\n",
      "         -1.2349e-01, -9.3989e-02, -5.6765e-02,  1.1021e-01,  4.4259e-02,\n",
      "          1.6429e-01, -5.6412e-03, -9.8468e-03,  1.0040e-01, -9.1073e-02,\n",
      "          7.4509e-03,  5.1900e-02,  8.6484e-03, -5.7735e-03, -2.6832e-02,\n",
      "         -6.5422e-03,  2.0290e-02,  6.2307e-02,  6.4737e-02, -6.3975e-02,\n",
      "          1.9045e-02, -3.0250e-03, -1.8700e-02, -7.5620e-02,  1.3664e-01,\n",
      "          4.4879e-04,  7.5155e-03, -7.5019e-02,  1.3500e-01, -3.0972e-02,\n",
      "         -2.8967e-02, -8.6360e-02, -1.0079e-01, -6.4977e-02, -7.4696e-02,\n",
      "          2.8114e-02,  1.6805e-01,  2.0385e-01,  1.5798e-02, -1.2789e-01,\n",
      "         -4.1313e-02,  4.4969e-02,  8.4151e-02, -1.5981e-01,  1.6834e-01,\n",
      "         -3.9090e-02, -4.7430e-03, -4.7607e-02, -7.8994e-03,  5.6070e-02,\n",
      "         -5.2046e-03, -2.0947e-01,  8.0291e-02, -6.2866e-02, -6.6779e-02,\n",
      "          7.4592e-02,  4.2613e-02, -7.9148e-04, -5.4408e-02,  3.0757e-02,\n",
      "         -1.7751e-02, -1.7426e-01, -6.6540e-03,  8.7303e-02, -4.6660e-02,\n",
      "         -5.5183e-02,  1.5772e-01,  9.5954e-02, -6.0842e-02, -4.5630e-04,\n",
      "         -5.5308e-03, -1.7666e-01,  5.3603e-02, -7.0070e-02,  6.0348e-02,\n",
      "         -1.5020e-01,  7.1148e-02,  1.0242e-01, -4.6297e-02,  8.7124e-02,\n",
      "         -1.1936e-02,  2.0476e-01, -4.7607e-02],\n",
      "        [ 4.4462e-02, -4.6394e-03,  1.0122e-01, -1.3196e-01, -5.4145e-02,\n",
      "         -8.6881e-02,  9.8789e-02,  3.7600e-03, -8.9752e-03, -7.7112e-02,\n",
      "         -7.1729e-02,  9.3669e-02,  1.2580e-01, -5.6803e-02, -1.5275e-02,\n",
      "          2.0349e-02, -7.3266e-02, -1.5598e-01, -1.0294e-01,  1.8827e-02,\n",
      "         -9.0629e-02, -4.0415e-02, -2.4430e-03,  1.2184e-02, -1.4644e-01,\n",
      "         -2.3747e-02,  6.9268e-02,  8.8646e-02, -3.9135e-02,  4.6125e-02,\n",
      "         -1.5916e-02,  2.8019e-02,  5.4595e-02,  6.1038e-02,  7.4571e-02,\n",
      "          2.3677e-02,  9.8785e-02,  1.0111e-02, -5.3486e-02,  4.4305e-02,\n",
      "          1.6012e-02, -7.4926e-02,  1.7418e-03,  1.1711e-01,  2.3327e-01,\n",
      "          9.2873e-02, -9.2463e-03,  3.3360e-02,  1.1516e-01, -1.5906e-02,\n",
      "          1.0150e-01,  4.8190e-02,  1.3619e-01,  9.4817e-02,  6.8006e-02,\n",
      "         -1.0204e-02, -4.0641e-02, -1.6051e-01, -2.4565e-04,  1.1949e-01,\n",
      "         -1.2808e-01, -1.0009e-01, -5.3092e-02,  5.2548e-02,  3.5078e-03,\n",
      "         -5.9086e-02,  4.0808e-02, -9.5765e-03, -5.9843e-02,  1.5519e-02,\n",
      "          3.4930e-02, -3.0933e-02,  1.4369e-01,  2.2498e-02,  1.4735e-01,\n",
      "          1.1212e-01, -3.0000e-01, -1.0588e-01, -4.8732e-02, -5.8967e-02,\n",
      "         -1.1962e-02, -7.3789e-03,  6.6316e-02, -7.5796e-02,  5.3620e-02,\n",
      "         -6.8391e-02,  4.5987e-02,  8.1355e-02, -8.0151e-02,  1.5094e-02,\n",
      "          5.2891e-02, -1.9096e-02,  1.4054e-01, -2.4624e-02,  3.3108e-02,\n",
      "         -4.2670e-03, -7.9415e-02,  5.3008e-02,  2.7088e-02,  1.7066e-01,\n",
      "          6.5170e-02,  2.8603e-02, -6.6636e-02, -1.4323e-01,  6.3277e-02,\n",
      "         -8.5435e-02, -4.4308e-02, -2.8329e-02, -9.3884e-03, -5.8044e-02,\n",
      "         -5.9031e-02,  9.4122e-02,  6.3573e-03, -1.9803e-01, -2.8568e-02,\n",
      "         -1.6101e-01, -4.8782e-02,  7.2059e-02,  1.5056e-01, -2.2324e-02,\n",
      "         -1.9496e-01, -3.3319e-02, -1.3185e-01,  8.1596e-02,  8.9572e-02,\n",
      "          1.3005e-01, -2.4510e-01,  3.9377e-02],\n",
      "        [-1.7639e-01,  5.2853e-02,  7.6239e-02,  2.4071e-02, -5.0241e-02,\n",
      "         -1.8627e-01, -1.0557e-04, -7.2618e-02, -8.7460e-02, -5.0669e-02,\n",
      "         -7.3311e-02,  2.4669e-02,  3.6514e-03,  9.6481e-02, -1.1215e-01,\n",
      "          3.2651e-02,  1.6923e-01,  1.0247e-01,  7.2810e-02,  4.7618e-02,\n",
      "         -1.4975e-01, -4.2591e-02, -9.5177e-02,  8.8301e-02, -8.6584e-02,\n",
      "          1.0451e-02, -1.1036e-01, -6.4741e-03,  7.7520e-02,  1.9374e-02,\n",
      "          1.7187e-01,  4.5734e-02, -5.9712e-02, -1.3716e-01,  1.5028e-02,\n",
      "          2.5061e-02, -1.4438e-01,  9.4290e-02,  6.1291e-02,  2.8854e-02,\n",
      "         -1.5652e-01, -5.5407e-02,  1.2867e-01,  7.0217e-02,  1.2547e-02,\n",
      "          1.6067e-01, -9.1952e-03,  2.4012e-02, -1.7457e-01,  1.4421e-02,\n",
      "         -8.5430e-02, -2.1278e-02, -2.5300e-03, -1.1448e-01,  1.8954e-01,\n",
      "          4.6016e-02, -1.6688e-02, -7.9685e-02,  2.5920e-02, -8.1473e-02,\n",
      "         -9.9569e-02, -1.7774e-03, -3.2666e-02,  1.3881e-01, -1.7685e-01,\n",
      "         -1.0258e-01,  9.4004e-02,  5.5553e-02, -4.5379e-02, -2.5486e-02,\n",
      "          3.6047e-02, -4.0697e-02,  3.6918e-02, -1.3685e-01,  2.3221e-02,\n",
      "         -5.2347e-02,  6.2031e-02,  2.3527e-01,  3.5037e-04,  8.3596e-02,\n",
      "          2.0701e-02,  7.9544e-02,  2.4199e-02, -3.3623e-02,  1.6697e-03,\n",
      "         -4.2330e-02, -3.0282e-02,  7.2539e-02,  3.0922e-04, -1.3955e-01,\n",
      "         -2.1049e-01,  7.0758e-02,  2.6861e-03,  1.0691e-01, -2.1116e-02,\n",
      "          8.1945e-02,  9.5775e-02, -2.8976e-02, -1.8660e-01, -4.2849e-03,\n",
      "          1.0682e-01,  8.5174e-02, -2.9371e-02, -8.7277e-02, -4.4466e-02,\n",
      "          1.6541e-02,  1.1714e-01,  7.2763e-02, -5.1066e-02,  1.0092e-01,\n",
      "          1.0473e-01, -5.0105e-02,  1.1766e-01,  4.7835e-02,  8.0696e-02,\n",
      "          3.0945e-02, -3.6726e-02, -8.6919e-02,  2.3159e-02,  3.2746e-02,\n",
      "          1.4038e-01, -4.0442e-02,  2.7732e-02,  7.6063e-02, -1.0228e-01,\n",
      "          8.6975e-03, -3.4556e-03, -1.4321e-01],\n",
      "        [-2.7400e-02,  1.1916e-02, -6.8606e-02, -7.2379e-03, -4.3663e-02,\n",
      "         -2.2544e-01, -2.1124e-02,  2.5886e-03,  3.4979e-02, -7.2163e-03,\n",
      "          3.0885e-02, -4.3944e-02, -1.7904e-03, -4.0406e-02,  1.1465e-02,\n",
      "          1.1567e-01,  7.1241e-02,  1.1188e-01,  1.0075e-01, -2.9930e-02,\n",
      "         -2.1968e-01, -8.6880e-02,  7.5131e-04,  1.1574e-01,  7.5624e-02,\n",
      "         -1.5176e-01,  2.8579e-02,  8.9454e-03,  1.7290e-01, -7.1921e-02,\n",
      "          1.0813e-01, -2.6067e-02, -5.9501e-02, -9.9925e-02, -4.1943e-02,\n",
      "         -1.0891e-03, -7.5576e-02, -1.8743e-02,  7.9089e-02, -6.3115e-02,\n",
      "         -1.9372e-01, -1.0973e-01,  4.3875e-02,  7.0785e-03, -1.2338e-02,\n",
      "          1.7797e-01, -5.9895e-02, -1.2967e-02,  1.2549e-03,  6.3344e-02,\n",
      "         -8.1133e-02,  6.5785e-02,  2.2931e-02, -1.5384e-01,  4.3675e-02,\n",
      "         -1.6442e-02, -3.9611e-02, -1.0773e-01, -7.6312e-02,  1.1012e-01,\n",
      "          2.0200e-02, -1.1413e-01, -5.4555e-02,  6.2493e-02, -2.2083e-01,\n",
      "          3.5768e-03, -3.7444e-03,  6.6344e-02, -4.2318e-02,  3.4331e-02,\n",
      "          1.0820e-01, -1.7740e-02,  8.9529e-02, -1.2155e-01,  6.0540e-02,\n",
      "         -1.5577e-02,  7.6811e-02,  2.6215e-01, -8.1885e-02,  2.3246e-02,\n",
      "         -4.7114e-02,  1.2870e-01,  2.4820e-02, -1.6314e-01,  3.5277e-02,\n",
      "          2.0095e-02, -9.4904e-02,  4.4065e-02,  8.2415e-02, -9.9243e-02,\n",
      "         -5.8098e-02,  5.9290e-02, -1.1834e-02,  1.4493e-01, -4.3900e-02,\n",
      "          1.1974e-02,  1.3670e-02, -1.7311e-01, -6.6713e-03, -5.7475e-02,\n",
      "          8.1899e-02,  9.8274e-02,  7.7335e-02, -7.7714e-02,  6.3594e-02,\n",
      "          9.1135e-02,  6.8232e-02,  4.5556e-02,  4.5143e-02,  9.2816e-02,\n",
      "          8.7201e-02, -4.3956e-02,  1.6548e-01,  2.1130e-02,  1.1198e-01,\n",
      "          7.2959e-02,  5.4314e-02, -2.4678e-02,  4.6451e-02,  2.3110e-02,\n",
      "          1.7217e-01, -6.6894e-02, -6.6147e-02,  4.9717e-02, -1.7807e-01,\n",
      "         -5.6434e-02, -1.0113e-01, -1.1912e-01]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Logits (Similarity Matrix): tensor([[13.5578,  0.9622, -3.2801, -4.0161],\n",
      "        [ 1.7353, 13.8280, -1.2040, -0.3369],\n",
      "        [-2.7814, -2.2515, 13.8408,  9.5786],\n",
      "        [-2.5082, -2.0182,  8.7793, 13.8507]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Positive Logits (Diagonal Elements): tensor([13.5578, 13.8280, 13.8408, 13.8507], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0_copy>)\n",
      "Loss1 (Positive Pair Loss): tensor(0.0051, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Negative Logits: tensor([[ 0.9622, -3.2801, -4.0161],\n",
      "        [ 1.7353, -1.2040, -0.3369],\n",
      "        [-2.7814, -2.2515,  9.5786],\n",
      "        [-2.5082, -2.0182,  8.7793]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Loss2 (Negative Pair Loss): tensor(0.0017, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "Final Loss (Average of Loss1 and Loss2): tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss for batch 7: 0.003376077627763152\n",
      "Epoch [10/10], Loss: 0.0206\n",
      "Matrix features output: tensor([[ 0.4093, -0.4270, -2.3287, -0.8186,  0.3204, -1.0931, -0.1608,  0.5836,\n",
      "          0.5912,  0.1499,  1.2565, -1.1045, -0.7207, -0.3900,  2.2502, -0.1073,\n",
      "          0.0935,  1.8445,  0.3208, -1.5820, -0.1245,  0.2386,  0.5450,  0.3089,\n",
      "          2.9537, -1.7604,  0.5674, -0.5408,  1.5283, -1.2001, -0.8227,  0.6003,\n",
      "         -0.5016, -1.2329, -0.3014,  0.8835, -0.4541, -1.3099,  0.6233, -0.9711,\n",
      "         -0.2070, -0.4728, -0.7043,  0.1477, -0.3733,  0.1380, -0.6319,  0.8125,\n",
      "          0.9414, -0.0502, -0.7499,  0.7887,  0.0032, -1.3174, -2.0241, -0.1632,\n",
      "         -0.1361, -0.0132, -1.4876,  1.0650,  2.0809, -0.7109,  0.0288,  0.1043,\n",
      "         -1.3548,  1.9987,  0.1513,  0.3597,  0.6941,  0.3814,  1.1647,  0.6721,\n",
      "          0.8877, -0.5117,  0.1614, -0.7906,  0.8238,  0.7648, -1.4199,  0.1497,\n",
      "         -1.4406, -0.4153, -0.8278, -1.8525, -0.4374,  1.5019, -1.4494, -0.4489,\n",
      "          2.0504,  0.3989,  0.9841,  0.2034, -1.0120, -0.3687, -0.7479, -0.1955,\n",
      "         -0.7415, -1.6628,  0.8650, -0.1782,  0.1333, -0.1265,  1.5916,  0.7102,\n",
      "          0.4209,  0.5699,  0.7051, -1.1419,  1.1492,  1.3390,  0.8062, -0.6986,\n",
      "          1.1021, -0.5619,  1.5198,  1.3135,  1.5335,  0.1666, -0.1827, -1.6372,\n",
      "          1.4686, -0.3518, -1.0191, -0.2383, -1.9618, -0.5405,  0.1587,  0.1609]],\n",
      "       device='cuda:0')\n",
      "Vector features output: tensor([[ 4.0577e-01, -5.8353e-01, -2.4180e+00, -1.0366e+00,  1.5577e-01,\n",
      "         -1.1733e+00, -6.2476e-02,  4.1101e-01,  5.2438e-01,  4.1096e-01,\n",
      "          1.5076e+00, -1.2566e+00, -5.3000e-01, -2.5811e-01,  2.1971e+00,\n",
      "         -6.4215e-02,  1.6519e-01,  1.8232e+00,  1.7399e-01, -1.8833e+00,\n",
      "         -7.0590e-02,  1.3231e-01,  6.3562e-01,  1.9618e-01,  2.8773e+00,\n",
      "         -1.7668e+00,  5.9297e-01, -3.5465e-01,  1.3851e+00, -1.0443e+00,\n",
      "         -8.9326e-01,  8.9241e-01, -4.0152e-01, -1.0959e+00, -1.1173e-01,\n",
      "          1.1460e+00, -4.8236e-01, -1.1487e+00,  4.3759e-01, -8.6960e-01,\n",
      "         -2.4150e-01, -4.3409e-01, -6.7686e-01,  3.1952e-01, -1.8953e-01,\n",
      "          3.5201e-01, -4.3035e-01,  8.0832e-01,  8.4968e-01,  6.9780e-02,\n",
      "         -9.7405e-01,  8.3983e-01,  1.3597e-01, -1.3198e+00, -1.9164e+00,\n",
      "         -4.0331e-01, -2.1716e-01,  9.0373e-02, -1.4060e+00,  1.1936e+00,\n",
      "          2.0418e+00, -9.9436e-01, -1.2106e-01,  2.5406e-02, -1.1017e+00,\n",
      "          2.0742e+00, -1.3936e-01,  4.2846e-01,  7.8321e-01,  5.1539e-01,\n",
      "          1.2760e+00,  7.3759e-01,  1.1400e+00, -3.5592e-01,  2.3294e-01,\n",
      "         -4.0120e-01,  7.7242e-01,  5.1779e-01, -1.2063e+00,  8.3689e-02,\n",
      "         -1.4815e+00, -4.6755e-01, -8.8565e-01, -1.7937e+00, -3.4782e-01,\n",
      "          1.5247e+00, -1.5293e+00, -4.5775e-01,  2.2225e+00,  4.6827e-01,\n",
      "          1.1572e+00,  2.8987e-01, -8.5336e-01, -5.0966e-01, -9.6938e-01,\n",
      "         -2.2565e-01, -6.1848e-01, -1.6437e+00,  9.2995e-01, -2.9115e-02,\n",
      "          1.5723e-01, -8.5219e-04,  1.4618e+00,  6.0850e-01,  3.7498e-01,\n",
      "          8.0072e-01,  5.1384e-01, -1.2111e+00,  1.2566e+00,  1.0660e+00,\n",
      "          4.5497e-01, -7.4394e-01,  1.0151e+00, -7.2796e-01,  1.3432e+00,\n",
      "          8.5473e-01,  1.6860e+00,  2.1266e-01, -2.0068e-01, -1.6112e+00,\n",
      "          1.1834e+00, -7.2565e-01, -1.2229e+00, -2.1418e-01, -1.8900e+00,\n",
      "         -7.4309e-01, -9.7049e-02,  2.1177e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51440888/ipykernel_4065281/1258055250.py:237: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"clip_model.pth\", map_location=device),)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "from unicore.modules import TransformerEncoderLayer, LayerNorm\n",
    "\n",
    "# Define the dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, matrix_data, vector_data):\n",
    "        self.matrix_data = matrix_data\n",
    "        self.vector_data = vector_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matrix_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.matrix_data[idx], self.vector_data[idx]\n",
    "\n",
    "# Define the 2D matrix encoder (similar to an image encoder)\n",
    "class MatrixEncoder(nn.Module):\n",
    "    def __init__(self, input_channels, output_dim):\n",
    "        super(MatrixEncoder, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 8 * 8, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "# Define the 1D vector encoder (similar to a text encoder)\n",
    "class VectorEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(VectorEncoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Define the Transformer encoder with pair\n",
    "class TransformerEncoderWithPair(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_layers: int = 6,\n",
    "        embed_dim: int = 128,\n",
    "        ffn_embed_dim: int = 3072,\n",
    "        attention_heads: int = 4,\n",
    "        emb_dropout: float = 0.1,\n",
    "        dropout: float = 0.1,\n",
    "        attention_dropout: float = 0.1,\n",
    "        activation_dropout: float = 0.0,\n",
    "        max_seq_len: int = 256,\n",
    "        activation_fn: str = \"gelu\",\n",
    "        post_ln: bool = False,\n",
    "        no_final_head_layer_norm: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.emb_dropout = emb_dropout\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.embed_dim = 128\n",
    "        self.attention_heads = 4\n",
    "        self.emb_layer_norm = LayerNorm(self.embed_dim)\n",
    "        if not post_ln:\n",
    "            self.final_layer_norm = LayerNorm(self.embed_dim)\n",
    "        else:\n",
    "            self.final_layer_norm = None\n",
    "\n",
    "        if not no_final_head_layer_norm:\n",
    "            self.final_head_layer_norm = LayerNorm(attention_heads)\n",
    "        else:\n",
    "            self.final_head_layer_norm = None\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerEncoderLayer(\n",
    "                    embed_dim=self.embed_dim,\n",
    "                    ffn_embed_dim=ffn_embed_dim,\n",
    "                    attention_heads=attention_heads,\n",
    "                    dropout=dropout,\n",
    "                    attention_dropout=attention_dropout,\n",
    "                    activation_dropout=activation_dropout,\n",
    "                    activation_fn=activation_fn,\n",
    "                    post_ln=post_ln,\n",
    "                )\n",
    "                for _ in range(encoder_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        emb: torch.Tensor,\n",
    "        attn_mask: Optional[torch.Tensor] = None,\n",
    "        padding_mask: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        bsz = emb.size(0)\n",
    "        seq_len = emb.size(1)\n",
    "        x = self.emb_layer_norm(emb)\n",
    "        x = F.dropout(x, p=self.emb_dropout, training=self.training)\n",
    "\n",
    "        # account for padding while computing the representation\n",
    "        if padding_mask is not None:\n",
    "            x = x * (1 - padding_mask.unsqueeze(-1).type_as(x))\n",
    "\n",
    "        if attn_mask is None:\n",
    "            attn_mask = torch.zeros((bsz, 1, seq_len, seq_len), device=emb.device).repeat(1, self.attention_heads, 1, 1).view(-1, seq_len, seq_len)\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            x, attn_mask, _ = self.layers[i](\n",
    "                x, padding_mask=padding_mask, attn_bias=attn_mask, return_attn=True\n",
    "            )\n",
    "\n",
    "        if self.final_layer_norm is not None:\n",
    "            x = self.final_layer_norm(x)\n",
    "\n",
    "        return x, attn_mask\n",
    "\n",
    "# Define the CLIP model\n",
    "class CLIPModel(nn.Module):\n",
    "    def __init__(self, matrix_encoder, vector_encoder, transformer_encoder):\n",
    "        super(CLIPModel, self).__init__()\n",
    "        self.matrix_encoder = matrix_encoder\n",
    "        self.vector_encoder = vector_encoder\n",
    "        self.transformer_encoder = transformer_encoder\n",
    "\n",
    "    def forward(self, matrix, vector):\n",
    "        matrix_features = self.matrix_encoder(matrix)\n",
    "        vector_features = self.vector_encoder(vector)\n",
    "        transformer_input = torch.cat((matrix_features.unsqueeze(1), vector_features.unsqueeze(1)), dim=1)\n",
    "        transformer_output, _ = self.transformer_encoder(transformer_input)\n",
    "        return transformer_output[:, 0, :], transformer_output[:, 1, :]\n",
    "\n",
    "# Contrastive loss function\n",
    "def contrastive_loss(matrix_features, vector_features, temperature=0.07):\n",
    "    print(\"=== Contrastive Loss Calculation ===\")\n",
    "    # Normalize the features\n",
    "    matrix_features = F.normalize(matrix_features, dim=-1)\n",
    "    print(\"Normalized Matrix Features:\", matrix_features)\n",
    "    vector_features = F.normalize(vector_features, dim=-1)\n",
    "    print(\"Normalized Vector Features:\", vector_features)\n",
    "\n",
    "    # Compute the logits\n",
    "    logits = torch.matmul(matrix_features, vector_features.t()) / temperature\n",
    "    print(\"Logits (Similarity Matrix):\", logits)\n",
    "    labels = torch.arange(len(matrix_features)).to(matrix_features.device)\n",
    "\n",
    "    # Calculate positive pair loss (loss1)\n",
    "    positive_logit = torch.diag(logits)\n",
    "    print(\"Positive Logits (Diagonal Elements):\", positive_logit)\n",
    "    loss1 = -torch.mean(torch.log(torch.exp(positive_logit) / torch.sum(torch.exp(logits), dim=1)))\n",
    "    print(\"Loss1 (Positive Pair Loss):\", loss1)\n",
    "\n",
    "    # Calculate negative pair loss (loss2)\n",
    "    negative_logits = logits[~torch.eye(len(matrix_features), dtype=bool)].view(len(matrix_features), -1)\n",
    "    print(\"Negative Logits:\", negative_logits)\n",
    "    loss2 = -torch.mean(torch.log(1 - torch.exp(negative_logits) / torch.sum(torch.exp(logits), dim=1, keepdim=True)))\n",
    "    print(\"Loss2 (Negative Pair Loss):\", loss2)\n",
    "\n",
    "    # Combine loss1 and loss2\n",
    "    loss = (loss1 + loss2) / 2\n",
    "    print(\"Final Loss (Average of Loss1 and Loss2):\", loss)\n",
    "    return loss\n",
    "\n",
    "# Training loop\n",
    "def train_clip(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (matrix, vector) in enumerate(dataloader):\n",
    "        matrix, vector = matrix.to(device), vector.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        matrix_features, vector_features = model(matrix, vector)\n",
    "        print(f\"Batch {batch_idx + 1}/{len(dataloader)}: Matrix features: {matrix_features.shape}, Vector features: {vector_features.shape}\")\n",
    "\n",
    "        # Compute loss\n",
    "        loss = contrastive_loss(matrix_features, vector_features)\n",
    "        print(f\"Loss for batch {batch_idx + 1}: {loss.item()}\")\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Sample data (replace with actual data)\n",
    "    matrix_data = torch.randn(100, 3, 32, 32)  # 100 samples of 3x32x32 matrices\n",
    "    vector_data = torch.randn(100, 50)          # 100 samples of 1D vectors with 50 elements each\n",
    "\n",
    "    # Hyperparameters\n",
    "    output_dim = 128\n",
    "    batch_size = 16\n",
    "    learning_rate = 1e-3\n",
    "    num_epochs = 10\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = CustomDataset(matrix_data, vector_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize model, optimizer\n",
    "    matrix_encoder = MatrixEncoder(input_channels=3, output_dim=output_dim)\n",
    "    vector_encoder = VectorEncoder(input_dim=50, output_dim=output_dim)\n",
    "    transformer_encoder = TransformerEncoderWithPair()\n",
    "    model = CLIPModel(matrix_encoder, vector_encoder, transformer_encoder).to(device)\n",
    "    print(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train_clip(model, dataloader, optimizer, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), \"clip_model.pth\")\n",
    "\n",
    "    # Load the trained model and test with new input\n",
    "    model.load_state_dict(torch.load(\"clip_model.pth\", map_location=device),)\n",
    "    model.eval()\n",
    "\n",
    "    # Define new inputs\n",
    "    matrix_input = torch.randn(1, 3, 32, 32).to(device)  # A single 3x32x32 matrix\n",
    "    vector_input = torch.randn(1, 50).to(device)          # A single 1D vector with 50 elements\n",
    "\n",
    "    # Pass the inputs through the model\n",
    "    with torch.no_grad():\n",
    "        matrix_features, vector_features = model(matrix_input, vector_input)\n",
    "\n",
    "    # Print the output features\n",
    "    print(\"Matrix features output:\", matrix_features)\n",
    "    print(\"Vector features output:\", vector_features)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76ec0237-49de-4d4b-815a-fd04c1120a47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIPModel(\n",
      "  (matrix_encoder): MatrixEncoder(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): ReLU()\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "      (7): Linear(in_features=2048, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (vector_encoder): VectorEncoder(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoderWithPair(\n",
      "    (emb_layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
      "    (final_layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
      "    (final_head_layer_norm): LayerNorm(torch.Size([4]), eps=1e-05, elementwise_affine=True)\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): SelfMultiheadAttention(\n",
      "          (in_proj): Linear(in_features=128, out_features=384, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=128, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=128, bias=True)\n",
      "        (final_layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Matrix features output: tensor([[ 1.2426, -0.3116,  0.6259,  0.2904, -0.6465,  2.2859,  0.3133, -0.4428,\n",
      "         -0.7696, -1.2821,  0.4956,  0.4850,  0.1117,  0.4511, -0.7102, -1.7928,\n",
      "          0.5763, -1.1175,  0.7527,  0.5782, -0.2017,  0.6410,  1.0400,  0.1606,\n",
      "         -0.5974,  1.6009, -0.4199, -0.6429, -0.1116, -0.4493, -0.4432,  1.3800,\n",
      "         -0.8285,  0.5960,  0.8449,  0.9052,  0.1126,  1.1719,  0.5934, -0.4924,\n",
      "          1.3288,  0.5109, -0.6381, -1.3229,  0.5188, -1.6698,  0.3714, -0.0675,\n",
      "         -0.2031,  0.8900, -0.8080, -0.9501, -0.3292, -2.0568, -0.7891, -0.8129,\n",
      "         -0.8461, -0.8681, -0.2686, -0.6004, -0.4554,  1.1506, -0.4469, -1.2585,\n",
      "          0.8216,  1.6497, -0.8582, -1.3745,  1.7025,  0.8171, -0.2638, -0.4463,\n",
      "          0.5313,  1.7162,  0.3401, -0.0489, -1.0800, -0.8224, -0.4710,  0.8579,\n",
      "         -0.4496,  1.4987, -1.1507,  1.6512,  1.3069, -1.9108, -1.9182, -0.0526,\n",
      "          2.4815,  1.6402,  1.1203,  1.1365, -0.6104,  0.3706,  0.3457,  0.9219,\n",
      "         -1.7761,  0.8273, -1.4756, -0.3158, -0.0425, -1.1468,  1.0373, -0.1792,\n",
      "         -0.7232,  0.1811,  1.0645, -1.2890,  0.5004, -1.1231,  1.7947,  1.7712,\n",
      "          0.4448, -0.3239,  0.4816,  0.6233, -0.9784,  0.0998, -0.8594,  1.2073,\n",
      "         -1.9175, -1.2215, -0.7465, -1.9732,  0.1203,  0.1214,  0.7401, -0.6770]],\n",
      "       device='cuda:0')\n",
      "Vector features output: tensor([[ 1.4014, -0.3167,  0.8061,  0.0401, -0.6045,  2.1231,  0.2287, -0.4457,\n",
      "         -0.7160, -1.1213,  0.4891,  0.3621,  0.0762,  0.5608, -0.6996, -1.9901,\n",
      "          0.4055, -1.0166,  0.6038,  0.5680, -0.1609,  0.7310,  0.7531,  0.1113,\n",
      "         -0.3958,  1.8302, -0.4704, -0.5438,  0.1197, -0.4936, -0.5313,  1.5222,\n",
      "         -0.7420,  0.2720,  0.8449,  0.7933,  0.1848,  1.2672,  0.5176, -0.3090,\n",
      "          1.3056,  0.6483, -0.6153, -1.3319,  0.5003, -1.5937,  0.4832, -0.0032,\n",
      "         -0.2088,  1.0975, -0.7467, -0.7030, -0.5382, -1.9760, -0.8956, -0.7876,\n",
      "         -0.8072, -0.9478, -0.2248, -0.6822, -0.3279,  0.8247, -0.3349, -1.5359,\n",
      "          0.8441,  1.6809, -0.8814, -1.4077,  1.7706,  0.8456, -0.5391, -0.5022,\n",
      "          0.4228,  1.5392,  0.2119, -0.3140, -1.2261, -0.8278, -0.3872,  0.7329,\n",
      "         -0.4924,  1.3693, -1.0918,  1.7599,  1.4627, -1.7194, -2.0016, -0.1630,\n",
      "          2.3915,  1.5616,  1.2470,  1.1400, -0.4004,  0.3368,  0.4554,  1.1989,\n",
      "         -1.4927,  1.0594, -1.8843, -0.3566, -0.2087, -0.9929,  1.0655, -0.0449,\n",
      "         -0.5560,  0.2228,  0.8145, -1.3426,  0.6617, -1.3421,  1.7768,  1.6916,\n",
      "          0.5774, -0.1135,  0.4550,  0.6800, -0.7180, -0.1346, -0.8411,  1.2201,\n",
      "         -1.9211, -1.3549, -0.7582, -1.9732, -0.1032,  0.1928,  0.6441, -0.5280]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51440888/ipykernel_4065281/3935206531.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"clip_model.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "output_dim = 128\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "# Create dataset and dataloader\n",
    "\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize model, optimizer\n",
    "matrix_encoder = MatrixEncoder(input_channels=3, output_dim=output_dim)\n",
    "vector_encoder = VectorEncoder(input_dim=50, output_dim=output_dim)\n",
    "transformer_encoder = TransformerEncoderWithPair()\n",
    "model = CLIPModel(matrix_encoder, vector_encoder, transformer_encoder).to(device)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Load the trained model and test with new input\n",
    "model.load_state_dict(torch.load(\"clip_model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Define new inputs\n",
    "matrix_input = torch.randn(1, 3, 32, 32).to(device)  # A single 3x32x32 matrix\n",
    "vector_input = torch.randn(1, 50).to(device)          # A single 1D vector with 50 elements\n",
    "\n",
    "# Pass the inputs through the model\n",
    "with torch.no_grad():\n",
    "    matrix_features, vector_features = model(matrix_input, vector_input)\n",
    "\n",
    "# Print the output features\n",
    "print(\"Matrix features output:\", matrix_features)\n",
    "print(\"Vector features output:\", vector_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2da35555-5e28-405f-aaa1-dfec15a3ad9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2217\n",
      "Epoch [2/10], Loss: 0.0262\n",
      "Epoch [3/10], Loss: 0.0198\n",
      "Epoch [4/10], Loss: 0.0141\n",
      "Epoch [5/10], Loss: 0.0109\n",
      "Epoch [6/10], Loss: 0.0114\n",
      "Epoch [7/10], Loss: 0.0111\n",
      "Epoch [8/10], Loss: 0.0105\n",
      "Epoch [9/10], Loss: 0.0096\n",
      "Epoch [10/10], Loss: 0.0081\n",
      "Matrix features output: tensor([[-0.1062, -0.6231,  0.0466,  0.6175, -0.2106, -1.3731, -1.3836, -0.1255,\n",
      "          0.2300, -0.1454,  0.0505,  0.3020, -1.9088, -0.6142,  0.8860, -0.3528,\n",
      "         -0.5218, -0.3380,  1.1101, -0.2486, -0.2771,  0.9125, -0.8314,  2.3649,\n",
      "         -0.5489, -1.5923, -2.7846, -0.9512, -0.2407, -0.6325,  0.1340,  1.1260,\n",
      "         -1.3846, -1.5218,  1.7004, -2.0450, -0.1582, -0.8042,  0.1150,  0.6896,\n",
      "         -0.5543,  0.0840,  0.4283, -0.7652,  2.7006,  0.0977,  1.7894, -0.4454,\n",
      "          0.6268,  0.2087,  0.7317,  1.0694,  0.6220,  0.0481, -1.5968,  0.4783,\n",
      "         -0.1574, -0.4091, -0.8259,  0.3940,  0.3037,  0.9135, -0.4993,  0.3582,\n",
      "          1.1283, -0.0860, -1.0280, -0.9660, -0.0829,  1.5973, -0.6707, -2.8235,\n",
      "         -0.0658,  0.2099, -0.3038, -0.1128, -0.0234,  1.4798, -0.1732,  0.9405,\n",
      "          0.0384,  0.9186,  1.3875, -0.4297,  0.2578,  0.8877, -0.9654, -1.3131,\n",
      "         -1.2694,  0.9611,  0.3540,  0.8078, -0.2085, -0.7251,  0.5791, -1.4599,\n",
      "          0.1527,  0.4861,  1.3373,  0.0720, -0.2567,  0.3814, -0.6522,  0.3443,\n",
      "         -0.4757, -1.2500,  0.7590,  1.2375,  1.6450,  1.2543,  1.7336,  1.1970,\n",
      "          0.5911,  0.9305,  0.8526,  0.4464, -0.0057, -0.4440,  0.5541,  0.0033,\n",
      "         -0.8624, -1.3442,  0.8265,  0.5288, -1.1275,  1.9740, -1.3161, -2.5929]],\n",
      "       device='cuda:0')\n",
      "Vector features output: tensor([[-0.1450, -0.4067, -0.0094,  0.8781, -0.1272, -1.4747, -1.4527, -0.1472,\n",
      "          0.2735, -0.1873, -0.0758,  0.4256, -1.7658, -0.5531,  0.7484, -0.3173,\n",
      "         -0.6084, -0.4652,  1.2372, -0.1870, -0.2096,  0.8024, -1.1104,  2.0841,\n",
      "         -0.5835, -1.7915, -2.7041, -1.0538, -0.1793, -0.5996,  0.1742,  0.8495,\n",
      "         -1.6018, -1.2852,  1.8506, -2.0933, -0.3099, -0.8393,  0.0069,  0.6762,\n",
      "         -0.6065,  0.2198,  0.5663, -0.6102,  3.0195,  0.0560,  1.5383, -0.5729,\n",
      "          0.7912,  0.0971,  0.8578,  0.8384,  0.7888, -0.0537, -1.6334,  0.7157,\n",
      "         -0.1239, -0.2485, -0.8972,  0.4423,  0.4581,  0.9170, -0.4853,  0.3357,\n",
      "          1.4864, -0.0549, -0.7559, -0.9501, -0.2075,  1.5434, -0.6833, -2.7066,\n",
      "         -0.1481,  0.1731, -0.3070, -0.2229, -0.0608,  1.6839, -0.2553,  0.9271,\n",
      "          0.0705,  1.2030,  1.4527, -0.4327,  0.5146,  0.7897, -1.0133, -0.9504,\n",
      "         -1.2244,  1.0065,  0.3223,  0.9441, -0.1782, -0.8473,  0.4871, -1.5899,\n",
      "         -0.0360,  0.2452,  1.2415, -0.1355, -0.0106,  0.1687, -0.6128,  0.3534,\n",
      "         -0.3683, -1.5413,  0.7123,  1.2271,  1.8100,  1.0821,  1.7119,  0.9455,\n",
      "          0.5715,  0.9054,  0.6177,  0.2885, -0.0475, -0.5840,  0.4510,  0.2101,\n",
      "         -0.9187, -1.2284,  0.7894,  0.5625, -1.0282,  1.9249, -1.1219, -2.3479]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51440888/ipykernel_4065281/869846716.py:225: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"clip_model.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "from unicore.modules import TransformerEncoderLayer, LayerNorm\n",
    "\n",
    "# Define the dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, matrix_data, vector_data):\n",
    "        self.matrix_data = matrix_data\n",
    "        self.vector_data = vector_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matrix_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.matrix_data[idx], self.vector_data[idx]\n",
    "\n",
    "# Define the 2D matrix encoder (similar to an image encoder)\n",
    "class MatrixEncoder(nn.Module):\n",
    "    def __init__(self, input_channels, output_dim):\n",
    "        super(MatrixEncoder, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 8 * 8, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "# Define the 1D vector encoder (similar to a text encoder)\n",
    "class VectorEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(VectorEncoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Define the Transformer encoder with pair\n",
    "class TransformerEncoderWithPair(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_layers: int = 6,\n",
    "        embed_dim: int = 128,\n",
    "        ffn_embed_dim: int = 3072,\n",
    "        attention_heads: int = 4,\n",
    "        emb_dropout: float = 0.1,\n",
    "        dropout: float = 0.1,\n",
    "        attention_dropout: float = 0.1,\n",
    "        activation_dropout: float = 0.0,\n",
    "        max_seq_len: int = 256,\n",
    "        activation_fn: str = \"gelu\",\n",
    "        post_ln: bool = False,\n",
    "        no_final_head_layer_norm: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.emb_dropout = emb_dropout\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.embed_dim = 128\n",
    "        self.attention_heads = 4\n",
    "        self.emb_layer_norm = LayerNorm(self.embed_dim)\n",
    "        if not post_ln:\n",
    "            self.final_layer_norm = LayerNorm(self.embed_dim)\n",
    "        else:\n",
    "            self.final_layer_norm = None\n",
    "\n",
    "        if not no_final_head_layer_norm:\n",
    "            self.final_head_layer_norm = LayerNorm(attention_heads)\n",
    "        else:\n",
    "            self.final_head_layer_norm = None\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerEncoderLayer(\n",
    "                    embed_dim=self.embed_dim,\n",
    "                    ffn_embed_dim=ffn_embed_dim,\n",
    "                    attention_heads=attention_heads,\n",
    "                    dropout=dropout,\n",
    "                    attention_dropout=attention_dropout,\n",
    "                    activation_dropout=activation_dropout,\n",
    "                    activation_fn=activation_fn,\n",
    "                    post_ln=post_ln,\n",
    "                )\n",
    "                for _ in range(encoder_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        emb: torch.Tensor,\n",
    "        attn_mask: Optional[torch.Tensor] = None,\n",
    "        padding_mask: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        bsz = emb.size(0)\n",
    "        seq_len = emb.size(1)\n",
    "        x = self.emb_layer_norm(emb)\n",
    "        x = F.dropout(x, p=self.emb_dropout, training=self.training)\n",
    "\n",
    "        # account for padding while computing the representation\n",
    "        if padding_mask is not None:\n",
    "            x = x * (1 - padding_mask.unsqueeze(-1).type_as(x))\n",
    "\n",
    "        if attn_mask is None:\n",
    "            attn_mask = torch.zeros((bsz, 1, seq_len, seq_len), device=emb.device).repeat(1, self.attention_heads, 1, 1).view(-1, seq_len, seq_len)\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            x, attn_mask, _ = self.layers[i](\n",
    "                x, padding_mask=padding_mask, attn_bias=attn_mask, return_attn=True\n",
    "            )\n",
    "\n",
    "        if self.final_layer_norm is not None:\n",
    "            x = self.final_layer_norm(x)\n",
    "\n",
    "        return x, attn_mask\n",
    "\n",
    "# Define the CLIP model\n",
    "class CLIPModel(nn.Module):\n",
    "    def __init__(self, matrix_encoder, vector_encoder, transformer_encoder):\n",
    "        super(CLIPModel, self).__init__()\n",
    "        self.matrix_encoder = matrix_encoder\n",
    "        self.vector_encoder = vector_encoder\n",
    "        self.transformer_encoder = transformer_encoder\n",
    "\n",
    "    def forward(self, matrix, vector):\n",
    "        matrix_features = self.matrix_encoder(matrix)\n",
    "        vector_features = self.vector_encoder(vector)\n",
    "        transformer_input = torch.cat((matrix_features.unsqueeze(1), vector_features.unsqueeze(1)), dim=1)\n",
    "        transformer_output, _ = self.transformer_encoder(transformer_input)\n",
    "        return transformer_output[:, 0, :], transformer_output[:, 1, :]\n",
    "\n",
    "# Contrastive loss function\n",
    "def contrastive_loss(matrix_features, vector_features, temperature=0.07):\n",
    "    # Normalize the features\n",
    "    matrix_features = F.normalize(matrix_features, dim=-1)\n",
    "    vector_features = F.normalize(vector_features, dim=-1)\n",
    "\n",
    "    # Compute the logits\n",
    "    logits = torch.matmul(matrix_features, vector_features.t()) / temperature\n",
    "    labels = torch.arange(len(matrix_features)).to(matrix_features.device)\n",
    "\n",
    "    # Calculate positive pair loss (loss1)\n",
    "    positive_logit = torch.diag(logits)\n",
    "    loss1 = -torch.mean(torch.log(torch.exp(positive_logit) / torch.sum(torch.exp(logits), dim=1)))\n",
    "\n",
    "    # Calculate negative pair loss (loss2)\n",
    "    negative_logits = logits[~torch.eye(len(matrix_features), dtype=bool)].view(len(matrix_features), -1)\n",
    "    loss2 = -torch.mean(torch.log(1 - torch.exp(negative_logits) / torch.sum(torch.exp(logits), dim=1, keepdim=True)))\n",
    "\n",
    "    # Combine loss1 and loss2\n",
    "    loss = (loss1 + loss2) / 2\n",
    "    return loss\n",
    "\n",
    "# Training loop\n",
    "def train_clip(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (matrix, vector) in enumerate(dataloader):\n",
    "        matrix, vector = matrix.to(device), vector.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        matrix_features, vector_features = model(matrix, vector)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = contrastive_loss(matrix_features, vector_features)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Sample data (replace with actual data)\n",
    "    matrix_data = torch.randn(1000, 3, 32, 32)  # 100 samples of 3x32x32 matrices\n",
    "    vector_data = torch.randn(1000, 50)          # 100 samples of 1D vectors with 50 elements each\n",
    "\n",
    "    # Hyperparameters\n",
    "    output_dim = 128\n",
    "    batch_size = 16\n",
    "    learning_rate = 1e-3\n",
    "    num_epochs = 10\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = CustomDataset(matrix_data, vector_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize model, optimizer\n",
    "    matrix_encoder = MatrixEncoder(input_channels=3, output_dim=output_dim)\n",
    "    vector_encoder = VectorEncoder(input_dim=50, output_dim=output_dim)\n",
    "    transformer_encoder = TransformerEncoderWithPair()\n",
    "    model = CLIPModel(matrix_encoder, vector_encoder, transformer_encoder).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train_clip(model, dataloader, optimizer, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), \"clip_model.pth\")\n",
    "\n",
    "    # Load the trained model and test with new input\n",
    "    model.load_state_dict(torch.load(\"clip_model.pth\", map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Define new inputs\n",
    "    matrix_input = torch.randn(1, 3, 32, 32).to(device)  # A single 3x32x32 matrix\n",
    "    vector_input = torch.randn(1, 50).to(device)          # A single 1D vector with 50 elements\n",
    "\n",
    "    # Pass the inputs through the model\n",
    "    with torch.no_grad():\n",
    "        matrix_features, vector_features = model(matrix_input, vector_input)\n",
    "\n",
    "    # Print the output features\n",
    "    print(\"Matrix features output:\", matrix_features)\n",
    "    print(\"Vector features output:\", vector_features)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c593c-47a4-4dee-a0ca-ca80d6e9b8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copra",
   "language": "python",
   "name": "copra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
