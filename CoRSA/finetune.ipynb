{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f067dc6-6461-488f-925e-92f195ba8b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "from unicore.modules import TransformerEncoderLayer, LayerNorm\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "# Define the dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, matrix_data, vector_data):\n",
    "        self.matrix_data = matrix_data\n",
    "        self.vector_data = vector_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matrix_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.matrix_data[idx], self.vector_data[idx]\n",
    "\n",
    "# Define the 2D matrix encoder (similar to an image encoder)\n",
    "class MatrixEncoder(nn.Module):\n",
    "    def __init__(self, input_channels, output_dim):\n",
    "        super(MatrixEncoder, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 38 * 38, output_dim),  # Adjusted for input size 621x621 with pooling\n",
    "            nn.Dropout(0.3)  # Add Dropout layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure the input has the correct shape (batch_size, channels, height, width)\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(1)  # Add channel dimension if missing\n",
    "        return self.cnn(x)\n",
    "\n",
    "# Define the 1D vector encoder (similar to a text encoder)\n",
    "class VectorEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(VectorEncoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Add Dropout layer\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Add Dropout layer\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Define the Transformer encoder with pair\n",
    "class TransformerEncoderWithPair(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_layers: int = 4,\n",
    "        embed_dim: int = 512,\n",
    "        ffn_embed_dim: int = 2048,\n",
    "        attention_heads: int = 4,\n",
    "        emb_dropout: float = 0.1,\n",
    "        dropout: float = 0.1,\n",
    "        attention_dropout: float = 0.1,\n",
    "        activation_dropout: float = 0.0,\n",
    "        max_seq_len: int = 256,\n",
    "        activation_fn: str = \"gelu\",\n",
    "        post_ln: bool = False,\n",
    "        no_final_head_layer_norm: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.emb_dropout = emb_dropout\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.attention_heads = attention_heads\n",
    "        self.emb_layer_norm = LayerNorm(self.embed_dim)\n",
    "        if not post_ln:\n",
    "            self.final_layer_norm = LayerNorm(self.embed_dim)\n",
    "        else:\n",
    "            self.final_layer_norm = None\n",
    "\n",
    "        if not no_final_head_layer_norm:\n",
    "            self.final_head_layer_norm = LayerNorm(attention_heads)\n",
    "        else:\n",
    "            self.final_head_layer_norm = None\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerEncoderLayer(\n",
    "                    embed_dim=self.embed_dim,\n",
    "                    ffn_embed_dim=ffn_embed_dim,\n",
    "                    attention_heads=attention_heads,\n",
    "                    dropout=dropout,\n",
    "                    attention_dropout=attention_dropout,\n",
    "                    activation_dropout=activation_dropout,\n",
    "                    activation_fn=activation_fn,\n",
    "                    post_ln=post_ln,\n",
    "                )\n",
    "                for _ in range(encoder_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        emb: torch.Tensor,\n",
    "        attn_mask: Optional[torch.Tensor] = None,\n",
    "        padding_mask: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        bsz = emb.size(0)\n",
    "        seq_len = emb.size(1)\n",
    "        x = self.emb_layer_norm(emb)\n",
    "        x = F.dropout(x, p=self.emb_dropout, training=self.training)\n",
    "\n",
    "        # account for padding while computing the representation\n",
    "        if padding_mask is not None:\n",
    "            x = x * (1 - padding_mask.unsqueeze(-1).type_as(x))\n",
    "\n",
    "        if attn_mask is None:\n",
    "            attn_mask = torch.zeros((bsz, 1, seq_len, seq_len), device=emb.device).repeat(1, self.attention_heads, 1, 1).view(-1, seq_len, seq_len)\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            x, attn_mask, _ = self.layers[i](\n",
    "                x, padding_mask=padding_mask, attn_bias=attn_mask, return_attn=True\n",
    "            )\n",
    "\n",
    "        if self.final_layer_norm is not None:\n",
    "            x = self.final_layer_norm(x)\n",
    "\n",
    "        return x, attn_mask\n",
    "\n",
    "# Define the CLIP model\n",
    "class CLIPModel(nn.Module):\n",
    "    def __init__(self, matrix_encoder, vector_encoder, transformer_encoder):\n",
    "        super(CLIPModel, self).__init__()\n",
    "        self.matrix_encoder = matrix_encoder\n",
    "        self.vector_encoder = vector_encoder\n",
    "        self.transformer_encoder = transformer_encoder\n",
    "\n",
    "    def forward(self, matrix, vector):\n",
    "        matrix_features = self.matrix_encoder(matrix)\n",
    "        vector_features = self.vector_encoder(vector)\n",
    "        transformer_input = torch.cat((matrix_features.unsqueeze(1), vector_features.unsqueeze(1)), dim=1)\n",
    "        transformer_output, _ = self.transformer_encoder(transformer_input)\n",
    "        return transformer_output[:, 0, :], transformer_output[:, 1, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47cd37f4-5888-4dad-8ecd-45b415f71d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preparation function\n",
    "def prepare_data(data_path_csv, data_path_npy):\n",
    "    # Load encoded vector data from CSV file\n",
    "    encoded_df = pd.read_csv(data_path_csv, keep_default_na=False)\n",
    "\n",
    "    # Load matrix data from a separate .npy file\n",
    "    matrix_data = np.load(data_path_npy)\n",
    "    matrix_data = torch.tensor(matrix_data, dtype=torch.float32)\n",
    "    \n",
    "    # Print matrix data size for verification\n",
    "    print(f\"Matrix Data Size: {matrix_data.size()}\")\n",
    "\n",
    "    # Convert the lists in 'rna_embedding' and 'smiles_embedding' columns to NumPy arrays\n",
    "    loaded_rna_data = np.stack(encoded_df['rna_embedding'].apply(lambda x: np.array(eval(x))).values)\n",
    "    loaded_smiles_data = np.stack(encoded_df['smiles_embedding'].apply(lambda x: np.array(eval(x))).values)\n",
    "\n",
    "    # Convert loaded data to tensors\n",
    "    loaded_rna_data = torch.tensor(loaded_rna_data, dtype=torch.float32)\n",
    "    loaded_smiles_data = torch.tensor(loaded_smiles_data, dtype=torch.float32)\n",
    "\n",
    "    # Create combined data\n",
    "    combined_data = torch.cat((loaded_rna_data, loaded_smiles_data), dim=1)\n",
    "\n",
    "    # Print sizes for verification\n",
    "    print(f\"Loaded RNA Data Size: {loaded_rna_data.size()}\")\n",
    "    print(f\"Loaded SMILES Data Size: {loaded_smiles_data.size()}\")\n",
    "    print(f\"Combined Data Size: {combined_data.size()}\")\n",
    "\n",
    "    \n",
    "\n",
    "    return matrix_data, combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527e4901-b7f4-4127-abce-24aedb728bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_freeze_model(model_path, output_dim=768):\n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize model\n",
    "    matrix_encoder = MatrixEncoder(input_channels=1, output_dim=output_dim).to(device)\n",
    "    vector_encoder = VectorEncoder(input_dim=2048, output_dim=output_dim).to(device)  # Assuming input_dim is 2048 for inference\n",
    "    transformer_encoder = TransformerEncoderWithPair(embed_dim=output_dim).to(device)\n",
    "    model = CLIPModel(matrix_encoder, vector_encoder, transformer_encoder).to(device)\n",
    "\n",
    "    # Load the trained model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    # Freeze model weights\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c879b6-703f-4a37-b1b0-424ac4f83cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_encodings(model, data_loader, device):\n",
    "    matrix_encodings = []\n",
    "    vector_encodings = []\n",
    "    with torch.no_grad():\n",
    "        for matrix, vector in data_loader:\n",
    "            matrix, vector = matrix.to(device), vector.to(device)\n",
    "            matrix_features, vector_features = model(matrix, vector)\n",
    "            matrix_encodings.append(matrix_features.cpu())\n",
    "            vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "    matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "    vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "    return matrix_encodings, vector_encodings\n",
    "\n",
    "# Get encodings from model\n",
    "def get_encodings(model, data_loader, device):\n",
    "    matrix_encoder, vector_encoder = model.matrix_encoder, model.vector_encoder\n",
    "    matrix_encodings = []\n",
    "    vector_encodings = []\n",
    "    with torch.no_grad():\n",
    "        for matrix, vector in data_loader:\n",
    "            matrix, vector = matrix.to(device), vector.to(device)\n",
    "            matrix_features_encoder = model.matrix_encoder(matrix)\n",
    "            vector_features_encoder = model.vector_encoder(vector)\n",
    "            matrix_features, vector_features = model(matrix, vector)\n",
    "            # Concatenate both outputs\n",
    "            matrix_features = torch.cat((matrix_features, matrix_features_encoder), dim=-1)\n",
    "            vector_features = torch.cat((vector_features, vector_features_encoder), dim=-1)\n",
    "            matrix_encodings.append(matrix_features.cpu())\n",
    "            vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "    matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "    vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "    return matrix_encodings, vector_encodings\n",
    "\n",
    "# Get encodings from model\n",
    "def get_encodings(model, data_loader, device):\n",
    "    matrix_encodings = []\n",
    "    vector_encodings = []\n",
    "    with torch.no_grad():\n",
    "        for matrix, vector in data_loader:\n",
    "            matrix, vector = matrix.to(device), vector.to(device)\n",
    "            matrix_features = model.matrix_encoder(matrix)\n",
    "            vector_features = model.vector_encoder(vector)\n",
    "            matrix_encodings.append(matrix_features.cpu())\n",
    "            vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "    matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "    vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "    return matrix_encodings, vector_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c8e7429-9dc3-4bb3-8139-fa34fa1b66f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Data Size: torch.Size([118, 621, 621])\n",
      "Loaded RNA Data Size: torch.Size([118, 1280])\n",
      "Loaded SMILES Data Size: torch.Size([118, 768])\n",
      "Combined Data Size: torch.Size([118, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/52606460/ipykernel_1321099/816644269.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "data_path_csv = 'pdbbind_dataset_rna/pdbbind_rna_processed_index_encoded.csv'\n",
    "data_path_npy = 'pdbbind_dataset_rna/combined_distance_matrices_finetune.npy'\n",
    "\n",
    "encoded_df = pd.read_csv(data_path_csv, keep_default_na=False)\n",
    "\n",
    "# Prepare the data\n",
    "matrix_data, combined_data = prepare_data(data_path_csv, data_path_npy)\n",
    "\n",
    "# Create dataset\n",
    "dataset = CustomDataset(matrix_data, combined_data)\n",
    "data_loader = DataLoader(dataset)\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"best_clip_model.pth\"\n",
    "model = load_and_freeze_model(model_path, output_dim=768)\n",
    "matrix_encodings, vector_encodings = get_encodings(model,data_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca968895-4818-4076-89ed-720a897c930d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([118, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db7e95d-f884-43bf-b67c-d51eed02bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Load and freeze pretrained model\n",
    "def load_and_freeze_model(model_path, output_dim=768):\n",
    "    # Load pretrained encoders (MatrixEncoder and VectorEncoder) instead of using CLIPModel's output for training\n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize model\n",
    "    matrix_encoder = MatrixEncoder(input_channels=1, output_dim=output_dim).to(device)\n",
    "    vector_encoder = VectorEncoder(input_dim=2048, output_dim=output_dim).to(device)  # Assuming input_dim is 2048 for inference\n",
    "    transformer_encoder = TransformerEncoderWithPair(embed_dim=output_dim).to(device)\n",
    "    model = CLIPModel(matrix_encoder, vector_encoder, transformer_encoder).to(device)\n",
    "\n",
    "    # Load the trained model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    # Freeze model weights\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Define fully connected neural network class\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 8),\n",
    "            nn.BatchNorm1d(hidden_dim // 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 8, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Train fully connected neural network to predict labels and record metrics\n",
    "def train_fully_connected_nn(train_matrix_encodings, train_vector_encodings, y_train, val_matrix_encodings, val_vector_encodings, y_val, output_dim=768, learning_rate=3*1e-3, num_epochs=500, batch_size=256, early_stop_patience=50):\n",
    "    # Combine matrix and vector encodings\n",
    "    train_features = torch.cat((train_matrix_encodings, train_vector_encodings), dim=1)\n",
    "    val_features = torch.cat((val_matrix_encodings, val_vector_encodings), dim=1)\n",
    "    \n",
    "    # Create training and validation datasets\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_features, torch.tensor(y_train, dtype=torch.float32))\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_features, torch.tensor(y_val, dtype=torch.float32))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    input_dim = train_features.size(1)\n",
    "    hidden_dim = 256\n",
    "    output_dim = 1  # Assuming regression task\n",
    "    model = FullyConnectedNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "    criterion = nn.MSELoss() if output_dim == 1 else nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50, verbose=True)\n",
    "\n",
    "    # DataFrame to store metrics\n",
    "    metrics_df = pd.DataFrame(columns=[\"Epoch\", \"Train Loss\", \"Train RMSE\", \"Valid RMSE\", \"Valid PR\"])\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            print(f\"Training Batch Size: {features.size()}\")\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_rmse = torch.sqrt(torch.tensor(avg_train_loss)).item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                print(f\"Validation Batch Size: {features.size()}\")\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(features).squeeze()\n",
    "                val_loss = criterion(outputs, labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "                val_outputs_list.append(outputs.cpu())\n",
    "                val_labels_list.append(labels.cpu())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_rmse = torch.sqrt(torch.tensor(avg_val_loss)).item()\n",
    "        val_outputs = torch.cat(val_outputs_list, dim=0)\n",
    "        val_labels = torch.cat(val_labels_list, dim=0)\n",
    "        valid_pr = torch.corrcoef(torch.stack([val_outputs, val_labels]))[0, 1].item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation RMSE: {val_rmse:.4f}, Valid PR: {valid_pr:.4f}\")\n",
    "\n",
    "        # Record metrics\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": avg_train_loss,\n",
    "            \"Train RMSE\": train_rmse,\n",
    "            \"Valid RMSE\": val_rmse,\n",
    "            \"Valid PR\": valid_pr\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "        # Learning rate decay\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stop_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # Save the metrics to a CSV file\n",
    "    metrics_df.to_csv(\"training_metrics.csv\", index=False)\n",
    "\n",
    "    # Save the best model\n",
    "    if best_model_state is not None:\n",
    "        torch.save(best_model_state, \"best_finetuned_fully_connected_nn.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "957bb7c2-4504-4b3b-b377-348f0f262294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and test the final model and record metrics\n",
    "def test_fully_connected_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path, batch_size=64):\n",
    "    # Combine matrix and vector encodings\n",
    "    test_features = torch.cat((test_matrix_encodings, test_vector_encodings), dim=1)\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_features, torch.tensor(y_test, dtype=torch.float32))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    input_dim = test_features.size(1)\n",
    "    hidden_dim = 256\n",
    "    output_dim = 1  # Assuming regression task\n",
    "    model = FullyConnectedNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # Define loss function\n",
    "    criterion = nn.MSELoss() if output_dim == 1 else nn.BCEWithLogitsLoss()\n",
    "    total_test_loss = 0\n",
    "    test_outputs_list = []\n",
    "    test_labels_list = []\n",
    "    \n",
    "    # Testing loop\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            print(f\"Testing Batch Size: {features.size()}\")\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_test_loss += loss.item()\n",
    "            test_outputs_list.append(outputs.cpu())\n",
    "            test_labels_list.append(labels.cpu())\n",
    "    \n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_rmse = torch.sqrt(torch.tensor(avg_test_loss)).item()\n",
    "    test_outputs = torch.cat(test_outputs_list, dim=0)\n",
    "    test_labels = torch.cat(test_labels_list, dim=0)\n",
    "    test_pr = torch.corrcoef(torch.stack([test_outputs, test_labels]))[0, 1].item()\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test RMSE: {test_rmse:.4f}, Test PR: {test_pr:.4f}\")\n",
    "    \n",
    "    # Save test metrics to a CSV file\n",
    "    test_metrics_df = pd.DataFrame([{ \"Test RMSE\": test_rmse, \"Test PR\": test_pr }])\n",
    "    test_metrics_df.to_csv(\"test_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7a5363b-2c72-47b4-a390-240369d7ac2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/1908106410.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Data Size: torch.Size([118, 621, 621])\n",
      "Loaded RNA Data Size: torch.Size([118, 1280])\n",
      "Loaded SMILES Data Size: torch.Size([118, 768])\n",
      "Combined Data Size: torch.Size([118, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/1908106410.py:136: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [1/500], Train Loss: 37.4302, Train RMSE: 6.1180\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [1/500], Validation Loss: 33.0325, Validation RMSE: 5.7474, Valid PR: 0.8702\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [2/500], Train Loss: 36.1020, Train RMSE: 6.0085\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [2/500], Validation Loss: 32.6450, Validation RMSE: 5.7136, Valid PR: 0.7471\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [3/500], Train Loss: 34.3243, Train RMSE: 5.8587\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [3/500], Validation Loss: 31.9936, Validation RMSE: 5.6563, Valid PR: 0.7819\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [4/500], Train Loss: 34.6415, Train RMSE: 5.8857\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [4/500], Validation Loss: 30.8667, Validation RMSE: 5.5558, Valid PR: 0.7700\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [5/500], Train Loss: 34.2586, Train RMSE: 5.8531\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [5/500], Validation Loss: 29.6828, Validation RMSE: 5.4482, Valid PR: 0.7421\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [6/500], Train Loss: 33.2269, Train RMSE: 5.7643\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [6/500], Validation Loss: 28.5055, Validation RMSE: 5.3391, Valid PR: 0.7161\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [7/500], Train Loss: 32.0932, Train RMSE: 5.6651\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [7/500], Validation Loss: 27.2824, Validation RMSE: 5.2233, Valid PR: 0.6959\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [8/500], Train Loss: 31.1116, Train RMSE: 5.5778\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [8/500], Validation Loss: 26.2268, Validation RMSE: 5.1212, Valid PR: 0.6824\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [9/500], Train Loss: 30.8050, Train RMSE: 5.5502\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [9/500], Validation Loss: 25.2487, Validation RMSE: 5.0248, Valid PR: 0.6772\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [10/500], Train Loss: 30.3887, Train RMSE: 5.5126\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [10/500], Validation Loss: 24.2692, Validation RMSE: 4.9264, Valid PR: 0.6675\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [11/500], Train Loss: 29.3410, Train RMSE: 5.4167\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [11/500], Validation Loss: 23.2200, Validation RMSE: 4.8187, Valid PR: 0.6655\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [12/500], Train Loss: 28.8351, Train RMSE: 5.3698\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [12/500], Validation Loss: 22.2466, Validation RMSE: 4.7166, Valid PR: 0.6704\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [13/500], Train Loss: 28.3893, Train RMSE: 5.3282\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [13/500], Validation Loss: 21.3331, Validation RMSE: 4.6188, Valid PR: 0.6775\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [14/500], Train Loss: 27.7799, Train RMSE: 5.2707\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [14/500], Validation Loss: 20.4729, Validation RMSE: 4.5247, Valid PR: 0.6737\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [15/500], Train Loss: 26.9031, Train RMSE: 5.1868\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [15/500], Validation Loss: 19.6475, Validation RMSE: 4.4326, Valid PR: 0.6788\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [16/500], Train Loss: 27.1998, Train RMSE: 5.2153\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [16/500], Validation Loss: 18.9496, Validation RMSE: 4.3531, Valid PR: 0.6876\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [17/500], Train Loss: 26.1647, Train RMSE: 5.1151\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [17/500], Validation Loss: 18.3030, Validation RMSE: 4.2782, Valid PR: 0.6994\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [18/500], Train Loss: 25.5902, Train RMSE: 5.0587\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [18/500], Validation Loss: 17.5948, Validation RMSE: 4.1946, Valid PR: 0.7022\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [19/500], Train Loss: 23.4618, Train RMSE: 4.8437\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [19/500], Validation Loss: 16.9918, Validation RMSE: 4.1221, Valid PR: 0.7101\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [20/500], Train Loss: 24.4234, Train RMSE: 4.9420\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [20/500], Validation Loss: 16.3277, Validation RMSE: 4.0408, Valid PR: 0.7134\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [21/500], Train Loss: 23.6291, Train RMSE: 4.8610\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [21/500], Validation Loss: 15.7123, Validation RMSE: 3.9639, Valid PR: 0.7201\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [22/500], Train Loss: 23.4698, Train RMSE: 4.8446\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [22/500], Validation Loss: 15.1987, Validation RMSE: 3.8986, Valid PR: 0.7249\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [23/500], Train Loss: 23.7976, Train RMSE: 4.8783\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [23/500], Validation Loss: 14.8154, Validation RMSE: 3.8491, Valid PR: 0.7286\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [24/500], Train Loss: 21.7434, Train RMSE: 4.6630\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [24/500], Validation Loss: 14.4303, Validation RMSE: 3.7987, Valid PR: 0.7326\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [25/500], Train Loss: 22.2901, Train RMSE: 4.7212\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [25/500], Validation Loss: 14.1884, Validation RMSE: 3.7667, Valid PR: 0.7316\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [26/500], Train Loss: 21.2388, Train RMSE: 4.6086\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [26/500], Validation Loss: 13.9654, Validation RMSE: 3.7370, Valid PR: 0.7280\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [27/500], Train Loss: 20.8605, Train RMSE: 4.5673\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [27/500], Validation Loss: 13.8812, Validation RMSE: 3.7257, Valid PR: 0.7276\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [28/500], Train Loss: 20.4415, Train RMSE: 4.5212\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [28/500], Validation Loss: 13.6989, Validation RMSE: 3.7012, Valid PR: 0.7271\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [29/500], Train Loss: 19.4410, Train RMSE: 4.4092\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [29/500], Validation Loss: 13.5960, Validation RMSE: 3.6873, Valid PR: 0.7226\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [30/500], Train Loss: 19.9166, Train RMSE: 4.4628\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [30/500], Validation Loss: 13.4753, Validation RMSE: 3.6709, Valid PR: 0.7191\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [31/500], Train Loss: 18.6772, Train RMSE: 4.3217\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [31/500], Validation Loss: 13.1972, Validation RMSE: 3.6328, Valid PR: 0.7167\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [32/500], Train Loss: 18.4097, Train RMSE: 4.2907\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [32/500], Validation Loss: 12.8366, Validation RMSE: 3.5828, Valid PR: 0.7139\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [33/500], Train Loss: 17.7822, Train RMSE: 4.2169\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [33/500], Validation Loss: 12.4803, Validation RMSE: 3.5327, Valid PR: 0.7083\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [34/500], Train Loss: 17.2676, Train RMSE: 4.1554\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [34/500], Validation Loss: 12.1688, Validation RMSE: 3.4884, Valid PR: 0.7057\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [35/500], Train Loss: 17.1800, Train RMSE: 4.1449\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [35/500], Validation Loss: 11.9017, Validation RMSE: 3.4499, Valid PR: 0.7015\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [36/500], Train Loss: 16.3206, Train RMSE: 4.0399\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [36/500], Validation Loss: 11.5538, Validation RMSE: 3.3991, Valid PR: 0.6962\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [37/500], Train Loss: 16.5798, Train RMSE: 4.0718\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [37/500], Validation Loss: 11.1104, Validation RMSE: 3.3332, Valid PR: 0.6939\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [38/500], Train Loss: 15.8965, Train RMSE: 3.9870\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [38/500], Validation Loss: 10.8149, Validation RMSE: 3.2886, Valid PR: 0.6914\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [39/500], Train Loss: 15.4871, Train RMSE: 3.9354\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [39/500], Validation Loss: 10.4215, Validation RMSE: 3.2282, Valid PR: 0.6899\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [40/500], Train Loss: 14.1443, Train RMSE: 3.7609\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [40/500], Validation Loss: 10.1538, Validation RMSE: 3.1865, Valid PR: 0.6891\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [41/500], Train Loss: 14.9709, Train RMSE: 3.8692\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [41/500], Validation Loss: 9.7638, Validation RMSE: 3.1247, Valid PR: 0.6879\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [42/500], Train Loss: 14.4873, Train RMSE: 3.8062\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [42/500], Validation Loss: 9.3329, Validation RMSE: 3.0550, Valid PR: 0.6895\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [43/500], Train Loss: 14.1812, Train RMSE: 3.7658\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [43/500], Validation Loss: 9.1027, Validation RMSE: 3.0171, Valid PR: 0.6884\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [44/500], Train Loss: 12.2196, Train RMSE: 3.4957\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [44/500], Validation Loss: 8.9264, Validation RMSE: 2.9877, Valid PR: 0.6871\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [45/500], Train Loss: 12.8851, Train RMSE: 3.5896\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [45/500], Validation Loss: 8.7295, Validation RMSE: 2.9546, Valid PR: 0.6871\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [46/500], Train Loss: 12.9122, Train RMSE: 3.5934\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [46/500], Validation Loss: 8.5808, Validation RMSE: 2.9293, Valid PR: 0.6869\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [47/500], Train Loss: 11.7639, Train RMSE: 3.4299\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [47/500], Validation Loss: 8.4778, Validation RMSE: 2.9117, Valid PR: 0.6858\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [48/500], Train Loss: 11.3606, Train RMSE: 3.3705\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [48/500], Validation Loss: 8.4222, Validation RMSE: 2.9021, Valid PR: 0.6865\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [49/500], Train Loss: 11.6801, Train RMSE: 3.4176\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [49/500], Validation Loss: 8.3327, Validation RMSE: 2.8866, Valid PR: 0.6841\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [50/500], Train Loss: 10.6263, Train RMSE: 3.2598\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [50/500], Validation Loss: 8.1529, Validation RMSE: 2.8553, Valid PR: 0.6828\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [51/500], Train Loss: 10.5666, Train RMSE: 3.2506\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [51/500], Validation Loss: 8.0450, Validation RMSE: 2.8364, Valid PR: 0.6791\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [52/500], Train Loss: 10.4884, Train RMSE: 3.2386\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [52/500], Validation Loss: 7.9136, Validation RMSE: 2.8131, Valid PR: 0.6753\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [53/500], Train Loss: 9.1830, Train RMSE: 3.0303\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [53/500], Validation Loss: 7.7500, Validation RMSE: 2.7839, Valid PR: 0.6716\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [54/500], Train Loss: 9.2923, Train RMSE: 3.0483\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [54/500], Validation Loss: 7.6639, Validation RMSE: 2.7684, Valid PR: 0.6671\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [55/500], Train Loss: 9.8941, Train RMSE: 3.1455\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [55/500], Validation Loss: 7.5256, Validation RMSE: 2.7433, Valid PR: 0.6623\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [56/500], Train Loss: 8.6371, Train RMSE: 2.9389\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [56/500], Validation Loss: 7.3616, Validation RMSE: 2.7132, Valid PR: 0.6567\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [57/500], Train Loss: 8.2102, Train RMSE: 2.8653\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [57/500], Validation Loss: 7.2457, Validation RMSE: 2.6918, Valid PR: 0.6517\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [58/500], Train Loss: 8.2981, Train RMSE: 2.8806\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [58/500], Validation Loss: 7.0599, Validation RMSE: 2.6570, Valid PR: 0.6457\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [59/500], Train Loss: 7.8063, Train RMSE: 2.7940\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [59/500], Validation Loss: 6.9151, Validation RMSE: 2.6297, Valid PR: 0.6384\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [60/500], Train Loss: 7.6667, Train RMSE: 2.7689\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [60/500], Validation Loss: 6.7254, Validation RMSE: 2.5933, Valid PR: 0.6327\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [61/500], Train Loss: 8.2180, Train RMSE: 2.8667\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [61/500], Validation Loss: 6.4729, Validation RMSE: 2.5442, Valid PR: 0.6277\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [62/500], Train Loss: 6.8073, Train RMSE: 2.6091\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [62/500], Validation Loss: 6.2266, Validation RMSE: 2.4953, Valid PR: 0.6203\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [63/500], Train Loss: 7.1232, Train RMSE: 2.6689\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [63/500], Validation Loss: 5.9958, Validation RMSE: 2.4486, Valid PR: 0.6131\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [64/500], Train Loss: 7.1248, Train RMSE: 2.6692\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [64/500], Validation Loss: 5.7528, Validation RMSE: 2.3985, Valid PR: 0.6052\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [65/500], Train Loss: 5.6745, Train RMSE: 2.3821\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [65/500], Validation Loss: 5.5602, Validation RMSE: 2.3580, Valid PR: 0.5981\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [66/500], Train Loss: 6.5263, Train RMSE: 2.5547\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [66/500], Validation Loss: 5.4155, Validation RMSE: 2.3271, Valid PR: 0.5914\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [67/500], Train Loss: 6.2781, Train RMSE: 2.5056\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [67/500], Validation Loss: 5.2688, Validation RMSE: 2.2954, Valid PR: 0.5865\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [68/500], Train Loss: 5.6470, Train RMSE: 2.3763\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [68/500], Validation Loss: 5.1586, Validation RMSE: 2.2713, Valid PR: 0.5842\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [69/500], Train Loss: 5.7321, Train RMSE: 2.3942\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [69/500], Validation Loss: 4.9595, Validation RMSE: 2.2270, Valid PR: 0.5843\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [70/500], Train Loss: 4.9173, Train RMSE: 2.2175\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [70/500], Validation Loss: 4.7602, Validation RMSE: 2.1818, Valid PR: 0.5840\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [71/500], Train Loss: 4.7489, Train RMSE: 2.1792\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [71/500], Validation Loss: 4.6382, Validation RMSE: 2.1537, Valid PR: 0.5786\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [72/500], Train Loss: 5.1727, Train RMSE: 2.2743\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [72/500], Validation Loss: 4.5077, Validation RMSE: 2.1231, Valid PR: 0.5748\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [73/500], Train Loss: 4.1239, Train RMSE: 2.0307\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [73/500], Validation Loss: 4.3723, Validation RMSE: 2.0910, Valid PR: 0.5722\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [74/500], Train Loss: 5.2251, Train RMSE: 2.2859\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [74/500], Validation Loss: 4.2589, Validation RMSE: 2.0637, Valid PR: 0.5718\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [75/500], Train Loss: 4.8476, Train RMSE: 2.2017\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [75/500], Validation Loss: 4.1687, Validation RMSE: 2.0417, Valid PR: 0.5689\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [76/500], Train Loss: 3.7331, Train RMSE: 1.9321\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [76/500], Validation Loss: 4.1195, Validation RMSE: 2.0297, Valid PR: 0.5665\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [77/500], Train Loss: 4.9986, Train RMSE: 2.2358\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [77/500], Validation Loss: 4.1100, Validation RMSE: 2.0273, Valid PR: 0.5664\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [78/500], Train Loss: 3.7047, Train RMSE: 1.9248\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [78/500], Validation Loss: 4.0231, Validation RMSE: 2.0058, Valid PR: 0.5674\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [79/500], Train Loss: 3.4583, Train RMSE: 1.8597\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [79/500], Validation Loss: 3.9048, Validation RMSE: 1.9761, Valid PR: 0.5736\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [80/500], Train Loss: 4.3310, Train RMSE: 2.0811\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [80/500], Validation Loss: 3.8098, Validation RMSE: 1.9519, Valid PR: 0.5810\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [81/500], Train Loss: 4.3342, Train RMSE: 2.0819\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [81/500], Validation Loss: 3.7392, Validation RMSE: 1.9337, Valid PR: 0.5864\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [82/500], Train Loss: 3.1968, Train RMSE: 1.7880\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [82/500], Validation Loss: 3.6335, Validation RMSE: 1.9062, Valid PR: 0.5903\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [83/500], Train Loss: 3.2750, Train RMSE: 1.8097\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [83/500], Validation Loss: 3.5038, Validation RMSE: 1.8718, Valid PR: 0.5962\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [84/500], Train Loss: 2.8977, Train RMSE: 1.7023\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [84/500], Validation Loss: 3.4521, Validation RMSE: 1.8580, Valid PR: 0.5957\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [85/500], Train Loss: 3.4466, Train RMSE: 1.8565\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [85/500], Validation Loss: 3.4103, Validation RMSE: 1.8467, Valid PR: 0.5928\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [86/500], Train Loss: 2.9759, Train RMSE: 1.7251\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [86/500], Validation Loss: 3.3953, Validation RMSE: 1.8426, Valid PR: 0.5902\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [87/500], Train Loss: 2.5624, Train RMSE: 1.6007\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [87/500], Validation Loss: 3.2707, Validation RMSE: 1.8085, Valid PR: 0.5901\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [88/500], Train Loss: 3.1869, Train RMSE: 1.7852\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [88/500], Validation Loss: 3.1636, Validation RMSE: 1.7786, Valid PR: 0.5906\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [89/500], Train Loss: 3.0013, Train RMSE: 1.7324\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [89/500], Validation Loss: 3.0247, Validation RMSE: 1.7392, Valid PR: 0.5915\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [90/500], Train Loss: 2.8719, Train RMSE: 1.6947\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [90/500], Validation Loss: 2.9400, Validation RMSE: 1.7147, Valid PR: 0.5901\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [91/500], Train Loss: 2.4663, Train RMSE: 1.5704\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [91/500], Validation Loss: 2.8464, Validation RMSE: 1.6871, Valid PR: 0.5881\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [92/500], Train Loss: 2.7235, Train RMSE: 1.6503\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [92/500], Validation Loss: 2.7292, Validation RMSE: 1.6520, Valid PR: 0.5901\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [93/500], Train Loss: 2.8717, Train RMSE: 1.6946\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [93/500], Validation Loss: 2.6493, Validation RMSE: 1.6277, Valid PR: 0.5890\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [94/500], Train Loss: 2.0939, Train RMSE: 1.4470\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [94/500], Validation Loss: 2.5563, Validation RMSE: 1.5988, Valid PR: 0.5836\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [95/500], Train Loss: 2.7450, Train RMSE: 1.6568\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [95/500], Validation Loss: 2.4624, Validation RMSE: 1.5692, Valid PR: 0.5792\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [96/500], Train Loss: 1.8452, Train RMSE: 1.3584\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [96/500], Validation Loss: 2.4207, Validation RMSE: 1.5559, Valid PR: 0.5736\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [97/500], Train Loss: 2.3782, Train RMSE: 1.5422\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [97/500], Validation Loss: 2.3504, Validation RMSE: 1.5331, Valid PR: 0.5734\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [98/500], Train Loss: 2.5273, Train RMSE: 1.5897\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [98/500], Validation Loss: 2.3217, Validation RMSE: 1.5237, Valid PR: 0.5679\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [99/500], Train Loss: 2.1988, Train RMSE: 1.4828\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [99/500], Validation Loss: 2.2513, Validation RMSE: 1.5004, Valid PR: 0.5654\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [100/500], Train Loss: 2.0303, Train RMSE: 1.4249\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [100/500], Validation Loss: 2.2085, Validation RMSE: 1.4861, Valid PR: 0.5615\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [101/500], Train Loss: 2.4588, Train RMSE: 1.5681\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [101/500], Validation Loss: 2.1418, Validation RMSE: 1.4635, Valid PR: 0.5638\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [102/500], Train Loss: 1.9723, Train RMSE: 1.4044\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [102/500], Validation Loss: 2.0635, Validation RMSE: 1.4365, Valid PR: 0.5726\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [103/500], Train Loss: 2.9572, Train RMSE: 1.7197\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [103/500], Validation Loss: 2.0075, Validation RMSE: 1.4169, Valid PR: 0.5827\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [104/500], Train Loss: 2.6260, Train RMSE: 1.6205\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [104/500], Validation Loss: 1.9660, Validation RMSE: 1.4021, Valid PR: 0.5942\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [105/500], Train Loss: 1.8999, Train RMSE: 1.3784\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [105/500], Validation Loss: 1.9506, Validation RMSE: 1.3966, Valid PR: 0.6007\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [106/500], Train Loss: 1.9475, Train RMSE: 1.3955\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [106/500], Validation Loss: 1.9232, Validation RMSE: 1.3868, Valid PR: 0.6079\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [107/500], Train Loss: 1.8826, Train RMSE: 1.3721\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [107/500], Validation Loss: 1.9081, Validation RMSE: 1.3813, Valid PR: 0.6124\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [108/500], Train Loss: 1.9864, Train RMSE: 1.4094\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [108/500], Validation Loss: 1.9176, Validation RMSE: 1.3848, Valid PR: 0.6091\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [109/500], Train Loss: 2.2555, Train RMSE: 1.5018\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [109/500], Validation Loss: 1.9180, Validation RMSE: 1.3849, Valid PR: 0.6053\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [110/500], Train Loss: 2.1086, Train RMSE: 1.4521\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [110/500], Validation Loss: 1.8946, Validation RMSE: 1.3765, Valid PR: 0.6111\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [111/500], Train Loss: 1.9309, Train RMSE: 1.3896\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [111/500], Validation Loss: 1.9056, Validation RMSE: 1.3804, Valid PR: 0.6129\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [112/500], Train Loss: 2.1297, Train RMSE: 1.4594\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [112/500], Validation Loss: 1.9198, Validation RMSE: 1.3856, Valid PR: 0.6132\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [113/500], Train Loss: 2.1278, Train RMSE: 1.4587\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [113/500], Validation Loss: 1.9059, Validation RMSE: 1.3805, Valid PR: 0.6143\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [114/500], Train Loss: 1.8656, Train RMSE: 1.3659\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [114/500], Validation Loss: 1.8575, Validation RMSE: 1.3629, Valid PR: 0.6179\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [115/500], Train Loss: 2.1204, Train RMSE: 1.4562\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [115/500], Validation Loss: 1.8282, Validation RMSE: 1.3521, Valid PR: 0.6187\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [116/500], Train Loss: 1.8897, Train RMSE: 1.3747\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [116/500], Validation Loss: 1.7787, Validation RMSE: 1.3337, Valid PR: 0.6261\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [117/500], Train Loss: 1.6415, Train RMSE: 1.2812\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [117/500], Validation Loss: 1.7504, Validation RMSE: 1.3230, Valid PR: 0.6352\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [118/500], Train Loss: 1.7466, Train RMSE: 1.3216\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [118/500], Validation Loss: 1.7192, Validation RMSE: 1.3112, Valid PR: 0.6390\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [119/500], Train Loss: 1.7161, Train RMSE: 1.3100\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [119/500], Validation Loss: 1.6845, Validation RMSE: 1.2979, Valid PR: 0.6389\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [120/500], Train Loss: 1.8417, Train RMSE: 1.3571\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [120/500], Validation Loss: 1.6457, Validation RMSE: 1.2828, Valid PR: 0.6390\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [121/500], Train Loss: 1.9705, Train RMSE: 1.4038\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [121/500], Validation Loss: 1.6237, Validation RMSE: 1.2742, Valid PR: 0.6398\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [122/500], Train Loss: 2.9741, Train RMSE: 1.7246\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [122/500], Validation Loss: 1.6206, Validation RMSE: 1.2730, Valid PR: 0.6325\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [123/500], Train Loss: 2.2225, Train RMSE: 1.4908\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [123/500], Validation Loss: 1.6104, Validation RMSE: 1.2690, Valid PR: 0.6293\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [124/500], Train Loss: 2.3864, Train RMSE: 1.5448\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [124/500], Validation Loss: 1.6055, Validation RMSE: 1.2671, Valid PR: 0.6281\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [125/500], Train Loss: 2.0780, Train RMSE: 1.4415\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [125/500], Validation Loss: 1.6188, Validation RMSE: 1.2723, Valid PR: 0.6237\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [126/500], Train Loss: 1.7763, Train RMSE: 1.3328\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [126/500], Validation Loss: 1.6126, Validation RMSE: 1.2699, Valid PR: 0.6257\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [127/500], Train Loss: 2.2836, Train RMSE: 1.5112\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [127/500], Validation Loss: 1.6065, Validation RMSE: 1.2675, Valid PR: 0.6292\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [128/500], Train Loss: 1.6211, Train RMSE: 1.2732\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [128/500], Validation Loss: 1.6255, Validation RMSE: 1.2750, Valid PR: 0.6290\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [129/500], Train Loss: 1.8197, Train RMSE: 1.3490\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [129/500], Validation Loss: 1.6442, Validation RMSE: 1.2823, Valid PR: 0.6286\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [130/500], Train Loss: 1.7786, Train RMSE: 1.3336\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [130/500], Validation Loss: 1.6720, Validation RMSE: 1.2930, Valid PR: 0.6267\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [131/500], Train Loss: 2.1203, Train RMSE: 1.4561\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [131/500], Validation Loss: 1.6762, Validation RMSE: 1.2947, Valid PR: 0.6241\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [132/500], Train Loss: 2.1033, Train RMSE: 1.4503\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [132/500], Validation Loss: 1.6608, Validation RMSE: 1.2887, Valid PR: 0.6286\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [133/500], Train Loss: 2.2354, Train RMSE: 1.4951\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [133/500], Validation Loss: 1.5999, Validation RMSE: 1.2649, Valid PR: 0.6397\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [134/500], Train Loss: 1.5274, Train RMSE: 1.2359\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [134/500], Validation Loss: 1.5767, Validation RMSE: 1.2557, Valid PR: 0.6466\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [135/500], Train Loss: 2.1438, Train RMSE: 1.4642\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [135/500], Validation Loss: 1.5588, Validation RMSE: 1.2485, Valid PR: 0.6522\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [136/500], Train Loss: 1.9724, Train RMSE: 1.4044\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [136/500], Validation Loss: 1.5813, Validation RMSE: 1.2575, Valid PR: 0.6540\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [137/500], Train Loss: 2.0160, Train RMSE: 1.4198\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [137/500], Validation Loss: 1.6038, Validation RMSE: 1.2664, Valid PR: 0.6557\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [138/500], Train Loss: 1.5130, Train RMSE: 1.2300\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [138/500], Validation Loss: 1.6084, Validation RMSE: 1.2682, Valid PR: 0.6552\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [139/500], Train Loss: 1.2285, Train RMSE: 1.1084\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [139/500], Validation Loss: 1.6069, Validation RMSE: 1.2676, Valid PR: 0.6585\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [140/500], Train Loss: 2.0559, Train RMSE: 1.4338\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [140/500], Validation Loss: 1.5715, Validation RMSE: 1.2536, Valid PR: 0.6650\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [141/500], Train Loss: 1.4812, Train RMSE: 1.2170\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [141/500], Validation Loss: 1.5717, Validation RMSE: 1.2537, Valid PR: 0.6676\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [142/500], Train Loss: 2.5471, Train RMSE: 1.5960\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [142/500], Validation Loss: 1.5888, Validation RMSE: 1.2605, Valid PR: 0.6715\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [143/500], Train Loss: 1.7904, Train RMSE: 1.3381\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [143/500], Validation Loss: 1.5870, Validation RMSE: 1.2598, Valid PR: 0.6755\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [144/500], Train Loss: 1.9689, Train RMSE: 1.4032\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [144/500], Validation Loss: 1.5833, Validation RMSE: 1.2583, Valid PR: 0.6768\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [145/500], Train Loss: 2.0193, Train RMSE: 1.4210\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [145/500], Validation Loss: 1.5246, Validation RMSE: 1.2348, Valid PR: 0.6809\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [146/500], Train Loss: 1.9675, Train RMSE: 1.4027\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [146/500], Validation Loss: 1.4453, Validation RMSE: 1.2022, Valid PR: 0.6880\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [147/500], Train Loss: 2.0170, Train RMSE: 1.4202\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [147/500], Validation Loss: 1.4186, Validation RMSE: 1.1911, Valid PR: 0.6914\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [148/500], Train Loss: 2.1706, Train RMSE: 1.4733\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [148/500], Validation Loss: 1.4062, Validation RMSE: 1.1859, Valid PR: 0.6933\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [149/500], Train Loss: 1.6606, Train RMSE: 1.2886\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [149/500], Validation Loss: 1.3910, Validation RMSE: 1.1794, Valid PR: 0.6956\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [150/500], Train Loss: 1.9861, Train RMSE: 1.4093\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [150/500], Validation Loss: 1.4235, Validation RMSE: 1.1931, Valid PR: 0.6936\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [151/500], Train Loss: 1.8897, Train RMSE: 1.3747\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [151/500], Validation Loss: 1.4325, Validation RMSE: 1.1969, Valid PR: 0.6939\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [152/500], Train Loss: 2.1033, Train RMSE: 1.4503\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [152/500], Validation Loss: 1.4312, Validation RMSE: 1.1963, Valid PR: 0.6935\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [153/500], Train Loss: 2.0443, Train RMSE: 1.4298\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [153/500], Validation Loss: 1.4268, Validation RMSE: 1.1945, Valid PR: 0.6951\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [154/500], Train Loss: 1.9004, Train RMSE: 1.3785\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [154/500], Validation Loss: 1.4027, Validation RMSE: 1.1844, Valid PR: 0.6957\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [155/500], Train Loss: 1.8240, Train RMSE: 1.3506\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [155/500], Validation Loss: 1.4103, Validation RMSE: 1.1876, Valid PR: 0.6963\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [156/500], Train Loss: 1.8024, Train RMSE: 1.3426\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [156/500], Validation Loss: 1.4089, Validation RMSE: 1.1870, Valid PR: 0.6988\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [157/500], Train Loss: 2.0246, Train RMSE: 1.4229\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [157/500], Validation Loss: 1.3687, Validation RMSE: 1.1699, Valid PR: 0.7032\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [158/500], Train Loss: 1.4379, Train RMSE: 1.1991\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [158/500], Validation Loss: 1.3189, Validation RMSE: 1.1484, Valid PR: 0.7064\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [159/500], Train Loss: 1.4418, Train RMSE: 1.2007\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [159/500], Validation Loss: 1.2879, Validation RMSE: 1.1349, Valid PR: 0.7064\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [160/500], Train Loss: 1.9316, Train RMSE: 1.3898\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [160/500], Validation Loss: 1.2992, Validation RMSE: 1.1398, Valid PR: 0.7024\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [161/500], Train Loss: 1.7591, Train RMSE: 1.3263\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [161/500], Validation Loss: 1.2953, Validation RMSE: 1.1381, Valid PR: 0.7004\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [162/500], Train Loss: 1.3371, Train RMSE: 1.1563\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [162/500], Validation Loss: 1.3178, Validation RMSE: 1.1480, Valid PR: 0.6992\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [163/500], Train Loss: 1.5575, Train RMSE: 1.2480\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [163/500], Validation Loss: 1.3323, Validation RMSE: 1.1542, Valid PR: 0.6999\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [164/500], Train Loss: 1.5681, Train RMSE: 1.2522\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [164/500], Validation Loss: 1.3738, Validation RMSE: 1.1721, Valid PR: 0.7010\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [165/500], Train Loss: 1.7255, Train RMSE: 1.3136\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [165/500], Validation Loss: 1.4050, Validation RMSE: 1.1853, Valid PR: 0.7025\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [166/500], Train Loss: 1.3443, Train RMSE: 1.1594\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [166/500], Validation Loss: 1.4284, Validation RMSE: 1.1951, Valid PR: 0.7048\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [167/500], Train Loss: 1.9485, Train RMSE: 1.3959\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [167/500], Validation Loss: 1.4441, Validation RMSE: 1.2017, Valid PR: 0.7095\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [168/500], Train Loss: 1.8668, Train RMSE: 1.3663\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [168/500], Validation Loss: 1.3893, Validation RMSE: 1.1787, Valid PR: 0.7153\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [169/500], Train Loss: 1.6521, Train RMSE: 1.2853\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [169/500], Validation Loss: 1.3659, Validation RMSE: 1.1687, Valid PR: 0.7146\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [170/500], Train Loss: 2.0755, Train RMSE: 1.4407\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [170/500], Validation Loss: 1.3727, Validation RMSE: 1.1716, Valid PR: 0.7158\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [171/500], Train Loss: 2.1513, Train RMSE: 1.4667\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [171/500], Validation Loss: 1.3648, Validation RMSE: 1.1682, Valid PR: 0.7155\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [172/500], Train Loss: 2.0940, Train RMSE: 1.4471\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [172/500], Validation Loss: 1.3255, Validation RMSE: 1.1513, Valid PR: 0.7198\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [173/500], Train Loss: 1.9607, Train RMSE: 1.4003\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [173/500], Validation Loss: 1.3118, Validation RMSE: 1.1453, Valid PR: 0.7222\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [174/500], Train Loss: 1.7177, Train RMSE: 1.3106\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [174/500], Validation Loss: 1.2975, Validation RMSE: 1.1391, Valid PR: 0.7247\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [175/500], Train Loss: 1.9416, Train RMSE: 1.3934\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [175/500], Validation Loss: 1.2569, Validation RMSE: 1.1211, Valid PR: 0.7279\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [176/500], Train Loss: 1.3657, Train RMSE: 1.1686\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [176/500], Validation Loss: 1.2570, Validation RMSE: 1.1212, Valid PR: 0.7305\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [177/500], Train Loss: 1.9200, Train RMSE: 1.3857\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [177/500], Validation Loss: 1.2514, Validation RMSE: 1.1187, Valid PR: 0.7317\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [178/500], Train Loss: 1.6418, Train RMSE: 1.2813\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [178/500], Validation Loss: 1.2797, Validation RMSE: 1.1312, Valid PR: 0.7287\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [179/500], Train Loss: 1.7779, Train RMSE: 1.3334\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [179/500], Validation Loss: 1.2838, Validation RMSE: 1.1330, Valid PR: 0.7216\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [180/500], Train Loss: 1.6119, Train RMSE: 1.2696\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [180/500], Validation Loss: 1.2941, Validation RMSE: 1.1376, Valid PR: 0.7162\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [181/500], Train Loss: 1.5640, Train RMSE: 1.2506\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [181/500], Validation Loss: 1.3000, Validation RMSE: 1.1402, Valid PR: 0.7120\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [182/500], Train Loss: 1.9818, Train RMSE: 1.4078\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [182/500], Validation Loss: 1.2960, Validation RMSE: 1.1384, Valid PR: 0.7091\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [183/500], Train Loss: 1.5383, Train RMSE: 1.2403\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [183/500], Validation Loss: 1.3135, Validation RMSE: 1.1461, Valid PR: 0.7051\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [184/500], Train Loss: 1.8062, Train RMSE: 1.3439\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [184/500], Validation Loss: 1.3393, Validation RMSE: 1.1573, Valid PR: 0.7022\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [185/500], Train Loss: 1.7006, Train RMSE: 1.3041\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [185/500], Validation Loss: 1.3802, Validation RMSE: 1.1748, Valid PR: 0.7018\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [186/500], Train Loss: 2.2292, Train RMSE: 1.4931\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [186/500], Validation Loss: 1.4131, Validation RMSE: 1.1887, Valid PR: 0.7025\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [187/500], Train Loss: 2.2249, Train RMSE: 1.4916\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [187/500], Validation Loss: 1.4251, Validation RMSE: 1.1938, Valid PR: 0.6969\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [188/500], Train Loss: 1.4533, Train RMSE: 1.2055\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [188/500], Validation Loss: 1.4573, Validation RMSE: 1.2072, Valid PR: 0.6929\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [189/500], Train Loss: 1.8087, Train RMSE: 1.3449\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [189/500], Validation Loss: 1.4845, Validation RMSE: 1.2184, Valid PR: 0.6890\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [190/500], Train Loss: 1.3812, Train RMSE: 1.1753\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [190/500], Validation Loss: 1.4890, Validation RMSE: 1.2203, Valid PR: 0.6880\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [191/500], Train Loss: 2.1500, Train RMSE: 1.4663\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [191/500], Validation Loss: 1.4971, Validation RMSE: 1.2236, Valid PR: 0.6864\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [192/500], Train Loss: 1.6214, Train RMSE: 1.2734\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [192/500], Validation Loss: 1.4949, Validation RMSE: 1.2226, Valid PR: 0.6849\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [193/500], Train Loss: 1.8894, Train RMSE: 1.3746\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [193/500], Validation Loss: 1.4690, Validation RMSE: 1.2120, Valid PR: 0.6847\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [194/500], Train Loss: 2.3854, Train RMSE: 1.5445\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [194/500], Validation Loss: 1.4785, Validation RMSE: 1.2160, Valid PR: 0.6808\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [195/500], Train Loss: 1.8624, Train RMSE: 1.3647\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [195/500], Validation Loss: 1.4899, Validation RMSE: 1.2206, Valid PR: 0.6763\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [196/500], Train Loss: 2.2662, Train RMSE: 1.5054\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [196/500], Validation Loss: 1.5471, Validation RMSE: 1.2438, Valid PR: 0.6656\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [197/500], Train Loss: 1.8936, Train RMSE: 1.3761\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [197/500], Validation Loss: 1.6017, Validation RMSE: 1.2656, Valid PR: 0.6580\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [198/500], Train Loss: 1.5734, Train RMSE: 1.2544\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [198/500], Validation Loss: 1.6894, Validation RMSE: 1.2998, Valid PR: 0.6467\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [199/500], Train Loss: 1.5478, Train RMSE: 1.2441\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [199/500], Validation Loss: 1.7793, Validation RMSE: 1.3339, Valid PR: 0.6360\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [200/500], Train Loss: 1.5487, Train RMSE: 1.2445\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [200/500], Validation Loss: 1.8281, Validation RMSE: 1.3521, Valid PR: 0.6296\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [201/500], Train Loss: 2.0044, Train RMSE: 1.4158\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [201/500], Validation Loss: 1.8334, Validation RMSE: 1.3540, Valid PR: 0.6263\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [202/500], Train Loss: 1.5895, Train RMSE: 1.2608\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [202/500], Validation Loss: 1.8896, Validation RMSE: 1.3746, Valid PR: 0.6206\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [203/500], Train Loss: 1.7722, Train RMSE: 1.3313\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [203/500], Validation Loss: 1.9063, Validation RMSE: 1.3807, Valid PR: 0.6182\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [204/500], Train Loss: 1.4046, Train RMSE: 1.1852\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [204/500], Validation Loss: 1.8597, Validation RMSE: 1.3637, Valid PR: 0.6228\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [205/500], Train Loss: 1.7629, Train RMSE: 1.3277\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [205/500], Validation Loss: 1.8334, Validation RMSE: 1.3540, Valid PR: 0.6264\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [206/500], Train Loss: 1.5584, Train RMSE: 1.2484\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [206/500], Validation Loss: 1.8169, Validation RMSE: 1.3479, Valid PR: 0.6348\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [207/500], Train Loss: 1.4969, Train RMSE: 1.2235\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [207/500], Validation Loss: 1.8018, Validation RMSE: 1.3423, Valid PR: 0.6407\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [208/500], Train Loss: 2.2222, Train RMSE: 1.4907\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [208/500], Validation Loss: 1.8053, Validation RMSE: 1.3436, Valid PR: 0.6505\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [209/500], Train Loss: 2.1020, Train RMSE: 1.4498\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [209/500], Validation Loss: 1.7725, Validation RMSE: 1.3314, Valid PR: 0.6612\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [210/500], Train Loss: 1.4074, Train RMSE: 1.1863\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [210/500], Validation Loss: 1.7653, Validation RMSE: 1.3287, Valid PR: 0.6680\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [211/500], Train Loss: 1.8748, Train RMSE: 1.3692\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [211/500], Validation Loss: 1.8132, Validation RMSE: 1.3465, Valid PR: 0.6661\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [212/500], Train Loss: 2.1624, Train RMSE: 1.4705\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [212/500], Validation Loss: 1.8286, Validation RMSE: 1.3523, Valid PR: 0.6630\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [213/500], Train Loss: 1.9635, Train RMSE: 1.4013\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [213/500], Validation Loss: 1.8615, Validation RMSE: 1.3644, Valid PR: 0.6646\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [214/500], Train Loss: 1.6991, Train RMSE: 1.3035\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [214/500], Validation Loss: 1.8950, Validation RMSE: 1.3766, Valid PR: 0.6644\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [215/500], Train Loss: 1.7125, Train RMSE: 1.3086\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [215/500], Validation Loss: 1.9168, Validation RMSE: 1.3845, Valid PR: 0.6632\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [216/500], Train Loss: 1.5209, Train RMSE: 1.2333\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [216/500], Validation Loss: 1.9094, Validation RMSE: 1.3818, Valid PR: 0.6621\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [217/500], Train Loss: 1.9147, Train RMSE: 1.3837\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [217/500], Validation Loss: 1.9110, Validation RMSE: 1.3824, Valid PR: 0.6639\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [218/500], Train Loss: 1.6823, Train RMSE: 1.2970\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [218/500], Validation Loss: 1.9396, Validation RMSE: 1.3927, Valid PR: 0.6619\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [219/500], Train Loss: 1.3449, Train RMSE: 1.1597\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [219/500], Validation Loss: 1.9667, Validation RMSE: 1.4024, Valid PR: 0.6583\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [220/500], Train Loss: 1.8997, Train RMSE: 1.3783\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [220/500], Validation Loss: 1.9124, Validation RMSE: 1.3829, Valid PR: 0.6604\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [221/500], Train Loss: 1.5362, Train RMSE: 1.2395\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [221/500], Validation Loss: 1.8064, Validation RMSE: 1.3440, Valid PR: 0.6696\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [222/500], Train Loss: 2.0320, Train RMSE: 1.4255\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [222/500], Validation Loss: 1.7142, Validation RMSE: 1.3093, Valid PR: 0.6778\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [223/500], Train Loss: 1.3923, Train RMSE: 1.1799\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [223/500], Validation Loss: 1.6855, Validation RMSE: 1.2983, Valid PR: 0.6814\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [224/500], Train Loss: 1.5448, Train RMSE: 1.2429\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [224/500], Validation Loss: 1.6833, Validation RMSE: 1.2974, Valid PR: 0.6841\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [225/500], Train Loss: 1.4541, Train RMSE: 1.2059\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [225/500], Validation Loss: 1.6995, Validation RMSE: 1.3036, Valid PR: 0.6880\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [226/500], Train Loss: 2.1508, Train RMSE: 1.4666\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [226/500], Validation Loss: 1.7615, Validation RMSE: 1.3272, Valid PR: 0.6838\n",
      "Training Batch Size: torch.Size([81, 1536])\n",
      "Epoch [227/500], Train Loss: 1.7278, Train RMSE: 1.3145\n",
      "Validation Batch Size: torch.Size([10, 1536])\n",
      "Epoch [227/500], Validation Loss: 1.7568, Validation RMSE: 1.3255, Valid PR: 0.6868\n",
      "Early stopping triggered.\n",
      "Testing Batch Size: torch.Size([27, 1536])\n",
      "Test Loss: 6.0513, Test RMSE: 2.4599, Test PR: -0.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/4111471290.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"best_clip_model.pth\"\n",
    "model = load_and_freeze_model(model_path, output_dim=768)\n",
    "\n",
    "# Data paths for finetuning\n",
    "data_path_csv = 'pdbbind_dataset_rna/pdbbind_rna_processed_index_encoded.csv'\n",
    "data_path_npy = 'pdbbind_dataset_rna/combined_distance_matrices_finetune.npy'\n",
    "\n",
    "# Prepare data\n",
    "matrix_data, combined_data = prepare_data(data_path_csv, data_path_npy)\n",
    "encoded_df = pd.read_csv(data_path_csv, keep_default_na=False)\n",
    "train_indices = encoded_df[encoded_df['set'] == 'train'].index\n",
    "val_indices = encoded_df[encoded_df['set'] == 'valid'].index\n",
    "test_indices = encoded_df[encoded_df['set'] == 'test'].index\n",
    "y_train = encoded_df.loc[train_indices, 'label'].values\n",
    "y_val = encoded_df.loc[val_indices, 'label'].values\n",
    "y_test = encoded_df.loc[test_indices, 'label'].values\n",
    "\n",
    "# Create train, validation, and test datasets\n",
    "train_dataset = CustomDataset(matrix_data[train_indices], combined_data[train_indices])\n",
    "val_dataset = CustomDataset(matrix_data[val_indices], combined_data[val_indices])\n",
    "test_dataset = CustomDataset(matrix_data[test_indices], combined_data[test_indices])\n",
    "train_loader = DataLoader(train_dataset)\n",
    "val_loader = DataLoader(val_dataset)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Get encodings\n",
    "train_matrix_encodings, train_vector_encodings = get_encodings(model, train_loader, device)\n",
    "val_matrix_encodings, val_vector_encodings = get_encodings(model, val_loader, device)\n",
    "test_matrix_encodings, test_vector_encodings = get_encodings(model, test_loader, device)\n",
    "\n",
    "# Train fully connected neural network to predict labels\n",
    "train_fully_connected_nn(train_matrix_encodings, train_vector_encodings, y_train, val_matrix_encodings, val_vector_encodings, y_val)\n",
    "\n",
    "# Test the final model\n",
    "test_fully_connected_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path=\"best_finetuned_fully_connected_nn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3665dd-5ee0-4b67-8f45-5a79abdf517b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "08ab4d50-c306-4bfe-b655-e994af6394c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing method1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/1961612305.py:111: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 41.0601, Train RMSE: 6.4078\n",
      "Epoch [1/500], Validation Loss: 35.2109, Validation RMSE: 5.9339, Valid PR: 0.6663\n",
      "Epoch [2/500], Train Loss: 39.5215, Train RMSE: 6.2866\n",
      "Epoch [2/500], Validation Loss: 35.4287, Validation RMSE: 5.9522, Valid PR: 0.7000\n",
      "Epoch [3/500], Train Loss: 38.6737, Train RMSE: 6.2188\n",
      "Epoch [3/500], Validation Loss: 34.7783, Validation RMSE: 5.8973, Valid PR: 0.7101\n",
      "Epoch [4/500], Train Loss: 38.3718, Train RMSE: 6.1945\n",
      "Epoch [4/500], Validation Loss: 33.3149, Validation RMSE: 5.7719, Valid PR: 0.7556\n",
      "Epoch [5/500], Train Loss: 37.9688, Train RMSE: 6.1619\n",
      "Epoch [5/500], Validation Loss: 31.6154, Validation RMSE: 5.6228, Valid PR: 0.8083\n",
      "Epoch [6/500], Train Loss: 36.8164, Train RMSE: 6.0677\n",
      "Epoch [6/500], Validation Loss: 29.8202, Validation RMSE: 5.4608, Valid PR: 0.8691\n",
      "Epoch [7/500], Train Loss: 36.4041, Train RMSE: 6.0336\n",
      "Epoch [7/500], Validation Loss: 27.9349, Validation RMSE: 5.2853, Valid PR: 0.8871\n",
      "Epoch [8/500], Train Loss: 35.3551, Train RMSE: 5.9460\n",
      "Epoch [8/500], Validation Loss: 26.4824, Validation RMSE: 5.1461, Valid PR: 0.8619\n",
      "Epoch [9/500], Train Loss: 34.8603, Train RMSE: 5.9043\n",
      "Epoch [9/500], Validation Loss: 25.0326, Validation RMSE: 5.0033, Valid PR: 0.8262\n",
      "Epoch [10/500], Train Loss: 34.2107, Train RMSE: 5.8490\n",
      "Epoch [10/500], Validation Loss: 23.6502, Validation RMSE: 4.8632, Valid PR: 0.8068\n",
      "Epoch [11/500], Train Loss: 33.7096, Train RMSE: 5.8060\n",
      "Epoch [11/500], Validation Loss: 22.4431, Validation RMSE: 4.7374, Valid PR: 0.7870\n",
      "Epoch [12/500], Train Loss: 33.7099, Train RMSE: 5.8060\n",
      "Epoch [12/500], Validation Loss: 21.3687, Validation RMSE: 4.6226, Valid PR: 0.7782\n",
      "Epoch [13/500], Train Loss: 32.7291, Train RMSE: 5.7209\n",
      "Epoch [13/500], Validation Loss: 20.3184, Validation RMSE: 4.5076, Valid PR: 0.7697\n",
      "Epoch [14/500], Train Loss: 31.7691, Train RMSE: 5.6364\n",
      "Epoch [14/500], Validation Loss: 19.3527, Validation RMSE: 4.3992, Valid PR: 0.7705\n",
      "Epoch [15/500], Train Loss: 31.9635, Train RMSE: 5.6536\n",
      "Epoch [15/500], Validation Loss: 18.5980, Validation RMSE: 4.3125, Valid PR: 0.7804\n",
      "Epoch [16/500], Train Loss: 31.3558, Train RMSE: 5.5996\n",
      "Epoch [16/500], Validation Loss: 17.8801, Validation RMSE: 4.2285, Valid PR: 0.7876\n",
      "Epoch [17/500], Train Loss: 30.4729, Train RMSE: 5.5202\n",
      "Epoch [17/500], Validation Loss: 17.3670, Validation RMSE: 4.1674, Valid PR: 0.7930\n",
      "Epoch [18/500], Train Loss: 29.6377, Train RMSE: 5.4440\n",
      "Epoch [18/500], Validation Loss: 16.7810, Validation RMSE: 4.0965, Valid PR: 0.7891\n",
      "Epoch [19/500], Train Loss: 29.4561, Train RMSE: 5.4273\n",
      "Epoch [19/500], Validation Loss: 16.3724, Validation RMSE: 4.0463, Valid PR: 0.7859\n",
      "Epoch [20/500], Train Loss: 28.9205, Train RMSE: 5.3778\n",
      "Epoch [20/500], Validation Loss: 16.1767, Validation RMSE: 4.0220, Valid PR: 0.7828\n",
      "Epoch [21/500], Train Loss: 28.2570, Train RMSE: 5.3157\n",
      "Epoch [21/500], Validation Loss: 15.9966, Validation RMSE: 3.9996, Valid PR: 0.7758\n",
      "Epoch [22/500], Train Loss: 28.5170, Train RMSE: 5.3401\n",
      "Epoch [22/500], Validation Loss: 15.7550, Validation RMSE: 3.9693, Valid PR: 0.7716\n",
      "Epoch [23/500], Train Loss: 27.4665, Train RMSE: 5.2409\n",
      "Epoch [23/500], Validation Loss: 15.6377, Validation RMSE: 3.9545, Valid PR: 0.7650\n",
      "Epoch [24/500], Train Loss: 27.1209, Train RMSE: 5.2078\n",
      "Epoch [24/500], Validation Loss: 15.6107, Validation RMSE: 3.9510, Valid PR: 0.7542\n",
      "Epoch [25/500], Train Loss: 25.7374, Train RMSE: 5.0732\n",
      "Epoch [25/500], Validation Loss: 15.5145, Validation RMSE: 3.9388, Valid PR: 0.7452\n",
      "Epoch [26/500], Train Loss: 25.6526, Train RMSE: 5.0648\n",
      "Epoch [26/500], Validation Loss: 15.3275, Validation RMSE: 3.9150, Valid PR: 0.7380\n",
      "Epoch [27/500], Train Loss: 25.6665, Train RMSE: 5.0662\n",
      "Epoch [27/500], Validation Loss: 15.1974, Validation RMSE: 3.8984, Valid PR: 0.7295\n",
      "Epoch [28/500], Train Loss: 25.1964, Train RMSE: 5.0196\n",
      "Epoch [28/500], Validation Loss: 15.0862, Validation RMSE: 3.8841, Valid PR: 0.7224\n",
      "Epoch [29/500], Train Loss: 24.4651, Train RMSE: 4.9462\n",
      "Epoch [29/500], Validation Loss: 14.8660, Validation RMSE: 3.8557, Valid PR: 0.7203\n",
      "Epoch [30/500], Train Loss: 24.0013, Train RMSE: 4.8991\n",
      "Epoch [30/500], Validation Loss: 14.6478, Validation RMSE: 3.8272, Valid PR: 0.7159\n",
      "Epoch [31/500], Train Loss: 23.5157, Train RMSE: 4.8493\n",
      "Epoch [31/500], Validation Loss: 14.5516, Validation RMSE: 3.8147, Valid PR: 0.7146\n",
      "Epoch [32/500], Train Loss: 23.3278, Train RMSE: 4.8299\n",
      "Epoch [32/500], Validation Loss: 14.4002, Validation RMSE: 3.7948, Valid PR: 0.7161\n",
      "Epoch [33/500], Train Loss: 22.6643, Train RMSE: 4.7607\n",
      "Epoch [33/500], Validation Loss: 14.1679, Validation RMSE: 3.7640, Valid PR: 0.7159\n",
      "Epoch [34/500], Train Loss: 21.6974, Train RMSE: 4.6581\n",
      "Epoch [34/500], Validation Loss: 13.7762, Validation RMSE: 3.7116, Valid PR: 0.7187\n",
      "Epoch [35/500], Train Loss: 21.3466, Train RMSE: 4.6202\n",
      "Epoch [35/500], Validation Loss: 13.4259, Validation RMSE: 3.6641, Valid PR: 0.7180\n",
      "Epoch [36/500], Train Loss: 21.2700, Train RMSE: 4.6119\n",
      "Epoch [36/500], Validation Loss: 13.1861, Validation RMSE: 3.6313, Valid PR: 0.7129\n",
      "Epoch [37/500], Train Loss: 20.5210, Train RMSE: 4.5300\n",
      "Epoch [37/500], Validation Loss: 13.0670, Validation RMSE: 3.6148, Valid PR: 0.7058\n",
      "Epoch [38/500], Train Loss: 20.2975, Train RMSE: 4.5053\n",
      "Epoch [38/500], Validation Loss: 12.8675, Validation RMSE: 3.5871, Valid PR: 0.6998\n",
      "Epoch [39/500], Train Loss: 20.1938, Train RMSE: 4.4938\n",
      "Epoch [39/500], Validation Loss: 12.6164, Validation RMSE: 3.5520, Valid PR: 0.6932\n",
      "Epoch [40/500], Train Loss: 19.1608, Train RMSE: 4.3773\n",
      "Epoch [40/500], Validation Loss: 12.4869, Validation RMSE: 3.5337, Valid PR: 0.6882\n",
      "Epoch [41/500], Train Loss: 18.8007, Train RMSE: 4.3360\n",
      "Epoch [41/500], Validation Loss: 12.3443, Validation RMSE: 3.5135, Valid PR: 0.6814\n",
      "Epoch [42/500], Train Loss: 17.7108, Train RMSE: 4.2084\n",
      "Epoch [42/500], Validation Loss: 12.2106, Validation RMSE: 3.4944, Valid PR: 0.6753\n",
      "Epoch [43/500], Train Loss: 18.0644, Train RMSE: 4.2502\n",
      "Epoch [43/500], Validation Loss: 12.0949, Validation RMSE: 3.4778, Valid PR: 0.6725\n",
      "Epoch [44/500], Train Loss: 17.0252, Train RMSE: 4.1262\n",
      "Epoch [44/500], Validation Loss: 11.9607, Validation RMSE: 3.4584, Valid PR: 0.6675\n",
      "Epoch [45/500], Train Loss: 17.2800, Train RMSE: 4.1569\n",
      "Epoch [45/500], Validation Loss: 11.8296, Validation RMSE: 3.4394, Valid PR: 0.6608\n",
      "Epoch [46/500], Train Loss: 15.9908, Train RMSE: 3.9989\n",
      "Epoch [46/500], Validation Loss: 11.6311, Validation RMSE: 3.4104, Valid PR: 0.6530\n",
      "Epoch [47/500], Train Loss: 15.8498, Train RMSE: 3.9812\n",
      "Epoch [47/500], Validation Loss: 11.4840, Validation RMSE: 3.3888, Valid PR: 0.6450\n",
      "Epoch [48/500], Train Loss: 16.1511, Train RMSE: 4.0188\n",
      "Epoch [48/500], Validation Loss: 11.4926, Validation RMSE: 3.3901, Valid PR: 0.6327\n",
      "Epoch [49/500], Train Loss: 16.2998, Train RMSE: 4.0373\n",
      "Epoch [49/500], Validation Loss: 11.4382, Validation RMSE: 3.3820, Valid PR: 0.6230\n",
      "Epoch [50/500], Train Loss: 14.9641, Train RMSE: 3.8683\n",
      "Epoch [50/500], Validation Loss: 11.2557, Validation RMSE: 3.3549, Valid PR: 0.6162\n",
      "Epoch [51/500], Train Loss: 14.1618, Train RMSE: 3.7632\n",
      "Epoch [51/500], Validation Loss: 11.2358, Validation RMSE: 3.3520, Valid PR: 0.6053\n",
      "Epoch [52/500], Train Loss: 13.8656, Train RMSE: 3.7237\n",
      "Epoch [52/500], Validation Loss: 11.2109, Validation RMSE: 3.3483, Valid PR: 0.5957\n",
      "Epoch [53/500], Train Loss: 13.3576, Train RMSE: 3.6548\n",
      "Epoch [53/500], Validation Loss: 11.2222, Validation RMSE: 3.3500, Valid PR: 0.5847\n",
      "Epoch [54/500], Train Loss: 13.7953, Train RMSE: 3.7142\n",
      "Epoch [54/500], Validation Loss: 11.0747, Validation RMSE: 3.3279, Valid PR: 0.5784\n",
      "Epoch [55/500], Train Loss: 13.7375, Train RMSE: 3.7064\n",
      "Epoch [55/500], Validation Loss: 10.9673, Validation RMSE: 3.3117, Valid PR: 0.5731\n",
      "Epoch [56/500], Train Loss: 12.8636, Train RMSE: 3.5866\n",
      "Epoch [56/500], Validation Loss: 10.8737, Validation RMSE: 3.2975, Valid PR: 0.5679\n",
      "Epoch [57/500], Train Loss: 12.4181, Train RMSE: 3.5239\n",
      "Epoch [57/500], Validation Loss: 10.8216, Validation RMSE: 3.2896, Valid PR: 0.5607\n",
      "Epoch [58/500], Train Loss: 12.1812, Train RMSE: 3.4902\n",
      "Epoch [58/500], Validation Loss: 10.6946, Validation RMSE: 3.2703, Valid PR: 0.5604\n",
      "Epoch [59/500], Train Loss: 10.8904, Train RMSE: 3.3001\n",
      "Epoch [59/500], Validation Loss: 10.4376, Validation RMSE: 3.2307, Valid PR: 0.5633\n",
      "Epoch [60/500], Train Loss: 10.6158, Train RMSE: 3.2582\n",
      "Epoch [60/500], Validation Loss: 10.1423, Validation RMSE: 3.1847, Valid PR: 0.5639\n",
      "Epoch [61/500], Train Loss: 10.8215, Train RMSE: 3.2896\n",
      "Epoch [61/500], Validation Loss: 9.8915, Validation RMSE: 3.1451, Valid PR: 0.5631\n",
      "Epoch [62/500], Train Loss: 10.7306, Train RMSE: 3.2758\n",
      "Epoch [62/500], Validation Loss: 9.5912, Validation RMSE: 3.0970, Valid PR: 0.5671\n",
      "Epoch [63/500], Train Loss: 10.4489, Train RMSE: 3.2325\n",
      "Epoch [63/500], Validation Loss: 9.4772, Validation RMSE: 3.0785, Valid PR: 0.5629\n",
      "Epoch [64/500], Train Loss: 9.5563, Train RMSE: 3.0913\n",
      "Epoch [64/500], Validation Loss: 9.2419, Validation RMSE: 3.0400, Valid PR: 0.5677\n",
      "Epoch [65/500], Train Loss: 9.5385, Train RMSE: 3.0884\n",
      "Epoch [65/500], Validation Loss: 8.9976, Validation RMSE: 2.9996, Valid PR: 0.5724\n",
      "Epoch [66/500], Train Loss: 9.4114, Train RMSE: 3.0678\n",
      "Epoch [66/500], Validation Loss: 8.7598, Validation RMSE: 2.9597, Valid PR: 0.5736\n",
      "Epoch [67/500], Train Loss: 8.2113, Train RMSE: 2.8655\n",
      "Epoch [67/500], Validation Loss: 8.5746, Validation RMSE: 2.9282, Valid PR: 0.5721\n",
      "Epoch [68/500], Train Loss: 8.7117, Train RMSE: 2.9516\n",
      "Epoch [68/500], Validation Loss: 8.4557, Validation RMSE: 2.9079, Valid PR: 0.5644\n",
      "Epoch [69/500], Train Loss: 8.1876, Train RMSE: 2.8614\n",
      "Epoch [69/500], Validation Loss: 8.2311, Validation RMSE: 2.8690, Valid PR: 0.5580\n",
      "Epoch [70/500], Train Loss: 7.9935, Train RMSE: 2.8273\n",
      "Epoch [70/500], Validation Loss: 8.0566, Validation RMSE: 2.8384, Valid PR: 0.5495\n",
      "Epoch [71/500], Train Loss: 7.3775, Train RMSE: 2.7162\n",
      "Epoch [71/500], Validation Loss: 7.8457, Validation RMSE: 2.8010, Valid PR: 0.5413\n",
      "Epoch [72/500], Train Loss: 7.7708, Train RMSE: 2.7876\n",
      "Epoch [72/500], Validation Loss: 7.6905, Validation RMSE: 2.7732, Valid PR: 0.5320\n",
      "Epoch [73/500], Train Loss: 7.2916, Train RMSE: 2.7003\n",
      "Epoch [73/500], Validation Loss: 7.5151, Validation RMSE: 2.7414, Valid PR: 0.5181\n",
      "Epoch [74/500], Train Loss: 7.6137, Train RMSE: 2.7593\n",
      "Epoch [74/500], Validation Loss: 7.3130, Validation RMSE: 2.7043, Valid PR: 0.5114\n",
      "Epoch [75/500], Train Loss: 6.8460, Train RMSE: 2.6165\n",
      "Epoch [75/500], Validation Loss: 7.0971, Validation RMSE: 2.6640, Valid PR: 0.5010\n",
      "Epoch [76/500], Train Loss: 6.0525, Train RMSE: 2.4602\n",
      "Epoch [76/500], Validation Loss: 6.9427, Validation RMSE: 2.6349, Valid PR: 0.4902\n",
      "Epoch [77/500], Train Loss: 5.6796, Train RMSE: 2.3832\n",
      "Epoch [77/500], Validation Loss: 6.7284, Validation RMSE: 2.5939, Valid PR: 0.4804\n",
      "Epoch [78/500], Train Loss: 5.9340, Train RMSE: 2.4360\n",
      "Epoch [78/500], Validation Loss: 6.5537, Validation RMSE: 2.5600, Valid PR: 0.4718\n",
      "Epoch [79/500], Train Loss: 6.1898, Train RMSE: 2.4879\n",
      "Epoch [79/500], Validation Loss: 6.3510, Validation RMSE: 2.5201, Valid PR: 0.4643\n",
      "Epoch [80/500], Train Loss: 5.1583, Train RMSE: 2.2712\n",
      "Epoch [80/500], Validation Loss: 6.1506, Validation RMSE: 2.4800, Valid PR: 0.4617\n",
      "Epoch [81/500], Train Loss: 5.5258, Train RMSE: 2.3507\n",
      "Epoch [81/500], Validation Loss: 5.9918, Validation RMSE: 2.4478, Valid PR: 0.4557\n",
      "Epoch [82/500], Train Loss: 5.2910, Train RMSE: 2.3002\n",
      "Epoch [82/500], Validation Loss: 5.7714, Validation RMSE: 2.4024, Valid PR: 0.4590\n",
      "Epoch [83/500], Train Loss: 5.5338, Train RMSE: 2.3524\n",
      "Epoch [83/500], Validation Loss: 5.5630, Validation RMSE: 2.3586, Valid PR: 0.4561\n",
      "Epoch [84/500], Train Loss: 4.2923, Train RMSE: 2.0718\n",
      "Epoch [84/500], Validation Loss: 5.3491, Validation RMSE: 2.3128, Valid PR: 0.4551\n",
      "Epoch [85/500], Train Loss: 4.6289, Train RMSE: 2.1515\n",
      "Epoch [85/500], Validation Loss: 5.1723, Validation RMSE: 2.2743, Valid PR: 0.4519\n",
      "Epoch [86/500], Train Loss: 4.0284, Train RMSE: 2.0071\n",
      "Epoch [86/500], Validation Loss: 5.0138, Validation RMSE: 2.2391, Valid PR: 0.4462\n",
      "Epoch [87/500], Train Loss: 4.2797, Train RMSE: 2.0687\n",
      "Epoch [87/500], Validation Loss: 4.8615, Validation RMSE: 2.2049, Valid PR: 0.4435\n",
      "Epoch [88/500], Train Loss: 3.8002, Train RMSE: 1.9494\n",
      "Epoch [88/500], Validation Loss: 4.7118, Validation RMSE: 2.1707, Valid PR: 0.4384\n",
      "Epoch [89/500], Train Loss: 4.1881, Train RMSE: 2.0465\n",
      "Epoch [89/500], Validation Loss: 4.6007, Validation RMSE: 2.1449, Valid PR: 0.4304\n",
      "Epoch [90/500], Train Loss: 3.2979, Train RMSE: 1.8160\n",
      "Epoch [90/500], Validation Loss: 4.5180, Validation RMSE: 2.1256, Valid PR: 0.4266\n",
      "Epoch [91/500], Train Loss: 3.1949, Train RMSE: 1.7874\n",
      "Epoch [91/500], Validation Loss: 4.5144, Validation RMSE: 2.1247, Valid PR: 0.4178\n",
      "Epoch [92/500], Train Loss: 3.2596, Train RMSE: 1.8054\n",
      "Epoch [92/500], Validation Loss: 4.5026, Validation RMSE: 2.1219, Valid PR: 0.4089\n",
      "Epoch [93/500], Train Loss: 3.3935, Train RMSE: 1.8421\n",
      "Epoch [93/500], Validation Loss: 4.5161, Validation RMSE: 2.1251, Valid PR: 0.3976\n",
      "Epoch [94/500], Train Loss: 2.7131, Train RMSE: 1.6472\n",
      "Epoch [94/500], Validation Loss: 4.5318, Validation RMSE: 2.1288, Valid PR: 0.3849\n",
      "Epoch [95/500], Train Loss: 3.0248, Train RMSE: 1.7392\n",
      "Epoch [95/500], Validation Loss: 4.5527, Validation RMSE: 2.1337, Valid PR: 0.3703\n",
      "Epoch [96/500], Train Loss: 3.1877, Train RMSE: 1.7854\n",
      "Epoch [96/500], Validation Loss: 4.4673, Validation RMSE: 2.1136, Valid PR: 0.3606\n",
      "Epoch [97/500], Train Loss: 2.6136, Train RMSE: 1.6167\n",
      "Epoch [97/500], Validation Loss: 4.3879, Validation RMSE: 2.0947, Valid PR: 0.3550\n",
      "Epoch [98/500], Train Loss: 2.6778, Train RMSE: 1.6364\n",
      "Epoch [98/500], Validation Loss: 4.3528, Validation RMSE: 2.0863, Valid PR: 0.3484\n",
      "Epoch [99/500], Train Loss: 2.6383, Train RMSE: 1.6243\n",
      "Epoch [99/500], Validation Loss: 4.2572, Validation RMSE: 2.0633, Valid PR: 0.3492\n",
      "Epoch [100/500], Train Loss: 2.7279, Train RMSE: 1.6516\n",
      "Epoch [100/500], Validation Loss: 4.1599, Validation RMSE: 2.0396, Valid PR: 0.3509\n",
      "Epoch [101/500], Train Loss: 2.4081, Train RMSE: 1.5518\n",
      "Epoch [101/500], Validation Loss: 4.1285, Validation RMSE: 2.0319, Valid PR: 0.3495\n",
      "Epoch [102/500], Train Loss: 3.2011, Train RMSE: 1.7892\n",
      "Epoch [102/500], Validation Loss: 3.9834, Validation RMSE: 1.9959, Valid PR: 0.3668\n",
      "Epoch [103/500], Train Loss: 2.3275, Train RMSE: 1.5256\n",
      "Epoch [103/500], Validation Loss: 3.8994, Validation RMSE: 1.9747, Valid PR: 0.3840\n",
      "Epoch [104/500], Train Loss: 2.6059, Train RMSE: 1.6143\n",
      "Epoch [104/500], Validation Loss: 3.8440, Validation RMSE: 1.9606, Valid PR: 0.3912\n",
      "Epoch [105/500], Train Loss: 2.0741, Train RMSE: 1.4402\n",
      "Epoch [105/500], Validation Loss: 3.7119, Validation RMSE: 1.9266, Valid PR: 0.4042\n",
      "Epoch [106/500], Train Loss: 2.3940, Train RMSE: 1.5473\n",
      "Epoch [106/500], Validation Loss: 3.6655, Validation RMSE: 1.9145, Valid PR: 0.4103\n",
      "Epoch [107/500], Train Loss: 2.7571, Train RMSE: 1.6605\n",
      "Epoch [107/500], Validation Loss: 3.6371, Validation RMSE: 1.9071, Valid PR: 0.4118\n",
      "Epoch [108/500], Train Loss: 2.2450, Train RMSE: 1.4983\n",
      "Epoch [108/500], Validation Loss: 3.5770, Validation RMSE: 1.8913, Valid PR: 0.4167\n",
      "Epoch [109/500], Train Loss: 1.9026, Train RMSE: 1.3793\n",
      "Epoch [109/500], Validation Loss: 3.5644, Validation RMSE: 1.8880, Valid PR: 0.4122\n",
      "Epoch [110/500], Train Loss: 2.2823, Train RMSE: 1.5107\n",
      "Epoch [110/500], Validation Loss: 3.5392, Validation RMSE: 1.8813, Valid PR: 0.4054\n",
      "Epoch [111/500], Train Loss: 1.5573, Train RMSE: 1.2479\n",
      "Epoch [111/500], Validation Loss: 3.5501, Validation RMSE: 1.8842, Valid PR: 0.3875\n",
      "Epoch [112/500], Train Loss: 2.5696, Train RMSE: 1.6030\n",
      "Epoch [112/500], Validation Loss: 3.5363, Validation RMSE: 1.8805, Valid PR: 0.3694\n",
      "Epoch [113/500], Train Loss: 2.3287, Train RMSE: 1.5260\n",
      "Epoch [113/500], Validation Loss: 3.5117, Validation RMSE: 1.8740, Valid PR: 0.3565\n",
      "Epoch [114/500], Train Loss: 1.7728, Train RMSE: 1.3315\n",
      "Epoch [114/500], Validation Loss: 3.4773, Validation RMSE: 1.8648, Valid PR: 0.3459\n",
      "Epoch [115/500], Train Loss: 2.3357, Train RMSE: 1.5283\n",
      "Epoch [115/500], Validation Loss: 3.4718, Validation RMSE: 1.8633, Valid PR: 0.3256\n",
      "Epoch [116/500], Train Loss: 2.2588, Train RMSE: 1.5029\n",
      "Epoch [116/500], Validation Loss: 3.3734, Validation RMSE: 1.8367, Valid PR: 0.3271\n",
      "Epoch [117/500], Train Loss: 2.3835, Train RMSE: 1.5439\n",
      "Epoch [117/500], Validation Loss: 3.2404, Validation RMSE: 1.8001, Valid PR: 0.3450\n",
      "Epoch [118/500], Train Loss: 2.3873, Train RMSE: 1.5451\n",
      "Epoch [118/500], Validation Loss: 3.1978, Validation RMSE: 1.7882, Valid PR: 0.3402\n",
      "Epoch [119/500], Train Loss: 2.1797, Train RMSE: 1.4764\n",
      "Epoch [119/500], Validation Loss: 3.0694, Validation RMSE: 1.7520, Valid PR: 0.3592\n",
      "Epoch [120/500], Train Loss: 1.9416, Train RMSE: 1.3934\n",
      "Epoch [120/500], Validation Loss: 2.9570, Validation RMSE: 1.7196, Valid PR: 0.3781\n",
      "Epoch [121/500], Train Loss: 2.1248, Train RMSE: 1.4577\n",
      "Epoch [121/500], Validation Loss: 2.8314, Validation RMSE: 1.6827, Valid PR: 0.4030\n",
      "Epoch [122/500], Train Loss: 1.9580, Train RMSE: 1.3993\n",
      "Epoch [122/500], Validation Loss: 2.6981, Validation RMSE: 1.6426, Valid PR: 0.4323\n",
      "Epoch [123/500], Train Loss: 2.2929, Train RMSE: 1.5142\n",
      "Epoch [123/500], Validation Loss: 2.5574, Validation RMSE: 1.5992, Valid PR: 0.4620\n",
      "Epoch [124/500], Train Loss: 2.1938, Train RMSE: 1.4812\n",
      "Epoch [124/500], Validation Loss: 2.4792, Validation RMSE: 1.5745, Valid PR: 0.4847\n",
      "Epoch [125/500], Train Loss: 2.0368, Train RMSE: 1.4272\n",
      "Epoch [125/500], Validation Loss: 2.3794, Validation RMSE: 1.5425, Valid PR: 0.5032\n",
      "Epoch [126/500], Train Loss: 1.6346, Train RMSE: 1.2785\n",
      "Epoch [126/500], Validation Loss: 2.2653, Validation RMSE: 1.5051, Valid PR: 0.5199\n",
      "Epoch [127/500], Train Loss: 2.6280, Train RMSE: 1.6211\n",
      "Epoch [127/500], Validation Loss: 2.1598, Validation RMSE: 1.4696, Valid PR: 0.5353\n",
      "Epoch [128/500], Train Loss: 1.8879, Train RMSE: 1.3740\n",
      "Epoch [128/500], Validation Loss: 2.0898, Validation RMSE: 1.4456, Valid PR: 0.5420\n",
      "Epoch [129/500], Train Loss: 2.2667, Train RMSE: 1.5056\n",
      "Epoch [129/500], Validation Loss: 2.0313, Validation RMSE: 1.4252, Valid PR: 0.5440\n",
      "Epoch [130/500], Train Loss: 1.7729, Train RMSE: 1.3315\n",
      "Epoch [130/500], Validation Loss: 1.9677, Validation RMSE: 1.4028, Valid PR: 0.5490\n",
      "Epoch [131/500], Train Loss: 2.3391, Train RMSE: 1.5294\n",
      "Epoch [131/500], Validation Loss: 1.9359, Validation RMSE: 1.3914, Valid PR: 0.5476\n",
      "Epoch [132/500], Train Loss: 2.0520, Train RMSE: 1.4325\n",
      "Epoch [132/500], Validation Loss: 1.9276, Validation RMSE: 1.3884, Valid PR: 0.5426\n",
      "Epoch [133/500], Train Loss: 1.7703, Train RMSE: 1.3305\n",
      "Epoch [133/500], Validation Loss: 1.9258, Validation RMSE: 1.3877, Valid PR: 0.5342\n",
      "Epoch [134/500], Train Loss: 2.2677, Train RMSE: 1.5059\n",
      "Epoch [134/500], Validation Loss: 1.9380, Validation RMSE: 1.3921, Valid PR: 0.5231\n",
      "Epoch [135/500], Train Loss: 1.2524, Train RMSE: 1.1191\n",
      "Epoch [135/500], Validation Loss: 1.9956, Validation RMSE: 1.4127, Valid PR: 0.5021\n",
      "Epoch [136/500], Train Loss: 1.8514, Train RMSE: 1.3607\n",
      "Epoch [136/500], Validation Loss: 2.0634, Validation RMSE: 1.4365, Valid PR: 0.4806\n",
      "Epoch [137/500], Train Loss: 2.3696, Train RMSE: 1.5393\n",
      "Epoch [137/500], Validation Loss: 2.1188, Validation RMSE: 1.4556, Valid PR: 0.4668\n",
      "Epoch [138/500], Train Loss: 2.3491, Train RMSE: 1.5327\n",
      "Epoch [138/500], Validation Loss: 2.1969, Validation RMSE: 1.4822, Valid PR: 0.4483\n",
      "Epoch [139/500], Train Loss: 2.2373, Train RMSE: 1.4958\n",
      "Epoch [139/500], Validation Loss: 2.1988, Validation RMSE: 1.4828, Valid PR: 0.4445\n",
      "Epoch [140/500], Train Loss: 2.0885, Train RMSE: 1.4452\n",
      "Epoch [140/500], Validation Loss: 2.1130, Validation RMSE: 1.4536, Valid PR: 0.4598\n",
      "Epoch [141/500], Train Loss: 2.0186, Train RMSE: 1.4208\n",
      "Epoch [141/500], Validation Loss: 2.0331, Validation RMSE: 1.4259, Valid PR: 0.4739\n",
      "Epoch [142/500], Train Loss: 2.1057, Train RMSE: 1.4511\n",
      "Epoch [142/500], Validation Loss: 1.9880, Validation RMSE: 1.4100, Valid PR: 0.4896\n",
      "Epoch [143/500], Train Loss: 2.3246, Train RMSE: 1.5247\n",
      "Epoch [143/500], Validation Loss: 1.9619, Validation RMSE: 1.4007, Valid PR: 0.5013\n",
      "Early stopping triggered.\n",
      "Test Loss: 6.5182, Test RMSE: 2.5531, Test PR: -0.0836\n",
      "Testing method2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/1961612305.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/scratch/local/51712327/ipykernel_500297/1961612305.py:260: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_summary = pd.concat([metrics_summary, pd.DataFrame([{\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/1961612305.py:111: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 40.8831, Train RMSE: 6.3940\n",
      "Epoch [1/500], Validation Loss: 171.3224, Validation RMSE: 13.0890, Valid PR: -0.3450\n",
      "Epoch [2/500], Train Loss: 40.8246, Train RMSE: 6.3894\n",
      "Epoch [2/500], Validation Loss: 59.4096, Validation RMSE: 7.7078, Valid PR: -0.2351\n",
      "Epoch [3/500], Train Loss: 39.8143, Train RMSE: 6.3099\n",
      "Epoch [3/500], Validation Loss: 49.6483, Validation RMSE: 7.0462, Valid PR: -0.4466\n",
      "Epoch [4/500], Train Loss: 38.0747, Train RMSE: 6.1705\n",
      "Epoch [4/500], Validation Loss: 47.5816, Validation RMSE: 6.8979, Valid PR: -0.4675\n",
      "Epoch [5/500], Train Loss: 38.4693, Train RMSE: 6.2024\n",
      "Epoch [5/500], Validation Loss: 48.0030, Validation RMSE: 6.9284, Valid PR: -0.4439\n",
      "Epoch [6/500], Train Loss: 36.2706, Train RMSE: 6.0225\n",
      "Epoch [6/500], Validation Loss: 47.2899, Validation RMSE: 6.8768, Valid PR: -0.4304\n",
      "Epoch [7/500], Train Loss: 35.6352, Train RMSE: 5.9695\n",
      "Epoch [7/500], Validation Loss: 46.4422, Validation RMSE: 6.8149, Valid PR: -0.4188\n",
      "Epoch [8/500], Train Loss: 35.5483, Train RMSE: 5.9622\n",
      "Epoch [8/500], Validation Loss: 44.7004, Validation RMSE: 6.6858, Valid PR: -0.4117\n",
      "Epoch [9/500], Train Loss: 34.9853, Train RMSE: 5.9148\n",
      "Epoch [9/500], Validation Loss: 42.3203, Validation RMSE: 6.5054, Valid PR: -0.4094\n",
      "Epoch [10/500], Train Loss: 33.6750, Train RMSE: 5.8030\n",
      "Epoch [10/500], Validation Loss: 39.5416, Validation RMSE: 6.2882, Valid PR: -0.3691\n",
      "Epoch [11/500], Train Loss: 32.9447, Train RMSE: 5.7397\n",
      "Epoch [11/500], Validation Loss: 37.6790, Validation RMSE: 6.1383, Valid PR: -0.2939\n",
      "Epoch [12/500], Train Loss: 31.3065, Train RMSE: 5.5952\n",
      "Epoch [12/500], Validation Loss: 35.9690, Validation RMSE: 5.9974, Valid PR: -0.1988\n",
      "Epoch [13/500], Train Loss: 32.0621, Train RMSE: 5.6623\n",
      "Epoch [13/500], Validation Loss: 34.9581, Validation RMSE: 5.9125, Valid PR: -0.1588\n",
      "Epoch [14/500], Train Loss: 31.1023, Train RMSE: 5.5769\n",
      "Epoch [14/500], Validation Loss: 34.5503, Validation RMSE: 5.8780, Valid PR: -0.1573\n",
      "Epoch [15/500], Train Loss: 30.9159, Train RMSE: 5.5602\n",
      "Epoch [15/500], Validation Loss: 34.4947, Validation RMSE: 5.8732, Valid PR: -0.1668\n",
      "Epoch [16/500], Train Loss: 29.9867, Train RMSE: 5.4760\n",
      "Epoch [16/500], Validation Loss: 33.7269, Validation RMSE: 5.8075, Valid PR: -0.1290\n",
      "Epoch [17/500], Train Loss: 29.9042, Train RMSE: 5.4685\n",
      "Epoch [17/500], Validation Loss: 32.4797, Validation RMSE: 5.6991, Valid PR: -0.0393\n",
      "Epoch [18/500], Train Loss: 29.7934, Train RMSE: 5.4583\n",
      "Epoch [18/500], Validation Loss: 31.0369, Validation RMSE: 5.5711, Valid PR: 0.0897\n",
      "Epoch [19/500], Train Loss: 28.6308, Train RMSE: 5.3508\n",
      "Epoch [19/500], Validation Loss: 29.6496, Validation RMSE: 5.4451, Valid PR: 0.2558\n",
      "Epoch [20/500], Train Loss: 28.0095, Train RMSE: 5.2924\n",
      "Epoch [20/500], Validation Loss: 27.8992, Validation RMSE: 5.2820, Valid PR: 0.5580\n",
      "Epoch [21/500], Train Loss: 27.0975, Train RMSE: 5.2055\n",
      "Epoch [21/500], Validation Loss: 26.3129, Validation RMSE: 5.1296, Valid PR: 0.7259\n",
      "Epoch [22/500], Train Loss: 27.0520, Train RMSE: 5.2012\n",
      "Epoch [22/500], Validation Loss: 25.0876, Validation RMSE: 5.0087, Valid PR: 0.7883\n",
      "Epoch [23/500], Train Loss: 27.1063, Train RMSE: 5.2064\n",
      "Epoch [23/500], Validation Loss: 24.0135, Validation RMSE: 4.9004, Valid PR: 0.7912\n",
      "Epoch [24/500], Train Loss: 26.3881, Train RMSE: 5.1369\n",
      "Epoch [24/500], Validation Loss: 23.3100, Validation RMSE: 4.8280, Valid PR: 0.7676\n",
      "Epoch [25/500], Train Loss: 25.8783, Train RMSE: 5.0871\n",
      "Epoch [25/500], Validation Loss: 22.6601, Validation RMSE: 4.7603, Valid PR: 0.7548\n",
      "Epoch [26/500], Train Loss: 25.2387, Train RMSE: 5.0238\n",
      "Epoch [26/500], Validation Loss: 21.9619, Validation RMSE: 4.6863, Valid PR: 0.7425\n",
      "Epoch [27/500], Train Loss: 25.0232, Train RMSE: 5.0023\n",
      "Epoch [27/500], Validation Loss: 21.3068, Validation RMSE: 4.6159, Valid PR: 0.7432\n",
      "Epoch [28/500], Train Loss: 24.4366, Train RMSE: 4.9433\n",
      "Epoch [28/500], Validation Loss: 20.3908, Validation RMSE: 4.5156, Valid PR: 0.7439\n",
      "Epoch [29/500], Train Loss: 24.4740, Train RMSE: 4.9471\n",
      "Epoch [29/500], Validation Loss: 19.6705, Validation RMSE: 4.4351, Valid PR: 0.7458\n",
      "Epoch [30/500], Train Loss: 23.3808, Train RMSE: 4.8354\n",
      "Epoch [30/500], Validation Loss: 19.0073, Validation RMSE: 4.3597, Valid PR: 0.7503\n",
      "Epoch [31/500], Train Loss: 22.7787, Train RMSE: 4.7727\n",
      "Epoch [31/500], Validation Loss: 18.5677, Validation RMSE: 4.3090, Valid PR: 0.7584\n",
      "Epoch [32/500], Train Loss: 22.4599, Train RMSE: 4.7392\n",
      "Epoch [32/500], Validation Loss: 18.2523, Validation RMSE: 4.2723, Valid PR: 0.7642\n",
      "Epoch [33/500], Train Loss: 22.7189, Train RMSE: 4.7664\n",
      "Epoch [33/500], Validation Loss: 17.8991, Validation RMSE: 4.2307, Valid PR: 0.7693\n",
      "Epoch [34/500], Train Loss: 22.0147, Train RMSE: 4.6920\n",
      "Epoch [34/500], Validation Loss: 17.6030, Validation RMSE: 4.1956, Valid PR: 0.7796\n",
      "Epoch [35/500], Train Loss: 21.2674, Train RMSE: 4.6117\n",
      "Epoch [35/500], Validation Loss: 17.2151, Validation RMSE: 4.1491, Valid PR: 0.7855\n",
      "Epoch [36/500], Train Loss: 21.4570, Train RMSE: 4.6322\n",
      "Epoch [36/500], Validation Loss: 16.7993, Validation RMSE: 4.0987, Valid PR: 0.7843\n",
      "Epoch [37/500], Train Loss: 21.2946, Train RMSE: 4.6146\n",
      "Epoch [37/500], Validation Loss: 16.4069, Validation RMSE: 4.0505, Valid PR: 0.7756\n",
      "Epoch [38/500], Train Loss: 21.7989, Train RMSE: 4.6689\n",
      "Epoch [38/500], Validation Loss: 15.9966, Validation RMSE: 3.9996, Valid PR: 0.7651\n",
      "Epoch [39/500], Train Loss: 20.6142, Train RMSE: 4.5403\n",
      "Epoch [39/500], Validation Loss: 15.5803, Validation RMSE: 3.9472, Valid PR: 0.7566\n",
      "Epoch [40/500], Train Loss: 20.2888, Train RMSE: 4.5043\n",
      "Epoch [40/500], Validation Loss: 15.1981, Validation RMSE: 3.8985, Valid PR: 0.7514\n",
      "Epoch [41/500], Train Loss: 19.1009, Train RMSE: 4.3705\n",
      "Epoch [41/500], Validation Loss: 14.8528, Validation RMSE: 3.8539, Valid PR: 0.7451\n",
      "Epoch [42/500], Train Loss: 19.3128, Train RMSE: 4.3946\n",
      "Epoch [42/500], Validation Loss: 14.5376, Validation RMSE: 3.8128, Valid PR: 0.7442\n",
      "Epoch [43/500], Train Loss: 18.6451, Train RMSE: 4.3180\n",
      "Epoch [43/500], Validation Loss: 14.2398, Validation RMSE: 3.7736, Valid PR: 0.7433\n",
      "Epoch [44/500], Train Loss: 18.3332, Train RMSE: 4.2817\n",
      "Epoch [44/500], Validation Loss: 13.9866, Validation RMSE: 3.7399, Valid PR: 0.7444\n",
      "Epoch [45/500], Train Loss: 17.5814, Train RMSE: 4.1930\n",
      "Epoch [45/500], Validation Loss: 13.7718, Validation RMSE: 3.7110, Valid PR: 0.7438\n",
      "Epoch [46/500], Train Loss: 17.8666, Train RMSE: 4.2269\n",
      "Epoch [46/500], Validation Loss: 13.5357, Validation RMSE: 3.6791, Valid PR: 0.7432\n",
      "Epoch [47/500], Train Loss: 17.4453, Train RMSE: 4.1768\n",
      "Epoch [47/500], Validation Loss: 13.2861, Validation RMSE: 3.6450, Valid PR: 0.7439\n",
      "Epoch [48/500], Train Loss: 16.5492, Train RMSE: 4.0681\n",
      "Epoch [48/500], Validation Loss: 13.0895, Validation RMSE: 3.6179, Valid PR: 0.7506\n",
      "Epoch [49/500], Train Loss: 15.3266, Train RMSE: 3.9149\n",
      "Epoch [49/500], Validation Loss: 12.8224, Validation RMSE: 3.5808, Valid PR: 0.7511\n",
      "Epoch [50/500], Train Loss: 15.6518, Train RMSE: 3.9562\n",
      "Epoch [50/500], Validation Loss: 12.4988, Validation RMSE: 3.5354, Valid PR: 0.7488\n",
      "Epoch [51/500], Train Loss: 15.0166, Train RMSE: 3.8751\n",
      "Epoch [51/500], Validation Loss: 12.0559, Validation RMSE: 3.4722, Valid PR: 0.7459\n",
      "Epoch [52/500], Train Loss: 16.0191, Train RMSE: 4.0024\n",
      "Epoch [52/500], Validation Loss: 11.7107, Validation RMSE: 3.4221, Valid PR: 0.7455\n",
      "Epoch [53/500], Train Loss: 15.2045, Train RMSE: 3.8993\n",
      "Epoch [53/500], Validation Loss: 11.3068, Validation RMSE: 3.3626, Valid PR: 0.7450\n",
      "Epoch [54/500], Train Loss: 14.9291, Train RMSE: 3.8638\n",
      "Epoch [54/500], Validation Loss: 11.0397, Validation RMSE: 3.3226, Valid PR: 0.7473\n",
      "Epoch [55/500], Train Loss: 14.3502, Train RMSE: 3.7882\n",
      "Epoch [55/500], Validation Loss: 10.7550, Validation RMSE: 3.2795, Valid PR: 0.7485\n",
      "Epoch [56/500], Train Loss: 14.4232, Train RMSE: 3.7978\n",
      "Epoch [56/500], Validation Loss: 10.5141, Validation RMSE: 3.2425, Valid PR: 0.7541\n",
      "Epoch [57/500], Train Loss: 13.5618, Train RMSE: 3.6826\n",
      "Epoch [57/500], Validation Loss: 10.3534, Validation RMSE: 3.2177, Valid PR: 0.7608\n",
      "Epoch [58/500], Train Loss: 13.3012, Train RMSE: 3.6471\n",
      "Epoch [58/500], Validation Loss: 10.1243, Validation RMSE: 3.1819, Valid PR: 0.7655\n",
      "Epoch [59/500], Train Loss: 13.4557, Train RMSE: 3.6682\n",
      "Epoch [59/500], Validation Loss: 9.9461, Validation RMSE: 3.1537, Valid PR: 0.7659\n",
      "Epoch [60/500], Train Loss: 12.4139, Train RMSE: 3.5233\n",
      "Epoch [60/500], Validation Loss: 9.6460, Validation RMSE: 3.1058, Valid PR: 0.7610\n",
      "Epoch [61/500], Train Loss: 12.4297, Train RMSE: 3.5256\n",
      "Epoch [61/500], Validation Loss: 9.3774, Validation RMSE: 3.0623, Valid PR: 0.7535\n",
      "Epoch [62/500], Train Loss: 12.8900, Train RMSE: 3.5903\n",
      "Epoch [62/500], Validation Loss: 8.9760, Validation RMSE: 2.9960, Valid PR: 0.7402\n",
      "Epoch [63/500], Train Loss: 12.6671, Train RMSE: 3.5591\n",
      "Epoch [63/500], Validation Loss: 8.6671, Validation RMSE: 2.9440, Valid PR: 0.7200\n",
      "Epoch [64/500], Train Loss: 12.1104, Train RMSE: 3.4800\n",
      "Epoch [64/500], Validation Loss: 8.2904, Validation RMSE: 2.8793, Valid PR: 0.7032\n",
      "Epoch [65/500], Train Loss: 11.0406, Train RMSE: 3.3227\n",
      "Epoch [65/500], Validation Loss: 7.8996, Validation RMSE: 2.8106, Valid PR: 0.6863\n",
      "Epoch [66/500], Train Loss: 10.6138, Train RMSE: 3.2579\n",
      "Epoch [66/500], Validation Loss: 7.5532, Validation RMSE: 2.7483, Valid PR: 0.6845\n",
      "Epoch [67/500], Train Loss: 10.6196, Train RMSE: 3.2588\n",
      "Epoch [67/500], Validation Loss: 7.1746, Validation RMSE: 2.6785, Valid PR: 0.6736\n",
      "Epoch [68/500], Train Loss: 11.7265, Train RMSE: 3.4244\n",
      "Epoch [68/500], Validation Loss: 6.9494, Validation RMSE: 2.6362, Valid PR: 0.6694\n",
      "Epoch [69/500], Train Loss: 11.0440, Train RMSE: 3.3233\n",
      "Epoch [69/500], Validation Loss: 6.6916, Validation RMSE: 2.5868, Valid PR: 0.6620\n",
      "Epoch [70/500], Train Loss: 10.3564, Train RMSE: 3.2181\n",
      "Epoch [70/500], Validation Loss: 6.4676, Validation RMSE: 2.5431, Valid PR: 0.6539\n",
      "Epoch [71/500], Train Loss: 10.1346, Train RMSE: 3.1835\n",
      "Epoch [71/500], Validation Loss: 6.3371, Validation RMSE: 2.5174, Valid PR: 0.6483\n",
      "Epoch [72/500], Train Loss: 8.8442, Train RMSE: 2.9739\n",
      "Epoch [72/500], Validation Loss: 6.2348, Validation RMSE: 2.4969, Valid PR: 0.6481\n",
      "Epoch [73/500], Train Loss: 8.8361, Train RMSE: 2.9726\n",
      "Epoch [73/500], Validation Loss: 6.1586, Validation RMSE: 2.4817, Valid PR: 0.6504\n",
      "Epoch [74/500], Train Loss: 8.9622, Train RMSE: 2.9937\n",
      "Epoch [74/500], Validation Loss: 6.0403, Validation RMSE: 2.4577, Valid PR: 0.6482\n",
      "Epoch [75/500], Train Loss: 8.5109, Train RMSE: 2.9173\n",
      "Epoch [75/500], Validation Loss: 5.8573, Validation RMSE: 2.4202, Valid PR: 0.6202\n",
      "Epoch [76/500], Train Loss: 8.7181, Train RMSE: 2.9526\n",
      "Epoch [76/500], Validation Loss: 5.7150, Validation RMSE: 2.3906, Valid PR: 0.6155\n",
      "Epoch [77/500], Train Loss: 7.9807, Train RMSE: 2.8250\n",
      "Epoch [77/500], Validation Loss: 5.6618, Validation RMSE: 2.3794, Valid PR: 0.6053\n",
      "Epoch [78/500], Train Loss: 7.8568, Train RMSE: 2.8030\n",
      "Epoch [78/500], Validation Loss: 5.6198, Validation RMSE: 2.3706, Valid PR: 0.6096\n",
      "Epoch [79/500], Train Loss: 7.5044, Train RMSE: 2.7394\n",
      "Epoch [79/500], Validation Loss: 5.5336, Validation RMSE: 2.3524, Valid PR: 0.6039\n",
      "Epoch [80/500], Train Loss: 7.7753, Train RMSE: 2.7884\n",
      "Epoch [80/500], Validation Loss: 5.3891, Validation RMSE: 2.3214, Valid PR: 0.5979\n",
      "Epoch [81/500], Train Loss: 7.3483, Train RMSE: 2.7108\n",
      "Epoch [81/500], Validation Loss: 5.1621, Validation RMSE: 2.2720, Valid PR: 0.5703\n",
      "Epoch [82/500], Train Loss: 6.1711, Train RMSE: 2.4842\n",
      "Epoch [82/500], Validation Loss: 4.9528, Validation RMSE: 2.2255, Valid PR: 0.5670\n",
      "Epoch [83/500], Train Loss: 6.2866, Train RMSE: 2.5073\n",
      "Epoch [83/500], Validation Loss: 4.7700, Validation RMSE: 2.1840, Valid PR: 0.5582\n",
      "Epoch [84/500], Train Loss: 6.7944, Train RMSE: 2.6066\n",
      "Epoch [84/500], Validation Loss: 4.5234, Validation RMSE: 2.1268, Valid PR: 0.4875\n",
      "Epoch [85/500], Train Loss: 6.3208, Train RMSE: 2.5141\n",
      "Epoch [85/500], Validation Loss: 4.3954, Validation RMSE: 2.0965, Valid PR: 0.5135\n",
      "Epoch [86/500], Train Loss: 6.2883, Train RMSE: 2.5076\n",
      "Epoch [86/500], Validation Loss: 4.2168, Validation RMSE: 2.0535, Valid PR: 0.6385\n",
      "Epoch [87/500], Train Loss: 5.7401, Train RMSE: 2.3958\n",
      "Epoch [87/500], Validation Loss: 4.1994, Validation RMSE: 2.0492, Valid PR: 0.6966\n",
      "Epoch [88/500], Train Loss: 5.3163, Train RMSE: 2.3057\n",
      "Epoch [88/500], Validation Loss: 4.1606, Validation RMSE: 2.0398, Valid PR: 0.7074\n",
      "Epoch [89/500], Train Loss: 5.5602, Train RMSE: 2.3580\n",
      "Epoch [89/500], Validation Loss: 4.2897, Validation RMSE: 2.0712, Valid PR: 0.7208\n",
      "Epoch [90/500], Train Loss: 6.0199, Train RMSE: 2.4536\n",
      "Epoch [90/500], Validation Loss: 4.2531, Validation RMSE: 2.0623, Valid PR: 0.7271\n",
      "Epoch [91/500], Train Loss: 5.2854, Train RMSE: 2.2990\n",
      "Epoch [91/500], Validation Loss: 4.1500, Validation RMSE: 2.0372, Valid PR: 0.7225\n",
      "Epoch [92/500], Train Loss: 4.6720, Train RMSE: 2.1615\n",
      "Epoch [92/500], Validation Loss: 4.3838, Validation RMSE: 2.0938, Valid PR: 0.7456\n",
      "Epoch [93/500], Train Loss: 4.8175, Train RMSE: 2.1949\n",
      "Epoch [93/500], Validation Loss: 4.6177, Validation RMSE: 2.1489, Valid PR: 0.7764\n",
      "Epoch [94/500], Train Loss: 4.5566, Train RMSE: 2.1346\n",
      "Epoch [94/500], Validation Loss: 4.9128, Validation RMSE: 2.2165, Valid PR: 0.7497\n",
      "Epoch [95/500], Train Loss: 3.9379, Train RMSE: 1.9844\n",
      "Epoch [95/500], Validation Loss: 4.6360, Validation RMSE: 2.1531, Valid PR: 0.6764\n",
      "Epoch [96/500], Train Loss: 3.9947, Train RMSE: 1.9987\n",
      "Epoch [96/500], Validation Loss: 5.0541, Validation RMSE: 2.2481, Valid PR: 0.5129\n",
      "Epoch [97/500], Train Loss: 3.6785, Train RMSE: 1.9179\n",
      "Epoch [97/500], Validation Loss: 5.4892, Validation RMSE: 2.3429, Valid PR: 0.3498\n",
      "Epoch [98/500], Train Loss: 4.4941, Train RMSE: 2.1199\n",
      "Epoch [98/500], Validation Loss: 5.8643, Validation RMSE: 2.4216, Valid PR: 0.2304\n",
      "Epoch [99/500], Train Loss: 3.3200, Train RMSE: 1.8221\n",
      "Epoch [99/500], Validation Loss: 5.8232, Validation RMSE: 2.4131, Valid PR: 0.1824\n",
      "Epoch [100/500], Train Loss: 3.3134, Train RMSE: 1.8203\n",
      "Epoch [100/500], Validation Loss: 5.9749, Validation RMSE: 2.4444, Valid PR: 0.1001\n",
      "Epoch [101/500], Train Loss: 4.3504, Train RMSE: 2.0858\n",
      "Epoch [101/500], Validation Loss: 5.7731, Validation RMSE: 2.4027, Valid PR: 0.0560\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/1961612305.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 8.0697, Test RMSE: 2.8407, Test PR: 0.4184\n",
      "Testing method3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/1961612305.py:111: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 38.3125, Train RMSE: 6.1897\n",
      "Epoch [1/500], Validation Loss: 60.9750, Validation RMSE: 7.8086, Valid PR: 0.7090\n",
      "Epoch [2/500], Train Loss: 37.8201, Train RMSE: 6.1498\n",
      "Epoch [2/500], Validation Loss: 50.0074, Validation RMSE: 7.0716, Valid PR: 0.6209\n",
      "Epoch [3/500], Train Loss: 37.2656, Train RMSE: 6.1046\n",
      "Epoch [3/500], Validation Loss: 48.9294, Validation RMSE: 6.9950, Valid PR: 0.6822\n",
      "Epoch [4/500], Train Loss: 35.7026, Train RMSE: 5.9752\n",
      "Epoch [4/500], Validation Loss: 46.4708, Validation RMSE: 6.8169, Valid PR: 0.7468\n",
      "Epoch [5/500], Train Loss: 35.2868, Train RMSE: 5.9403\n",
      "Epoch [5/500], Validation Loss: 46.2620, Validation RMSE: 6.8016, Valid PR: 0.7041\n",
      "Epoch [6/500], Train Loss: 34.7832, Train RMSE: 5.8977\n",
      "Epoch [6/500], Validation Loss: 45.5637, Validation RMSE: 6.7501, Valid PR: 0.2788\n",
      "Epoch [7/500], Train Loss: 33.8981, Train RMSE: 5.8222\n",
      "Epoch [7/500], Validation Loss: 44.9575, Validation RMSE: 6.7050, Valid PR: -0.2592\n",
      "Epoch [8/500], Train Loss: 33.4446, Train RMSE: 5.7831\n",
      "Epoch [8/500], Validation Loss: 42.4353, Validation RMSE: 6.5142, Valid PR: -0.3618\n",
      "Epoch [9/500], Train Loss: 33.9396, Train RMSE: 5.8258\n",
      "Epoch [9/500], Validation Loss: 39.5778, Validation RMSE: 6.2911, Valid PR: -0.3764\n",
      "Epoch [10/500], Train Loss: 32.0951, Train RMSE: 5.6653\n",
      "Epoch [10/500], Validation Loss: 37.8382, Validation RMSE: 6.1513, Valid PR: -0.4519\n",
      "Epoch [11/500], Train Loss: 31.9608, Train RMSE: 5.6534\n",
      "Epoch [11/500], Validation Loss: 36.6127, Validation RMSE: 6.0508, Valid PR: -0.5491\n",
      "Epoch [12/500], Train Loss: 32.2410, Train RMSE: 5.6781\n",
      "Epoch [12/500], Validation Loss: 35.6047, Validation RMSE: 5.9670, Valid PR: -0.6055\n",
      "Epoch [13/500], Train Loss: 30.8043, Train RMSE: 5.5502\n",
      "Epoch [13/500], Validation Loss: 35.3222, Validation RMSE: 5.9432, Valid PR: -0.6076\n",
      "Epoch [14/500], Train Loss: 30.1892, Train RMSE: 5.4945\n",
      "Epoch [14/500], Validation Loss: 34.8487, Validation RMSE: 5.9033, Valid PR: -0.5933\n",
      "Epoch [15/500], Train Loss: 29.3807, Train RMSE: 5.4204\n",
      "Epoch [15/500], Validation Loss: 34.1766, Validation RMSE: 5.8461, Valid PR: -0.5771\n",
      "Epoch [16/500], Train Loss: 29.5050, Train RMSE: 5.4318\n",
      "Epoch [16/500], Validation Loss: 34.1384, Validation RMSE: 5.8428, Valid PR: -0.5542\n",
      "Epoch [17/500], Train Loss: 28.3342, Train RMSE: 5.3230\n",
      "Epoch [17/500], Validation Loss: 33.1010, Validation RMSE: 5.7533, Valid PR: -0.5461\n",
      "Epoch [18/500], Train Loss: 27.9277, Train RMSE: 5.2847\n",
      "Epoch [18/500], Validation Loss: 32.4476, Validation RMSE: 5.6963, Valid PR: -0.5314\n",
      "Epoch [19/500], Train Loss: 27.0821, Train RMSE: 5.2040\n",
      "Epoch [19/500], Validation Loss: 31.7365, Validation RMSE: 5.6335, Valid PR: -0.5127\n",
      "Epoch [20/500], Train Loss: 27.7868, Train RMSE: 5.2713\n",
      "Epoch [20/500], Validation Loss: 30.5470, Validation RMSE: 5.5269, Valid PR: -0.4922\n",
      "Epoch [21/500], Train Loss: 26.8114, Train RMSE: 5.1780\n",
      "Epoch [21/500], Validation Loss: 29.5370, Validation RMSE: 5.4348, Valid PR: -0.4743\n",
      "Epoch [22/500], Train Loss: 26.4221, Train RMSE: 5.1402\n",
      "Epoch [22/500], Validation Loss: 28.3768, Validation RMSE: 5.3270, Valid PR: -0.4462\n",
      "Epoch [23/500], Train Loss: 25.4893, Train RMSE: 5.0487\n",
      "Epoch [23/500], Validation Loss: 27.2230, Validation RMSE: 5.2176, Valid PR: -0.4017\n",
      "Epoch [24/500], Train Loss: 25.9280, Train RMSE: 5.0920\n",
      "Epoch [24/500], Validation Loss: 26.2381, Validation RMSE: 5.1223, Valid PR: -0.3621\n",
      "Epoch [25/500], Train Loss: 24.4877, Train RMSE: 4.9485\n",
      "Epoch [25/500], Validation Loss: 24.9810, Validation RMSE: 4.9981, Valid PR: -0.3219\n",
      "Epoch [26/500], Train Loss: 25.1969, Train RMSE: 5.0197\n",
      "Epoch [26/500], Validation Loss: 23.8620, Validation RMSE: 4.8849, Valid PR: -0.2900\n",
      "Epoch [27/500], Train Loss: 24.4698, Train RMSE: 4.9467\n",
      "Epoch [27/500], Validation Loss: 22.8238, Validation RMSE: 4.7774, Valid PR: -0.2677\n",
      "Epoch [28/500], Train Loss: 23.5747, Train RMSE: 4.8554\n",
      "Epoch [28/500], Validation Loss: 21.8551, Validation RMSE: 4.6749, Valid PR: -0.2467\n",
      "Epoch [29/500], Train Loss: 22.5272, Train RMSE: 4.7463\n",
      "Epoch [29/500], Validation Loss: 20.8889, Validation RMSE: 4.5704, Valid PR: -0.2200\n",
      "Epoch [30/500], Train Loss: 22.2611, Train RMSE: 4.7182\n",
      "Epoch [30/500], Validation Loss: 20.0651, Validation RMSE: 4.4794, Valid PR: -0.2087\n",
      "Epoch [31/500], Train Loss: 21.8499, Train RMSE: 4.6744\n",
      "Epoch [31/500], Validation Loss: 19.3025, Validation RMSE: 4.3935, Valid PR: -0.1914\n",
      "Epoch [32/500], Train Loss: 21.9683, Train RMSE: 4.6870\n",
      "Epoch [32/500], Validation Loss: 18.5265, Validation RMSE: 4.3042, Valid PR: -0.1794\n",
      "Epoch [33/500], Train Loss: 21.3350, Train RMSE: 4.6190\n",
      "Epoch [33/500], Validation Loss: 17.9180, Validation RMSE: 4.2330, Valid PR: -0.1676\n",
      "Epoch [34/500], Train Loss: 20.8350, Train RMSE: 4.5645\n",
      "Epoch [34/500], Validation Loss: 17.3343, Validation RMSE: 4.1634, Valid PR: -0.1707\n",
      "Epoch [35/500], Train Loss: 20.3351, Train RMSE: 4.5094\n",
      "Epoch [35/500], Validation Loss: 16.7931, Validation RMSE: 4.0979, Valid PR: -0.1760\n",
      "Epoch [36/500], Train Loss: 19.7366, Train RMSE: 4.4426\n",
      "Epoch [36/500], Validation Loss: 16.3374, Validation RMSE: 4.0420, Valid PR: -0.1811\n",
      "Epoch [37/500], Train Loss: 20.0332, Train RMSE: 4.4758\n",
      "Epoch [37/500], Validation Loss: 15.8394, Validation RMSE: 3.9799, Valid PR: -0.1847\n",
      "Epoch [38/500], Train Loss: 18.9984, Train RMSE: 4.3587\n",
      "Epoch [38/500], Validation Loss: 15.3432, Validation RMSE: 3.9170, Valid PR: -0.1757\n",
      "Epoch [39/500], Train Loss: 19.0687, Train RMSE: 4.3668\n",
      "Epoch [39/500], Validation Loss: 14.7603, Validation RMSE: 3.8419, Valid PR: -0.1531\n",
      "Epoch [40/500], Train Loss: 18.3635, Train RMSE: 4.2853\n",
      "Epoch [40/500], Validation Loss: 14.2720, Validation RMSE: 3.7778, Valid PR: -0.1339\n",
      "Epoch [41/500], Train Loss: 17.7536, Train RMSE: 4.2135\n",
      "Epoch [41/500], Validation Loss: 13.8297, Validation RMSE: 3.7188, Valid PR: -0.1252\n",
      "Epoch [42/500], Train Loss: 17.3870, Train RMSE: 4.1698\n",
      "Epoch [42/500], Validation Loss: 13.3595, Validation RMSE: 3.6551, Valid PR: -0.1211\n",
      "Epoch [43/500], Train Loss: 17.4462, Train RMSE: 4.1769\n",
      "Epoch [43/500], Validation Loss: 12.9511, Validation RMSE: 3.5988, Valid PR: -0.1232\n",
      "Epoch [44/500], Train Loss: 17.0125, Train RMSE: 4.1246\n",
      "Epoch [44/500], Validation Loss: 12.5043, Validation RMSE: 3.5361, Valid PR: -0.1033\n",
      "Epoch [45/500], Train Loss: 16.5085, Train RMSE: 4.0631\n",
      "Epoch [45/500], Validation Loss: 12.0649, Validation RMSE: 3.4735, Valid PR: -0.0835\n",
      "Epoch [46/500], Train Loss: 15.6738, Train RMSE: 3.9590\n",
      "Epoch [46/500], Validation Loss: 11.6728, Validation RMSE: 3.4166, Valid PR: -0.0711\n",
      "Epoch [47/500], Train Loss: 15.1331, Train RMSE: 3.8901\n",
      "Epoch [47/500], Validation Loss: 11.3563, Validation RMSE: 3.3699, Valid PR: -0.0517\n",
      "Epoch [48/500], Train Loss: 14.7133, Train RMSE: 3.8358\n",
      "Epoch [48/500], Validation Loss: 11.0350, Validation RMSE: 3.3219, Valid PR: -0.0272\n",
      "Epoch [49/500], Train Loss: 14.3649, Train RMSE: 3.7901\n",
      "Epoch [49/500], Validation Loss: 10.7222, Validation RMSE: 3.2745, Valid PR: 0.0014\n",
      "Epoch [50/500], Train Loss: 13.6552, Train RMSE: 3.6953\n",
      "Epoch [50/500], Validation Loss: 10.4278, Validation RMSE: 3.2292, Valid PR: 0.0096\n",
      "Epoch [51/500], Train Loss: 13.8304, Train RMSE: 3.7189\n",
      "Epoch [51/500], Validation Loss: 10.1336, Validation RMSE: 3.1833, Valid PR: 0.0371\n",
      "Epoch [52/500], Train Loss: 13.4411, Train RMSE: 3.6662\n",
      "Epoch [52/500], Validation Loss: 9.7887, Validation RMSE: 3.1287, Valid PR: 0.0910\n",
      "Epoch [53/500], Train Loss: 13.2526, Train RMSE: 3.6404\n",
      "Epoch [53/500], Validation Loss: 9.4181, Validation RMSE: 3.0689, Valid PR: 0.1241\n",
      "Epoch [54/500], Train Loss: 12.9548, Train RMSE: 3.5993\n",
      "Epoch [54/500], Validation Loss: 9.0004, Validation RMSE: 3.0001, Valid PR: 0.1637\n",
      "Epoch [55/500], Train Loss: 12.2900, Train RMSE: 3.5057\n",
      "Epoch [55/500], Validation Loss: 8.5319, Validation RMSE: 2.9209, Valid PR: 0.1932\n",
      "Epoch [56/500], Train Loss: 11.6516, Train RMSE: 3.4134\n",
      "Epoch [56/500], Validation Loss: 8.1336, Validation RMSE: 2.8519, Valid PR: 0.2209\n",
      "Epoch [57/500], Train Loss: 11.5209, Train RMSE: 3.3942\n",
      "Epoch [57/500], Validation Loss: 7.8054, Validation RMSE: 2.7938, Valid PR: 0.2147\n",
      "Epoch [58/500], Train Loss: 11.1690, Train RMSE: 3.3420\n",
      "Epoch [58/500], Validation Loss: 7.5453, Validation RMSE: 2.7469, Valid PR: 0.1936\n",
      "Epoch [59/500], Train Loss: 10.0791, Train RMSE: 3.1748\n",
      "Epoch [59/500], Validation Loss: 7.3200, Validation RMSE: 2.7055, Valid PR: 0.1831\n",
      "Epoch [60/500], Train Loss: 10.3706, Train RMSE: 3.2203\n",
      "Epoch [60/500], Validation Loss: 7.1942, Validation RMSE: 2.6822, Valid PR: 0.1924\n",
      "Epoch [61/500], Train Loss: 9.6410, Train RMSE: 3.1050\n",
      "Epoch [61/500], Validation Loss: 7.0321, Validation RMSE: 2.6518, Valid PR: 0.1900\n",
      "Epoch [62/500], Train Loss: 10.6324, Train RMSE: 3.2607\n",
      "Epoch [62/500], Validation Loss: 6.8815, Validation RMSE: 2.6233, Valid PR: 0.1965\n",
      "Epoch [63/500], Train Loss: 9.2275, Train RMSE: 3.0377\n",
      "Epoch [63/500], Validation Loss: 6.6863, Validation RMSE: 2.5858, Valid PR: 0.1640\n",
      "Epoch [64/500], Train Loss: 8.8050, Train RMSE: 2.9673\n",
      "Epoch [64/500], Validation Loss: 6.4573, Validation RMSE: 2.5411, Valid PR: 0.1425\n",
      "Epoch [65/500], Train Loss: 8.6442, Train RMSE: 2.9401\n",
      "Epoch [65/500], Validation Loss: 6.2940, Validation RMSE: 2.5088, Valid PR: 0.1558\n",
      "Epoch [66/500], Train Loss: 8.4150, Train RMSE: 2.9009\n",
      "Epoch [66/500], Validation Loss: 6.1979, Validation RMSE: 2.4896, Valid PR: 0.1025\n",
      "Epoch [67/500], Train Loss: 8.2813, Train RMSE: 2.8777\n",
      "Epoch [67/500], Validation Loss: 6.0012, Validation RMSE: 2.4497, Valid PR: 0.0432\n",
      "Epoch [68/500], Train Loss: 8.5389, Train RMSE: 2.9221\n",
      "Epoch [68/500], Validation Loss: 5.7538, Validation RMSE: 2.3987, Valid PR: -0.0210\n",
      "Epoch [69/500], Train Loss: 7.1794, Train RMSE: 2.6794\n",
      "Epoch [69/500], Validation Loss: 5.5580, Validation RMSE: 2.3575, Valid PR: -0.0581\n",
      "Epoch [70/500], Train Loss: 6.6981, Train RMSE: 2.5881\n",
      "Epoch [70/500], Validation Loss: 5.3708, Validation RMSE: 2.3175, Valid PR: -0.0478\n",
      "Epoch [71/500], Train Loss: 6.9388, Train RMSE: 2.6342\n",
      "Epoch [71/500], Validation Loss: 5.1207, Validation RMSE: 2.2629, Valid PR: 0.0007\n",
      "Epoch [72/500], Train Loss: 6.1265, Train RMSE: 2.4752\n",
      "Epoch [72/500], Validation Loss: 4.8355, Validation RMSE: 2.1990, Valid PR: 0.0676\n",
      "Epoch [73/500], Train Loss: 7.2928, Train RMSE: 2.7005\n",
      "Epoch [73/500], Validation Loss: 4.6600, Validation RMSE: 2.1587, Valid PR: 0.1327\n",
      "Epoch [74/500], Train Loss: 6.6092, Train RMSE: 2.5708\n",
      "Epoch [74/500], Validation Loss: 4.5494, Validation RMSE: 2.1329, Valid PR: 0.1866\n",
      "Epoch [75/500], Train Loss: 7.1160, Train RMSE: 2.6676\n",
      "Epoch [75/500], Validation Loss: 4.5199, Validation RMSE: 2.1260, Valid PR: 0.2446\n",
      "Epoch [76/500], Train Loss: 6.1763, Train RMSE: 2.4852\n",
      "Epoch [76/500], Validation Loss: 4.5914, Validation RMSE: 2.1427, Valid PR: 0.2817\n",
      "Epoch [77/500], Train Loss: 5.5916, Train RMSE: 2.3647\n",
      "Epoch [77/500], Validation Loss: 4.6957, Validation RMSE: 2.1669, Valid PR: 0.2857\n",
      "Epoch [78/500], Train Loss: 6.3688, Train RMSE: 2.5237\n",
      "Epoch [78/500], Validation Loss: 4.5529, Validation RMSE: 2.1338, Valid PR: 0.3010\n",
      "Epoch [79/500], Train Loss: 5.3608, Train RMSE: 2.3154\n",
      "Epoch [79/500], Validation Loss: 4.2127, Validation RMSE: 2.0525, Valid PR: 0.2752\n",
      "Epoch [80/500], Train Loss: 5.1706, Train RMSE: 2.2739\n",
      "Epoch [80/500], Validation Loss: 3.8476, Validation RMSE: 1.9615, Valid PR: 0.2343\n",
      "Epoch [81/500], Train Loss: 5.0143, Train RMSE: 2.2393\n",
      "Epoch [81/500], Validation Loss: 3.5486, Validation RMSE: 1.8838, Valid PR: 0.2084\n",
      "Epoch [82/500], Train Loss: 4.7600, Train RMSE: 2.1817\n",
      "Epoch [82/500], Validation Loss: 3.3518, Validation RMSE: 1.8308, Valid PR: 0.2032\n",
      "Epoch [83/500], Train Loss: 4.9588, Train RMSE: 2.2268\n",
      "Epoch [83/500], Validation Loss: 3.2835, Validation RMSE: 1.8121, Valid PR: 0.1832\n",
      "Epoch [84/500], Train Loss: 4.6691, Train RMSE: 2.1608\n",
      "Epoch [84/500], Validation Loss: 3.2274, Validation RMSE: 1.7965, Valid PR: 0.1607\n",
      "Epoch [85/500], Train Loss: 3.8234, Train RMSE: 1.9554\n",
      "Epoch [85/500], Validation Loss: 3.1986, Validation RMSE: 1.7885, Valid PR: 0.1416\n",
      "Epoch [86/500], Train Loss: 4.0751, Train RMSE: 2.0187\n",
      "Epoch [86/500], Validation Loss: 3.2320, Validation RMSE: 1.7978, Valid PR: 0.1094\n",
      "Epoch [87/500], Train Loss: 3.1828, Train RMSE: 1.7840\n",
      "Epoch [87/500], Validation Loss: 3.2085, Validation RMSE: 1.7912, Valid PR: 0.0987\n",
      "Epoch [88/500], Train Loss: 4.4944, Train RMSE: 2.1200\n",
      "Epoch [88/500], Validation Loss: 3.1493, Validation RMSE: 1.7746, Valid PR: 0.0978\n",
      "Epoch [89/500], Train Loss: 3.3131, Train RMSE: 1.8202\n",
      "Epoch [89/500], Validation Loss: 3.1678, Validation RMSE: 1.7798, Valid PR: 0.0685\n",
      "Epoch [90/500], Train Loss: 3.7551, Train RMSE: 1.9378\n",
      "Epoch [90/500], Validation Loss: 3.1334, Validation RMSE: 1.7701, Valid PR: 0.0612\n",
      "Epoch [91/500], Train Loss: 3.2706, Train RMSE: 1.8085\n",
      "Epoch [91/500], Validation Loss: 3.0202, Validation RMSE: 1.7379, Valid PR: 0.0761\n",
      "Epoch [92/500], Train Loss: 4.1264, Train RMSE: 2.0313\n",
      "Epoch [92/500], Validation Loss: 2.8941, Validation RMSE: 1.7012, Valid PR: 0.0953\n",
      "Epoch [93/500], Train Loss: 4.4874, Train RMSE: 2.1183\n",
      "Epoch [93/500], Validation Loss: 2.6831, Validation RMSE: 1.6380, Valid PR: 0.1481\n",
      "Epoch [94/500], Train Loss: 3.3970, Train RMSE: 1.8431\n",
      "Epoch [94/500], Validation Loss: 2.4785, Validation RMSE: 1.5743, Valid PR: 0.2041\n",
      "Epoch [95/500], Train Loss: 3.3593, Train RMSE: 1.8328\n",
      "Epoch [95/500], Validation Loss: 2.3685, Validation RMSE: 1.5390, Valid PR: 0.2317\n",
      "Epoch [96/500], Train Loss: 3.6111, Train RMSE: 1.9003\n",
      "Epoch [96/500], Validation Loss: 2.3234, Validation RMSE: 1.5243, Valid PR: 0.2366\n",
      "Epoch [97/500], Train Loss: 2.9736, Train RMSE: 1.7244\n",
      "Epoch [97/500], Validation Loss: 2.2378, Validation RMSE: 1.4959, Valid PR: 0.2731\n",
      "Epoch [98/500], Train Loss: 3.6695, Train RMSE: 1.9156\n",
      "Epoch [98/500], Validation Loss: 2.1817, Validation RMSE: 1.4771, Valid PR: 0.3009\n",
      "Epoch [99/500], Train Loss: 3.1118, Train RMSE: 1.7640\n",
      "Epoch [99/500], Validation Loss: 2.2544, Validation RMSE: 1.5015, Valid PR: 0.2578\n",
      "Epoch [100/500], Train Loss: 2.7417, Train RMSE: 1.6558\n",
      "Epoch [100/500], Validation Loss: 2.3970, Validation RMSE: 1.5482, Valid PR: 0.1695\n",
      "Epoch [101/500], Train Loss: 2.9986, Train RMSE: 1.7317\n",
      "Epoch [101/500], Validation Loss: 2.4301, Validation RMSE: 1.5589, Valid PR: 0.1484\n",
      "Epoch [102/500], Train Loss: 2.8426, Train RMSE: 1.6860\n",
      "Epoch [102/500], Validation Loss: 2.4696, Validation RMSE: 1.5715, Valid PR: 0.1311\n",
      "Epoch [103/500], Train Loss: 3.5023, Train RMSE: 1.8715\n",
      "Epoch [103/500], Validation Loss: 2.4834, Validation RMSE: 1.5759, Valid PR: 0.1226\n",
      "Epoch [104/500], Train Loss: 3.3691, Train RMSE: 1.8355\n",
      "Epoch [104/500], Validation Loss: 2.5168, Validation RMSE: 1.5864, Valid PR: 0.1106\n",
      "Epoch [105/500], Train Loss: 3.1921, Train RMSE: 1.7866\n",
      "Epoch [105/500], Validation Loss: 2.5839, Validation RMSE: 1.6075, Valid PR: 0.1011\n",
      "Epoch [106/500], Train Loss: 2.9833, Train RMSE: 1.7272\n",
      "Epoch [106/500], Validation Loss: 2.6699, Validation RMSE: 1.6340, Valid PR: 0.0914\n",
      "Epoch [107/500], Train Loss: 2.7738, Train RMSE: 1.6655\n",
      "Epoch [107/500], Validation Loss: 2.7283, Validation RMSE: 1.6517, Valid PR: 0.0906\n",
      "Epoch [108/500], Train Loss: 3.1398, Train RMSE: 1.7720\n",
      "Epoch [108/500], Validation Loss: 2.7876, Validation RMSE: 1.6696, Valid PR: 0.0806\n",
      "Early stopping triggered.\n",
      "Test Loss: 4.6001, Test RMSE: 2.1448, Test PR: -0.1873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/1961612305.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "# Define fully connected neural network class\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 8),\n",
    "            nn.BatchNorm1d(hidden_dim // 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 8, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Train fully connected neural network to predict labels and record metrics\n",
    "def train_fully_connected_nn(train_matrix_encodings, train_vector_encodings, y_train, val_matrix_encodings, val_vector_encodings, y_val, output_dim=768, learning_rate=3*1e-3, num_epochs=500, batch_size=256, early_stop_patience=10):\n",
    "    # Combine matrix and vector encodings\n",
    "    train_features = torch.cat((train_matrix_encodings, train_vector_encodings), dim=1)\n",
    "    val_features = torch.cat((val_matrix_encodings, val_vector_encodings), dim=1)\n",
    "    \n",
    "    # Create training and validation datasets\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_features, torch.tensor(y_train, dtype=torch.float32))\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_features, torch.tensor(y_val, dtype=torch.float32))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    input_dim = train_features.size(1)\n",
    "    hidden_dim = 256\n",
    "    output_dim = 1  # Assuming regression task\n",
    "    model = FullyConnectedNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "    criterion = nn.MSELoss() if output_dim == 1 else nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50, verbose=True)\n",
    "\n",
    "    # DataFrame to store metrics\n",
    "    metrics_df = pd.DataFrame(columns=[\"Epoch\", \"Train Loss\", \"Train RMSE\", \"Valid RMSE\", \"Valid PR\"])\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_rmse = torch.sqrt(torch.tensor(avg_train_loss)).item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(features).squeeze()\n",
    "                val_loss = criterion(outputs, labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "                val_outputs_list.append(outputs.cpu())\n",
    "                val_labels_list.append(labels.cpu())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_rmse = torch.sqrt(torch.tensor(avg_val_loss)).item()\n",
    "        val_outputs = torch.cat(val_outputs_list, dim=0)\n",
    "        val_labels = torch.cat(val_labels_list, dim=0)\n",
    "        valid_pr = torch.corrcoef(torch.stack([val_outputs, val_labels]))[0, 1].item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation RMSE: {val_rmse:.4f}, Valid PR: {valid_pr:.4f}\")\n",
    "\n",
    "        # Record metrics\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": avg_train_loss,\n",
    "            \"Train RMSE\": train_rmse,\n",
    "            \"Valid RMSE\": val_rmse,\n",
    "            \"Valid PR\": valid_pr\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "        # Learning rate decay\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stop_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    return metrics_df, best_model_state\n",
    "\n",
    "# Load and test the final model and record metrics\n",
    "def test_fully_connected_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path, batch_size=64):\n",
    "    # Combine matrix and vector encodings\n",
    "    test_features = torch.cat((test_matrix_encodings, test_vector_encodings), dim=1)\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_features, torch.tensor(y_test, dtype=torch.float32))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    input_dim = test_features.size(1)\n",
    "    hidden_dim = 256\n",
    "    output_dim = 1  # Assuming regression task\n",
    "    model = FullyConnectedNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # Define loss function\n",
    "    criterion = nn.MSELoss() if output_dim == 1 else nn.BCEWithLogitsLoss()\n",
    "    total_test_loss = 0\n",
    "    test_outputs_list = []\n",
    "    test_labels_list = []\n",
    "    \n",
    "    # Testing loop\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_test_loss += loss.item()\n",
    "            test_outputs_list.append(outputs.cpu())\n",
    "            test_labels_list.append(labels.cpu())\n",
    "    \n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_rmse = torch.sqrt(torch.tensor(avg_test_loss)).item()\n",
    "    test_outputs = torch.cat(test_outputs_list, dim=0)\n",
    "    test_labels = torch.cat(test_labels_list, dim=0)\n",
    "    test_pr = torch.corrcoef(torch.stack([test_outputs, test_labels]))[0, 1].item()\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test RMSE: {test_rmse:.4f}, Test PR: {test_pr:.4f}\")\n",
    "    \n",
    "    return test_rmse, test_pr\n",
    "\n",
    "# Refactor to test three encoding methods\n",
    "encoding_methods = [\n",
    "    \"method1\",\n",
    "    \"method2\",\n",
    "    \"method3\"\n",
    "]\n",
    "\n",
    "metrics_summary = pd.DataFrame(columns=[\"Method\", \"Train Loss\", \"Train RMSE\", \"Valid RMSE\", \"Valid PR\", \"Test RMSE\", \"Test PR\"])\n",
    "\n",
    "for method in encoding_methods:\n",
    "    print(f\"Testing {method}...\")\n",
    "    \n",
    "    # Define different get_encodings functions for each method\n",
    "    if method == \"method1\":\n",
    "        def get_encodings(model, data_loader, device):\n",
    "            matrix_encodings = []\n",
    "            vector_encodings = []\n",
    "            with torch.no_grad():\n",
    "                for matrix, vector in data_loader:\n",
    "                    matrix, vector = matrix.to(device), vector.to(device)\n",
    "                    matrix_features, vector_features = model(matrix, vector)\n",
    "                    matrix_encodings.append(matrix_features.cpu())\n",
    "                    vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "            matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "            vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "            return matrix_encodings, vector_encodings\n",
    "    elif method == \"method2\":\n",
    "        def get_encodings(model, data_loader, device):\n",
    "            matrix_encoder, vector_encoder = model.matrix_encoder, model.vector_encoder\n",
    "            matrix_encodings = []\n",
    "            vector_encodings = []\n",
    "            with torch.no_grad():\n",
    "                for matrix, vector in data_loader:\n",
    "                    matrix, vector = matrix.to(device), vector.to(device)\n",
    "                    matrix_features_encoder = model.matrix_encoder(matrix)\n",
    "                    vector_features_encoder = model.vector_encoder(vector)\n",
    "                    matrix_features, vector_features = model(matrix, vector)\n",
    "                    # Concatenate both outputs\n",
    "                    matrix_features = torch.cat((matrix_features, matrix_features_encoder), dim=-1)\n",
    "                    vector_features = torch.cat((vector_features, vector_features_encoder), dim=-1)\n",
    "                    matrix_encodings.append(matrix_features.cpu())\n",
    "                    vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "            matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "            vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "            return matrix_encodings, vector_encodings\n",
    "    elif method == \"method3\":\n",
    "        def get_encodings(model, data_loader, device):\n",
    "            matrix_encodings = []\n",
    "            vector_encodings = []\n",
    "            with torch.no_grad():\n",
    "                for matrix, vector in data_loader:\n",
    "                    matrix, vector = matrix.to(device), vector.to(device)\n",
    "                    matrix_features = model.matrix_encoder(matrix)\n",
    "                    vector_features = model.vector_encoder(vector)\n",
    "                    matrix_encodings.append(matrix_features.cpu())\n",
    "                    vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "            matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "            vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "            return matrix_encodings, vector_encodings\n",
    "    \n",
    "    # Get encodings\n",
    "    train_matrix_encodings, train_vector_encodings = get_encodings(model, train_loader, device)\n",
    "    val_matrix_encodings, val_vector_encodings = get_encodings(model, val_loader, device)\n",
    "    test_matrix_encodings, test_vector_encodings = get_encodings(model, test_loader, device)\n",
    "\n",
    "    # Train fully connected neural network to predict labels\n",
    "    metrics_df, best_model_state = train_fully_connected_nn(\n",
    "        train_matrix_encodings, train_vector_encodings, y_train,\n",
    "        val_matrix_encodings, val_vector_encodings, y_val\n",
    "    )\n",
    "\n",
    "    # Test the final model\n",
    "    torch.save(best_model_state, f\"best_finetuned_fully_connected_nn_{method}.pth\")\n",
    "    test_rmse, test_pr = test_fully_connected_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path=f\"best_finetuned_fully_connected_nn_{method}.pth\")\n",
    "\n",
    "    # Store metrics\n",
    "    final_metrics = metrics_df.iloc[-1]\n",
    "    metrics_summary = pd.concat([metrics_summary, pd.DataFrame([{\n",
    "        \"Method\": method,\n",
    "        \"Train Loss\": final_metrics[\"Train Loss\"],\n",
    "        \"Train RMSE\": final_metrics[\"Train RMSE\"],\n",
    "        \"Valid RMSE\": final_metrics[\"Valid RMSE\"],\n",
    "        \"Valid PR\": final_metrics[\"Valid PR\"],\n",
    "        \"Test RMSE\": test_rmse,\n",
    "        \"Test PR\": test_pr\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "# Save summary metrics to CSV\n",
    "metrics_summary.to_csv(\"encoding_methods_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cd7aa15e-5bc7-49f3-9740-07ff2dc97b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Valid RMSE</th>\n",
       "      <th>Valid PR</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>method1</td>\n",
       "      <td>2.324642</td>\n",
       "      <td>1.524678</td>\n",
       "      <td>1.400668</td>\n",
       "      <td>0.501312</td>\n",
       "      <td>2.553071</td>\n",
       "      <td>-0.083575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>method2</td>\n",
       "      <td>4.350411</td>\n",
       "      <td>2.085764</td>\n",
       "      <td>2.402722</td>\n",
       "      <td>0.056041</td>\n",
       "      <td>2.840714</td>\n",
       "      <td>0.418415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>method3</td>\n",
       "      <td>3.139814</td>\n",
       "      <td>1.771952</td>\n",
       "      <td>1.669624</td>\n",
       "      <td>0.080565</td>\n",
       "      <td>2.144782</td>\n",
       "      <td>-0.187259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Method  Train Loss  Train RMSE  Valid RMSE  Valid PR  Test RMSE   Test PR\n",
       "0  method1    2.324642    1.524678    1.400668  0.501312   2.553071 -0.083575\n",
       "1  method2    4.350411    2.085764    2.402722  0.056041   2.840714  0.418415\n",
       "2  method3    3.139814    1.771952    1.669624  0.080565   2.144782 -0.187259"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d15261db-6f85-4b93-a340-d3c111925272",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing method1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3123897583.py:109: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 39.5877, Train RMSE: 6.2919\n",
      "Epoch [1/500], Validation Loss: 33.9518, Validation RMSE: 5.8268, Valid PR: 0.5168\n",
      "Epoch [2/500], Train Loss: 38.2543, Train RMSE: 6.1850\n",
      "Epoch [2/500], Validation Loss: 33.2271, Validation RMSE: 5.7643, Valid PR: 0.6426\n",
      "Epoch [3/500], Train Loss: 38.2742, Train RMSE: 6.1866\n",
      "Epoch [3/500], Validation Loss: 32.3545, Validation RMSE: 5.6881, Valid PR: 0.7508\n",
      "Epoch [4/500], Train Loss: 36.7306, Train RMSE: 6.0606\n",
      "Epoch [4/500], Validation Loss: 31.2323, Validation RMSE: 5.5886, Valid PR: 0.7954\n",
      "Epoch [5/500], Train Loss: 36.7382, Train RMSE: 6.0612\n",
      "Epoch [5/500], Validation Loss: 30.0536, Validation RMSE: 5.4821, Valid PR: 0.8094\n",
      "Epoch [6/500], Train Loss: 35.1673, Train RMSE: 5.9302\n",
      "Epoch [6/500], Validation Loss: 28.9409, Validation RMSE: 5.3797, Valid PR: 0.8105\n",
      "Epoch [7/500], Train Loss: 35.1256, Train RMSE: 5.9267\n",
      "Epoch [7/500], Validation Loss: 27.7284, Validation RMSE: 5.2658, Valid PR: 0.8047\n",
      "Epoch [8/500], Train Loss: 33.9705, Train RMSE: 5.8284\n",
      "Epoch [8/500], Validation Loss: 26.7592, Validation RMSE: 5.1729, Valid PR: 0.8091\n",
      "Epoch [9/500], Train Loss: 33.7133, Train RMSE: 5.8063\n",
      "Epoch [9/500], Validation Loss: 25.7447, Validation RMSE: 5.0739, Valid PR: 0.8010\n",
      "Epoch [10/500], Train Loss: 33.2700, Train RMSE: 5.7680\n",
      "Epoch [10/500], Validation Loss: 24.8797, Validation RMSE: 4.9880, Valid PR: 0.7981\n",
      "Epoch [11/500], Train Loss: 32.9368, Train RMSE: 5.7391\n",
      "Epoch [11/500], Validation Loss: 24.1252, Validation RMSE: 4.9117, Valid PR: 0.7875\n",
      "Epoch [12/500], Train Loss: 31.9047, Train RMSE: 5.6484\n",
      "Epoch [12/500], Validation Loss: 23.5451, Validation RMSE: 4.8523, Valid PR: 0.7828\n",
      "Epoch [13/500], Train Loss: 31.3100, Train RMSE: 5.5955\n",
      "Epoch [13/500], Validation Loss: 23.0187, Validation RMSE: 4.7978, Valid PR: 0.7800\n",
      "Epoch [14/500], Train Loss: 30.2281, Train RMSE: 5.4980\n",
      "Epoch [14/500], Validation Loss: 22.3934, Validation RMSE: 4.7322, Valid PR: 0.7684\n",
      "Epoch [15/500], Train Loss: 29.8148, Train RMSE: 5.4603\n",
      "Epoch [15/500], Validation Loss: 21.8614, Validation RMSE: 4.6756, Valid PR: 0.7579\n",
      "Epoch [16/500], Train Loss: 29.7786, Train RMSE: 5.4570\n",
      "Epoch [16/500], Validation Loss: 21.3863, Validation RMSE: 4.6245, Valid PR: 0.7438\n",
      "Epoch [17/500], Train Loss: 28.7771, Train RMSE: 5.3644\n",
      "Epoch [17/500], Validation Loss: 20.8053, Validation RMSE: 4.5613, Valid PR: 0.7275\n",
      "Epoch [18/500], Train Loss: 28.9205, Train RMSE: 5.3778\n",
      "Epoch [18/500], Validation Loss: 20.4819, Validation RMSE: 4.5257, Valid PR: 0.7092\n",
      "Epoch [19/500], Train Loss: 27.9036, Train RMSE: 5.2824\n",
      "Epoch [19/500], Validation Loss: 20.1652, Validation RMSE: 4.4906, Valid PR: 0.6906\n",
      "Epoch [20/500], Train Loss: 27.3818, Train RMSE: 5.2328\n",
      "Epoch [20/500], Validation Loss: 19.8818, Validation RMSE: 4.4589, Valid PR: 0.6688\n",
      "Epoch [21/500], Train Loss: 27.7440, Train RMSE: 5.2673\n",
      "Epoch [21/500], Validation Loss: 19.7004, Validation RMSE: 4.4385, Valid PR: 0.6606\n",
      "Epoch [22/500], Train Loss: 26.4294, Train RMSE: 5.1410\n",
      "Epoch [22/500], Validation Loss: 19.4449, Validation RMSE: 4.4096, Valid PR: 0.6616\n",
      "Epoch [23/500], Train Loss: 25.1421, Train RMSE: 5.0142\n",
      "Epoch [23/500], Validation Loss: 19.0623, Validation RMSE: 4.3660, Valid PR: 0.6699\n",
      "Epoch [24/500], Train Loss: 24.6474, Train RMSE: 4.9646\n",
      "Epoch [24/500], Validation Loss: 18.6523, Validation RMSE: 4.3188, Valid PR: 0.6739\n",
      "Epoch [25/500], Train Loss: 24.9088, Train RMSE: 4.9909\n",
      "Epoch [25/500], Validation Loss: 18.3035, Validation RMSE: 4.2783, Valid PR: 0.6754\n",
      "Epoch [26/500], Train Loss: 23.2450, Train RMSE: 4.8213\n",
      "Epoch [26/500], Validation Loss: 18.0355, Validation RMSE: 4.2468, Valid PR: 0.6833\n",
      "Epoch [27/500], Train Loss: 23.7967, Train RMSE: 4.8782\n",
      "Epoch [27/500], Validation Loss: 17.6569, Validation RMSE: 4.2020, Valid PR: 0.6897\n",
      "Epoch [28/500], Train Loss: 22.8575, Train RMSE: 4.7810\n",
      "Epoch [28/500], Validation Loss: 17.2978, Validation RMSE: 4.1591, Valid PR: 0.6875\n",
      "Epoch [29/500], Train Loss: 22.6090, Train RMSE: 4.7549\n",
      "Epoch [29/500], Validation Loss: 16.9320, Validation RMSE: 4.1148, Valid PR: 0.6861\n",
      "Epoch [30/500], Train Loss: 22.0703, Train RMSE: 4.6979\n",
      "Epoch [30/500], Validation Loss: 16.5052, Validation RMSE: 4.0627, Valid PR: 0.6858\n",
      "Epoch [31/500], Train Loss: 21.7032, Train RMSE: 4.6587\n",
      "Epoch [31/500], Validation Loss: 16.1441, Validation RMSE: 4.0180, Valid PR: 0.6838\n",
      "Epoch [32/500], Train Loss: 20.5052, Train RMSE: 4.5283\n",
      "Epoch [32/500], Validation Loss: 15.9211, Validation RMSE: 3.9901, Valid PR: 0.6827\n",
      "Epoch [33/500], Train Loss: 20.4334, Train RMSE: 4.5203\n",
      "Epoch [33/500], Validation Loss: 15.6614, Validation RMSE: 3.9574, Valid PR: 0.6752\n",
      "Epoch [34/500], Train Loss: 20.1943, Train RMSE: 4.4938\n",
      "Epoch [34/500], Validation Loss: 15.4553, Validation RMSE: 3.9313, Valid PR: 0.6638\n",
      "Epoch [35/500], Train Loss: 20.0829, Train RMSE: 4.4814\n",
      "Epoch [35/500], Validation Loss: 15.1372, Validation RMSE: 3.8907, Valid PR: 0.6568\n",
      "Epoch [36/500], Train Loss: 19.1065, Train RMSE: 4.3711\n",
      "Epoch [36/500], Validation Loss: 14.8301, Validation RMSE: 3.8510, Valid PR: 0.6467\n",
      "Epoch [37/500], Train Loss: 19.0825, Train RMSE: 4.3684\n",
      "Epoch [37/500], Validation Loss: 14.5115, Validation RMSE: 3.8094, Valid PR: 0.6365\n",
      "Epoch [38/500], Train Loss: 17.9240, Train RMSE: 4.2337\n",
      "Epoch [38/500], Validation Loss: 14.2537, Validation RMSE: 3.7754, Valid PR: 0.6226\n",
      "Epoch [39/500], Train Loss: 18.0058, Train RMSE: 4.2433\n",
      "Epoch [39/500], Validation Loss: 14.0974, Validation RMSE: 3.7547, Valid PR: 0.6096\n",
      "Epoch [40/500], Train Loss: 17.4723, Train RMSE: 4.1800\n",
      "Epoch [40/500], Validation Loss: 14.0842, Validation RMSE: 3.7529, Valid PR: 0.6021\n",
      "Epoch [41/500], Train Loss: 17.1463, Train RMSE: 4.1408\n",
      "Epoch [41/500], Validation Loss: 14.0093, Validation RMSE: 3.7429, Valid PR: 0.6029\n",
      "Epoch [42/500], Train Loss: 16.0593, Train RMSE: 4.0074\n",
      "Epoch [42/500], Validation Loss: 13.8204, Validation RMSE: 3.7176, Valid PR: 0.6124\n",
      "Epoch [43/500], Train Loss: 16.3082, Train RMSE: 4.0383\n",
      "Epoch [43/500], Validation Loss: 13.5262, Validation RMSE: 3.6778, Valid PR: 0.6144\n",
      "Epoch [44/500], Train Loss: 15.6628, Train RMSE: 3.9576\n",
      "Epoch [44/500], Validation Loss: 13.2399, Validation RMSE: 3.6387, Valid PR: 0.6154\n",
      "Epoch [45/500], Train Loss: 15.6392, Train RMSE: 3.9546\n",
      "Epoch [45/500], Validation Loss: 12.9305, Validation RMSE: 3.5959, Valid PR: 0.6153\n",
      "Epoch [46/500], Train Loss: 14.2493, Train RMSE: 3.7748\n",
      "Epoch [46/500], Validation Loss: 12.5648, Validation RMSE: 3.5447, Valid PR: 0.6137\n",
      "Epoch [47/500], Train Loss: 13.9711, Train RMSE: 3.7378\n",
      "Epoch [47/500], Validation Loss: 12.2043, Validation RMSE: 3.4935, Valid PR: 0.6121\n",
      "Epoch [48/500], Train Loss: 14.4445, Train RMSE: 3.8006\n",
      "Epoch [48/500], Validation Loss: 11.7422, Validation RMSE: 3.4267, Valid PR: 0.6121\n",
      "Epoch [49/500], Train Loss: 13.3536, Train RMSE: 3.6543\n",
      "Epoch [49/500], Validation Loss: 11.4191, Validation RMSE: 3.3792, Valid PR: 0.6006\n",
      "Epoch [50/500], Train Loss: 12.8931, Train RMSE: 3.5907\n",
      "Epoch [50/500], Validation Loss: 11.0899, Validation RMSE: 3.3301, Valid PR: 0.5882\n",
      "Epoch [51/500], Train Loss: 12.3665, Train RMSE: 3.5166\n",
      "Epoch [51/500], Validation Loss: 10.8818, Validation RMSE: 3.2988, Valid PR: 0.5766\n",
      "Epoch [52/500], Train Loss: 11.5329, Train RMSE: 3.3960\n",
      "Epoch [52/500], Validation Loss: 10.5850, Validation RMSE: 3.2535, Valid PR: 0.5622\n",
      "Epoch [53/500], Train Loss: 12.0346, Train RMSE: 3.4691\n",
      "Epoch [53/500], Validation Loss: 10.3257, Validation RMSE: 3.2134, Valid PR: 0.5496\n",
      "Epoch [54/500], Train Loss: 11.6694, Train RMSE: 3.4160\n",
      "Epoch [54/500], Validation Loss: 10.1260, Validation RMSE: 3.1821, Valid PR: 0.5403\n",
      "Epoch [55/500], Train Loss: 11.4900, Train RMSE: 3.3897\n",
      "Epoch [55/500], Validation Loss: 9.9616, Validation RMSE: 3.1562, Valid PR: 0.5304\n",
      "Epoch [56/500], Train Loss: 10.8250, Train RMSE: 3.2901\n",
      "Epoch [56/500], Validation Loss: 9.7635, Validation RMSE: 3.1247, Valid PR: 0.5282\n",
      "Epoch [57/500], Train Loss: 11.1556, Train RMSE: 3.3400\n",
      "Epoch [57/500], Validation Loss: 9.5647, Validation RMSE: 3.0927, Valid PR: 0.5316\n",
      "Epoch [58/500], Train Loss: 10.1103, Train RMSE: 3.1797\n",
      "Epoch [58/500], Validation Loss: 9.2888, Validation RMSE: 3.0478, Valid PR: 0.5401\n",
      "Epoch [59/500], Train Loss: 10.1514, Train RMSE: 3.1861\n",
      "Epoch [59/500], Validation Loss: 8.9625, Validation RMSE: 2.9937, Valid PR: 0.5520\n",
      "Epoch [60/500], Train Loss: 8.8285, Train RMSE: 2.9713\n",
      "Epoch [60/500], Validation Loss: 8.7372, Validation RMSE: 2.9559, Valid PR: 0.5696\n",
      "Epoch [61/500], Train Loss: 8.8875, Train RMSE: 2.9812\n",
      "Epoch [61/500], Validation Loss: 8.5029, Validation RMSE: 2.9160, Valid PR: 0.5847\n",
      "Epoch [62/500], Train Loss: 8.4681, Train RMSE: 2.9100\n",
      "Epoch [62/500], Validation Loss: 8.1680, Validation RMSE: 2.8580, Valid PR: 0.5982\n",
      "Epoch [63/500], Train Loss: 8.5596, Train RMSE: 2.9257\n",
      "Epoch [63/500], Validation Loss: 7.7866, Validation RMSE: 2.7905, Valid PR: 0.6081\n",
      "Epoch [64/500], Train Loss: 8.7485, Train RMSE: 2.9578\n",
      "Epoch [64/500], Validation Loss: 7.5061, Validation RMSE: 2.7397, Valid PR: 0.6163\n",
      "Epoch [65/500], Train Loss: 8.0877, Train RMSE: 2.8439\n",
      "Epoch [65/500], Validation Loss: 7.1884, Validation RMSE: 2.6811, Valid PR: 0.6206\n",
      "Epoch [66/500], Train Loss: 8.0287, Train RMSE: 2.8335\n",
      "Epoch [66/500], Validation Loss: 6.8567, Validation RMSE: 2.6185, Valid PR: 0.6229\n",
      "Epoch [67/500], Train Loss: 7.7239, Train RMSE: 2.7792\n",
      "Epoch [67/500], Validation Loss: 6.5972, Validation RMSE: 2.5685, Valid PR: 0.6235\n",
      "Epoch [68/500], Train Loss: 7.1000, Train RMSE: 2.6646\n",
      "Epoch [68/500], Validation Loss: 6.3011, Validation RMSE: 2.5102, Valid PR: 0.6219\n",
      "Epoch [69/500], Train Loss: 7.1034, Train RMSE: 2.6652\n",
      "Epoch [69/500], Validation Loss: 6.0516, Validation RMSE: 2.4600, Valid PR: 0.6179\n",
      "Epoch [70/500], Train Loss: 6.6106, Train RMSE: 2.5711\n",
      "Epoch [70/500], Validation Loss: 5.8928, Validation RMSE: 2.4275, Valid PR: 0.6105\n",
      "Epoch [71/500], Train Loss: 6.5154, Train RMSE: 2.5525\n",
      "Epoch [71/500], Validation Loss: 5.7790, Validation RMSE: 2.4040, Valid PR: 0.6052\n",
      "Epoch [72/500], Train Loss: 6.1366, Train RMSE: 2.4772\n",
      "Epoch [72/500], Validation Loss: 5.6844, Validation RMSE: 2.3842, Valid PR: 0.5920\n",
      "Epoch [73/500], Train Loss: 6.1350, Train RMSE: 2.4769\n",
      "Epoch [73/500], Validation Loss: 5.5685, Validation RMSE: 2.3598, Valid PR: 0.5868\n",
      "Epoch [74/500], Train Loss: 6.3376, Train RMSE: 2.5175\n",
      "Epoch [74/500], Validation Loss: 5.4488, Validation RMSE: 2.3343, Valid PR: 0.5774\n",
      "Epoch [75/500], Train Loss: 5.1006, Train RMSE: 2.2584\n",
      "Epoch [75/500], Validation Loss: 5.3756, Validation RMSE: 2.3185, Valid PR: 0.5684\n",
      "Epoch [76/500], Train Loss: 4.8311, Train RMSE: 2.1980\n",
      "Epoch [76/500], Validation Loss: 5.2127, Validation RMSE: 2.2831, Valid PR: 0.5624\n",
      "Epoch [77/500], Train Loss: 4.5964, Train RMSE: 2.1439\n",
      "Epoch [77/500], Validation Loss: 5.1708, Validation RMSE: 2.2739, Valid PR: 0.5534\n",
      "Epoch [78/500], Train Loss: 4.9330, Train RMSE: 2.2210\n",
      "Epoch [78/500], Validation Loss: 5.1228, Validation RMSE: 2.2634, Valid PR: 0.5471\n",
      "Epoch [79/500], Train Loss: 5.3082, Train RMSE: 2.3040\n",
      "Epoch [79/500], Validation Loss: 5.0700, Validation RMSE: 2.2517, Valid PR: 0.5389\n",
      "Epoch [80/500], Train Loss: 4.7658, Train RMSE: 2.1831\n",
      "Epoch [80/500], Validation Loss: 4.9317, Validation RMSE: 2.2207, Valid PR: 0.5381\n",
      "Epoch [81/500], Train Loss: 4.5144, Train RMSE: 2.1247\n",
      "Epoch [81/500], Validation Loss: 4.8153, Validation RMSE: 2.1944, Valid PR: 0.5318\n",
      "Epoch [82/500], Train Loss: 4.6203, Train RMSE: 2.1495\n",
      "Epoch [82/500], Validation Loss: 4.6998, Validation RMSE: 2.1679, Valid PR: 0.5369\n",
      "Epoch [83/500], Train Loss: 4.0790, Train RMSE: 2.0197\n",
      "Epoch [83/500], Validation Loss: 4.5646, Validation RMSE: 2.1365, Valid PR: 0.5429\n",
      "Epoch [84/500], Train Loss: 4.1203, Train RMSE: 2.0298\n",
      "Epoch [84/500], Validation Loss: 4.3748, Validation RMSE: 2.0916, Valid PR: 0.5474\n",
      "Epoch [85/500], Train Loss: 3.7693, Train RMSE: 1.9415\n",
      "Epoch [85/500], Validation Loss: 4.2469, Validation RMSE: 2.0608, Valid PR: 0.5440\n",
      "Epoch [86/500], Train Loss: 3.3752, Train RMSE: 1.8372\n",
      "Epoch [86/500], Validation Loss: 4.0803, Validation RMSE: 2.0200, Valid PR: 0.5387\n",
      "Epoch [87/500], Train Loss: 3.6397, Train RMSE: 1.9078\n",
      "Epoch [87/500], Validation Loss: 3.8964, Validation RMSE: 1.9739, Valid PR: 0.5452\n",
      "Epoch [88/500], Train Loss: 2.9010, Train RMSE: 1.7032\n",
      "Epoch [88/500], Validation Loss: 3.7448, Validation RMSE: 1.9352, Valid PR: 0.5531\n",
      "Epoch [89/500], Train Loss: 3.2153, Train RMSE: 1.7931\n",
      "Epoch [89/500], Validation Loss: 3.5879, Validation RMSE: 1.8942, Valid PR: 0.5642\n",
      "Epoch [90/500], Train Loss: 3.1010, Train RMSE: 1.7610\n",
      "Epoch [90/500], Validation Loss: 3.4487, Validation RMSE: 1.8571, Valid PR: 0.5679\n",
      "Epoch [91/500], Train Loss: 3.3074, Train RMSE: 1.8186\n",
      "Epoch [91/500], Validation Loss: 3.3527, Validation RMSE: 1.8310, Valid PR: 0.5781\n",
      "Epoch [92/500], Train Loss: 3.2513, Train RMSE: 1.8031\n",
      "Epoch [92/500], Validation Loss: 3.3088, Validation RMSE: 1.8190, Valid PR: 0.5814\n",
      "Epoch [93/500], Train Loss: 2.9321, Train RMSE: 1.7123\n",
      "Epoch [93/500], Validation Loss: 3.2222, Validation RMSE: 1.7951, Valid PR: 0.5882\n",
      "Epoch [94/500], Train Loss: 3.3030, Train RMSE: 1.8174\n",
      "Epoch [94/500], Validation Loss: 3.1364, Validation RMSE: 1.7710, Valid PR: 0.5902\n",
      "Epoch [95/500], Train Loss: 2.7513, Train RMSE: 1.6587\n",
      "Epoch [95/500], Validation Loss: 3.0137, Validation RMSE: 1.7360, Valid PR: 0.5981\n",
      "Epoch [96/500], Train Loss: 3.1398, Train RMSE: 1.7719\n",
      "Epoch [96/500], Validation Loss: 3.0047, Validation RMSE: 1.7334, Valid PR: 0.5964\n",
      "Epoch [97/500], Train Loss: 2.5822, Train RMSE: 1.6069\n",
      "Epoch [97/500], Validation Loss: 2.9101, Validation RMSE: 1.7059, Valid PR: 0.6014\n",
      "Epoch [98/500], Train Loss: 2.3593, Train RMSE: 1.5360\n",
      "Epoch [98/500], Validation Loss: 2.7988, Validation RMSE: 1.6730, Valid PR: 0.6045\n",
      "Epoch [99/500], Train Loss: 2.2393, Train RMSE: 1.4964\n",
      "Epoch [99/500], Validation Loss: 2.7442, Validation RMSE: 1.6565, Valid PR: 0.6034\n",
      "Epoch [100/500], Train Loss: 3.2049, Train RMSE: 1.7902\n",
      "Epoch [100/500], Validation Loss: 2.7216, Validation RMSE: 1.6497, Valid PR: 0.6028\n",
      "Epoch [101/500], Train Loss: 2.3315, Train RMSE: 1.5269\n",
      "Epoch [101/500], Validation Loss: 2.6560, Validation RMSE: 1.6297, Valid PR: 0.6047\n",
      "Epoch [102/500], Train Loss: 2.2843, Train RMSE: 1.5114\n",
      "Epoch [102/500], Validation Loss: 2.5816, Validation RMSE: 1.6067, Valid PR: 0.5976\n",
      "Epoch [103/500], Train Loss: 2.4898, Train RMSE: 1.5779\n",
      "Epoch [103/500], Validation Loss: 2.5948, Validation RMSE: 1.6109, Valid PR: 0.5927\n",
      "Epoch [104/500], Train Loss: 2.4273, Train RMSE: 1.5580\n",
      "Epoch [104/500], Validation Loss: 2.5181, Validation RMSE: 1.5868, Valid PR: 0.5979\n",
      "Epoch [105/500], Train Loss: 1.6851, Train RMSE: 1.2981\n",
      "Epoch [105/500], Validation Loss: 2.4189, Validation RMSE: 1.5553, Valid PR: 0.6022\n",
      "Epoch [106/500], Train Loss: 2.3840, Train RMSE: 1.5440\n",
      "Epoch [106/500], Validation Loss: 2.3199, Validation RMSE: 1.5231, Valid PR: 0.6130\n",
      "Epoch [107/500], Train Loss: 2.0170, Train RMSE: 1.4202\n",
      "Epoch [107/500], Validation Loss: 2.1198, Validation RMSE: 1.4559, Valid PR: 0.6271\n",
      "Epoch [108/500], Train Loss: 2.5853, Train RMSE: 1.6079\n",
      "Epoch [108/500], Validation Loss: 1.9754, Validation RMSE: 1.4055, Valid PR: 0.6393\n",
      "Epoch [109/500], Train Loss: 1.9673, Train RMSE: 1.4026\n",
      "Epoch [109/500], Validation Loss: 1.8737, Validation RMSE: 1.3688, Valid PR: 0.6484\n",
      "Epoch [110/500], Train Loss: 2.2992, Train RMSE: 1.5163\n",
      "Epoch [110/500], Validation Loss: 1.7741, Validation RMSE: 1.3320, Valid PR: 0.6599\n",
      "Epoch [111/500], Train Loss: 2.5378, Train RMSE: 1.5930\n",
      "Epoch [111/500], Validation Loss: 1.6987, Validation RMSE: 1.3033, Valid PR: 0.6729\n",
      "Epoch [112/500], Train Loss: 2.3183, Train RMSE: 1.5226\n",
      "Epoch [112/500], Validation Loss: 1.6393, Validation RMSE: 1.2803, Valid PR: 0.6863\n",
      "Epoch [113/500], Train Loss: 2.1841, Train RMSE: 1.4779\n",
      "Epoch [113/500], Validation Loss: 1.5516, Validation RMSE: 1.2456, Valid PR: 0.6990\n",
      "Epoch [114/500], Train Loss: 2.3877, Train RMSE: 1.5452\n",
      "Epoch [114/500], Validation Loss: 1.4686, Validation RMSE: 1.2118, Valid PR: 0.7100\n",
      "Epoch [115/500], Train Loss: 1.7204, Train RMSE: 1.3117\n",
      "Epoch [115/500], Validation Loss: 1.4380, Validation RMSE: 1.1992, Valid PR: 0.7133\n",
      "Epoch [116/500], Train Loss: 2.0351, Train RMSE: 1.4266\n",
      "Epoch [116/500], Validation Loss: 1.4577, Validation RMSE: 1.2074, Valid PR: 0.7143\n",
      "Epoch [117/500], Train Loss: 2.5485, Train RMSE: 1.5964\n",
      "Epoch [117/500], Validation Loss: 1.5007, Validation RMSE: 1.2250, Valid PR: 0.7098\n",
      "Epoch [118/500], Train Loss: 1.7763, Train RMSE: 1.3328\n",
      "Epoch [118/500], Validation Loss: 1.5525, Validation RMSE: 1.2460, Valid PR: 0.7036\n",
      "Epoch [119/500], Train Loss: 2.4065, Train RMSE: 1.5513\n",
      "Epoch [119/500], Validation Loss: 1.6106, Validation RMSE: 1.2691, Valid PR: 0.6976\n",
      "Epoch [120/500], Train Loss: 1.5954, Train RMSE: 1.2631\n",
      "Epoch [120/500], Validation Loss: 1.6361, Validation RMSE: 1.2791, Valid PR: 0.6975\n",
      "Epoch [121/500], Train Loss: 2.2570, Train RMSE: 1.5023\n",
      "Epoch [121/500], Validation Loss: 1.6901, Validation RMSE: 1.3000, Valid PR: 0.6900\n",
      "Epoch [122/500], Train Loss: 2.2569, Train RMSE: 1.5023\n",
      "Epoch [122/500], Validation Loss: 1.7420, Validation RMSE: 1.3198, Valid PR: 0.6833\n",
      "Epoch [123/500], Train Loss: 1.8647, Train RMSE: 1.3655\n",
      "Epoch [123/500], Validation Loss: 1.7955, Validation RMSE: 1.3399, Valid PR: 0.6801\n",
      "Epoch [124/500], Train Loss: 1.6502, Train RMSE: 1.2846\n",
      "Epoch [124/500], Validation Loss: 1.8181, Validation RMSE: 1.3484, Valid PR: 0.6791\n",
      "Epoch [125/500], Train Loss: 2.3065, Train RMSE: 1.5187\n",
      "Epoch [125/500], Validation Loss: 1.8020, Validation RMSE: 1.3424, Valid PR: 0.6812\n",
      "Epoch [126/500], Train Loss: 2.6830, Train RMSE: 1.6380\n",
      "Epoch [126/500], Validation Loss: 1.7526, Validation RMSE: 1.3239, Valid PR: 0.6796\n",
      "Epoch [127/500], Train Loss: 2.2150, Train RMSE: 1.4883\n",
      "Epoch [127/500], Validation Loss: 1.6870, Validation RMSE: 1.2988, Valid PR: 0.6843\n",
      "Epoch [128/500], Train Loss: 2.4362, Train RMSE: 1.5608\n",
      "Epoch [128/500], Validation Loss: 1.5767, Validation RMSE: 1.2557, Valid PR: 0.6871\n",
      "Epoch [129/500], Train Loss: 2.6140, Train RMSE: 1.6168\n",
      "Epoch [129/500], Validation Loss: 1.4901, Validation RMSE: 1.2207, Valid PR: 0.6926\n",
      "Epoch [130/500], Train Loss: 1.9489, Train RMSE: 1.3960\n",
      "Epoch [130/500], Validation Loss: 1.4488, Validation RMSE: 1.2037, Valid PR: 0.6921\n",
      "Epoch [131/500], Train Loss: 1.7279, Train RMSE: 1.3145\n",
      "Epoch [131/500], Validation Loss: 1.4376, Validation RMSE: 1.1990, Valid PR: 0.6858\n",
      "Epoch [132/500], Train Loss: 1.8924, Train RMSE: 1.3756\n",
      "Epoch [132/500], Validation Loss: 1.4519, Validation RMSE: 1.2049, Valid PR: 0.6793\n",
      "Epoch [133/500], Train Loss: 1.6517, Train RMSE: 1.2852\n",
      "Epoch [133/500], Validation Loss: 1.5367, Validation RMSE: 1.2396, Valid PR: 0.6684\n",
      "Epoch [134/500], Train Loss: 1.8647, Train RMSE: 1.3656\n",
      "Epoch [134/500], Validation Loss: 1.6022, Validation RMSE: 1.2658, Valid PR: 0.6559\n",
      "Epoch [135/500], Train Loss: 1.2797, Train RMSE: 1.1312\n",
      "Epoch [135/500], Validation Loss: 1.6331, Validation RMSE: 1.2779, Valid PR: 0.6516\n",
      "Epoch [136/500], Train Loss: 2.1687, Train RMSE: 1.4726\n",
      "Epoch [136/500], Validation Loss: 1.6575, Validation RMSE: 1.2874, Valid PR: 0.6411\n",
      "Epoch [137/500], Train Loss: 1.7843, Train RMSE: 1.3358\n",
      "Epoch [137/500], Validation Loss: 1.6803, Validation RMSE: 1.2962, Valid PR: 0.6313\n",
      "Epoch [138/500], Train Loss: 2.1283, Train RMSE: 1.4589\n",
      "Epoch [138/500], Validation Loss: 1.7070, Validation RMSE: 1.3065, Valid PR: 0.6233\n",
      "Epoch [139/500], Train Loss: 1.8036, Train RMSE: 1.3430\n",
      "Epoch [139/500], Validation Loss: 1.7065, Validation RMSE: 1.3063, Valid PR: 0.6199\n",
      "Epoch [140/500], Train Loss: 1.8078, Train RMSE: 1.3446\n",
      "Epoch [140/500], Validation Loss: 1.7569, Validation RMSE: 1.3255, Valid PR: 0.6027\n",
      "Epoch [141/500], Train Loss: 2.4337, Train RMSE: 1.5600\n",
      "Epoch [141/500], Validation Loss: 1.8364, Validation RMSE: 1.3551, Valid PR: 0.5708\n",
      "Epoch [142/500], Train Loss: 1.8664, Train RMSE: 1.3662\n",
      "Epoch [142/500], Validation Loss: 1.9051, Validation RMSE: 1.3802, Valid PR: 0.5314\n",
      "Epoch [143/500], Train Loss: 1.9012, Train RMSE: 1.3788\n",
      "Epoch [143/500], Validation Loss: 1.9613, Validation RMSE: 1.4005, Valid PR: 0.4955\n",
      "Epoch [144/500], Train Loss: 1.8176, Train RMSE: 1.3482\n",
      "Epoch [144/500], Validation Loss: 1.9751, Validation RMSE: 1.4054, Valid PR: 0.4788\n",
      "Epoch [145/500], Train Loss: 2.0667, Train RMSE: 1.4376\n",
      "Epoch [145/500], Validation Loss: 1.9920, Validation RMSE: 1.4114, Valid PR: 0.4602\n",
      "Epoch [146/500], Train Loss: 1.9146, Train RMSE: 1.3837\n",
      "Epoch [146/500], Validation Loss: 1.9689, Validation RMSE: 1.4032, Valid PR: 0.4527\n",
      "Epoch [147/500], Train Loss: 1.6696, Train RMSE: 1.2921\n",
      "Epoch [147/500], Validation Loss: 1.9363, Validation RMSE: 1.3915, Valid PR: 0.4621\n",
      "Epoch [148/500], Train Loss: 1.6837, Train RMSE: 1.2976\n",
      "Epoch [148/500], Validation Loss: 1.8839, Validation RMSE: 1.3726, Valid PR: 0.4785\n",
      "Epoch [149/500], Train Loss: 1.8809, Train RMSE: 1.3714\n",
      "Epoch [149/500], Validation Loss: 1.8193, Validation RMSE: 1.3488, Valid PR: 0.4988\n",
      "Epoch [150/500], Train Loss: 2.0941, Train RMSE: 1.4471\n",
      "Epoch [150/500], Validation Loss: 1.7702, Validation RMSE: 1.3305, Valid PR: 0.5129\n",
      "Epoch [151/500], Train Loss: 1.7888, Train RMSE: 1.3374\n",
      "Epoch [151/500], Validation Loss: 1.7016, Validation RMSE: 1.3044, Valid PR: 0.5344\n",
      "Epoch [152/500], Train Loss: 1.6265, Train RMSE: 1.2754\n",
      "Epoch [152/500], Validation Loss: 1.6892, Validation RMSE: 1.2997, Valid PR: 0.5430\n",
      "Epoch [153/500], Train Loss: 1.9842, Train RMSE: 1.4086\n",
      "Epoch [153/500], Validation Loss: 1.6828, Validation RMSE: 1.2972, Valid PR: 0.5561\n",
      "Epoch [154/500], Train Loss: 1.7841, Train RMSE: 1.3357\n",
      "Epoch [154/500], Validation Loss: 1.6555, Validation RMSE: 1.2867, Valid PR: 0.5759\n",
      "Epoch [155/500], Train Loss: 1.7488, Train RMSE: 1.3224\n",
      "Epoch [155/500], Validation Loss: 1.6697, Validation RMSE: 1.2922, Valid PR: 0.5845\n",
      "Epoch [156/500], Train Loss: 2.3171, Train RMSE: 1.5222\n",
      "Epoch [156/500], Validation Loss: 1.6952, Validation RMSE: 1.3020, Valid PR: 0.5857\n",
      "Epoch [157/500], Train Loss: 1.9217, Train RMSE: 1.3862\n",
      "Epoch [157/500], Validation Loss: 1.7256, Validation RMSE: 1.3136, Valid PR: 0.5806\n",
      "Epoch [158/500], Train Loss: 2.2203, Train RMSE: 1.4901\n",
      "Epoch [158/500], Validation Loss: 1.7459, Validation RMSE: 1.3213, Valid PR: 0.5731\n",
      "Epoch [159/500], Train Loss: 2.0061, Train RMSE: 1.4164\n",
      "Epoch [159/500], Validation Loss: 1.7246, Validation RMSE: 1.3133, Valid PR: 0.5749\n",
      "Epoch [160/500], Train Loss: 1.8225, Train RMSE: 1.3500\n",
      "Epoch [160/500], Validation Loss: 1.6547, Validation RMSE: 1.2863, Valid PR: 0.5863\n",
      "Epoch [161/500], Train Loss: 1.6653, Train RMSE: 1.2905\n",
      "Epoch [161/500], Validation Loss: 1.6019, Validation RMSE: 1.2656, Valid PR: 0.5884\n",
      "Epoch [162/500], Train Loss: 2.1464, Train RMSE: 1.4651\n",
      "Epoch [162/500], Validation Loss: 1.5677, Validation RMSE: 1.2521, Valid PR: 0.5851\n",
      "Epoch [163/500], Train Loss: 1.7345, Train RMSE: 1.3170\n",
      "Epoch [163/500], Validation Loss: 1.5214, Validation RMSE: 1.2334, Valid PR: 0.5948\n",
      "Epoch [164/500], Train Loss: 1.8004, Train RMSE: 1.3418\n",
      "Epoch [164/500], Validation Loss: 1.4655, Validation RMSE: 1.2106, Valid PR: 0.6059\n",
      "Epoch [165/500], Train Loss: 2.2346, Train RMSE: 1.4949\n",
      "Epoch [165/500], Validation Loss: 1.4002, Validation RMSE: 1.1833, Valid PR: 0.6218\n",
      "Epoch [166/500], Train Loss: 1.8753, Train RMSE: 1.3694\n",
      "Epoch [166/500], Validation Loss: 1.3396, Validation RMSE: 1.1574, Valid PR: 0.6386\n",
      "Epoch [167/500], Train Loss: 1.9330, Train RMSE: 1.3903\n",
      "Epoch [167/500], Validation Loss: 1.3031, Validation RMSE: 1.1415, Valid PR: 0.6507\n",
      "Epoch [168/500], Train Loss: 1.9589, Train RMSE: 1.3996\n",
      "Epoch [168/500], Validation Loss: 1.2891, Validation RMSE: 1.1354, Valid PR: 0.6576\n",
      "Epoch [169/500], Train Loss: 2.2755, Train RMSE: 1.5085\n",
      "Epoch [169/500], Validation Loss: 1.3167, Validation RMSE: 1.1475, Valid PR: 0.6538\n",
      "Epoch [170/500], Train Loss: 2.3708, Train RMSE: 1.5397\n",
      "Epoch [170/500], Validation Loss: 1.3706, Validation RMSE: 1.1707, Valid PR: 0.6463\n",
      "Epoch [171/500], Train Loss: 1.7121, Train RMSE: 1.3085\n",
      "Epoch [171/500], Validation Loss: 1.4311, Validation RMSE: 1.1963, Valid PR: 0.6386\n",
      "Epoch [172/500], Train Loss: 1.6775, Train RMSE: 1.2952\n",
      "Epoch [172/500], Validation Loss: 1.4784, Validation RMSE: 1.2159, Valid PR: 0.6328\n",
      "Epoch [173/500], Train Loss: 2.2176, Train RMSE: 1.4892\n",
      "Epoch [173/500], Validation Loss: 1.5213, Validation RMSE: 1.2334, Valid PR: 0.6257\n",
      "Epoch [174/500], Train Loss: 2.1119, Train RMSE: 1.4532\n",
      "Epoch [174/500], Validation Loss: 1.5828, Validation RMSE: 1.2581, Valid PR: 0.6099\n",
      "Epoch [175/500], Train Loss: 1.7579, Train RMSE: 1.3258\n",
      "Epoch [175/500], Validation Loss: 1.6144, Validation RMSE: 1.2706, Valid PR: 0.6026\n",
      "Epoch [176/500], Train Loss: 1.9408, Train RMSE: 1.3931\n",
      "Epoch [176/500], Validation Loss: 1.6128, Validation RMSE: 1.2699, Valid PR: 0.6082\n",
      "Epoch [177/500], Train Loss: 2.2156, Train RMSE: 1.4885\n",
      "Epoch [177/500], Validation Loss: 1.5732, Validation RMSE: 1.2543, Valid PR: 0.6201\n",
      "Epoch [178/500], Train Loss: 1.8798, Train RMSE: 1.3711\n",
      "Epoch [178/500], Validation Loss: 1.5065, Validation RMSE: 1.2274, Valid PR: 0.6351\n",
      "Epoch [179/500], Train Loss: 1.3247, Train RMSE: 1.1510\n",
      "Epoch [179/500], Validation Loss: 1.4454, Validation RMSE: 1.2023, Valid PR: 0.6441\n",
      "Epoch [180/500], Train Loss: 1.9521, Train RMSE: 1.3972\n",
      "Epoch [180/500], Validation Loss: 1.4191, Validation RMSE: 1.1913, Valid PR: 0.6476\n",
      "Epoch [181/500], Train Loss: 1.7209, Train RMSE: 1.3118\n",
      "Epoch [181/500], Validation Loss: 1.3790, Validation RMSE: 1.1743, Valid PR: 0.6566\n",
      "Epoch [182/500], Train Loss: 1.9743, Train RMSE: 1.4051\n",
      "Epoch [182/500], Validation Loss: 1.3424, Validation RMSE: 1.1586, Valid PR: 0.6653\n",
      "Epoch [183/500], Train Loss: 1.3881, Train RMSE: 1.1782\n",
      "Epoch [183/500], Validation Loss: 1.3110, Validation RMSE: 1.1450, Valid PR: 0.6715\n",
      "Epoch [184/500], Train Loss: 2.6735, Train RMSE: 1.6351\n",
      "Epoch [184/500], Validation Loss: 1.3217, Validation RMSE: 1.1497, Valid PR: 0.6662\n",
      "Epoch [185/500], Train Loss: 1.9714, Train RMSE: 1.4041\n",
      "Epoch [185/500], Validation Loss: 1.3417, Validation RMSE: 1.1583, Valid PR: 0.6524\n",
      "Epoch [186/500], Train Loss: 1.6655, Train RMSE: 1.2905\n",
      "Epoch [186/500], Validation Loss: 1.3527, Validation RMSE: 1.1631, Valid PR: 0.6368\n",
      "Epoch [187/500], Train Loss: 1.9203, Train RMSE: 1.3857\n",
      "Epoch [187/500], Validation Loss: 1.3693, Validation RMSE: 1.1702, Valid PR: 0.6222\n",
      "Epoch [188/500], Train Loss: 1.4721, Train RMSE: 1.2133\n",
      "Epoch [188/500], Validation Loss: 1.3891, Validation RMSE: 1.1786, Valid PR: 0.6094\n",
      "Epoch [189/500], Train Loss: 2.1120, Train RMSE: 1.4533\n",
      "Epoch [189/500], Validation Loss: 1.4164, Validation RMSE: 1.1901, Valid PR: 0.5975\n",
      "Epoch [190/500], Train Loss: 1.6788, Train RMSE: 1.2957\n",
      "Epoch [190/500], Validation Loss: 1.4464, Validation RMSE: 1.2027, Valid PR: 0.5848\n",
      "Epoch [191/500], Train Loss: 1.6144, Train RMSE: 1.2706\n",
      "Epoch [191/500], Validation Loss: 1.4100, Validation RMSE: 1.1874, Valid PR: 0.5995\n",
      "Epoch [192/500], Train Loss: 2.1173, Train RMSE: 1.4551\n",
      "Epoch [192/500], Validation Loss: 1.3660, Validation RMSE: 1.1688, Valid PR: 0.6166\n",
      "Epoch [193/500], Train Loss: 2.0778, Train RMSE: 1.4415\n",
      "Epoch [193/500], Validation Loss: 1.3042, Validation RMSE: 1.1420, Valid PR: 0.6411\n",
      "Epoch [194/500], Train Loss: 2.0972, Train RMSE: 1.4482\n",
      "Epoch [194/500], Validation Loss: 1.2471, Validation RMSE: 1.1167, Valid PR: 0.6619\n",
      "Epoch [195/500], Train Loss: 2.0254, Train RMSE: 1.4232\n",
      "Epoch [195/500], Validation Loss: 1.1938, Validation RMSE: 1.0926, Valid PR: 0.6801\n",
      "Epoch [196/500], Train Loss: 2.0326, Train RMSE: 1.4257\n",
      "Epoch [196/500], Validation Loss: 1.1686, Validation RMSE: 1.0810, Valid PR: 0.6887\n",
      "Epoch [197/500], Train Loss: 1.7845, Train RMSE: 1.3358\n",
      "Epoch [197/500], Validation Loss: 1.1846, Validation RMSE: 1.0884, Valid PR: 0.6826\n",
      "Epoch [198/500], Train Loss: 2.1405, Train RMSE: 1.4630\n",
      "Epoch [198/500], Validation Loss: 1.2056, Validation RMSE: 1.0980, Valid PR: 0.6751\n",
      "Epoch [199/500], Train Loss: 1.3760, Train RMSE: 1.1730\n",
      "Epoch [199/500], Validation Loss: 1.2518, Validation RMSE: 1.1189, Valid PR: 0.6585\n",
      "Epoch [200/500], Train Loss: 1.8065, Train RMSE: 1.3441\n",
      "Epoch [200/500], Validation Loss: 1.3077, Validation RMSE: 1.1435, Valid PR: 0.6381\n",
      "Epoch [201/500], Train Loss: 1.6749, Train RMSE: 1.2942\n",
      "Epoch [201/500], Validation Loss: 1.3891, Validation RMSE: 1.1786, Valid PR: 0.6093\n",
      "Epoch [202/500], Train Loss: 2.1329, Train RMSE: 1.4604\n",
      "Epoch [202/500], Validation Loss: 1.4787, Validation RMSE: 1.2160, Valid PR: 0.5755\n",
      "Epoch [203/500], Train Loss: 1.9107, Train RMSE: 1.3823\n",
      "Epoch [203/500], Validation Loss: 1.5643, Validation RMSE: 1.2507, Valid PR: 0.5405\n",
      "Epoch [204/500], Train Loss: 2.1543, Train RMSE: 1.4677\n",
      "Epoch [204/500], Validation Loss: 1.6807, Validation RMSE: 1.2964, Valid PR: 0.4919\n",
      "Epoch [205/500], Train Loss: 1.7040, Train RMSE: 1.3054\n",
      "Epoch [205/500], Validation Loss: 1.8201, Validation RMSE: 1.3491, Valid PR: 0.4342\n",
      "Epoch [206/500], Train Loss: 1.6325, Train RMSE: 1.2777\n",
      "Epoch [206/500], Validation Loss: 1.9359, Validation RMSE: 1.3913, Valid PR: 0.3868\n",
      "Epoch [207/500], Train Loss: 2.1330, Train RMSE: 1.4605\n",
      "Epoch [207/500], Validation Loss: 1.9985, Validation RMSE: 1.4137, Valid PR: 0.3594\n",
      "Epoch [208/500], Train Loss: 1.8461, Train RMSE: 1.3587\n",
      "Epoch [208/500], Validation Loss: 2.0411, Validation RMSE: 1.4287, Valid PR: 0.3373\n",
      "Epoch [209/500], Train Loss: 1.6314, Train RMSE: 1.2773\n",
      "Epoch [209/500], Validation Loss: 2.0284, Validation RMSE: 1.4242, Valid PR: 0.3339\n",
      "Epoch [210/500], Train Loss: 1.3015, Train RMSE: 1.1408\n",
      "Epoch [210/500], Validation Loss: 2.0184, Validation RMSE: 1.4207, Valid PR: 0.3302\n",
      "Epoch [211/500], Train Loss: 2.1454, Train RMSE: 1.4647\n",
      "Epoch [211/500], Validation Loss: 1.9753, Validation RMSE: 1.4054, Valid PR: 0.3428\n",
      "Epoch [212/500], Train Loss: 1.8377, Train RMSE: 1.3556\n",
      "Epoch [212/500], Validation Loss: 1.9371, Validation RMSE: 1.3918, Valid PR: 0.3627\n",
      "Epoch [213/500], Train Loss: 1.6830, Train RMSE: 1.2973\n",
      "Epoch [213/500], Validation Loss: 1.8834, Validation RMSE: 1.3724, Valid PR: 0.3955\n",
      "Epoch [214/500], Train Loss: 1.7254, Train RMSE: 1.3136\n",
      "Epoch [214/500], Validation Loss: 1.8575, Validation RMSE: 1.3629, Valid PR: 0.4141\n",
      "Epoch [215/500], Train Loss: 1.6773, Train RMSE: 1.2951\n",
      "Epoch [215/500], Validation Loss: 1.8289, Validation RMSE: 1.3524, Valid PR: 0.4357\n",
      "Epoch [216/500], Train Loss: 1.6666, Train RMSE: 1.2910\n",
      "Epoch [216/500], Validation Loss: 1.7769, Validation RMSE: 1.3330, Valid PR: 0.4604\n",
      "Epoch [217/500], Train Loss: 1.4174, Train RMSE: 1.1905\n",
      "Epoch [217/500], Validation Loss: 1.7380, Validation RMSE: 1.3184, Valid PR: 0.4801\n",
      "Epoch [218/500], Train Loss: 1.3362, Train RMSE: 1.1559\n",
      "Epoch [218/500], Validation Loss: 1.7287, Validation RMSE: 1.3148, Valid PR: 0.4835\n",
      "Epoch [219/500], Train Loss: 1.7274, Train RMSE: 1.3143\n",
      "Epoch [219/500], Validation Loss: 1.7304, Validation RMSE: 1.3154, Valid PR: 0.4800\n",
      "Epoch [220/500], Train Loss: 1.9478, Train RMSE: 1.3956\n",
      "Epoch [220/500], Validation Loss: 1.7491, Validation RMSE: 1.3225, Valid PR: 0.4678\n",
      "Epoch [221/500], Train Loss: 1.6445, Train RMSE: 1.2824\n",
      "Epoch [221/500], Validation Loss: 1.7626, Validation RMSE: 1.3276, Valid PR: 0.4608\n",
      "Epoch [222/500], Train Loss: 1.9845, Train RMSE: 1.4087\n",
      "Epoch [222/500], Validation Loss: 1.7795, Validation RMSE: 1.3340, Valid PR: 0.4508\n",
      "Epoch [223/500], Train Loss: 1.6109, Train RMSE: 1.2692\n",
      "Epoch [223/500], Validation Loss: 1.8356, Validation RMSE: 1.3548, Valid PR: 0.4266\n",
      "Epoch [224/500], Train Loss: 1.6197, Train RMSE: 1.2727\n",
      "Epoch [224/500], Validation Loss: 1.9016, Validation RMSE: 1.3790, Valid PR: 0.4046\n",
      "Epoch [225/500], Train Loss: 1.5533, Train RMSE: 1.2463\n",
      "Epoch [225/500], Validation Loss: 1.9418, Validation RMSE: 1.3935, Valid PR: 0.3935\n",
      "Epoch [226/500], Train Loss: 1.1994, Train RMSE: 1.0952\n",
      "Epoch [226/500], Validation Loss: 1.9774, Validation RMSE: 1.4062, Valid PR: 0.3842\n",
      "Epoch [227/500], Train Loss: 1.9107, Train RMSE: 1.3823\n",
      "Epoch [227/500], Validation Loss: 1.9803, Validation RMSE: 1.4072, Valid PR: 0.3874\n",
      "Epoch [228/500], Train Loss: 1.2589, Train RMSE: 1.1220\n",
      "Epoch [228/500], Validation Loss: 1.9809, Validation RMSE: 1.4074, Valid PR: 0.3899\n",
      "Epoch [229/500], Train Loss: 1.8970, Train RMSE: 1.3773\n",
      "Epoch [229/500], Validation Loss: 1.9622, Validation RMSE: 1.4008, Valid PR: 0.3970\n",
      "Epoch [230/500], Train Loss: 1.6445, Train RMSE: 1.2824\n",
      "Epoch [230/500], Validation Loss: 1.9201, Validation RMSE: 1.3857, Valid PR: 0.4100\n",
      "Epoch [231/500], Train Loss: 1.5093, Train RMSE: 1.2285\n",
      "Epoch [231/500], Validation Loss: 1.8843, Validation RMSE: 1.3727, Valid PR: 0.4233\n",
      "Epoch [232/500], Train Loss: 2.6333, Train RMSE: 1.6227\n",
      "Epoch [232/500], Validation Loss: 1.8625, Validation RMSE: 1.3648, Valid PR: 0.4307\n",
      "Epoch [233/500], Train Loss: 1.5255, Train RMSE: 1.2351\n",
      "Epoch [233/500], Validation Loss: 1.8422, Validation RMSE: 1.3573, Valid PR: 0.4387\n",
      "Epoch [234/500], Train Loss: 1.6567, Train RMSE: 1.2871\n",
      "Epoch [234/500], Validation Loss: 1.8327, Validation RMSE: 1.3538, Valid PR: 0.4407\n",
      "Epoch [235/500], Train Loss: 1.6298, Train RMSE: 1.2766\n",
      "Epoch [235/500], Validation Loss: 1.8182, Validation RMSE: 1.3484, Valid PR: 0.4467\n",
      "Epoch [236/500], Train Loss: 1.5162, Train RMSE: 1.2313\n",
      "Epoch [236/500], Validation Loss: 1.8185, Validation RMSE: 1.3485, Valid PR: 0.4476\n",
      "Epoch [237/500], Train Loss: 1.8904, Train RMSE: 1.3749\n",
      "Epoch [237/500], Validation Loss: 1.8633, Validation RMSE: 1.3650, Valid PR: 0.4282\n",
      "Epoch [238/500], Train Loss: 1.5487, Train RMSE: 1.2445\n",
      "Epoch [238/500], Validation Loss: 1.8951, Validation RMSE: 1.3766, Valid PR: 0.4164\n",
      "Epoch [239/500], Train Loss: 1.4169, Train RMSE: 1.1903\n",
      "Epoch [239/500], Validation Loss: 1.8924, Validation RMSE: 1.3757, Valid PR: 0.4159\n",
      "Epoch [240/500], Train Loss: 1.3095, Train RMSE: 1.1443\n",
      "Epoch [240/500], Validation Loss: 1.8850, Validation RMSE: 1.3730, Valid PR: 0.4174\n",
      "Epoch [241/500], Train Loss: 1.7004, Train RMSE: 1.3040\n",
      "Epoch [241/500], Validation Loss: 1.8799, Validation RMSE: 1.3711, Valid PR: 0.4171\n",
      "Epoch [242/500], Train Loss: 1.5688, Train RMSE: 1.2525\n",
      "Epoch [242/500], Validation Loss: 1.8606, Validation RMSE: 1.3640, Valid PR: 0.4221\n",
      "Epoch [243/500], Train Loss: 2.0801, Train RMSE: 1.4423\n",
      "Epoch [243/500], Validation Loss: 1.8628, Validation RMSE: 1.3648, Valid PR: 0.4191\n",
      "Epoch [244/500], Train Loss: 1.3853, Train RMSE: 1.1770\n",
      "Epoch [244/500], Validation Loss: 1.8681, Validation RMSE: 1.3668, Valid PR: 0.4166\n",
      "Epoch [245/500], Train Loss: 1.6845, Train RMSE: 1.2979\n",
      "Epoch [245/500], Validation Loss: 1.8722, Validation RMSE: 1.3683, Valid PR: 0.4140\n",
      "Epoch [246/500], Train Loss: 1.8059, Train RMSE: 1.3438\n",
      "Epoch [246/500], Validation Loss: 1.8796, Validation RMSE: 1.3710, Valid PR: 0.4114\n",
      "Early stopping triggered.\n",
      "Test Loss: 6.5351, Test RMSE: 2.5564, Test PR: -0.2104\n",
      "Test Loss: 5.4620, Test RMSE: 2.3371, Test PR: -0.2302\n",
      "Testing method2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3123897583.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/scratch/local/51712327/ipykernel_500297/3123897583.py:266: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_summary = pd.concat([metrics_summary, best_metrics], ignore_index=True)\n",
      "/scratch/local/51712327/ipykernel_500297/3123897583.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3123897583.py:109: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 35.4392, Train RMSE: 5.9531\n",
      "Epoch [1/500], Validation Loss: 19.7730, Validation RMSE: 4.4467, Valid PR: 0.4544\n",
      "Epoch [2/500], Train Loss: 34.6205, Train RMSE: 5.8839\n",
      "Epoch [2/500], Validation Loss: 33.9745, Validation RMSE: 5.8288, Valid PR: 0.5993\n",
      "Epoch [3/500], Train Loss: 34.4731, Train RMSE: 5.8714\n",
      "Epoch [3/500], Validation Loss: 35.0736, Validation RMSE: 5.9223, Valid PR: -0.4495\n",
      "Epoch [4/500], Train Loss: 33.3590, Train RMSE: 5.7757\n",
      "Epoch [4/500], Validation Loss: 35.3204, Validation RMSE: 5.9431, Valid PR: -0.4797\n",
      "Epoch [5/500], Train Loss: 32.7683, Train RMSE: 5.7244\n",
      "Epoch [5/500], Validation Loss: 35.1689, Validation RMSE: 5.9303, Valid PR: -0.3427\n",
      "Epoch [6/500], Train Loss: 31.7726, Train RMSE: 5.6367\n",
      "Epoch [6/500], Validation Loss: 34.7590, Validation RMSE: 5.8957, Valid PR: -0.1830\n",
      "Epoch [7/500], Train Loss: 31.3995, Train RMSE: 5.6035\n",
      "Epoch [7/500], Validation Loss: 34.3630, Validation RMSE: 5.8620, Valid PR: 0.0438\n",
      "Epoch [8/500], Train Loss: 30.8986, Train RMSE: 5.5586\n",
      "Epoch [8/500], Validation Loss: 34.2756, Validation RMSE: 5.8545, Valid PR: 0.2423\n",
      "Epoch [9/500], Train Loss: 30.4308, Train RMSE: 5.5164\n",
      "Epoch [9/500], Validation Loss: 33.6378, Validation RMSE: 5.7998, Valid PR: 0.6337\n",
      "Epoch [10/500], Train Loss: 29.4285, Train RMSE: 5.4248\n",
      "Epoch [10/500], Validation Loss: 32.8128, Validation RMSE: 5.7282, Valid PR: 0.8047\n",
      "Epoch [11/500], Train Loss: 28.7987, Train RMSE: 5.3664\n",
      "Epoch [11/500], Validation Loss: 32.1645, Validation RMSE: 5.6714, Valid PR: 0.8058\n",
      "Epoch [12/500], Train Loss: 27.8465, Train RMSE: 5.2770\n",
      "Epoch [12/500], Validation Loss: 31.4765, Validation RMSE: 5.6104, Valid PR: 0.7870\n",
      "Epoch [13/500], Train Loss: 28.0123, Train RMSE: 5.2927\n",
      "Epoch [13/500], Validation Loss: 30.7691, Validation RMSE: 5.5470, Valid PR: 0.7746\n",
      "Epoch [14/500], Train Loss: 26.9923, Train RMSE: 5.1954\n",
      "Epoch [14/500], Validation Loss: 30.2558, Validation RMSE: 5.5005, Valid PR: 0.7467\n",
      "Epoch [15/500], Train Loss: 26.8335, Train RMSE: 5.1801\n",
      "Epoch [15/500], Validation Loss: 29.6693, Validation RMSE: 5.4469, Valid PR: 0.7258\n",
      "Epoch [16/500], Train Loss: 26.0899, Train RMSE: 5.1078\n",
      "Epoch [16/500], Validation Loss: 29.0533, Validation RMSE: 5.3901, Valid PR: 0.7236\n",
      "Epoch [17/500], Train Loss: 25.5886, Train RMSE: 5.0585\n",
      "Epoch [17/500], Validation Loss: 27.9549, Validation RMSE: 5.2872, Valid PR: 0.7466\n",
      "Epoch [18/500], Train Loss: 25.4249, Train RMSE: 5.0423\n",
      "Epoch [18/500], Validation Loss: 26.8770, Validation RMSE: 5.1843, Valid PR: 0.7544\n",
      "Epoch [19/500], Train Loss: 24.8869, Train RMSE: 4.9887\n",
      "Epoch [19/500], Validation Loss: 25.8599, Validation RMSE: 5.0853, Valid PR: 0.7750\n",
      "Epoch [20/500], Train Loss: 24.1271, Train RMSE: 4.9119\n",
      "Epoch [20/500], Validation Loss: 25.1164, Validation RMSE: 5.0116, Valid PR: 0.7882\n",
      "Epoch [21/500], Train Loss: 23.3850, Train RMSE: 4.8358\n",
      "Epoch [21/500], Validation Loss: 24.3341, Validation RMSE: 4.9330, Valid PR: 0.8176\n",
      "Epoch [22/500], Train Loss: 23.0922, Train RMSE: 4.8054\n",
      "Epoch [22/500], Validation Loss: 23.5289, Validation RMSE: 4.8507, Valid PR: 0.8482\n",
      "Epoch [23/500], Train Loss: 22.6215, Train RMSE: 4.7562\n",
      "Epoch [23/500], Validation Loss: 22.7613, Validation RMSE: 4.7709, Valid PR: 0.8745\n",
      "Epoch [24/500], Train Loss: 23.4677, Train RMSE: 4.8443\n",
      "Epoch [24/500], Validation Loss: 22.0590, Validation RMSE: 4.6967, Valid PR: 0.8948\n",
      "Epoch [25/500], Train Loss: 22.0008, Train RMSE: 4.6905\n",
      "Epoch [25/500], Validation Loss: 21.4775, Validation RMSE: 4.6344, Valid PR: 0.9054\n",
      "Epoch [26/500], Train Loss: 21.1184, Train RMSE: 4.5955\n",
      "Epoch [26/500], Validation Loss: 20.8072, Validation RMSE: 4.5615, Valid PR: 0.9149\n",
      "Epoch [27/500], Train Loss: 20.6211, Train RMSE: 4.5411\n",
      "Epoch [27/500], Validation Loss: 20.2549, Validation RMSE: 4.5005, Valid PR: 0.9188\n",
      "Epoch [28/500], Train Loss: 20.4192, Train RMSE: 4.5188\n",
      "Epoch [28/500], Validation Loss: 19.5521, Validation RMSE: 4.4218, Valid PR: 0.9189\n",
      "Epoch [29/500], Train Loss: 19.4231, Train RMSE: 4.4072\n",
      "Epoch [29/500], Validation Loss: 18.7466, Validation RMSE: 4.3297, Valid PR: 0.9180\n",
      "Epoch [30/500], Train Loss: 19.8981, Train RMSE: 4.4607\n",
      "Epoch [30/500], Validation Loss: 17.9605, Validation RMSE: 4.2380, Valid PR: 0.9100\n",
      "Epoch [31/500], Train Loss: 19.0962, Train RMSE: 4.3699\n",
      "Epoch [31/500], Validation Loss: 17.1612, Validation RMSE: 4.1426, Valid PR: 0.8964\n",
      "Epoch [32/500], Train Loss: 18.9305, Train RMSE: 4.3509\n",
      "Epoch [32/500], Validation Loss: 16.4381, Validation RMSE: 4.0544, Valid PR: 0.8791\n",
      "Epoch [33/500], Train Loss: 18.6852, Train RMSE: 4.3226\n",
      "Epoch [33/500], Validation Loss: 15.7252, Validation RMSE: 3.9655, Valid PR: 0.8618\n",
      "Epoch [34/500], Train Loss: 17.5830, Train RMSE: 4.1932\n",
      "Epoch [34/500], Validation Loss: 15.0956, Validation RMSE: 3.8853, Valid PR: 0.8469\n",
      "Epoch [35/500], Train Loss: 17.4952, Train RMSE: 4.1827\n",
      "Epoch [35/500], Validation Loss: 14.6072, Validation RMSE: 3.8219, Valid PR: 0.8218\n",
      "Epoch [36/500], Train Loss: 17.4229, Train RMSE: 4.1741\n",
      "Epoch [36/500], Validation Loss: 14.1255, Validation RMSE: 3.7584, Valid PR: 0.7887\n",
      "Epoch [37/500], Train Loss: 16.1058, Train RMSE: 4.0132\n",
      "Epoch [37/500], Validation Loss: 13.5866, Validation RMSE: 3.6860, Valid PR: 0.7681\n",
      "Epoch [38/500], Train Loss: 16.3371, Train RMSE: 4.0419\n",
      "Epoch [38/500], Validation Loss: 13.0838, Validation RMSE: 3.6172, Valid PR: 0.7472\n",
      "Epoch [39/500], Train Loss: 15.6731, Train RMSE: 3.9589\n",
      "Epoch [39/500], Validation Loss: 12.4921, Validation RMSE: 3.5344, Valid PR: 0.7329\n",
      "Epoch [40/500], Train Loss: 14.6795, Train RMSE: 3.8314\n",
      "Epoch [40/500], Validation Loss: 12.0920, Validation RMSE: 3.4773, Valid PR: 0.7198\n",
      "Epoch [41/500], Train Loss: 14.8727, Train RMSE: 3.8565\n",
      "Epoch [41/500], Validation Loss: 11.6574, Validation RMSE: 3.4143, Valid PR: 0.7112\n",
      "Epoch [42/500], Train Loss: 13.5887, Train RMSE: 3.6863\n",
      "Epoch [42/500], Validation Loss: 11.2322, Validation RMSE: 3.3514, Valid PR: 0.6985\n",
      "Epoch [43/500], Train Loss: 14.4185, Train RMSE: 3.7972\n",
      "Epoch [43/500], Validation Loss: 10.8908, Validation RMSE: 3.3001, Valid PR: 0.6833\n",
      "Epoch [44/500], Train Loss: 13.5993, Train RMSE: 3.6877\n",
      "Epoch [44/500], Validation Loss: 10.5204, Validation RMSE: 3.2435, Valid PR: 0.6774\n",
      "Epoch [45/500], Train Loss: 13.3873, Train RMSE: 3.6589\n",
      "Epoch [45/500], Validation Loss: 10.1492, Validation RMSE: 3.1858, Valid PR: 0.6674\n",
      "Epoch [46/500], Train Loss: 13.0855, Train RMSE: 3.6174\n",
      "Epoch [46/500], Validation Loss: 9.8180, Validation RMSE: 3.1334, Valid PR: 0.6576\n",
      "Epoch [47/500], Train Loss: 12.3299, Train RMSE: 3.5114\n",
      "Epoch [47/500], Validation Loss: 9.5068, Validation RMSE: 3.0833, Valid PR: 0.6563\n",
      "Epoch [48/500], Train Loss: 12.1651, Train RMSE: 3.4878\n",
      "Epoch [48/500], Validation Loss: 9.1762, Validation RMSE: 3.0292, Valid PR: 0.6564\n",
      "Epoch [49/500], Train Loss: 12.3328, Train RMSE: 3.5118\n",
      "Epoch [49/500], Validation Loss: 8.9074, Validation RMSE: 2.9845, Valid PR: 0.6590\n",
      "Epoch [50/500], Train Loss: 11.4892, Train RMSE: 3.3896\n",
      "Epoch [50/500], Validation Loss: 8.7095, Validation RMSE: 2.9512, Valid PR: 0.6528\n",
      "Epoch [51/500], Train Loss: 10.7847, Train RMSE: 3.2840\n",
      "Epoch [51/500], Validation Loss: 8.5397, Validation RMSE: 2.9223, Valid PR: 0.6370\n",
      "Epoch [52/500], Train Loss: 10.3750, Train RMSE: 3.2210\n",
      "Epoch [52/500], Validation Loss: 8.2925, Validation RMSE: 2.8797, Valid PR: 0.6222\n",
      "Epoch [53/500], Train Loss: 11.0328, Train RMSE: 3.3216\n",
      "Epoch [53/500], Validation Loss: 8.1031, Validation RMSE: 2.8466, Valid PR: 0.6014\n",
      "Epoch [54/500], Train Loss: 10.3378, Train RMSE: 3.2153\n",
      "Epoch [54/500], Validation Loss: 7.7796, Validation RMSE: 2.7892, Valid PR: 0.5932\n",
      "Epoch [55/500], Train Loss: 10.0857, Train RMSE: 3.1758\n",
      "Epoch [55/500], Validation Loss: 7.5330, Validation RMSE: 2.7446, Valid PR: 0.5795\n",
      "Epoch [56/500], Train Loss: 9.0826, Train RMSE: 3.0137\n",
      "Epoch [56/500], Validation Loss: 7.4487, Validation RMSE: 2.7292, Valid PR: 0.5601\n",
      "Epoch [57/500], Train Loss: 8.6780, Train RMSE: 2.9458\n",
      "Epoch [57/500], Validation Loss: 7.3471, Validation RMSE: 2.7106, Valid PR: 0.5414\n",
      "Epoch [58/500], Train Loss: 9.0357, Train RMSE: 3.0059\n",
      "Epoch [58/500], Validation Loss: 7.1796, Validation RMSE: 2.6795, Valid PR: 0.5331\n",
      "Epoch [59/500], Train Loss: 8.2246, Train RMSE: 2.8679\n",
      "Epoch [59/500], Validation Loss: 7.0182, Validation RMSE: 2.6492, Valid PR: 0.5270\n",
      "Epoch [60/500], Train Loss: 7.5922, Train RMSE: 2.7554\n",
      "Epoch [60/500], Validation Loss: 6.8308, Validation RMSE: 2.6136, Valid PR: 0.5305\n",
      "Epoch [61/500], Train Loss: 8.5888, Train RMSE: 2.9307\n",
      "Epoch [61/500], Validation Loss: 6.6717, Validation RMSE: 2.5830, Valid PR: 0.5284\n",
      "Epoch [62/500], Train Loss: 8.2112, Train RMSE: 2.8655\n",
      "Epoch [62/500], Validation Loss: 6.6368, Validation RMSE: 2.5762, Valid PR: 0.5113\n",
      "Epoch [63/500], Train Loss: 7.2253, Train RMSE: 2.6880\n",
      "Epoch [63/500], Validation Loss: 6.6459, Validation RMSE: 2.5780, Valid PR: 0.4874\n",
      "Epoch [64/500], Train Loss: 7.6194, Train RMSE: 2.7603\n",
      "Epoch [64/500], Validation Loss: 6.5814, Validation RMSE: 2.5654, Valid PR: 0.4764\n",
      "Epoch [65/500], Train Loss: 7.7428, Train RMSE: 2.7826\n",
      "Epoch [65/500], Validation Loss: 6.4501, Validation RMSE: 2.5397, Valid PR: 0.4618\n",
      "Epoch [66/500], Train Loss: 7.0056, Train RMSE: 2.6468\n",
      "Epoch [66/500], Validation Loss: 6.1629, Validation RMSE: 2.4825, Valid PR: 0.4795\n",
      "Epoch [67/500], Train Loss: 5.6956, Train RMSE: 2.3865\n",
      "Epoch [67/500], Validation Loss: 5.9058, Validation RMSE: 2.4302, Valid PR: 0.4888\n",
      "Epoch [68/500], Train Loss: 6.2179, Train RMSE: 2.4936\n",
      "Epoch [68/500], Validation Loss: 5.7315, Validation RMSE: 2.3941, Valid PR: 0.5004\n",
      "Epoch [69/500], Train Loss: 5.8218, Train RMSE: 2.4128\n",
      "Epoch [69/500], Validation Loss: 5.4346, Validation RMSE: 2.3312, Valid PR: 0.5255\n",
      "Epoch [70/500], Train Loss: 7.0588, Train RMSE: 2.6568\n",
      "Epoch [70/500], Validation Loss: 5.1601, Validation RMSE: 2.2716, Valid PR: 0.5442\n",
      "Epoch [71/500], Train Loss: 5.4571, Train RMSE: 2.3360\n",
      "Epoch [71/500], Validation Loss: 4.9131, Validation RMSE: 2.2166, Valid PR: 0.5623\n",
      "Epoch [72/500], Train Loss: 5.9303, Train RMSE: 2.4352\n",
      "Epoch [72/500], Validation Loss: 4.5857, Validation RMSE: 2.1414, Valid PR: 0.5740\n",
      "Epoch [73/500], Train Loss: 5.7287, Train RMSE: 2.3935\n",
      "Epoch [73/500], Validation Loss: 4.3012, Validation RMSE: 2.0739, Valid PR: 0.5903\n",
      "Epoch [74/500], Train Loss: 5.4591, Train RMSE: 2.3365\n",
      "Epoch [74/500], Validation Loss: 4.0092, Validation RMSE: 2.0023, Valid PR: 0.6040\n",
      "Epoch [75/500], Train Loss: 5.4491, Train RMSE: 2.3343\n",
      "Epoch [75/500], Validation Loss: 3.6041, Validation RMSE: 1.8984, Valid PR: 0.6270\n",
      "Epoch [76/500], Train Loss: 4.8870, Train RMSE: 2.2106\n",
      "Epoch [76/500], Validation Loss: 3.3128, Validation RMSE: 1.8201, Valid PR: 0.6400\n",
      "Epoch [77/500], Train Loss: 4.0803, Train RMSE: 2.0200\n",
      "Epoch [77/500], Validation Loss: 3.1335, Validation RMSE: 1.7702, Valid PR: 0.6343\n",
      "Epoch [78/500], Train Loss: 5.0447, Train RMSE: 2.2460\n",
      "Epoch [78/500], Validation Loss: 3.0133, Validation RMSE: 1.7359, Valid PR: 0.6289\n",
      "Epoch [79/500], Train Loss: 5.2507, Train RMSE: 2.2914\n",
      "Epoch [79/500], Validation Loss: 2.9305, Validation RMSE: 1.7119, Valid PR: 0.6272\n",
      "Epoch [80/500], Train Loss: 4.5089, Train RMSE: 2.1234\n",
      "Epoch [80/500], Validation Loss: 2.8887, Validation RMSE: 1.6996, Valid PR: 0.6252\n",
      "Epoch [81/500], Train Loss: 4.4473, Train RMSE: 2.1089\n",
      "Epoch [81/500], Validation Loss: 2.8602, Validation RMSE: 1.6912, Valid PR: 0.6269\n",
      "Epoch [82/500], Train Loss: 4.3582, Train RMSE: 2.0876\n",
      "Epoch [82/500], Validation Loss: 2.7558, Validation RMSE: 1.6601, Valid PR: 0.6305\n",
      "Epoch [83/500], Train Loss: 4.0003, Train RMSE: 2.0001\n",
      "Epoch [83/500], Validation Loss: 2.7593, Validation RMSE: 1.6611, Valid PR: 0.6136\n",
      "Epoch [84/500], Train Loss: 3.5216, Train RMSE: 1.8766\n",
      "Epoch [84/500], Validation Loss: 2.7084, Validation RMSE: 1.6457, Valid PR: 0.5832\n",
      "Epoch [85/500], Train Loss: 4.2686, Train RMSE: 2.0661\n",
      "Epoch [85/500], Validation Loss: 2.6278, Validation RMSE: 1.6211, Valid PR: 0.5403\n",
      "Epoch [86/500], Train Loss: 3.5164, Train RMSE: 1.8752\n",
      "Epoch [86/500], Validation Loss: 2.6344, Validation RMSE: 1.6231, Valid PR: 0.4840\n",
      "Epoch [87/500], Train Loss: 3.1533, Train RMSE: 1.7758\n",
      "Epoch [87/500], Validation Loss: 2.6350, Validation RMSE: 1.6233, Valid PR: 0.4312\n",
      "Epoch [88/500], Train Loss: 3.1219, Train RMSE: 1.7669\n",
      "Epoch [88/500], Validation Loss: 2.6348, Validation RMSE: 1.6232, Valid PR: 0.3523\n",
      "Epoch [89/500], Train Loss: 4.2242, Train RMSE: 2.0553\n",
      "Epoch [89/500], Validation Loss: 2.6954, Validation RMSE: 1.6418, Valid PR: 0.2588\n",
      "Epoch [90/500], Train Loss: 3.3089, Train RMSE: 1.8190\n",
      "Epoch [90/500], Validation Loss: 2.8060, Validation RMSE: 1.6751, Valid PR: 0.1501\n",
      "Epoch [91/500], Train Loss: 3.3672, Train RMSE: 1.8350\n",
      "Epoch [91/500], Validation Loss: 3.0072, Validation RMSE: 1.7341, Valid PR: 0.0078\n",
      "Epoch [92/500], Train Loss: 2.9298, Train RMSE: 1.7117\n",
      "Epoch [92/500], Validation Loss: 3.2107, Validation RMSE: 1.7918, Valid PR: -0.1179\n",
      "Epoch [93/500], Train Loss: 2.3254, Train RMSE: 1.5249\n",
      "Epoch [93/500], Validation Loss: 3.4309, Validation RMSE: 1.8523, Valid PR: -0.2242\n",
      "Epoch [94/500], Train Loss: 2.5477, Train RMSE: 1.5962\n",
      "Epoch [94/500], Validation Loss: 3.6818, Validation RMSE: 1.9188, Valid PR: -0.3436\n",
      "Epoch [95/500], Train Loss: 2.7601, Train RMSE: 1.6613\n",
      "Epoch [95/500], Validation Loss: 3.7899, Validation RMSE: 1.9468, Valid PR: -0.4080\n",
      "Epoch [96/500], Train Loss: 3.1485, Train RMSE: 1.7744\n",
      "Epoch [96/500], Validation Loss: 3.8549, Validation RMSE: 1.9634, Valid PR: -0.4508\n",
      "Epoch [97/500], Train Loss: 3.3467, Train RMSE: 1.8294\n",
      "Epoch [97/500], Validation Loss: 3.8467, Validation RMSE: 1.9613, Valid PR: -0.4719\n",
      "Epoch [98/500], Train Loss: 2.7841, Train RMSE: 1.6686\n",
      "Epoch [98/500], Validation Loss: 3.8310, Validation RMSE: 1.9573, Valid PR: -0.4803\n",
      "Epoch [99/500], Train Loss: 3.1535, Train RMSE: 1.7758\n",
      "Epoch [99/500], Validation Loss: 3.7573, Validation RMSE: 1.9384, Valid PR: -0.4488\n",
      "Epoch [100/500], Train Loss: 2.8132, Train RMSE: 1.6773\n",
      "Epoch [100/500], Validation Loss: 3.6345, Validation RMSE: 1.9064, Valid PR: -0.3849\n",
      "Epoch [101/500], Train Loss: 3.6207, Train RMSE: 1.9028\n",
      "Epoch [101/500], Validation Loss: 3.4550, Validation RMSE: 1.8587, Valid PR: -0.2995\n",
      "Epoch [102/500], Train Loss: 2.8900, Train RMSE: 1.7000\n",
      "Epoch [102/500], Validation Loss: 3.2719, Validation RMSE: 1.8088, Valid PR: -0.2127\n",
      "Epoch [103/500], Train Loss: 2.5989, Train RMSE: 1.6121\n",
      "Epoch [103/500], Validation Loss: 3.1757, Validation RMSE: 1.7820, Valid PR: -0.1749\n",
      "Epoch [104/500], Train Loss: 2.8541, Train RMSE: 1.6894\n",
      "Epoch [104/500], Validation Loss: 3.1111, Validation RMSE: 1.7638, Valid PR: -0.1469\n",
      "Epoch [105/500], Train Loss: 2.3265, Train RMSE: 1.5253\n",
      "Epoch [105/500], Validation Loss: 3.0999, Validation RMSE: 1.7606, Valid PR: -0.1413\n",
      "Epoch [106/500], Train Loss: 3.0363, Train RMSE: 1.7425\n",
      "Epoch [106/500], Validation Loss: 3.0904, Validation RMSE: 1.7579, Valid PR: -0.1376\n",
      "Epoch [107/500], Train Loss: 3.6452, Train RMSE: 1.9092\n",
      "Epoch [107/500], Validation Loss: 3.1648, Validation RMSE: 1.7790, Valid PR: -0.1558\n",
      "Epoch [108/500], Train Loss: 2.4957, Train RMSE: 1.5798\n",
      "Epoch [108/500], Validation Loss: 3.1787, Validation RMSE: 1.7829, Valid PR: -0.1416\n",
      "Epoch [109/500], Train Loss: 2.5557, Train RMSE: 1.5987\n",
      "Epoch [109/500], Validation Loss: 3.1739, Validation RMSE: 1.7816, Valid PR: -0.1333\n",
      "Epoch [110/500], Train Loss: 2.8382, Train RMSE: 1.6847\n",
      "Epoch [110/500], Validation Loss: 3.1525, Validation RMSE: 1.7755, Valid PR: -0.1282\n",
      "Epoch [111/500], Train Loss: 2.7934, Train RMSE: 1.6713\n",
      "Epoch [111/500], Validation Loss: 2.9057, Validation RMSE: 1.7046, Valid PR: -0.0510\n",
      "Epoch [112/500], Train Loss: 2.7056, Train RMSE: 1.6449\n",
      "Epoch [112/500], Validation Loss: 2.8649, Validation RMSE: 1.6926, Valid PR: -0.0318\n",
      "Epoch [113/500], Train Loss: 2.8353, Train RMSE: 1.6838\n",
      "Epoch [113/500], Validation Loss: 2.8381, Validation RMSE: 1.6847, Valid PR: -0.0080\n",
      "Epoch [114/500], Train Loss: 2.7770, Train RMSE: 1.6664\n",
      "Epoch [114/500], Validation Loss: 2.7121, Validation RMSE: 1.6469, Valid PR: 0.0549\n",
      "Epoch [115/500], Train Loss: 2.4353, Train RMSE: 1.5605\n",
      "Epoch [115/500], Validation Loss: 2.7110, Validation RMSE: 1.6465, Valid PR: 0.0917\n",
      "Epoch [116/500], Train Loss: 2.7693, Train RMSE: 1.6641\n",
      "Epoch [116/500], Validation Loss: 2.6353, Validation RMSE: 1.6233, Valid PR: 0.1514\n",
      "Epoch [117/500], Train Loss: 3.0576, Train RMSE: 1.7486\n",
      "Epoch [117/500], Validation Loss: 2.7412, Validation RMSE: 1.6557, Valid PR: 0.1295\n",
      "Epoch [118/500], Train Loss: 2.8735, Train RMSE: 1.6951\n",
      "Epoch [118/500], Validation Loss: 2.7656, Validation RMSE: 1.6630, Valid PR: 0.1549\n",
      "Epoch [119/500], Train Loss: 3.0451, Train RMSE: 1.7450\n",
      "Epoch [119/500], Validation Loss: 2.7443, Validation RMSE: 1.6566, Valid PR: 0.1594\n",
      "Epoch [120/500], Train Loss: 2.8703, Train RMSE: 1.6942\n",
      "Epoch [120/500], Validation Loss: 2.9376, Validation RMSE: 1.7139, Valid PR: 0.1019\n",
      "Epoch [121/500], Train Loss: 2.6536, Train RMSE: 1.6290\n",
      "Epoch [121/500], Validation Loss: 3.0366, Validation RMSE: 1.7426, Valid PR: 0.0809\n",
      "Epoch [122/500], Train Loss: 3.0249, Train RMSE: 1.7392\n",
      "Epoch [122/500], Validation Loss: 3.0692, Validation RMSE: 1.7519, Valid PR: 0.0769\n",
      "Epoch [123/500], Train Loss: 2.7494, Train RMSE: 1.6581\n",
      "Epoch [123/500], Validation Loss: 3.0262, Validation RMSE: 1.7396, Valid PR: 0.0813\n",
      "Epoch [124/500], Train Loss: 2.7572, Train RMSE: 1.6605\n",
      "Epoch [124/500], Validation Loss: 2.9975, Validation RMSE: 1.7313, Valid PR: 0.0859\n",
      "Epoch [125/500], Train Loss: 2.3905, Train RMSE: 1.5461\n",
      "Epoch [125/500], Validation Loss: 3.0689, Validation RMSE: 1.7518, Valid PR: 0.0581\n",
      "Epoch [126/500], Train Loss: 3.1012, Train RMSE: 1.7610\n",
      "Epoch [126/500], Validation Loss: 3.0867, Validation RMSE: 1.7569, Valid PR: 0.0166\n",
      "Epoch [127/500], Train Loss: 3.2698, Train RMSE: 1.8083\n",
      "Epoch [127/500], Validation Loss: 2.9316, Validation RMSE: 1.7122, Valid PR: 0.0158\n",
      "Epoch [128/500], Train Loss: 3.2378, Train RMSE: 1.7994\n",
      "Epoch [128/500], Validation Loss: 3.0420, Validation RMSE: 1.7441, Valid PR: -0.0591\n",
      "Epoch [129/500], Train Loss: 2.9968, Train RMSE: 1.7311\n",
      "Epoch [129/500], Validation Loss: 3.0997, Validation RMSE: 1.7606, Valid PR: -0.1349\n",
      "Epoch [130/500], Train Loss: 2.9927, Train RMSE: 1.7299\n",
      "Epoch [130/500], Validation Loss: 3.3730, Validation RMSE: 1.8366, Valid PR: -0.2390\n",
      "Epoch [131/500], Train Loss: 2.8132, Train RMSE: 1.6773\n",
      "Epoch [131/500], Validation Loss: 3.6296, Validation RMSE: 1.9052, Valid PR: -0.3288\n",
      "Epoch [132/500], Train Loss: 2.5039, Train RMSE: 1.5824\n",
      "Epoch [132/500], Validation Loss: 4.0148, Validation RMSE: 2.0037, Valid PR: -0.3968\n",
      "Epoch [133/500], Train Loss: 2.3895, Train RMSE: 1.5458\n",
      "Epoch [133/500], Validation Loss: 4.6086, Validation RMSE: 2.1468, Valid PR: -0.4386\n",
      "Epoch [134/500], Train Loss: 2.4506, Train RMSE: 1.5654\n",
      "Epoch [134/500], Validation Loss: 5.2042, Validation RMSE: 2.2813, Valid PR: -0.4274\n",
      "Epoch [135/500], Train Loss: 2.7429, Train RMSE: 1.6562\n",
      "Epoch [135/500], Validation Loss: 5.4012, Validation RMSE: 2.3240, Valid PR: -0.4502\n",
      "Early stopping triggered.\n",
      "Test Loss: 7.1917, Test RMSE: 2.6817, Test PR: -0.2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3123897583.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/scratch/local/51712327/ipykernel_500297/3123897583.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.5228, Test RMSE: 2.1267, Test PR: -0.1722\n",
      "Testing method3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3123897583.py:109: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 38.6536, Train RMSE: 6.2172\n",
      "Epoch [1/500], Validation Loss: 22.5266, Validation RMSE: 4.7462, Valid PR: 0.5467\n",
      "Epoch [2/500], Train Loss: 38.1707, Train RMSE: 6.1782\n",
      "Epoch [2/500], Validation Loss: 33.9028, Validation RMSE: 5.8226, Valid PR: 0.6741\n",
      "Epoch [3/500], Train Loss: 37.0459, Train RMSE: 6.0865\n",
      "Epoch [3/500], Validation Loss: 33.3722, Validation RMSE: 5.7769, Valid PR: -0.4898\n",
      "Epoch [4/500], Train Loss: 37.0268, Train RMSE: 6.0850\n",
      "Epoch [4/500], Validation Loss: 31.7164, Validation RMSE: 5.6317, Valid PR: -0.5392\n",
      "Epoch [5/500], Train Loss: 35.7630, Train RMSE: 5.9802\n",
      "Epoch [5/500], Validation Loss: 32.1879, Validation RMSE: 5.6734, Valid PR: -0.5460\n",
      "Epoch [6/500], Train Loss: 34.9689, Train RMSE: 5.9135\n",
      "Epoch [6/500], Validation Loss: 33.4453, Validation RMSE: 5.7832, Valid PR: -0.5536\n",
      "Epoch [7/500], Train Loss: 34.4079, Train RMSE: 5.8658\n",
      "Epoch [7/500], Validation Loss: 34.8533, Validation RMSE: 5.9037, Valid PR: -0.5352\n",
      "Epoch [8/500], Train Loss: 34.0033, Train RMSE: 5.8312\n",
      "Epoch [8/500], Validation Loss: 36.2044, Validation RMSE: 6.0170, Valid PR: -0.5294\n",
      "Epoch [9/500], Train Loss: 32.5688, Train RMSE: 5.7069\n",
      "Epoch [9/500], Validation Loss: 37.5171, Validation RMSE: 6.1251, Valid PR: -0.5213\n",
      "Epoch [10/500], Train Loss: 32.1061, Train RMSE: 5.6662\n",
      "Epoch [10/500], Validation Loss: 37.9015, Validation RMSE: 6.1564, Valid PR: -0.5299\n",
      "Epoch [11/500], Train Loss: 32.3553, Train RMSE: 5.6882\n",
      "Epoch [11/500], Validation Loss: 37.9578, Validation RMSE: 6.1610, Valid PR: -0.5359\n",
      "Epoch [12/500], Train Loss: 30.6603, Train RMSE: 5.5372\n",
      "Epoch [12/500], Validation Loss: 37.0221, Validation RMSE: 6.0846, Valid PR: -0.5269\n",
      "Epoch [13/500], Train Loss: 30.7212, Train RMSE: 5.5427\n",
      "Epoch [13/500], Validation Loss: 35.5844, Validation RMSE: 5.9653, Valid PR: -0.5158\n",
      "Epoch [14/500], Train Loss: 29.5901, Train RMSE: 5.4397\n",
      "Epoch [14/500], Validation Loss: 34.7609, Validation RMSE: 5.8958, Valid PR: -0.5097\n",
      "Epoch [15/500], Train Loss: 29.3286, Train RMSE: 5.4156\n",
      "Epoch [15/500], Validation Loss: 34.0716, Validation RMSE: 5.8371, Valid PR: -0.5200\n",
      "Epoch [16/500], Train Loss: 28.3220, Train RMSE: 5.3218\n",
      "Epoch [16/500], Validation Loss: 33.0661, Validation RMSE: 5.7503, Valid PR: -0.5353\n",
      "Epoch [17/500], Train Loss: 27.9133, Train RMSE: 5.2833\n",
      "Epoch [17/500], Validation Loss: 32.2323, Validation RMSE: 5.6773, Valid PR: -0.5488\n",
      "Epoch [18/500], Train Loss: 27.8285, Train RMSE: 5.2753\n",
      "Epoch [18/500], Validation Loss: 30.8144, Validation RMSE: 5.5511, Valid PR: -0.5656\n",
      "Epoch [19/500], Train Loss: 27.7196, Train RMSE: 5.2649\n",
      "Epoch [19/500], Validation Loss: 29.7642, Validation RMSE: 5.4557, Valid PR: -0.5545\n",
      "Epoch [20/500], Train Loss: 27.1294, Train RMSE: 5.2086\n",
      "Epoch [20/500], Validation Loss: 29.0082, Validation RMSE: 5.3859, Valid PR: -0.5300\n",
      "Epoch [21/500], Train Loss: 26.1816, Train RMSE: 5.1168\n",
      "Epoch [21/500], Validation Loss: 28.3415, Validation RMSE: 5.3237, Valid PR: -0.4978\n",
      "Epoch [22/500], Train Loss: 25.8667, Train RMSE: 5.0859\n",
      "Epoch [22/500], Validation Loss: 27.4757, Validation RMSE: 5.2417, Valid PR: -0.4912\n",
      "Epoch [23/500], Train Loss: 25.3423, Train RMSE: 5.0341\n",
      "Epoch [23/500], Validation Loss: 26.4540, Validation RMSE: 5.1433, Valid PR: -0.4933\n",
      "Epoch [24/500], Train Loss: 24.5547, Train RMSE: 4.9553\n",
      "Epoch [24/500], Validation Loss: 25.4925, Validation RMSE: 5.0490, Valid PR: -0.4965\n",
      "Epoch [25/500], Train Loss: 24.7373, Train RMSE: 4.9737\n",
      "Epoch [25/500], Validation Loss: 24.5510, Validation RMSE: 4.9549, Valid PR: -0.5155\n",
      "Epoch [26/500], Train Loss: 23.6223, Train RMSE: 4.8603\n",
      "Epoch [26/500], Validation Loss: 23.9440, Validation RMSE: 4.8933, Valid PR: -0.5100\n",
      "Epoch [27/500], Train Loss: 22.9176, Train RMSE: 4.7872\n",
      "Epoch [27/500], Validation Loss: 23.2389, Validation RMSE: 4.8207, Valid PR: -0.4971\n",
      "Epoch [28/500], Train Loss: 23.3950, Train RMSE: 4.8368\n",
      "Epoch [28/500], Validation Loss: 22.5666, Validation RMSE: 4.7504, Valid PR: -0.4429\n",
      "Epoch [29/500], Train Loss: 22.0465, Train RMSE: 4.6954\n",
      "Epoch [29/500], Validation Loss: 21.9397, Validation RMSE: 4.6840, Valid PR: -0.3920\n",
      "Epoch [30/500], Train Loss: 21.3446, Train RMSE: 4.6200\n",
      "Epoch [30/500], Validation Loss: 21.2597, Validation RMSE: 4.6108, Valid PR: -0.3260\n",
      "Epoch [31/500], Train Loss: 21.4538, Train RMSE: 4.6318\n",
      "Epoch [31/500], Validation Loss: 20.5523, Validation RMSE: 4.5335, Valid PR: -0.2373\n",
      "Epoch [32/500], Train Loss: 21.0693, Train RMSE: 4.5901\n",
      "Epoch [32/500], Validation Loss: 19.8621, Validation RMSE: 4.4567, Valid PR: -0.1469\n",
      "Epoch [33/500], Train Loss: 20.2282, Train RMSE: 4.4976\n",
      "Epoch [33/500], Validation Loss: 19.2813, Validation RMSE: 4.3910, Valid PR: -0.0597\n",
      "Epoch [34/500], Train Loss: 20.2378, Train RMSE: 4.4986\n",
      "Epoch [34/500], Validation Loss: 18.6228, Validation RMSE: 4.3154, Valid PR: 0.0143\n",
      "Epoch [35/500], Train Loss: 20.7227, Train RMSE: 4.5522\n",
      "Epoch [35/500], Validation Loss: 18.0416, Validation RMSE: 4.2475, Valid PR: 0.0645\n",
      "Epoch [36/500], Train Loss: 19.0783, Train RMSE: 4.3679\n",
      "Epoch [36/500], Validation Loss: 17.4202, Validation RMSE: 4.1737, Valid PR: 0.1213\n",
      "Epoch [37/500], Train Loss: 18.1402, Train RMSE: 4.2591\n",
      "Epoch [37/500], Validation Loss: 16.9259, Validation RMSE: 4.1141, Valid PR: 0.1332\n",
      "Epoch [38/500], Train Loss: 18.4936, Train RMSE: 4.3004\n",
      "Epoch [38/500], Validation Loss: 16.4213, Validation RMSE: 4.0523, Valid PR: 0.1715\n",
      "Epoch [39/500], Train Loss: 18.1600, Train RMSE: 4.2615\n",
      "Epoch [39/500], Validation Loss: 16.0866, Validation RMSE: 4.0108, Valid PR: 0.2127\n",
      "Epoch [40/500], Train Loss: 17.2672, Train RMSE: 4.1554\n",
      "Epoch [40/500], Validation Loss: 15.6933, Validation RMSE: 3.9615, Valid PR: 0.2441\n",
      "Epoch [41/500], Train Loss: 17.7594, Train RMSE: 4.2142\n",
      "Epoch [41/500], Validation Loss: 15.2130, Validation RMSE: 3.9004, Valid PR: 0.2889\n",
      "Epoch [42/500], Train Loss: 17.0825, Train RMSE: 4.1331\n",
      "Epoch [42/500], Validation Loss: 14.7912, Validation RMSE: 3.8459, Valid PR: 0.3303\n",
      "Epoch [43/500], Train Loss: 15.9757, Train RMSE: 3.9970\n",
      "Epoch [43/500], Validation Loss: 14.4818, Validation RMSE: 3.8055, Valid PR: 0.3632\n",
      "Epoch [44/500], Train Loss: 15.9681, Train RMSE: 3.9960\n",
      "Epoch [44/500], Validation Loss: 14.1471, Validation RMSE: 3.7613, Valid PR: 0.3695\n",
      "Epoch [45/500], Train Loss: 15.9222, Train RMSE: 3.9903\n",
      "Epoch [45/500], Validation Loss: 13.7431, Validation RMSE: 3.7072, Valid PR: 0.3643\n",
      "Epoch [46/500], Train Loss: 15.4392, Train RMSE: 3.9293\n",
      "Epoch [46/500], Validation Loss: 13.4906, Validation RMSE: 3.6730, Valid PR: 0.3506\n",
      "Epoch [47/500], Train Loss: 14.9246, Train RMSE: 3.8632\n",
      "Epoch [47/500], Validation Loss: 13.2793, Validation RMSE: 3.6441, Valid PR: 0.3422\n",
      "Epoch [48/500], Train Loss: 13.9953, Train RMSE: 3.7410\n",
      "Epoch [48/500], Validation Loss: 12.9813, Validation RMSE: 3.6030, Valid PR: 0.3362\n",
      "Epoch [49/500], Train Loss: 13.5276, Train RMSE: 3.6780\n",
      "Epoch [49/500], Validation Loss: 12.7008, Validation RMSE: 3.5638, Valid PR: 0.3314\n",
      "Epoch [50/500], Train Loss: 14.0690, Train RMSE: 3.7509\n",
      "Epoch [50/500], Validation Loss: 12.4539, Validation RMSE: 3.5290, Valid PR: 0.3366\n",
      "Epoch [51/500], Train Loss: 14.6016, Train RMSE: 3.8212\n",
      "Epoch [51/500], Validation Loss: 12.2780, Validation RMSE: 3.5040, Valid PR: 0.3522\n",
      "Epoch [52/500], Train Loss: 13.1591, Train RMSE: 3.6276\n",
      "Epoch [52/500], Validation Loss: 12.0627, Validation RMSE: 3.4731, Valid PR: 0.3783\n",
      "Epoch [53/500], Train Loss: 12.6943, Train RMSE: 3.5629\n",
      "Epoch [53/500], Validation Loss: 11.8347, Validation RMSE: 3.4402, Valid PR: 0.4032\n",
      "Epoch [54/500], Train Loss: 12.1300, Train RMSE: 3.4828\n",
      "Epoch [54/500], Validation Loss: 11.5739, Validation RMSE: 3.4020, Valid PR: 0.4238\n",
      "Epoch [55/500], Train Loss: 12.7111, Train RMSE: 3.5653\n",
      "Epoch [55/500], Validation Loss: 11.3430, Validation RMSE: 3.3679, Valid PR: 0.4311\n",
      "Epoch [56/500], Train Loss: 11.9278, Train RMSE: 3.4537\n",
      "Epoch [56/500], Validation Loss: 11.0404, Validation RMSE: 3.3227, Valid PR: 0.4406\n",
      "Epoch [57/500], Train Loss: 10.8156, Train RMSE: 3.2887\n",
      "Epoch [57/500], Validation Loss: 10.6958, Validation RMSE: 3.2704, Valid PR: 0.4524\n",
      "Epoch [58/500], Train Loss: 10.6963, Train RMSE: 3.2705\n",
      "Epoch [58/500], Validation Loss: 10.3826, Validation RMSE: 3.2222, Valid PR: 0.4613\n",
      "Epoch [59/500], Train Loss: 11.7414, Train RMSE: 3.4266\n",
      "Epoch [59/500], Validation Loss: 10.0378, Validation RMSE: 3.1682, Valid PR: 0.4826\n",
      "Epoch [60/500], Train Loss: 10.3512, Train RMSE: 3.2173\n",
      "Epoch [60/500], Validation Loss: 9.7285, Validation RMSE: 3.1191, Valid PR: 0.5021\n",
      "Epoch [61/500], Train Loss: 10.3242, Train RMSE: 3.2131\n",
      "Epoch [61/500], Validation Loss: 9.4085, Validation RMSE: 3.0673, Valid PR: 0.5157\n",
      "Epoch [62/500], Train Loss: 9.2905, Train RMSE: 3.0480\n",
      "Epoch [62/500], Validation Loss: 9.1620, Validation RMSE: 3.0269, Valid PR: 0.5149\n",
      "Epoch [63/500], Train Loss: 9.7367, Train RMSE: 3.1204\n",
      "Epoch [63/500], Validation Loss: 8.8992, Validation RMSE: 2.9831, Valid PR: 0.5072\n",
      "Epoch [64/500], Train Loss: 8.6048, Train RMSE: 2.9334\n",
      "Epoch [64/500], Validation Loss: 8.6593, Validation RMSE: 2.9427, Valid PR: 0.4822\n",
      "Epoch [65/500], Train Loss: 9.4140, Train RMSE: 3.0682\n",
      "Epoch [65/500], Validation Loss: 8.4250, Validation RMSE: 2.9026, Valid PR: 0.4432\n",
      "Epoch [66/500], Train Loss: 8.2030, Train RMSE: 2.8641\n",
      "Epoch [66/500], Validation Loss: 8.1801, Validation RMSE: 2.8601, Valid PR: 0.4260\n",
      "Epoch [67/500], Train Loss: 8.9134, Train RMSE: 2.9855\n",
      "Epoch [67/500], Validation Loss: 7.9149, Validation RMSE: 2.8133, Valid PR: 0.4090\n",
      "Epoch [68/500], Train Loss: 8.2235, Train RMSE: 2.8677\n",
      "Epoch [68/500], Validation Loss: 7.7093, Validation RMSE: 2.7766, Valid PR: 0.3891\n",
      "Epoch [69/500], Train Loss: 7.6711, Train RMSE: 2.7697\n",
      "Epoch [69/500], Validation Loss: 7.5714, Validation RMSE: 2.7516, Valid PR: 0.3839\n",
      "Epoch [70/500], Train Loss: 8.6263, Train RMSE: 2.9371\n",
      "Epoch [70/500], Validation Loss: 7.4254, Validation RMSE: 2.7250, Valid PR: 0.3846\n",
      "Epoch [71/500], Train Loss: 7.4349, Train RMSE: 2.7267\n",
      "Epoch [71/500], Validation Loss: 7.2851, Validation RMSE: 2.6991, Valid PR: 0.3899\n",
      "Epoch [72/500], Train Loss: 7.2296, Train RMSE: 2.6888\n",
      "Epoch [72/500], Validation Loss: 7.1405, Validation RMSE: 2.6722, Valid PR: 0.3816\n",
      "Epoch [73/500], Train Loss: 6.4187, Train RMSE: 2.5335\n",
      "Epoch [73/500], Validation Loss: 6.9847, Validation RMSE: 2.6429, Valid PR: 0.3740\n",
      "Epoch [74/500], Train Loss: 6.8988, Train RMSE: 2.6266\n",
      "Epoch [74/500], Validation Loss: 6.8865, Validation RMSE: 2.6242, Valid PR: 0.3728\n",
      "Epoch [75/500], Train Loss: 6.2115, Train RMSE: 2.4923\n",
      "Epoch [75/500], Validation Loss: 6.7631, Validation RMSE: 2.6006, Valid PR: 0.3628\n",
      "Epoch [76/500], Train Loss: 6.6351, Train RMSE: 2.5759\n",
      "Epoch [76/500], Validation Loss: 6.6967, Validation RMSE: 2.5878, Valid PR: 0.3476\n",
      "Epoch [77/500], Train Loss: 6.7422, Train RMSE: 2.5966\n",
      "Epoch [77/500], Validation Loss: 6.5796, Validation RMSE: 2.5651, Valid PR: 0.3392\n",
      "Epoch [78/500], Train Loss: 5.9737, Train RMSE: 2.4441\n",
      "Epoch [78/500], Validation Loss: 6.4965, Validation RMSE: 2.5488, Valid PR: 0.3381\n",
      "Epoch [79/500], Train Loss: 6.8592, Train RMSE: 2.6190\n",
      "Epoch [79/500], Validation Loss: 6.4285, Validation RMSE: 2.5354, Valid PR: 0.3270\n",
      "Epoch [80/500], Train Loss: 6.3693, Train RMSE: 2.5238\n",
      "Epoch [80/500], Validation Loss: 6.3365, Validation RMSE: 2.5172, Valid PR: 0.3053\n",
      "Epoch [81/500], Train Loss: 5.4656, Train RMSE: 2.3379\n",
      "Epoch [81/500], Validation Loss: 6.2328, Validation RMSE: 2.4965, Valid PR: 0.3025\n",
      "Epoch [82/500], Train Loss: 4.9873, Train RMSE: 2.2332\n",
      "Epoch [82/500], Validation Loss: 6.1185, Validation RMSE: 2.4736, Valid PR: 0.3007\n",
      "Epoch [83/500], Train Loss: 5.0142, Train RMSE: 2.2392\n",
      "Epoch [83/500], Validation Loss: 5.9826, Validation RMSE: 2.4459, Valid PR: 0.3009\n",
      "Epoch [84/500], Train Loss: 6.1205, Train RMSE: 2.4740\n",
      "Epoch [84/500], Validation Loss: 5.8661, Validation RMSE: 2.4220, Valid PR: 0.2988\n",
      "Epoch [85/500], Train Loss: 5.0522, Train RMSE: 2.2477\n",
      "Epoch [85/500], Validation Loss: 5.7690, Validation RMSE: 2.4019, Valid PR: 0.2869\n",
      "Epoch [86/500], Train Loss: 5.9685, Train RMSE: 2.4430\n",
      "Epoch [86/500], Validation Loss: 5.6817, Validation RMSE: 2.3836, Valid PR: 0.2762\n",
      "Epoch [87/500], Train Loss: 4.7914, Train RMSE: 2.1889\n",
      "Epoch [87/500], Validation Loss: 5.5427, Validation RMSE: 2.3543, Valid PR: 0.2817\n",
      "Epoch [88/500], Train Loss: 4.7646, Train RMSE: 2.1828\n",
      "Epoch [88/500], Validation Loss: 5.2975, Validation RMSE: 2.3016, Valid PR: 0.2977\n",
      "Epoch [89/500], Train Loss: 5.2130, Train RMSE: 2.2832\n",
      "Epoch [89/500], Validation Loss: 5.0568, Validation RMSE: 2.2487, Valid PR: 0.3105\n",
      "Epoch [90/500], Train Loss: 4.4591, Train RMSE: 2.1116\n",
      "Epoch [90/500], Validation Loss: 4.8340, Validation RMSE: 2.1986, Valid PR: 0.3168\n",
      "Epoch [91/500], Train Loss: 4.8932, Train RMSE: 2.2121\n",
      "Epoch [91/500], Validation Loss: 4.5917, Validation RMSE: 2.1428, Valid PR: 0.2825\n",
      "Epoch [92/500], Train Loss: 3.9371, Train RMSE: 1.9842\n",
      "Epoch [92/500], Validation Loss: 4.4183, Validation RMSE: 2.1020, Valid PR: 0.2242\n",
      "Epoch [93/500], Train Loss: 5.2115, Train RMSE: 2.2829\n",
      "Epoch [93/500], Validation Loss: 4.0533, Validation RMSE: 2.0133, Valid PR: 0.1209\n",
      "Epoch [94/500], Train Loss: 3.9881, Train RMSE: 1.9970\n",
      "Epoch [94/500], Validation Loss: 3.6940, Validation RMSE: 1.9220, Valid PR: -0.0007\n",
      "Epoch [95/500], Train Loss: 4.1449, Train RMSE: 2.0359\n",
      "Epoch [95/500], Validation Loss: 3.4589, Validation RMSE: 1.8598, Valid PR: -0.0787\n",
      "Epoch [96/500], Train Loss: 4.1500, Train RMSE: 2.0372\n",
      "Epoch [96/500], Validation Loss: 3.1667, Validation RMSE: 1.7795, Valid PR: -0.0709\n",
      "Epoch [97/500], Train Loss: 3.3357, Train RMSE: 1.8264\n",
      "Epoch [97/500], Validation Loss: 3.0135, Validation RMSE: 1.7359, Valid PR: -0.0567\n",
      "Epoch [98/500], Train Loss: 3.2112, Train RMSE: 1.7920\n",
      "Epoch [98/500], Validation Loss: 2.8909, Validation RMSE: 1.7003, Valid PR: -0.0246\n",
      "Epoch [99/500], Train Loss: 3.6756, Train RMSE: 1.9172\n",
      "Epoch [99/500], Validation Loss: 2.8230, Validation RMSE: 1.6802, Valid PR: -0.0144\n",
      "Epoch [100/500], Train Loss: 2.9874, Train RMSE: 1.7284\n",
      "Epoch [100/500], Validation Loss: 2.8004, Validation RMSE: 1.6734, Valid PR: -0.0283\n",
      "Epoch [101/500], Train Loss: 2.7326, Train RMSE: 1.6530\n",
      "Epoch [101/500], Validation Loss: 2.7961, Validation RMSE: 1.6722, Valid PR: -0.0279\n",
      "Epoch [102/500], Train Loss: 3.4502, Train RMSE: 1.8575\n",
      "Epoch [102/500], Validation Loss: 2.8228, Validation RMSE: 1.6801, Valid PR: -0.0702\n",
      "Epoch [103/500], Train Loss: 2.7053, Train RMSE: 1.6448\n",
      "Epoch [103/500], Validation Loss: 2.8661, Validation RMSE: 1.6930, Valid PR: -0.1105\n",
      "Epoch [104/500], Train Loss: 3.6789, Train RMSE: 1.9181\n",
      "Epoch [104/500], Validation Loss: 2.8278, Validation RMSE: 1.6816, Valid PR: -0.0649\n",
      "Epoch [105/500], Train Loss: 2.8255, Train RMSE: 1.6809\n",
      "Epoch [105/500], Validation Loss: 2.9955, Validation RMSE: 1.7308, Valid PR: -0.1465\n",
      "Epoch [106/500], Train Loss: 3.1112, Train RMSE: 1.7639\n",
      "Epoch [106/500], Validation Loss: 3.0379, Validation RMSE: 1.7430, Valid PR: -0.1690\n",
      "Epoch [107/500], Train Loss: 3.4427, Train RMSE: 1.8555\n",
      "Epoch [107/500], Validation Loss: 3.0322, Validation RMSE: 1.7413, Valid PR: -0.1655\n",
      "Epoch [108/500], Train Loss: 3.2788, Train RMSE: 1.8108\n",
      "Epoch [108/500], Validation Loss: 2.9596, Validation RMSE: 1.7204, Valid PR: -0.1331\n",
      "Epoch [109/500], Train Loss: 3.7385, Train RMSE: 1.9335\n",
      "Epoch [109/500], Validation Loss: 2.8465, Validation RMSE: 1.6872, Valid PR: -0.0580\n",
      "Epoch [110/500], Train Loss: 2.3243, Train RMSE: 1.5246\n",
      "Epoch [110/500], Validation Loss: 2.7991, Validation RMSE: 1.6730, Valid PR: -0.0082\n",
      "Epoch [111/500], Train Loss: 3.4598, Train RMSE: 1.8601\n",
      "Epoch [111/500], Validation Loss: 2.7352, Validation RMSE: 1.6538, Valid PR: 0.1204\n",
      "Epoch [112/500], Train Loss: 2.7390, Train RMSE: 1.6550\n",
      "Epoch [112/500], Validation Loss: 2.7753, Validation RMSE: 1.6659, Valid PR: 0.2661\n",
      "Epoch [113/500], Train Loss: 2.8040, Train RMSE: 1.6745\n",
      "Epoch [113/500], Validation Loss: 2.6508, Validation RMSE: 1.6281, Valid PR: 0.4209\n",
      "Epoch [114/500], Train Loss: 3.1846, Train RMSE: 1.7845\n",
      "Epoch [114/500], Validation Loss: 2.6692, Validation RMSE: 1.6338, Valid PR: 0.4288\n",
      "Epoch [115/500], Train Loss: 2.3720, Train RMSE: 1.5401\n",
      "Epoch [115/500], Validation Loss: 2.6859, Validation RMSE: 1.6389, Valid PR: 0.4327\n",
      "Epoch [116/500], Train Loss: 2.8848, Train RMSE: 1.6985\n",
      "Epoch [116/500], Validation Loss: 2.6719, Validation RMSE: 1.6346, Valid PR: 0.4281\n",
      "Epoch [117/500], Train Loss: 3.7649, Train RMSE: 1.9403\n",
      "Epoch [117/500], Validation Loss: 2.6465, Validation RMSE: 1.6268, Valid PR: 0.4215\n",
      "Epoch [118/500], Train Loss: 3.1700, Train RMSE: 1.7805\n",
      "Epoch [118/500], Validation Loss: 2.6069, Validation RMSE: 1.6146, Valid PR: 0.4158\n",
      "Epoch [119/500], Train Loss: 3.1663, Train RMSE: 1.7794\n",
      "Epoch [119/500], Validation Loss: 2.5545, Validation RMSE: 1.5983, Valid PR: 0.4114\n",
      "Epoch [120/500], Train Loss: 2.3133, Train RMSE: 1.5210\n",
      "Epoch [120/500], Validation Loss: 2.5463, Validation RMSE: 1.5957, Valid PR: 0.4028\n",
      "Epoch [121/500], Train Loss: 3.2952, Train RMSE: 1.8153\n",
      "Epoch [121/500], Validation Loss: 2.4342, Validation RMSE: 1.5602, Valid PR: 0.4049\n",
      "Epoch [122/500], Train Loss: 2.6114, Train RMSE: 1.6160\n",
      "Epoch [122/500], Validation Loss: 2.3007, Validation RMSE: 1.5168, Valid PR: 0.4099\n",
      "Epoch [123/500], Train Loss: 2.9707, Train RMSE: 1.7236\n",
      "Epoch [123/500], Validation Loss: 2.2321, Validation RMSE: 1.4940, Valid PR: 0.4062\n",
      "Epoch [124/500], Train Loss: 2.6700, Train RMSE: 1.6340\n",
      "Epoch [124/500], Validation Loss: 2.1326, Validation RMSE: 1.4603, Valid PR: 0.4245\n",
      "Epoch [125/500], Train Loss: 2.6335, Train RMSE: 1.6228\n",
      "Epoch [125/500], Validation Loss: 2.0093, Validation RMSE: 1.4175, Valid PR: 0.4444\n",
      "Epoch [126/500], Train Loss: 3.1167, Train RMSE: 1.7654\n",
      "Epoch [126/500], Validation Loss: 1.8990, Validation RMSE: 1.3780, Valid PR: 0.4592\n",
      "Epoch [127/500], Train Loss: 2.8835, Train RMSE: 1.6981\n",
      "Epoch [127/500], Validation Loss: 1.8066, Validation RMSE: 1.3441, Valid PR: 0.4774\n",
      "Epoch [128/500], Train Loss: 2.8259, Train RMSE: 1.6811\n",
      "Epoch [128/500], Validation Loss: 1.7595, Validation RMSE: 1.3265, Valid PR: 0.4819\n",
      "Epoch [129/500], Train Loss: 2.5507, Train RMSE: 1.5971\n",
      "Epoch [129/500], Validation Loss: 1.7491, Validation RMSE: 1.3226, Valid PR: 0.4886\n",
      "Epoch [130/500], Train Loss: 2.7280, Train RMSE: 1.6517\n",
      "Epoch [130/500], Validation Loss: 1.7462, Validation RMSE: 1.3214, Valid PR: 0.4940\n",
      "Epoch [131/500], Train Loss: 3.1200, Train RMSE: 1.7663\n",
      "Epoch [131/500], Validation Loss: 1.7666, Validation RMSE: 1.3291, Valid PR: 0.4947\n",
      "Epoch [132/500], Train Loss: 2.3529, Train RMSE: 1.5339\n",
      "Epoch [132/500], Validation Loss: 1.7720, Validation RMSE: 1.3312, Valid PR: 0.4913\n",
      "Epoch [133/500], Train Loss: 3.4989, Train RMSE: 1.8705\n",
      "Epoch [133/500], Validation Loss: 1.8210, Validation RMSE: 1.3494, Valid PR: 0.4741\n",
      "Epoch [134/500], Train Loss: 2.8808, Train RMSE: 1.6973\n",
      "Epoch [134/500], Validation Loss: 1.8728, Validation RMSE: 1.3685, Valid PR: 0.4615\n",
      "Epoch [135/500], Train Loss: 3.7061, Train RMSE: 1.9251\n",
      "Epoch [135/500], Validation Loss: 1.9657, Validation RMSE: 1.4020, Valid PR: 0.4316\n",
      "Epoch [136/500], Train Loss: 2.5111, Train RMSE: 1.5846\n",
      "Epoch [136/500], Validation Loss: 2.0477, Validation RMSE: 1.4310, Valid PR: 0.4128\n",
      "Epoch [137/500], Train Loss: 2.2547, Train RMSE: 1.5016\n",
      "Epoch [137/500], Validation Loss: 2.0677, Validation RMSE: 1.4379, Valid PR: 0.4161\n",
      "Epoch [138/500], Train Loss: 2.7431, Train RMSE: 1.6562\n",
      "Epoch [138/500], Validation Loss: 2.1143, Validation RMSE: 1.4541, Valid PR: 0.3953\n",
      "Epoch [139/500], Train Loss: 2.9331, Train RMSE: 1.7126\n",
      "Epoch [139/500], Validation Loss: 2.1686, Validation RMSE: 1.4726, Valid PR: 0.3672\n",
      "Epoch [140/500], Train Loss: 3.4258, Train RMSE: 1.8509\n",
      "Epoch [140/500], Validation Loss: 2.2163, Validation RMSE: 1.4887, Valid PR: 0.3329\n",
      "Epoch [141/500], Train Loss: 3.0141, Train RMSE: 1.7361\n",
      "Epoch [141/500], Validation Loss: 2.3306, Validation RMSE: 1.5266, Valid PR: 0.2746\n",
      "Epoch [142/500], Train Loss: 2.0392, Train RMSE: 1.4280\n",
      "Epoch [142/500], Validation Loss: 2.4906, Validation RMSE: 1.5782, Valid PR: 0.1842\n",
      "Epoch [143/500], Train Loss: 3.7910, Train RMSE: 1.9470\n",
      "Epoch [143/500], Validation Loss: 2.7010, Validation RMSE: 1.6435, Valid PR: 0.1125\n",
      "Epoch [144/500], Train Loss: 2.4829, Train RMSE: 1.5757\n",
      "Epoch [144/500], Validation Loss: 2.9045, Validation RMSE: 1.7043, Valid PR: 0.0299\n",
      "Epoch [145/500], Train Loss: 3.1067, Train RMSE: 1.7626\n",
      "Epoch [145/500], Validation Loss: 3.0283, Validation RMSE: 1.7402, Valid PR: -0.0426\n",
      "Epoch [146/500], Train Loss: 2.7152, Train RMSE: 1.6478\n",
      "Epoch [146/500], Validation Loss: 3.0545, Validation RMSE: 1.7477, Valid PR: -0.0805\n",
      "Epoch [147/500], Train Loss: 2.6063, Train RMSE: 1.6144\n",
      "Epoch [147/500], Validation Loss: 2.9748, Validation RMSE: 1.7247, Valid PR: -0.1163\n",
      "Epoch [148/500], Train Loss: 1.9968, Train RMSE: 1.4131\n",
      "Epoch [148/500], Validation Loss: 2.9476, Validation RMSE: 1.7169, Valid PR: -0.1463\n",
      "Epoch [149/500], Train Loss: 2.6937, Train RMSE: 1.6412\n",
      "Epoch [149/500], Validation Loss: 3.0506, Validation RMSE: 1.7466, Valid PR: -0.1950\n",
      "Epoch [150/500], Train Loss: 3.0227, Train RMSE: 1.7386\n",
      "Epoch [150/500], Validation Loss: 3.2897, Validation RMSE: 1.8138, Valid PR: -0.2626\n",
      "Epoch [151/500], Train Loss: 2.4478, Train RMSE: 1.5645\n",
      "Epoch [151/500], Validation Loss: 3.5168, Validation RMSE: 1.8753, Valid PR: -0.3011\n",
      "Epoch [152/500], Train Loss: 2.9304, Train RMSE: 1.7118\n",
      "Epoch [152/500], Validation Loss: 3.5185, Validation RMSE: 1.8758, Valid PR: -0.2615\n",
      "Epoch [153/500], Train Loss: 3.1035, Train RMSE: 1.7617\n",
      "Epoch [153/500], Validation Loss: 3.2066, Validation RMSE: 1.7907, Valid PR: -0.1380\n",
      "Epoch [154/500], Train Loss: 3.8299, Train RMSE: 1.9570\n",
      "Epoch [154/500], Validation Loss: 2.9234, Validation RMSE: 1.7098, Valid PR: -0.0182\n",
      "Epoch [155/500], Train Loss: 2.4365, Train RMSE: 1.5609\n",
      "Epoch [155/500], Validation Loss: 2.7234, Validation RMSE: 1.6503, Valid PR: 0.0576\n",
      "Epoch [156/500], Train Loss: 3.7950, Train RMSE: 1.9481\n",
      "Epoch [156/500], Validation Loss: 2.3736, Validation RMSE: 1.5406, Valid PR: 0.1949\n",
      "Epoch [157/500], Train Loss: 2.2125, Train RMSE: 1.4875\n",
      "Epoch [157/500], Validation Loss: 2.2791, Validation RMSE: 1.5097, Valid PR: 0.2392\n",
      "Epoch [158/500], Train Loss: 3.1859, Train RMSE: 1.7849\n",
      "Epoch [158/500], Validation Loss: 2.2864, Validation RMSE: 1.5121, Valid PR: 0.2431\n",
      "Epoch [159/500], Train Loss: 2.7080, Train RMSE: 1.6456\n",
      "Epoch [159/500], Validation Loss: 2.1863, Validation RMSE: 1.4786, Valid PR: 0.2909\n",
      "Epoch [160/500], Train Loss: 2.6429, Train RMSE: 1.6257\n",
      "Epoch [160/500], Validation Loss: 2.0620, Validation RMSE: 1.4360, Valid PR: 0.3497\n",
      "Epoch [161/500], Train Loss: 1.9074, Train RMSE: 1.3811\n",
      "Epoch [161/500], Validation Loss: 2.0188, Validation RMSE: 1.4208, Valid PR: 0.3713\n",
      "Epoch [162/500], Train Loss: 2.7584, Train RMSE: 1.6608\n",
      "Epoch [162/500], Validation Loss: 2.0664, Validation RMSE: 1.4375, Valid PR: 0.3449\n",
      "Epoch [163/500], Train Loss: 3.1053, Train RMSE: 1.7622\n",
      "Epoch [163/500], Validation Loss: 2.1491, Validation RMSE: 1.4660, Valid PR: 0.3011\n",
      "Epoch [164/500], Train Loss: 3.3687, Train RMSE: 1.8354\n",
      "Epoch [164/500], Validation Loss: 2.1547, Validation RMSE: 1.4679, Valid PR: 0.3008\n",
      "Epoch [165/500], Train Loss: 3.1413, Train RMSE: 1.7724\n",
      "Epoch [165/500], Validation Loss: 2.1263, Validation RMSE: 1.4582, Valid PR: 0.3132\n",
      "Epoch [166/500], Train Loss: 2.4102, Train RMSE: 1.5525\n",
      "Epoch [166/500], Validation Loss: 2.0380, Validation RMSE: 1.4276, Valid PR: 0.3585\n",
      "Epoch [167/500], Train Loss: 2.1484, Train RMSE: 1.4657\n",
      "Epoch [167/500], Validation Loss: 1.9709, Validation RMSE: 1.4039, Valid PR: 0.3901\n",
      "Epoch [168/500], Train Loss: 3.2853, Train RMSE: 1.8126\n",
      "Epoch [168/500], Validation Loss: 2.0562, Validation RMSE: 1.4340, Valid PR: 0.3635\n",
      "Epoch [169/500], Train Loss: 2.2409, Train RMSE: 1.4969\n",
      "Epoch [169/500], Validation Loss: 2.0997, Validation RMSE: 1.4490, Valid PR: 0.3736\n",
      "Epoch [170/500], Train Loss: 2.4505, Train RMSE: 1.5654\n",
      "Epoch [170/500], Validation Loss: 2.2497, Validation RMSE: 1.4999, Valid PR: 0.3487\n",
      "Epoch [171/500], Train Loss: 2.1743, Train RMSE: 1.4745\n",
      "Epoch [171/500], Validation Loss: 2.2345, Validation RMSE: 1.4948, Valid PR: 0.3652\n",
      "Epoch [172/500], Train Loss: 2.7826, Train RMSE: 1.6681\n",
      "Epoch [172/500], Validation Loss: 2.2256, Validation RMSE: 1.4919, Valid PR: 0.3741\n",
      "Epoch [173/500], Train Loss: 2.8358, Train RMSE: 1.6840\n",
      "Epoch [173/500], Validation Loss: 2.2491, Validation RMSE: 1.4997, Valid PR: 0.3540\n",
      "Epoch [174/500], Train Loss: 2.2678, Train RMSE: 1.5059\n",
      "Epoch [174/500], Validation Loss: 2.4591, Validation RMSE: 1.5681, Valid PR: 0.3003\n",
      "Epoch [175/500], Train Loss: 2.9487, Train RMSE: 1.7172\n",
      "Epoch [175/500], Validation Loss: 2.4179, Validation RMSE: 1.5550, Valid PR: 0.2965\n",
      "Epoch [176/500], Train Loss: 2.6462, Train RMSE: 1.6267\n",
      "Epoch [176/500], Validation Loss: 2.5379, Validation RMSE: 1.5931, Valid PR: 0.2439\n",
      "Epoch [177/500], Train Loss: 2.8955, Train RMSE: 1.7016\n",
      "Epoch [177/500], Validation Loss: 2.7730, Validation RMSE: 1.6652, Valid PR: 0.1843\n",
      "Epoch [178/500], Train Loss: 3.1355, Train RMSE: 1.7707\n",
      "Epoch [178/500], Validation Loss: 3.0320, Validation RMSE: 1.7413, Valid PR: 0.1507\n",
      "Epoch [179/500], Train Loss: 2.8529, Train RMSE: 1.6891\n",
      "Epoch [179/500], Validation Loss: 3.2108, Validation RMSE: 1.7919, Valid PR: 0.0932\n",
      "Epoch [180/500], Train Loss: 2.3772, Train RMSE: 1.5418\n",
      "Epoch [180/500], Validation Loss: 3.7194, Validation RMSE: 1.9286, Valid PR: -0.0402\n",
      "Early stopping triggered.\n",
      "Test Loss: 5.0284, Test RMSE: 2.2424, Test PR: -0.0893\n",
      "Test Loss: 4.3188, Test RMSE: 2.0782, Test PR: -0.2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3123897583.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/scratch/local/51712327/ipykernel_500297/3123897583.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define fully connected neural network class\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 8),\n",
    "            nn.BatchNorm1d(hidden_dim // 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 8, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Train fully connected neural network to predict labels and record metrics\n",
    "def train_fully_connected_nn(train_matrix_encodings, train_vector_encodings, y_train, val_matrix_encodings, val_vector_encodings, y_val, output_dim=768, learning_rate=3*1e-3, num_epochs=500, batch_size=256, early_stop_patience=50):\n",
    "    # Combine matrix and vector encodings\n",
    "    train_features = torch.cat((train_matrix_encodings, train_vector_encodings), dim=1)\n",
    "    val_features = torch.cat((val_matrix_encodings, val_vector_encodings), dim=1)\n",
    "    \n",
    "    # Create training and validation datasets\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_features, torch.tensor(y_train, dtype=torch.float32))\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_features, torch.tensor(y_val, dtype=torch.float32))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    input_dim = train_features.size(1)\n",
    "    hidden_dim = 256\n",
    "    output_dim = 1  # Assuming regression task\n",
    "    model = FullyConnectedNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "    criterion = nn.MSELoss() if output_dim == 1 else nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50, verbose=True)\n",
    "\n",
    "    # DataFrame to store metrics\n",
    "    metrics_df = pd.DataFrame(columns=[\"Epoch\", \"Train Loss\", \"Train RMSE\", \"Valid RMSE\", \"Valid PR\"])\n",
    "\n",
    "    # Variables to track best model\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_rmse = torch.sqrt(torch.tensor(avg_train_loss)).item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(features).squeeze()\n",
    "                val_loss = criterion(outputs, labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "                val_outputs_list.append(outputs.cpu())\n",
    "                val_labels_list.append(labels.cpu())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_rmse = torch.sqrt(torch.tensor(avg_val_loss)).item()\n",
    "        val_outputs = torch.cat(val_outputs_list, dim=0)\n",
    "        val_labels = torch.cat(val_labels_list, dim=0)\n",
    "        valid_pr = torch.corrcoef(torch.stack([val_outputs, val_labels]))[0, 1].item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation RMSE: {val_rmse:.4f}, Valid PR: {valid_pr:.4f}\")\n",
    "\n",
    "        # Record metrics\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": avg_train_loss,\n",
    "            \"Train RMSE\": train_rmse,\n",
    "            \"Valid RMSE\": val_rmse,\n",
    "            \"Valid PR\": valid_pr\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "        # Update best model if validation loss improves\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), f\"best_model_state_{method}.pth\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        # Save the last model state at the end of each epoch\n",
    "        torch.save(model.state_dict(), f\"last_model_state_{method}.pth\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        # Learning rate decay\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "# Load and test the final model and record metrics\n",
    "def test_fully_connected_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path, batch_size=64):\n",
    "    # Combine matrix and vector encodings\n",
    "    test_features = torch.cat((test_matrix_encodings, test_vector_encodings), dim=1)\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_features, torch.tensor(y_test, dtype=torch.float32))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    input_dim = test_features.size(1)\n",
    "    hidden_dim = 256\n",
    "    output_dim = 1  # Assuming regression task\n",
    "    model = FullyConnectedNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # Define loss function\n",
    "    criterion = nn.MSELoss() if output_dim == 1 else nn.BCEWithLogitsLoss()\n",
    "    total_test_loss = 0\n",
    "    test_outputs_list = []\n",
    "    test_labels_list = []\n",
    "    \n",
    "    # Testing loop\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_test_loss += loss.item()\n",
    "            test_outputs_list.append(outputs.cpu())\n",
    "            test_labels_list.append(labels.cpu())\n",
    "    \n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_rmse = torch.sqrt(torch.tensor(avg_test_loss)).item()\n",
    "    test_outputs = torch.cat(test_outputs_list, dim=0)\n",
    "    test_labels = torch.cat(test_labels_list, dim=0)\n",
    "    test_pr = torch.corrcoef(torch.stack([test_outputs, test_labels]))[0, 1].item()\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test RMSE: {test_rmse:.4f}, Test PR: {test_pr:.4f}\")\n",
    "    \n",
    "    return test_rmse, test_pr\n",
    "\n",
    "# Refactor to test three encoding methods\n",
    "encoding_methods = [\n",
    "    \"method1\",\n",
    "    \"method2\",\n",
    "    \"method3\"\n",
    "]\n",
    "\n",
    "metrics_summary = pd.DataFrame(columns=[\"Method\", \"Epoch\", \"Model Type\", \"Train Loss\", \"Train RMSE\", \"Valid RMSE\", \"Valid PR\", \"Test RMSE\", \"Test PR\"])\n",
    "\n",
    "for method in encoding_methods:\n",
    "    print(f\"Testing {method}...\")\n",
    "    \n",
    "    # Define different get_encodings functions for each method\n",
    "    if method == \"method1\":\n",
    "        def get_encodings(model, data_loader, device):\n",
    "            matrix_encodings = []\n",
    "            vector_encodings = []\n",
    "            with torch.no_grad():\n",
    "                for matrix, vector in data_loader:\n",
    "                    matrix, vector = matrix.to(device), vector.to(device)\n",
    "                    matrix_features, vector_features = model(matrix, vector)\n",
    "                    matrix_encodings.append(matrix_features.cpu())\n",
    "                    vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "            matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "            vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "            return matrix_encodings, vector_encodings\n",
    "    elif method == \"method2\":\n",
    "        def get_encodings(model, data_loader, device):\n",
    "            matrix_encoder, vector_encoder = model.matrix_encoder, model.vector_encoder\n",
    "            matrix_encodings = []\n",
    "            vector_encodings = []\n",
    "            with torch.no_grad():\n",
    "                for matrix, vector in data_loader:\n",
    "                    matrix, vector = matrix.to(device), vector.to(device)\n",
    "                    matrix_features_encoder = model.matrix_encoder(matrix)\n",
    "                    vector_features_encoder = model.vector_encoder(vector)\n",
    "                    matrix_features, vector_features = model(matrix, vector)\n",
    "                    # Concatenate both outputs\n",
    "                    matrix_features = torch.cat((matrix_features, matrix_features_encoder), dim=-1)\n",
    "                    vector_features = torch.cat((vector_features, vector_features_encoder), dim=-1)\n",
    "                    matrix_encodings.append(matrix_features.cpu())\n",
    "                    vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "            matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "            vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "            return matrix_encodings, vector_encodings\n",
    "    elif method == \"method3\":\n",
    "        def get_encodings(model, data_loader, device):\n",
    "            matrix_encodings = []\n",
    "            vector_encodings = []\n",
    "            with torch.no_grad():\n",
    "                for matrix, vector in data_loader:\n",
    "                    matrix, vector = matrix.to(device), vector.to(device)\n",
    "                    matrix_features = model.matrix_encoder(matrix)\n",
    "                    vector_features = model.vector_encoder(vector)\n",
    "                    matrix_encodings.append(matrix_features.cpu())\n",
    "                    vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "            matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "            vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "            return matrix_encodings, vector_encodings\n",
    "    \n",
    "    # Get encodings\n",
    "    train_matrix_encodings, train_vector_encodings = get_encodings(model, train_loader, device)\n",
    "    val_matrix_encodings, val_vector_encodings = get_encodings(model, val_loader, device)\n",
    "    test_matrix_encodings, test_vector_encodings = get_encodings(model, test_loader, device)\n",
    "\n",
    "    # Train fully connected neural network to predict labels\n",
    "    metrics_df = train_fully_connected_nn(\n",
    "        train_matrix_encodings, train_vector_encodings, y_train,\n",
    "        val_matrix_encodings, val_vector_encodings, y_val\n",
    "    )\n",
    "\n",
    "    # Test the best model\n",
    "    best_test_rmse, best_test_pr = test_fully_connected_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path=f\"best_model_state_{method}.pth\")\n",
    "\n",
    "    # Store metrics for best model\n",
    "    best_metrics = metrics_df[metrics_df['Valid RMSE'] == metrics_df['Valid RMSE'].min()].copy()\n",
    "    best_metrics[\"Method\"] = method\n",
    "    best_metrics[\"Model Type\"] = \"Best\"\n",
    "    best_metrics[\"Test RMSE\"] = best_test_rmse\n",
    "    best_metrics[\"Test PR\"] = best_test_pr\n",
    "    metrics_summary = pd.concat([metrics_summary, best_metrics], ignore_index=True)\n",
    "\n",
    "    # Test the last model\n",
    "    last_test_rmse, last_test_pr = test_fully_connected_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path=f\"last_model_state_{method}.pth\")\n",
    "\n",
    "    # Store metrics for last model\n",
    "    last_metrics = metrics_df.iloc[-1:].copy()\n",
    "    last_metrics[\"Method\"] = method\n",
    "    last_metrics[\"Model Type\"] = \"Last\"\n",
    "    last_metrics[\"Test RMSE\"] = last_test_rmse\n",
    "    last_metrics[\"Test PR\"] = last_test_pr\n",
    "    metrics_summary = pd.concat([metrics_summary, last_metrics], ignore_index=True)\n",
    "\n",
    "# Save summary metrics to CSV\n",
    "metrics_summary.to_csv(\"encoding_methods_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "963da81d-bab0-406d-afdd-d922822a1e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Valid RMSE</th>\n",
       "      <th>Valid PR</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>method1</td>\n",
       "      <td>196</td>\n",
       "      <td>Best</td>\n",
       "      <td>2.032588</td>\n",
       "      <td>1.425689</td>\n",
       "      <td>1.081038</td>\n",
       "      <td>0.688684</td>\n",
       "      <td>2.556391</td>\n",
       "      <td>-0.210374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>method1</td>\n",
       "      <td>246</td>\n",
       "      <td>Last</td>\n",
       "      <td>1.805907</td>\n",
       "      <td>1.343841</td>\n",
       "      <td>1.370979</td>\n",
       "      <td>0.411379</td>\n",
       "      <td>2.337085</td>\n",
       "      <td>-0.230181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>method2</td>\n",
       "      <td>85</td>\n",
       "      <td>Best</td>\n",
       "      <td>4.268610</td>\n",
       "      <td>2.066061</td>\n",
       "      <td>1.621057</td>\n",
       "      <td>0.540302</td>\n",
       "      <td>2.681737</td>\n",
       "      <td>-0.248734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>method2</td>\n",
       "      <td>135</td>\n",
       "      <td>Last</td>\n",
       "      <td>2.742895</td>\n",
       "      <td>1.656169</td>\n",
       "      <td>2.324046</td>\n",
       "      <td>-0.450179</td>\n",
       "      <td>2.126693</td>\n",
       "      <td>-0.172201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>method3</td>\n",
       "      <td>130</td>\n",
       "      <td>Best</td>\n",
       "      <td>2.728034</td>\n",
       "      <td>1.651676</td>\n",
       "      <td>1.321446</td>\n",
       "      <td>0.493985</td>\n",
       "      <td>2.242416</td>\n",
       "      <td>-0.089293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>method3</td>\n",
       "      <td>180</td>\n",
       "      <td>Last</td>\n",
       "      <td>2.377199</td>\n",
       "      <td>1.541817</td>\n",
       "      <td>1.928581</td>\n",
       "      <td>-0.040235</td>\n",
       "      <td>2.078161</td>\n",
       "      <td>-0.218290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Method Epoch Model Type  Train Loss  Train RMSE  Valid RMSE  Valid PR  \\\n",
       "0  method1   196       Best    2.032588    1.425689    1.081038  0.688684   \n",
       "1  method1   246       Last    1.805907    1.343841    1.370979  0.411379   \n",
       "2  method2    85       Best    4.268610    2.066061    1.621057  0.540302   \n",
       "3  method2   135       Last    2.742895    1.656169    2.324046 -0.450179   \n",
       "4  method3   130       Best    2.728034    1.651676    1.321446  0.493985   \n",
       "5  method3   180       Last    2.377199    1.541817    1.928581 -0.040235   \n",
       "\n",
       "   Test RMSE   Test PR  \n",
       "0   2.556391 -0.210374  \n",
       "1   2.337085 -0.230181  \n",
       "2   2.681737 -0.248734  \n",
       "3   2.126693 -0.172201  \n",
       "4   2.242416 -0.089293  \n",
       "5   2.078161 -0.218290  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3499189d-6de0-4424-a83e-689a69aff401",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing method1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 35.5746, Train RMSE: 5.9644\n",
      "Epoch [1/500], Validation Loss: 28.1192, Validation RMSE: 5.3028, Valid PR: 0.7941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3966443589.py:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/500], Train Loss: 32.4889, Train RMSE: 5.6999\n",
      "Epoch [2/500], Validation Loss: 23.0879, Validation RMSE: 4.8050, Valid PR: 0.8529\n",
      "Epoch [3/500], Train Loss: 30.1288, Train RMSE: 5.4890\n",
      "Epoch [3/500], Validation Loss: 17.3053, Validation RMSE: 4.1600, Valid PR: 0.7914\n",
      "Epoch [4/500], Train Loss: 28.9649, Train RMSE: 5.3819\n",
      "Epoch [4/500], Validation Loss: 15.6832, Validation RMSE: 3.9602, Valid PR: 0.7433\n",
      "Epoch [5/500], Train Loss: 25.7724, Train RMSE: 5.0767\n",
      "Epoch [5/500], Validation Loss: 16.7092, Validation RMSE: 4.0877, Valid PR: 0.2229\n",
      "Epoch [6/500], Train Loss: 23.9211, Train RMSE: 4.8909\n",
      "Epoch [6/500], Validation Loss: 10.4128, Validation RMSE: 3.2269, Valid PR: 0.6545\n",
      "Epoch [7/500], Train Loss: 21.1162, Train RMSE: 4.5952\n",
      "Epoch [7/500], Validation Loss: 7.2028, Validation RMSE: 2.6838, Valid PR: 0.7801\n",
      "Epoch [8/500], Train Loss: 19.9463, Train RMSE: 4.4661\n",
      "Epoch [8/500], Validation Loss: 8.1499, Validation RMSE: 2.8548, Valid PR: 0.1267\n",
      "Epoch [9/500], Train Loss: 18.1807, Train RMSE: 4.2639\n",
      "Epoch [9/500], Validation Loss: 5.0339, Validation RMSE: 2.2436, Valid PR: 0.4768\n",
      "Epoch [10/500], Train Loss: 16.7914, Train RMSE: 4.0977\n",
      "Epoch [10/500], Validation Loss: 2.7247, Validation RMSE: 1.6507, Valid PR: 0.7251\n",
      "Epoch [11/500], Train Loss: 14.8252, Train RMSE: 3.8504\n",
      "Epoch [11/500], Validation Loss: 1.9517, Validation RMSE: 1.3970, Valid PR: 0.6640\n",
      "Epoch [12/500], Train Loss: 14.0463, Train RMSE: 3.7478\n",
      "Epoch [12/500], Validation Loss: 2.0756, Validation RMSE: 1.4407, Valid PR: 0.6199\n",
      "Epoch [13/500], Train Loss: 12.1565, Train RMSE: 3.4866\n",
      "Epoch [13/500], Validation Loss: 3.5131, Validation RMSE: 1.8743, Valid PR: 0.0206\n",
      "Epoch [14/500], Train Loss: 12.5478, Train RMSE: 3.5423\n",
      "Epoch [14/500], Validation Loss: 2.3263, Validation RMSE: 1.5252, Valid PR: 0.1912\n",
      "Epoch [15/500], Train Loss: 10.6562, Train RMSE: 3.2644\n",
      "Epoch [15/500], Validation Loss: 2.7961, Validation RMSE: 1.6722, Valid PR: 0.2483\n",
      "Epoch [16/500], Train Loss: 9.6825, Train RMSE: 3.1117\n",
      "Epoch [16/500], Validation Loss: 3.2931, Validation RMSE: 1.8147, Valid PR: 0.3250\n",
      "Epoch [17/500], Train Loss: 10.0905, Train RMSE: 3.1766\n",
      "Epoch [17/500], Validation Loss: 3.5314, Validation RMSE: 1.8792, Valid PR: 0.4320\n",
      "Epoch [18/500], Train Loss: 7.9529, Train RMSE: 2.8201\n",
      "Epoch [18/500], Validation Loss: 3.5558, Validation RMSE: 1.8857, Valid PR: 0.6515\n",
      "Epoch [19/500], Train Loss: 7.1373, Train RMSE: 2.6716\n",
      "Epoch [19/500], Validation Loss: 3.8698, Validation RMSE: 1.9672, Valid PR: 0.5094\n",
      "Epoch [20/500], Train Loss: 7.0268, Train RMSE: 2.6508\n",
      "Epoch [20/500], Validation Loss: 3.9500, Validation RMSE: 1.9875, Valid PR: 0.5356\n",
      "Epoch [21/500], Train Loss: 6.4544, Train RMSE: 2.5406\n",
      "Epoch [21/500], Validation Loss: 3.9680, Validation RMSE: 1.9920, Valid PR: 0.5656\n",
      "Epoch [22/500], Train Loss: 13.9977, Train RMSE: 3.7413\n",
      "Epoch [22/500], Validation Loss: 3.9973, Validation RMSE: 1.9993, Valid PR: 0.6382\n",
      "Epoch [23/500], Train Loss: 5.0741, Train RMSE: 2.2526\n",
      "Epoch [23/500], Validation Loss: 4.0417, Validation RMSE: 2.0104, Valid PR: 0.7104\n",
      "Epoch [24/500], Train Loss: 4.4076, Train RMSE: 2.0994\n",
      "Epoch [24/500], Validation Loss: 4.0546, Validation RMSE: 2.0136, Valid PR: 0.7968\n",
      "Epoch [25/500], Train Loss: 3.9354, Train RMSE: 1.9838\n",
      "Epoch [25/500], Validation Loss: 3.9338, Validation RMSE: 1.9834, Valid PR: 0.8720\n",
      "Epoch [26/500], Train Loss: 3.4289, Train RMSE: 1.8517\n",
      "Epoch [26/500], Validation Loss: 2.4763, Validation RMSE: 1.5736, Valid PR: 0.9262\n",
      "Epoch [27/500], Train Loss: 3.7696, Train RMSE: 1.9416\n",
      "Epoch [27/500], Validation Loss: 2.5665, Validation RMSE: 1.6020, Valid PR: 0.9251\n",
      "Epoch [28/500], Train Loss: 3.6285, Train RMSE: 1.9049\n",
      "Epoch [28/500], Validation Loss: 2.6595, Validation RMSE: 1.6308, Valid PR: 0.9234\n",
      "Epoch [29/500], Train Loss: 4.5043, Train RMSE: 2.1223\n",
      "Epoch [29/500], Validation Loss: 2.8232, Validation RMSE: 1.6803, Valid PR: 0.9200\n",
      "Epoch [30/500], Train Loss: 3.0990, Train RMSE: 1.7604\n",
      "Epoch [30/500], Validation Loss: 2.8158, Validation RMSE: 1.6780, Valid PR: 0.9152\n",
      "Epoch [31/500], Train Loss: 4.1722, Train RMSE: 2.0426\n",
      "Epoch [31/500], Validation Loss: 2.9738, Validation RMSE: 1.7245, Valid PR: 0.9140\n",
      "Epoch [32/500], Train Loss: 2.8705, Train RMSE: 1.6943\n",
      "Epoch [32/500], Validation Loss: 2.8870, Validation RMSE: 1.6991, Valid PR: 0.9092\n",
      "Epoch [33/500], Train Loss: 4.7205, Train RMSE: 2.1727\n",
      "Epoch [33/500], Validation Loss: 2.8090, Validation RMSE: 1.6760, Valid PR: 0.9108\n",
      "Epoch [34/500], Train Loss: 7.0603, Train RMSE: 2.6571\n",
      "Epoch [34/500], Validation Loss: 2.7713, Validation RMSE: 1.6647, Valid PR: 0.9201\n",
      "Epoch [35/500], Train Loss: 6.9654, Train RMSE: 2.6392\n",
      "Epoch [35/500], Validation Loss: 2.6424, Validation RMSE: 1.6255, Valid PR: 0.9258\n",
      "Epoch [36/500], Train Loss: 8.9555, Train RMSE: 2.9926\n",
      "Epoch [36/500], Validation Loss: 2.5621, Validation RMSE: 1.6006, Valid PR: 0.9248\n",
      "Epoch [37/500], Train Loss: 12.7638, Train RMSE: 3.5726\n",
      "Epoch [37/500], Validation Loss: 2.4152, Validation RMSE: 1.5541, Valid PR: 0.9253\n",
      "Epoch [38/500], Train Loss: 8.7603, Train RMSE: 2.9598\n",
      "Epoch [38/500], Validation Loss: 2.2379, Validation RMSE: 1.4960, Valid PR: 0.9124\n",
      "Epoch [39/500], Train Loss: 8.5224, Train RMSE: 2.9193\n",
      "Epoch [39/500], Validation Loss: 2.0809, Validation RMSE: 1.4425, Valid PR: 0.8939\n",
      "Epoch [40/500], Train Loss: 4.4548, Train RMSE: 2.1106\n",
      "Epoch [40/500], Validation Loss: 2.1593, Validation RMSE: 1.4694, Valid PR: 0.5696\n",
      "Epoch [41/500], Train Loss: 4.1892, Train RMSE: 2.0467\n",
      "Epoch [41/500], Validation Loss: 3.2450, Validation RMSE: 1.8014, Valid PR: -0.8265\n",
      "Epoch [42/500], Train Loss: 4.8052, Train RMSE: 2.1921\n",
      "Epoch [42/500], Validation Loss: 5.4247, Validation RMSE: 2.3291, Valid PR: -0.8899\n",
      "Epoch [43/500], Train Loss: 4.4158, Train RMSE: 2.1014\n",
      "Epoch [43/500], Validation Loss: 11.3362, Validation RMSE: 3.3669, Valid PR: -0.9084\n",
      "Epoch [44/500], Train Loss: 3.4250, Train RMSE: 1.8507\n",
      "Epoch [44/500], Validation Loss: 17.4431, Validation RMSE: 4.1765, Valid PR: -0.9140\n",
      "Epoch [45/500], Train Loss: 2.8466, Train RMSE: 1.6872\n",
      "Epoch [45/500], Validation Loss: 17.6796, Validation RMSE: 4.2047, Valid PR: -0.8100\n",
      "Epoch [46/500], Train Loss: 4.1896, Train RMSE: 2.0469\n",
      "Epoch [46/500], Validation Loss: 11.1816, Validation RMSE: 3.3439, Valid PR: -0.7219\n",
      "Epoch [47/500], Train Loss: 3.7451, Train RMSE: 1.9352\n",
      "Epoch [47/500], Validation Loss: 8.2923, Validation RMSE: 2.8796, Valid PR: -0.7219\n",
      "Epoch [48/500], Train Loss: 2.9168, Train RMSE: 1.7079\n",
      "Epoch [48/500], Validation Loss: 6.7293, Validation RMSE: 2.5941, Valid PR: -0.7219\n",
      "Epoch [49/500], Train Loss: 2.9627, Train RMSE: 1.7213\n",
      "Epoch [49/500], Validation Loss: 5.8025, Validation RMSE: 2.4088, Valid PR: -0.7217\n",
      "Epoch [50/500], Train Loss: 3.1056, Train RMSE: 1.7623\n",
      "Epoch [50/500], Validation Loss: 5.2390, Validation RMSE: 2.2889, Valid PR: -0.7101\n",
      "Epoch [51/500], Train Loss: 3.1232, Train RMSE: 1.7673\n",
      "Epoch [51/500], Validation Loss: 4.8981, Validation RMSE: 2.2132, Valid PR: -0.7053\n",
      "Epoch [52/500], Train Loss: 2.8999, Train RMSE: 1.7029\n",
      "Epoch [52/500], Validation Loss: 4.6631, Validation RMSE: 2.1594, Valid PR: -0.6675\n",
      "Epoch [53/500], Train Loss: 3.9098, Train RMSE: 1.9773\n",
      "Epoch [53/500], Validation Loss: 3.7216, Validation RMSE: 1.9292, Valid PR: -0.1921\n",
      "Epoch [54/500], Train Loss: 5.0189, Train RMSE: 2.2403\n",
      "Epoch [54/500], Validation Loss: 3.1281, Validation RMSE: 1.7686, Valid PR: 0.2863\n",
      "Epoch [55/500], Train Loss: 3.9553, Train RMSE: 1.9888\n",
      "Epoch [55/500], Validation Loss: 3.2801, Validation RMSE: 1.8111, Valid PR: 0.9067\n",
      "Epoch [56/500], Train Loss: 3.3430, Train RMSE: 1.8284\n",
      "Epoch [56/500], Validation Loss: 3.3189, Validation RMSE: 1.8218, Valid PR: 0.8970\n",
      "Epoch [57/500], Train Loss: 3.0786, Train RMSE: 1.7546\n",
      "Epoch [57/500], Validation Loss: 3.2768, Validation RMSE: 1.8102, Valid PR: 0.8137\n",
      "Epoch [58/500], Train Loss: 6.7550, Train RMSE: 2.5990\n",
      "Epoch [58/500], Validation Loss: 2.8204, Validation RMSE: 1.6794, Valid PR: -0.3715\n",
      "Epoch [59/500], Train Loss: 4.0514, Train RMSE: 2.0128\n",
      "Epoch [59/500], Validation Loss: 2.6067, Validation RMSE: 1.6145, Valid PR: -0.6215\n",
      "Epoch [60/500], Train Loss: 3.9521, Train RMSE: 1.9880\n",
      "Epoch [60/500], Validation Loss: 3.9928, Validation RMSE: 1.9982, Valid PR: 0.2162\n",
      "Epoch [61/500], Train Loss: 2.8499, Train RMSE: 1.6882\n",
      "Epoch [61/500], Validation Loss: 3.5105, Validation RMSE: 1.8736, Valid PR: 0.2067\n",
      "Early stopping triggered.\n",
      "Test Loss: 7.3880, Test RMSE: 2.7181, Test PR: 0.1176\n",
      "Test Loss: 2.8322, Test RMSE: 1.6829, Test PR: 0.1836\n",
      "Testing method2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3966443589.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/scratch/local/51712327/ipykernel_500297/3966443589.py:263: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_summary = pd.concat([metrics_summary, best_metrics], ignore_index=True)\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3966443589.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3966443589.py:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 36.2369, Train RMSE: 6.0197\n",
      "Epoch [1/500], Validation Loss: 31.9080, Validation RMSE: 5.6487, Valid PR: 0.4991\n",
      "Epoch [2/500], Train Loss: 34.2277, Train RMSE: 5.8504\n",
      "Epoch [2/500], Validation Loss: 35.2793, Validation RMSE: 5.9396, Valid PR: 0.2393\n",
      "Epoch [3/500], Train Loss: 32.4434, Train RMSE: 5.6959\n",
      "Epoch [3/500], Validation Loss: 36.1979, Validation RMSE: 6.0165, Valid PR: 0.4465\n",
      "Epoch [4/500], Train Loss: 30.5154, Train RMSE: 5.5241\n",
      "Epoch [4/500], Validation Loss: 35.7537, Validation RMSE: 5.9794, Valid PR: 0.5258\n",
      "Epoch [5/500], Train Loss: 28.9484, Train RMSE: 5.3804\n",
      "Epoch [5/500], Validation Loss: 34.7546, Validation RMSE: 5.8953, Valid PR: 0.5614\n",
      "Epoch [6/500], Train Loss: 26.6735, Train RMSE: 5.1646\n",
      "Epoch [6/500], Validation Loss: 32.9445, Validation RMSE: 5.7397, Valid PR: 0.5698\n",
      "Epoch [7/500], Train Loss: 25.7003, Train RMSE: 5.0695\n",
      "Epoch [7/500], Validation Loss: 31.3677, Validation RMSE: 5.6007, Valid PR: 0.5627\n",
      "Epoch [8/500], Train Loss: 24.0105, Train RMSE: 4.9000\n",
      "Epoch [8/500], Validation Loss: 29.0589, Validation RMSE: 5.3906, Valid PR: 0.6700\n",
      "Epoch [9/500], Train Loss: 21.7351, Train RMSE: 4.6621\n",
      "Epoch [9/500], Validation Loss: 26.2134, Validation RMSE: 5.1199, Valid PR: -0.2437\n",
      "Epoch [10/500], Train Loss: 21.1899, Train RMSE: 4.6032\n",
      "Epoch [10/500], Validation Loss: 24.1240, Validation RMSE: 4.9116, Valid PR: -0.3628\n",
      "Epoch [11/500], Train Loss: 19.9593, Train RMSE: 4.4676\n",
      "Epoch [11/500], Validation Loss: 21.9701, Validation RMSE: 4.6872, Valid PR: -0.3354\n",
      "Epoch [12/500], Train Loss: 19.2087, Train RMSE: 4.3828\n",
      "Epoch [12/500], Validation Loss: 20.2582, Validation RMSE: 4.5009, Valid PR: 0.5425\n",
      "Epoch [13/500], Train Loss: 17.1767, Train RMSE: 4.1445\n",
      "Epoch [13/500], Validation Loss: 17.8422, Validation RMSE: 4.2240, Valid PR: -0.3770\n",
      "Epoch [14/500], Train Loss: 16.0760, Train RMSE: 4.0095\n",
      "Epoch [14/500], Validation Loss: 15.9960, Validation RMSE: 3.9995, Valid PR: -0.4993\n",
      "Epoch [15/500], Train Loss: 14.1798, Train RMSE: 3.7656\n",
      "Epoch [15/500], Validation Loss: 14.9456, Validation RMSE: 3.8660, Valid PR: 0.4277\n",
      "Epoch [16/500], Train Loss: 13.8611, Train RMSE: 3.7230\n",
      "Epoch [16/500], Validation Loss: 13.7377, Validation RMSE: 3.7064, Valid PR: 0.5505\n",
      "Epoch [17/500], Train Loss: 13.4891, Train RMSE: 3.6728\n",
      "Epoch [17/500], Validation Loss: 12.4626, Validation RMSE: 3.5302, Valid PR: 0.6287\n",
      "Epoch [18/500], Train Loss: 11.7159, Train RMSE: 3.4228\n",
      "Epoch [18/500], Validation Loss: 11.0986, Validation RMSE: 3.3315, Valid PR: -0.6346\n",
      "Epoch [19/500], Train Loss: 10.9429, Train RMSE: 3.3080\n",
      "Epoch [19/500], Validation Loss: 8.9430, Validation RMSE: 2.9905, Valid PR: -0.6210\n",
      "Epoch [20/500], Train Loss: 10.5015, Train RMSE: 3.2406\n",
      "Epoch [20/500], Validation Loss: 7.1460, Validation RMSE: 2.6732, Valid PR: -0.6438\n",
      "Epoch [21/500], Train Loss: 9.7450, Train RMSE: 3.1217\n",
      "Epoch [21/500], Validation Loss: 5.5545, Validation RMSE: 2.3568, Valid PR: -0.7165\n",
      "Epoch [22/500], Train Loss: 8.7155, Train RMSE: 2.9522\n",
      "Epoch [22/500], Validation Loss: 4.0090, Validation RMSE: 2.0022, Valid PR: 0.0696\n",
      "Epoch [23/500], Train Loss: 7.8073, Train RMSE: 2.7942\n",
      "Epoch [23/500], Validation Loss: 2.9507, Validation RMSE: 1.7178, Valid PR: 0.4197\n",
      "Epoch [24/500], Train Loss: 8.0154, Train RMSE: 2.8312\n",
      "Epoch [24/500], Validation Loss: 2.3999, Validation RMSE: 1.5491, Valid PR: 0.4759\n",
      "Epoch [25/500], Train Loss: 7.3736, Train RMSE: 2.7154\n",
      "Epoch [25/500], Validation Loss: 2.1797, Validation RMSE: 1.4764, Valid PR: 0.5088\n",
      "Epoch [26/500], Train Loss: 6.9532, Train RMSE: 2.6369\n",
      "Epoch [26/500], Validation Loss: 2.4844, Validation RMSE: 1.5762, Valid PR: 0.5215\n",
      "Epoch [27/500], Train Loss: 6.2909, Train RMSE: 2.5082\n",
      "Epoch [27/500], Validation Loss: 3.6912, Validation RMSE: 1.9212, Valid PR: 0.5245\n",
      "Epoch [28/500], Train Loss: 4.8069, Train RMSE: 2.1925\n",
      "Epoch [28/500], Validation Loss: 5.5523, Validation RMSE: 2.3563, Valid PR: 0.5542\n",
      "Epoch [29/500], Train Loss: 5.5224, Train RMSE: 2.3500\n",
      "Epoch [29/500], Validation Loss: 8.4909, Validation RMSE: 2.9139, Valid PR: 0.5383\n",
      "Epoch [30/500], Train Loss: 5.0183, Train RMSE: 2.2401\n",
      "Epoch [30/500], Validation Loss: 10.9622, Validation RMSE: 3.3109, Valid PR: 0.6377\n",
      "Epoch [31/500], Train Loss: 5.0577, Train RMSE: 2.2489\n",
      "Epoch [31/500], Validation Loss: 13.7585, Validation RMSE: 3.7093, Valid PR: 0.5299\n",
      "Epoch [32/500], Train Loss: 4.3368, Train RMSE: 2.0825\n",
      "Epoch [32/500], Validation Loss: 16.1587, Validation RMSE: 4.0198, Valid PR: 0.5489\n",
      "Epoch [33/500], Train Loss: 3.9972, Train RMSE: 1.9993\n",
      "Epoch [33/500], Validation Loss: 18.0685, Validation RMSE: 4.2507, Valid PR: 0.4493\n",
      "Epoch [34/500], Train Loss: 4.1943, Train RMSE: 2.0480\n",
      "Epoch [34/500], Validation Loss: 21.8557, Validation RMSE: 4.6750, Valid PR: 0.2461\n",
      "Epoch [35/500], Train Loss: 3.7295, Train RMSE: 1.9312\n",
      "Epoch [35/500], Validation Loss: 25.5240, Validation RMSE: 5.0521, Valid PR: 0.4105\n",
      "Epoch [36/500], Train Loss: 4.3677, Train RMSE: 2.0899\n",
      "Epoch [36/500], Validation Loss: 29.0903, Validation RMSE: 5.3935, Valid PR: 0.2510\n",
      "Epoch [37/500], Train Loss: 3.6183, Train RMSE: 1.9022\n",
      "Epoch [37/500], Validation Loss: 33.4013, Validation RMSE: 5.7794, Valid PR: 0.4540\n",
      "Epoch [38/500], Train Loss: 3.8289, Train RMSE: 1.9568\n",
      "Epoch [38/500], Validation Loss: 38.7869, Validation RMSE: 6.2279, Valid PR: 0.3143\n",
      "Epoch [39/500], Train Loss: 4.8930, Train RMSE: 2.2120\n",
      "Epoch [39/500], Validation Loss: 43.8785, Validation RMSE: 6.6241, Valid PR: 0.4874\n",
      "Epoch [40/500], Train Loss: 4.4624, Train RMSE: 2.1124\n",
      "Epoch [40/500], Validation Loss: 51.0992, Validation RMSE: 7.1484, Valid PR: 0.5583\n",
      "Epoch [41/500], Train Loss: 4.5427, Train RMSE: 2.1314\n",
      "Epoch [41/500], Validation Loss: 57.7816, Validation RMSE: 7.6014, Valid PR: 0.5567\n",
      "Epoch [42/500], Train Loss: 4.0220, Train RMSE: 2.0055\n",
      "Epoch [42/500], Validation Loss: 64.1627, Validation RMSE: 8.0102, Valid PR: 0.5848\n",
      "Epoch [43/500], Train Loss: 3.8826, Train RMSE: 1.9704\n",
      "Epoch [43/500], Validation Loss: 71.2199, Validation RMSE: 8.4392, Valid PR: 0.5476\n",
      "Epoch [44/500], Train Loss: 3.0566, Train RMSE: 1.7483\n",
      "Epoch [44/500], Validation Loss: 77.2356, Validation RMSE: 8.7884, Valid PR: 0.5804\n",
      "Epoch [45/500], Train Loss: 3.6067, Train RMSE: 1.8991\n",
      "Epoch [45/500], Validation Loss: 79.6594, Validation RMSE: 8.9252, Valid PR: 0.5681\n",
      "Epoch [46/500], Train Loss: 3.8096, Train RMSE: 1.9518\n",
      "Epoch [46/500], Validation Loss: 81.1953, Validation RMSE: 9.0108, Valid PR: 0.5689\n",
      "Epoch [47/500], Train Loss: 4.2117, Train RMSE: 2.0522\n",
      "Epoch [47/500], Validation Loss: 81.6239, Validation RMSE: 9.0346, Valid PR: 0.5728\n",
      "Epoch [48/500], Train Loss: 3.8876, Train RMSE: 1.9717\n",
      "Epoch [48/500], Validation Loss: 88.2031, Validation RMSE: 9.3917, Valid PR: 0.5745\n",
      "Epoch [49/500], Train Loss: 4.5437, Train RMSE: 2.1316\n",
      "Epoch [49/500], Validation Loss: 96.3079, Validation RMSE: 9.8137, Valid PR: 0.5688\n",
      "Epoch [50/500], Train Loss: 3.9076, Train RMSE: 1.9768\n",
      "Epoch [50/500], Validation Loss: 97.4514, Validation RMSE: 9.8717, Valid PR: 0.5949\n",
      "Epoch [51/500], Train Loss: 5.3928, Train RMSE: 2.3222\n",
      "Epoch [51/500], Validation Loss: 101.4712, Validation RMSE: 10.0733, Valid PR: 0.6596\n",
      "Epoch [52/500], Train Loss: 4.3760, Train RMSE: 2.0919\n",
      "Epoch [52/500], Validation Loss: 105.8443, Validation RMSE: 10.2881, Valid PR: 0.6709\n",
      "Epoch [53/500], Train Loss: 4.4813, Train RMSE: 2.1169\n",
      "Epoch [53/500], Validation Loss: 104.8347, Validation RMSE: 10.2389, Valid PR: 0.6147\n",
      "Epoch [54/500], Train Loss: 3.5034, Train RMSE: 1.8717\n",
      "Epoch [54/500], Validation Loss: 103.3106, Validation RMSE: 10.1642, Valid PR: 0.6531\n",
      "Epoch [55/500], Train Loss: 3.3692, Train RMSE: 1.8355\n",
      "Epoch [55/500], Validation Loss: 106.0144, Validation RMSE: 10.2963, Valid PR: 0.5420\n",
      "Epoch [56/500], Train Loss: 3.9736, Train RMSE: 1.9934\n",
      "Epoch [56/500], Validation Loss: 96.7179, Validation RMSE: 9.8345, Valid PR: 0.6611\n",
      "Epoch [57/500], Train Loss: 3.6260, Train RMSE: 1.9042\n",
      "Epoch [57/500], Validation Loss: 93.1223, Validation RMSE: 9.6500, Valid PR: 0.6640\n",
      "Epoch [58/500], Train Loss: 3.7561, Train RMSE: 1.9381\n",
      "Epoch [58/500], Validation Loss: 95.5203, Validation RMSE: 9.7734, Valid PR: 0.6608\n",
      "Epoch [59/500], Train Loss: 3.2076, Train RMSE: 1.7910\n",
      "Epoch [59/500], Validation Loss: 98.1110, Validation RMSE: 9.9051, Valid PR: 0.6629\n",
      "Epoch [60/500], Train Loss: 4.5175, Train RMSE: 2.1254\n",
      "Epoch [60/500], Validation Loss: 116.1156, Validation RMSE: 10.7757, Valid PR: 0.6584\n",
      "Epoch [61/500], Train Loss: 3.5849, Train RMSE: 1.8934\n",
      "Epoch [61/500], Validation Loss: 119.3162, Validation RMSE: 10.9232, Valid PR: 0.4950\n",
      "Epoch [62/500], Train Loss: 3.8968, Train RMSE: 1.9740\n",
      "Epoch [62/500], Validation Loss: 109.1836, Validation RMSE: 10.4491, Valid PR: 0.6599\n",
      "Epoch [63/500], Train Loss: 3.6909, Train RMSE: 1.9212\n",
      "Epoch [63/500], Validation Loss: 126.7968, Validation RMSE: 11.2604, Valid PR: -0.2156\n",
      "Epoch [64/500], Train Loss: 3.9234, Train RMSE: 1.9808\n",
      "Epoch [64/500], Validation Loss: 179.5955, Validation RMSE: 13.4013, Valid PR: -0.3151\n",
      "Epoch [65/500], Train Loss: 4.2041, Train RMSE: 2.0504\n",
      "Epoch [65/500], Validation Loss: 154.6204, Validation RMSE: 12.4346, Valid PR: -0.5030\n",
      "Epoch [66/500], Train Loss: 3.2534, Train RMSE: 1.8037\n",
      "Epoch [66/500], Validation Loss: 126.1635, Validation RMSE: 11.2323, Valid PR: 0.4785\n",
      "Epoch [67/500], Train Loss: 3.8278, Train RMSE: 1.9565\n",
      "Epoch [67/500], Validation Loss: 97.9585, Validation RMSE: 9.8974, Valid PR: 0.4876\n",
      "Epoch [68/500], Train Loss: 3.3065, Train RMSE: 1.8184\n",
      "Epoch [68/500], Validation Loss: 79.7035, Validation RMSE: 8.9277, Valid PR: 0.5192\n",
      "Epoch [69/500], Train Loss: 3.5358, Train RMSE: 1.8804\n",
      "Epoch [69/500], Validation Loss: 63.9717, Validation RMSE: 7.9982, Valid PR: 0.5231\n",
      "Epoch [70/500], Train Loss: 3.0011, Train RMSE: 1.7324\n",
      "Epoch [70/500], Validation Loss: 49.7848, Validation RMSE: 7.0558, Valid PR: 0.5407\n",
      "Epoch [71/500], Train Loss: 3.6367, Train RMSE: 1.9070\n",
      "Epoch [71/500], Validation Loss: 39.0280, Validation RMSE: 6.2472, Valid PR: 0.6198\n",
      "Epoch [72/500], Train Loss: 3.9182, Train RMSE: 1.9795\n",
      "Epoch [72/500], Validation Loss: 32.3253, Validation RMSE: 5.6855, Valid PR: 0.7255\n",
      "Epoch [73/500], Train Loss: 4.3959, Train RMSE: 2.0966\n",
      "Epoch [73/500], Validation Loss: 29.5977, Validation RMSE: 5.4404, Valid PR: 0.5441\n",
      "Epoch [74/500], Train Loss: 3.2882, Train RMSE: 1.8133\n",
      "Epoch [74/500], Validation Loss: 26.1301, Validation RMSE: 5.1118, Valid PR: 0.5761\n",
      "Epoch [75/500], Train Loss: 3.3015, Train RMSE: 1.8170\n",
      "Epoch [75/500], Validation Loss: 22.4821, Validation RMSE: 4.7415, Valid PR: 0.5868\n",
      "Early stopping triggered.\n",
      "Test Loss: 3.1306, Test RMSE: 1.7693, Test PR: -0.1458\n",
      "Test Loss: 15.9741, Test RMSE: 3.9968, Test PR: 0.0516\n",
      "Testing method3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3966443589.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3966443589.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3966443589.py:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 35.7927, Train RMSE: 5.9827\n",
      "Epoch [1/500], Validation Loss: 27.8399, Validation RMSE: 5.2764, Valid PR: 0.5456\n",
      "Epoch [2/500], Train Loss: 33.6155, Train RMSE: 5.7979\n",
      "Epoch [2/500], Validation Loss: 29.0170, Validation RMSE: 5.3867, Valid PR: 0.5363\n",
      "Epoch [3/500], Train Loss: 31.0377, Train RMSE: 5.5711\n",
      "Epoch [3/500], Validation Loss: 30.1001, Validation RMSE: 5.4864, Valid PR: 0.5475\n",
      "Epoch [4/500], Train Loss: 30.1348, Train RMSE: 5.4895\n",
      "Epoch [4/500], Validation Loss: 28.6606, Validation RMSE: 5.3536, Valid PR: 0.5482\n",
      "Epoch [5/500], Train Loss: 27.3367, Train RMSE: 5.2285\n",
      "Epoch [5/500], Validation Loss: 27.4789, Validation RMSE: 5.2420, Valid PR: 0.5605\n",
      "Epoch [6/500], Train Loss: 26.4393, Train RMSE: 5.1419\n",
      "Epoch [6/500], Validation Loss: 24.7414, Validation RMSE: 4.9741, Valid PR: 0.5433\n",
      "Epoch [7/500], Train Loss: 25.2227, Train RMSE: 5.0222\n",
      "Epoch [7/500], Validation Loss: 21.9456, Validation RMSE: 4.6846, Valid PR: 0.6295\n",
      "Epoch [8/500], Train Loss: 22.6549, Train RMSE: 4.7597\n",
      "Epoch [8/500], Validation Loss: 21.6866, Validation RMSE: 4.6569, Valid PR: 0.7549\n",
      "Epoch [9/500], Train Loss: 22.6911, Train RMSE: 4.7635\n",
      "Epoch [9/500], Validation Loss: 21.5369, Validation RMSE: 4.6408, Valid PR: 0.6649\n",
      "Epoch [10/500], Train Loss: 20.7435, Train RMSE: 4.5545\n",
      "Epoch [10/500], Validation Loss: 21.0761, Validation RMSE: 4.5909, Valid PR: 0.6002\n",
      "Epoch [11/500], Train Loss: 19.0025, Train RMSE: 4.3592\n",
      "Epoch [11/500], Validation Loss: 20.4330, Validation RMSE: 4.5203, Valid PR: 0.5948\n",
      "Epoch [12/500], Train Loss: 17.2656, Train RMSE: 4.1552\n",
      "Epoch [12/500], Validation Loss: 21.3083, Validation RMSE: 4.6161, Valid PR: 0.5067\n",
      "Epoch [13/500], Train Loss: 16.3927, Train RMSE: 4.0488\n",
      "Epoch [13/500], Validation Loss: 21.6870, Validation RMSE: 4.6569, Valid PR: -0.5464\n",
      "Epoch [14/500], Train Loss: 15.3073, Train RMSE: 3.9125\n",
      "Epoch [14/500], Validation Loss: 19.4676, Validation RMSE: 4.4122, Valid PR: -0.2262\n",
      "Epoch [15/500], Train Loss: 13.5293, Train RMSE: 3.6782\n",
      "Epoch [15/500], Validation Loss: 18.2892, Validation RMSE: 4.2766, Valid PR: -0.4801\n",
      "Epoch [16/500], Train Loss: 13.2608, Train RMSE: 3.6415\n",
      "Epoch [16/500], Validation Loss: 16.1493, Validation RMSE: 4.0186, Valid PR: -0.5494\n",
      "Epoch [17/500], Train Loss: 12.6202, Train RMSE: 3.5525\n",
      "Epoch [17/500], Validation Loss: 13.7098, Validation RMSE: 3.7027, Valid PR: -0.5020\n",
      "Epoch [18/500], Train Loss: 10.9693, Train RMSE: 3.3120\n",
      "Epoch [18/500], Validation Loss: 11.2763, Validation RMSE: 3.3580, Valid PR: -0.5770\n",
      "Epoch [19/500], Train Loss: 10.9030, Train RMSE: 3.3020\n",
      "Epoch [19/500], Validation Loss: 9.0964, Validation RMSE: 3.0160, Valid PR: -0.3373\n",
      "Epoch [20/500], Train Loss: 10.2674, Train RMSE: 3.2043\n",
      "Epoch [20/500], Validation Loss: 7.0177, Validation RMSE: 2.6491, Valid PR: -0.5014\n",
      "Epoch [21/500], Train Loss: 8.4196, Train RMSE: 2.9017\n",
      "Epoch [21/500], Validation Loss: 5.1030, Validation RMSE: 2.2590, Valid PR: -0.1316\n",
      "Epoch [22/500], Train Loss: 8.3109, Train RMSE: 2.8829\n",
      "Epoch [22/500], Validation Loss: 3.7692, Validation RMSE: 1.9415, Valid PR: 0.1358\n",
      "Epoch [23/500], Train Loss: 7.6670, Train RMSE: 2.7689\n",
      "Epoch [23/500], Validation Loss: 2.8647, Validation RMSE: 1.6925, Valid PR: 0.1838\n",
      "Epoch [24/500], Train Loss: 7.0730, Train RMSE: 2.6595\n",
      "Epoch [24/500], Validation Loss: 2.3776, Validation RMSE: 1.5419, Valid PR: 0.3002\n",
      "Epoch [25/500], Train Loss: 6.1307, Train RMSE: 2.4760\n",
      "Epoch [25/500], Validation Loss: 2.1948, Validation RMSE: 1.4815, Valid PR: 0.1210\n",
      "Epoch [26/500], Train Loss: 6.0920, Train RMSE: 2.4682\n",
      "Epoch [26/500], Validation Loss: 2.1664, Validation RMSE: 1.4719, Valid PR: 0.5105\n",
      "Epoch [27/500], Train Loss: 6.6283, Train RMSE: 2.5745\n",
      "Epoch [27/500], Validation Loss: 2.3189, Validation RMSE: 1.5228, Valid PR: 0.4858\n",
      "Epoch [28/500], Train Loss: 6.0599, Train RMSE: 2.4617\n",
      "Epoch [28/500], Validation Loss: 2.7369, Validation RMSE: 1.6544, Valid PR: 0.3983\n",
      "Epoch [29/500], Train Loss: 4.4903, Train RMSE: 2.1190\n",
      "Epoch [29/500], Validation Loss: 3.6504, Validation RMSE: 1.9106, Valid PR: 0.5364\n",
      "Epoch [30/500], Train Loss: 4.5736, Train RMSE: 2.1386\n",
      "Epoch [30/500], Validation Loss: 4.6173, Validation RMSE: 2.1488, Valid PR: 0.5401\n",
      "Epoch [31/500], Train Loss: 4.2760, Train RMSE: 2.0678\n",
      "Epoch [31/500], Validation Loss: 5.3905, Validation RMSE: 2.3217, Valid PR: 0.5340\n",
      "Epoch [32/500], Train Loss: 4.1705, Train RMSE: 2.0422\n",
      "Epoch [32/500], Validation Loss: 6.1168, Validation RMSE: 2.4732, Valid PR: 0.5579\n",
      "Epoch [33/500], Train Loss: 4.3689, Train RMSE: 2.0902\n",
      "Epoch [33/500], Validation Loss: 6.4536, Validation RMSE: 2.5404, Valid PR: 0.5586\n",
      "Epoch [34/500], Train Loss: 3.6543, Train RMSE: 1.9116\n",
      "Epoch [34/500], Validation Loss: 6.2827, Validation RMSE: 2.5065, Valid PR: 0.5520\n",
      "Epoch [35/500], Train Loss: 4.4022, Train RMSE: 2.0981\n",
      "Epoch [35/500], Validation Loss: 6.8158, Validation RMSE: 2.6107, Valid PR: 0.5894\n",
      "Epoch [36/500], Train Loss: 3.6411, Train RMSE: 1.9082\n",
      "Epoch [36/500], Validation Loss: 6.9502, Validation RMSE: 2.6363, Valid PR: 0.5841\n",
      "Epoch [37/500], Train Loss: 4.9033, Train RMSE: 2.2143\n",
      "Epoch [37/500], Validation Loss: 8.6809, Validation RMSE: 2.9463, Valid PR: 0.5829\n",
      "Epoch [38/500], Train Loss: 4.0328, Train RMSE: 2.0082\n",
      "Epoch [38/500], Validation Loss: 10.7913, Validation RMSE: 3.2850, Valid PR: 0.5712\n",
      "Epoch [39/500], Train Loss: 4.3099, Train RMSE: 2.0760\n",
      "Epoch [39/500], Validation Loss: 11.3083, Validation RMSE: 3.3628, Valid PR: 0.6098\n",
      "Epoch [40/500], Train Loss: 5.1904, Train RMSE: 2.2782\n",
      "Epoch [40/500], Validation Loss: 11.8210, Validation RMSE: 3.4382, Valid PR: 0.5971\n",
      "Epoch [41/500], Train Loss: 5.0497, Train RMSE: 2.2472\n",
      "Epoch [41/500], Validation Loss: 12.3764, Validation RMSE: 3.5180, Valid PR: 0.6079\n",
      "Epoch [42/500], Train Loss: 4.3129, Train RMSE: 2.0768\n",
      "Epoch [42/500], Validation Loss: 11.4022, Validation RMSE: 3.3767, Valid PR: 0.6079\n",
      "Epoch [43/500], Train Loss: 5.5364, Train RMSE: 2.3529\n",
      "Epoch [43/500], Validation Loss: 9.3081, Validation RMSE: 3.0509, Valid PR: 0.5982\n",
      "Epoch [44/500], Train Loss: 4.1636, Train RMSE: 2.0405\n",
      "Epoch [44/500], Validation Loss: 7.5746, Validation RMSE: 2.7522, Valid PR: 0.6011\n",
      "Epoch [45/500], Train Loss: 3.9634, Train RMSE: 1.9908\n",
      "Epoch [45/500], Validation Loss: 5.8465, Validation RMSE: 2.4179, Valid PR: 0.5894\n",
      "Epoch [46/500], Train Loss: 3.6805, Train RMSE: 1.9185\n",
      "Epoch [46/500], Validation Loss: 4.7680, Validation RMSE: 2.1836, Valid PR: 0.5976\n",
      "Epoch [47/500], Train Loss: 3.8150, Train RMSE: 1.9532\n",
      "Epoch [47/500], Validation Loss: 4.2508, Validation RMSE: 2.0617, Valid PR: 0.6065\n",
      "Epoch [48/500], Train Loss: 4.6046, Train RMSE: 2.1458\n",
      "Epoch [48/500], Validation Loss: 4.8550, Validation RMSE: 2.2034, Valid PR: 0.5576\n",
      "Epoch [49/500], Train Loss: 3.7710, Train RMSE: 1.9419\n",
      "Epoch [49/500], Validation Loss: 5.8631, Validation RMSE: 2.4214, Valid PR: 0.6500\n",
      "Epoch [50/500], Train Loss: 4.0293, Train RMSE: 2.0073\n",
      "Epoch [50/500], Validation Loss: 7.5656, Validation RMSE: 2.7506, Valid PR: 0.4636\n",
      "Epoch [51/500], Train Loss: 4.0101, Train RMSE: 2.0025\n",
      "Epoch [51/500], Validation Loss: 9.9541, Validation RMSE: 3.1550, Valid PR: 0.4391\n",
      "Epoch [52/500], Train Loss: 3.9897, Train RMSE: 1.9974\n",
      "Epoch [52/500], Validation Loss: 12.4194, Validation RMSE: 3.5241, Valid PR: 0.4380\n",
      "Epoch [53/500], Train Loss: 3.0664, Train RMSE: 1.7511\n",
      "Epoch [53/500], Validation Loss: 15.0718, Validation RMSE: 3.8822, Valid PR: 0.4926\n",
      "Epoch [54/500], Train Loss: 4.6320, Train RMSE: 2.1522\n",
      "Epoch [54/500], Validation Loss: 19.6576, Validation RMSE: 4.4337, Valid PR: -0.6045\n",
      "Epoch [55/500], Train Loss: 4.0161, Train RMSE: 2.0040\n",
      "Epoch [55/500], Validation Loss: 25.7130, Validation RMSE: 5.0708, Valid PR: -0.6291\n",
      "Epoch [56/500], Train Loss: 3.0068, Train RMSE: 1.7340\n",
      "Epoch [56/500], Validation Loss: 29.7032, Validation RMSE: 5.4501, Valid PR: -0.6510\n",
      "Epoch [57/500], Train Loss: 3.8020, Train RMSE: 1.9499\n",
      "Epoch [57/500], Validation Loss: 34.1625, Validation RMSE: 5.8449, Valid PR: -0.6654\n",
      "Epoch [58/500], Train Loss: 3.7463, Train RMSE: 1.9355\n",
      "Epoch [58/500], Validation Loss: 37.1608, Validation RMSE: 6.0960, Valid PR: 0.1059\n",
      "Epoch [59/500], Train Loss: 4.2237, Train RMSE: 2.0552\n",
      "Epoch [59/500], Validation Loss: 38.3286, Validation RMSE: 6.1910, Valid PR: 0.1417\n",
      "Epoch [60/500], Train Loss: 3.5653, Train RMSE: 1.8882\n",
      "Epoch [60/500], Validation Loss: 39.2404, Validation RMSE: 6.2642, Valid PR: 0.3729\n",
      "Epoch [61/500], Train Loss: 3.6581, Train RMSE: 1.9126\n",
      "Epoch [61/500], Validation Loss: 40.1585, Validation RMSE: 6.3371, Valid PR: 0.4498\n",
      "Epoch [62/500], Train Loss: 3.4875, Train RMSE: 1.8675\n",
      "Epoch [62/500], Validation Loss: 41.8447, Validation RMSE: 6.4687, Valid PR: 0.4576\n",
      "Epoch [63/500], Train Loss: 4.0025, Train RMSE: 2.0006\n",
      "Epoch [63/500], Validation Loss: 47.6927, Validation RMSE: 6.9060, Valid PR: 0.4734\n",
      "Epoch [64/500], Train Loss: 3.7520, Train RMSE: 1.9370\n",
      "Epoch [64/500], Validation Loss: 50.8386, Validation RMSE: 7.1301, Valid PR: 0.4774\n",
      "Epoch [65/500], Train Loss: 4.2687, Train RMSE: 2.0661\n",
      "Epoch [65/500], Validation Loss: 53.2558, Validation RMSE: 7.2977, Valid PR: 0.4721\n",
      "Epoch [66/500], Train Loss: 4.7240, Train RMSE: 2.1735\n",
      "Epoch [66/500], Validation Loss: 55.1397, Validation RMSE: 7.4256, Valid PR: 0.4744\n",
      "Epoch [67/500], Train Loss: 3.5060, Train RMSE: 1.8724\n",
      "Epoch [67/500], Validation Loss: 56.6091, Validation RMSE: 7.5239, Valid PR: 0.4733\n",
      "Epoch [68/500], Train Loss: 3.6766, Train RMSE: 1.9174\n",
      "Epoch [68/500], Validation Loss: 58.9772, Validation RMSE: 7.6797, Valid PR: 0.4975\n",
      "Epoch [69/500], Train Loss: 3.4097, Train RMSE: 1.8465\n",
      "Epoch [69/500], Validation Loss: 60.5146, Validation RMSE: 7.7791, Valid PR: 0.5051\n",
      "Epoch [70/500], Train Loss: 3.0931, Train RMSE: 1.7587\n",
      "Epoch [70/500], Validation Loss: 59.4092, Validation RMSE: 7.7077, Valid PR: 0.5034\n",
      "Epoch [71/500], Train Loss: 2.9314, Train RMSE: 1.7121\n",
      "Epoch [71/500], Validation Loss: 58.1126, Validation RMSE: 7.6232, Valid PR: 0.5013\n",
      "Epoch [72/500], Train Loss: 3.8609, Train RMSE: 1.9649\n",
      "Epoch [72/500], Validation Loss: 57.6253, Validation RMSE: 7.5911, Valid PR: 0.4898\n",
      "Epoch [73/500], Train Loss: 4.1254, Train RMSE: 2.0311\n",
      "Epoch [73/500], Validation Loss: 54.0408, Validation RMSE: 7.3512, Valid PR: 0.4789\n",
      "Epoch [74/500], Train Loss: 4.1615, Train RMSE: 2.0400\n",
      "Epoch [74/500], Validation Loss: 52.2334, Validation RMSE: 7.2273, Valid PR: 0.4944\n",
      "Epoch [75/500], Train Loss: 3.9439, Train RMSE: 1.9859\n",
      "Epoch [75/500], Validation Loss: 50.5714, Validation RMSE: 7.1114, Valid PR: 0.4636\n",
      "Epoch [76/500], Train Loss: 4.1265, Train RMSE: 2.0314\n",
      "Epoch [76/500], Validation Loss: 47.8621, Validation RMSE: 6.9182, Valid PR: 0.4712\n",
      "Early stopping triggered.\n",
      "Test Loss: 2.8349, Test RMSE: 1.6837, Test PR: -0.2036\n",
      "Test Loss: 37.6646, Test RMSE: 6.1371, Test PR: -0.0662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3966443589.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3966443589.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define transformer-based neural network class\n",
    "class TransformerNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, output_dim):\n",
    "        super(TransformerNN, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)  # Adding sequence length dimension\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.squeeze(1)  # Removing sequence length dimension\n",
    "        return self.fc(x)\n",
    "\n",
    "# Train transformer-based neural network to predict labels and record metrics\n",
    "def train_transformer_nn(train_matrix_encodings, train_vector_encodings, y_train, val_matrix_encodings, val_vector_encodings, y_val, hidden_dim=256, num_heads=4, num_layers=2, learning_rate=3*1e-3, num_epochs=500, batch_size=256, early_stop_patience=50):\n",
    "    # Combine matrix and vector encodings\n",
    "    train_features = torch.cat((train_matrix_encodings, train_vector_encodings), dim=1)\n",
    "    val_features = torch.cat((val_matrix_encodings, val_vector_encodings), dim=1)\n",
    "    \n",
    "    # Create training and validation datasets\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_features, torch.tensor(y_train, dtype=torch.float32))\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_features, torch.tensor(y_val, dtype=torch.float32))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    input_dim = train_features.size(1)\n",
    "    output_dim = 1  # Assuming regression task\n",
    "    model = TransformerNN(input_dim, hidden_dim, num_heads, num_layers, output_dim).to(device)\n",
    "    criterion = nn.MSELoss() if output_dim == 1 else nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50, verbose=True)\n",
    "\n",
    "    # DataFrame to store metrics\n",
    "    metrics_df = pd.DataFrame(columns=[\"Epoch\", \"Train Loss\", \"Train RMSE\", \"Valid RMSE\", \"Valid PR\"])\n",
    "\n",
    "    # Variables to track best model\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_rmse = torch.sqrt(torch.tensor(avg_train_loss)).item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(features).squeeze()\n",
    "                val_loss = criterion(outputs, labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "                val_outputs_list.append(outputs.cpu())\n",
    "                val_labels_list.append(labels.cpu())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_rmse = torch.sqrt(torch.tensor(avg_val_loss)).item()\n",
    "        val_outputs = torch.cat(val_outputs_list, dim=0)\n",
    "        val_labels = torch.cat(val_labels_list, dim=0)\n",
    "        valid_pr = torch.corrcoef(torch.stack([val_outputs, val_labels]))[0, 1].item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation RMSE: {val_rmse:.4f}, Valid PR: {valid_pr:.4f}\")\n",
    "\n",
    "        # Record metrics\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": avg_train_loss,\n",
    "            \"Train RMSE\": train_rmse,\n",
    "            \"Valid RMSE\": val_rmse,\n",
    "            \"Valid PR\": valid_pr\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "        # Update best model if validation loss improves\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), f\"best_model_state_{method}.pth\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        # Save the last model state at the end of each epoch\n",
    "        torch.save(model.state_dict(), f\"last_model_state_{method}.pth\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        # Learning rate decay\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "# Load and test the final model and record metrics\n",
    "def test_transformer_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path, hidden_dim=256, num_heads=4, num_layers=2, batch_size=64):\n",
    "    # Combine matrix and vector encodings\n",
    "    test_features = torch.cat((test_matrix_encodings, test_vector_encodings), dim=1)\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_features, torch.tensor(y_test, dtype=torch.float32))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    input_dim = test_features.size(1)\n",
    "    output_dim = 1  # Assuming regression task\n",
    "    model = TransformerNN(input_dim, hidden_dim, num_heads, num_layers, output_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # Define loss function\n",
    "    criterion = nn.MSELoss() if output_dim == 1 else nn.BCEWithLogitsLoss()\n",
    "    total_test_loss = 0\n",
    "    test_outputs_list = []\n",
    "    test_labels_list = []\n",
    "    \n",
    "    # Testing loop\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_test_loss += loss.item()\n",
    "            test_outputs_list.append(outputs.cpu())\n",
    "            test_labels_list.append(labels.cpu())\n",
    "    \n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_rmse = torch.sqrt(torch.tensor(avg_test_loss)).item()\n",
    "    test_outputs = torch.cat(test_outputs_list, dim=0)\n",
    "    test_labels = torch.cat(test_labels_list, dim=0)\n",
    "    test_pr = torch.corrcoef(torch.stack([test_outputs, test_labels]))[0, 1].item()\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test RMSE: {test_rmse:.4f}, Test PR: {test_pr:.4f}\")\n",
    "    \n",
    "    return test_rmse, test_pr\n",
    "\n",
    "# Refactor to test three encoding methods\n",
    "encoding_methods = [\n",
    "    \"method1\",\n",
    "    \"method2\",\n",
    "    \"method3\"\n",
    "]\n",
    "\n",
    "metrics_summary = pd.DataFrame(columns=[\"Method\", \"Epoch\", \"Model Type\", \"Train Loss\", \"Train RMSE\", \"Valid RMSE\", \"Valid PR\", \"Test RMSE\", \"Test PR\"])\n",
    "\n",
    "for method in encoding_methods:\n",
    "    print(f\"Testing {method}...\")\n",
    "    \n",
    "    # Define different get_encodings functions for each method\n",
    "    if method == \"method1\":\n",
    "        def get_encodings(model, data_loader, device):\n",
    "            matrix_encodings = []\n",
    "            vector_encodings = []\n",
    "            with torch.no_grad():\n",
    "                for matrix, vector in data_loader:\n",
    "                    matrix, vector = matrix.to(device), vector.to(device)\n",
    "                    matrix_features, vector_features = model(matrix, vector)\n",
    "                    matrix_encodings.append(matrix_features.cpu())\n",
    "                    vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "            matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "            vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "            return matrix_encodings, vector_encodings\n",
    "    elif method == \"method2\":\n",
    "        def get_encodings(model, data_loader, device):\n",
    "            matrix_encoder, vector_encoder = model.matrix_encoder, model.vector_encoder\n",
    "            matrix_encodings = []\n",
    "            vector_encodings = []\n",
    "            with torch.no_grad():\n",
    "                for matrix, vector in data_loader:\n",
    "                    matrix, vector = matrix.to(device), vector.to(device)\n",
    "                    matrix_features_encoder = model.matrix_encoder(matrix)\n",
    "                    vector_features_encoder = model.vector_encoder(vector)\n",
    "                    matrix_features, vector_features = model(matrix, vector)\n",
    "                    # Concatenate both outputs\n",
    "                    matrix_features = torch.cat((matrix_features, matrix_features_encoder), dim=-1)\n",
    "                    vector_features = torch.cat((vector_features, vector_features_encoder), dim=-1)\n",
    "                    matrix_encodings.append(matrix_features.cpu())\n",
    "                    vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "            matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "            vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "            return matrix_encodings, vector_encodings\n",
    "    elif method == \"method3\":\n",
    "        def get_encodings(model, data_loader, device):\n",
    "            matrix_encodings = []\n",
    "            vector_encodings = []\n",
    "            with torch.no_grad():\n",
    "                for matrix, vector in data_loader:\n",
    "                    matrix, vector = matrix.to(device), vector.to(device)\n",
    "                    matrix_features = model.matrix_encoder(matrix)\n",
    "                    vector_features = model.vector_encoder(vector)\n",
    "                    matrix_encodings.append(matrix_features.cpu())\n",
    "                    vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "            matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "            vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "            return matrix_encodings, vector_encodings\n",
    "    \n",
    "    # Get encodings\n",
    "    train_matrix_encodings, train_vector_encodings = get_encodings(model, train_loader, device)\n",
    "    val_matrix_encodings, val_vector_encodings = get_encodings(model, val_loader, device)\n",
    "    test_matrix_encodings, test_vector_encodings = get_encodings(model, test_loader, device)\n",
    "\n",
    "    # Train transformer-based neural network to predict labels\n",
    "    metrics_df = train_transformer_nn(\n",
    "        train_matrix_encodings, train_vector_encodings, y_train,\n",
    "        val_matrix_encodings, val_vector_encodings, y_val\n",
    "    )\n",
    "\n",
    "    # Test the best model\n",
    "    best_test_rmse, best_test_pr = test_transformer_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path=f\"best_model_state_{method}.pth\")\n",
    "\n",
    "    # Store metrics for best model\n",
    "    best_metrics = metrics_df[metrics_df['Valid RMSE'] == metrics_df['Valid RMSE'].min()].copy()\n",
    "    best_metrics[\"Method\"] = method\n",
    "    best_metrics[\"Model Type\"] = \"Best\"\n",
    "    best_metrics[\"Test RMSE\"] = best_test_rmse\n",
    "    best_metrics[\"Test PR\"] = best_test_pr\n",
    "    metrics_summary = pd.concat([metrics_summary, best_metrics], ignore_index=True)\n",
    "\n",
    "    # Test the last model\n",
    "    last_test_rmse, last_test_pr = test_transformer_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path=f\"last_model_state_{method}.pth\")\n",
    "\n",
    "    # Store metrics for last model\n",
    "    last_metrics = metrics_df.iloc[-1:].copy()\n",
    "    last_metrics[\"Method\"] = method\n",
    "    last_metrics[\"Model Type\"] = \"Last\"\n",
    "    last_metrics[\"Test RMSE\"] = last_test_rmse\n",
    "    last_metrics[\"Test PR\"] = last_test_pr\n",
    "    metrics_summary = pd.concat([metrics_summary, last_metrics], ignore_index=True)\n",
    "\n",
    "# Save summary metrics to CSV\n",
    "metrics_summary.to_csv(\"encoding_methods_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e1c34854-8955-4751-881e-5a7b8993e2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Valid RMSE</th>\n",
       "      <th>Valid PR</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>method1</td>\n",
       "      <td>11</td>\n",
       "      <td>Best</td>\n",
       "      <td>14.825213</td>\n",
       "      <td>3.850353</td>\n",
       "      <td>1.397021</td>\n",
       "      <td>0.663954</td>\n",
       "      <td>2.718086</td>\n",
       "      <td>0.117585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>method1</td>\n",
       "      <td>61</td>\n",
       "      <td>Last</td>\n",
       "      <td>2.849923</td>\n",
       "      <td>1.688172</td>\n",
       "      <td>1.873621</td>\n",
       "      <td>0.206692</td>\n",
       "      <td>1.682905</td>\n",
       "      <td>0.183645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>method2</td>\n",
       "      <td>25</td>\n",
       "      <td>Best</td>\n",
       "      <td>7.373564</td>\n",
       "      <td>2.715431</td>\n",
       "      <td>1.476381</td>\n",
       "      <td>0.508836</td>\n",
       "      <td>1.769341</td>\n",
       "      <td>-0.145751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>method2</td>\n",
       "      <td>75</td>\n",
       "      <td>Last</td>\n",
       "      <td>3.301495</td>\n",
       "      <td>1.817002</td>\n",
       "      <td>4.741527</td>\n",
       "      <td>0.586770</td>\n",
       "      <td>3.996764</td>\n",
       "      <td>0.051575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>method3</td>\n",
       "      <td>26</td>\n",
       "      <td>Best</td>\n",
       "      <td>6.091993</td>\n",
       "      <td>2.468196</td>\n",
       "      <td>1.471873</td>\n",
       "      <td>0.510478</td>\n",
       "      <td>1.683729</td>\n",
       "      <td>-0.203566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>method3</td>\n",
       "      <td>76</td>\n",
       "      <td>Last</td>\n",
       "      <td>4.126519</td>\n",
       "      <td>2.031384</td>\n",
       "      <td>6.918242</td>\n",
       "      <td>0.471184</td>\n",
       "      <td>6.137150</td>\n",
       "      <td>-0.066232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Method Epoch Model Type  Train Loss  Train RMSE  Valid RMSE  Valid PR  \\\n",
       "0  method1    11       Best   14.825213    3.850353    1.397021  0.663954   \n",
       "1  method1    61       Last    2.849923    1.688172    1.873621  0.206692   \n",
       "2  method2    25       Best    7.373564    2.715431    1.476381  0.508836   \n",
       "3  method2    75       Last    3.301495    1.817002    4.741527  0.586770   \n",
       "4  method3    26       Best    6.091993    2.468196    1.471873  0.510478   \n",
       "5  method3    76       Last    4.126519    2.031384    6.918242  0.471184   \n",
       "\n",
       "   Test RMSE   Test PR  \n",
       "0   2.718086  0.117585  \n",
       "1   1.682905  0.183645  \n",
       "2   1.769341 -0.145751  \n",
       "3   3.996764  0.051575  \n",
       "4   1.683729 -0.203566  \n",
       "5   6.137150 -0.066232  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "83615c27-7098-4806-9000-d4ff39d241f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing method1...\n",
      "Replication 1 for method1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:122: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 7.7796, Train RMSE: 2.7892\n",
      "Epoch [1/500], Validation Loss: 15.1475, Validation RMSE: 3.8920, Valid PR: -0.2985\n",
      "Epoch [2/500], Train Loss: 4.0086, Train RMSE: 2.0022\n",
      "Epoch [2/500], Validation Loss: 10.8663, Validation RMSE: 3.2964, Valid PR: -0.5420\n",
      "Epoch [3/500], Train Loss: 2.9437, Train RMSE: 1.7157\n",
      "Epoch [3/500], Validation Loss: 8.7432, Validation RMSE: 2.9569, Valid PR: -0.5994\n",
      "Epoch [4/500], Train Loss: 2.3292, Train RMSE: 1.5262\n",
      "Epoch [4/500], Validation Loss: 7.4690, Validation RMSE: 2.7329, Valid PR: -0.5956\n",
      "Epoch [5/500], Train Loss: 2.0891, Train RMSE: 1.4454\n",
      "Epoch [5/500], Validation Loss: 6.5939, Validation RMSE: 2.5679, Valid PR: -0.5663\n",
      "Epoch [6/500], Train Loss: 1.9912, Train RMSE: 1.4111\n",
      "Epoch [6/500], Validation Loss: 5.9226, Validation RMSE: 2.4336, Valid PR: -0.4949\n",
      "Epoch [7/500], Train Loss: 1.8439, Train RMSE: 1.3579\n",
      "Epoch [7/500], Validation Loss: 5.4093, Validation RMSE: 2.3258, Valid PR: -0.3970\n",
      "Epoch [8/500], Train Loss: 1.7612, Train RMSE: 1.3271\n",
      "Epoch [8/500], Validation Loss: 5.0197, Validation RMSE: 2.2405, Valid PR: -0.2316\n",
      "Epoch [9/500], Train Loss: 1.6647, Train RMSE: 1.2902\n",
      "Epoch [9/500], Validation Loss: 4.7155, Validation RMSE: 2.1715, Valid PR: -0.0688\n",
      "Epoch [10/500], Train Loss: 1.5678, Train RMSE: 1.2521\n",
      "Epoch [10/500], Validation Loss: 4.4657, Validation RMSE: 2.1132, Valid PR: 0.0927\n",
      "Epoch [11/500], Train Loss: 1.5509, Train RMSE: 1.2454\n",
      "Epoch [11/500], Validation Loss: 4.2606, Validation RMSE: 2.0641, Valid PR: 0.1700\n",
      "Epoch [12/500], Train Loss: 1.4601, Train RMSE: 1.2084\n",
      "Epoch [12/500], Validation Loss: 4.0874, Validation RMSE: 2.0217, Valid PR: 0.1833\n",
      "Epoch [13/500], Train Loss: 1.4818, Train RMSE: 1.2173\n",
      "Epoch [13/500], Validation Loss: 3.9390, Validation RMSE: 1.9847, Valid PR: 0.1864\n",
      "Epoch [14/500], Train Loss: 1.3394, Train RMSE: 1.1573\n",
      "Epoch [14/500], Validation Loss: 3.8132, Validation RMSE: 1.9527, Valid PR: 0.1804\n",
      "Epoch [15/500], Train Loss: 1.3597, Train RMSE: 1.1660\n",
      "Epoch [15/500], Validation Loss: 3.7036, Validation RMSE: 1.9245, Valid PR: 0.1744\n",
      "Epoch [16/500], Train Loss: 1.3610, Train RMSE: 1.1666\n",
      "Epoch [16/500], Validation Loss: 3.6080, Validation RMSE: 1.8995, Valid PR: 0.1779\n",
      "Epoch [17/500], Train Loss: 1.1851, Train RMSE: 1.0886\n",
      "Epoch [17/500], Validation Loss: 3.5280, Validation RMSE: 1.8783, Valid PR: 0.1388\n",
      "Epoch [18/500], Train Loss: 1.1977, Train RMSE: 1.0944\n",
      "Epoch [18/500], Validation Loss: 3.4579, Validation RMSE: 1.8595, Valid PR: 0.0794\n",
      "Epoch [19/500], Train Loss: 1.2035, Train RMSE: 1.0970\n",
      "Epoch [19/500], Validation Loss: 3.3929, Validation RMSE: 1.8420, Valid PR: 0.0407\n",
      "Epoch [20/500], Train Loss: 1.1445, Train RMSE: 1.0698\n",
      "Epoch [20/500], Validation Loss: 3.3337, Validation RMSE: 1.8259, Valid PR: 0.0137\n",
      "Epoch [21/500], Train Loss: 1.1383, Train RMSE: 1.0669\n",
      "Epoch [21/500], Validation Loss: 3.2799, Validation RMSE: 1.8111, Valid PR: -0.0197\n",
      "Epoch [22/500], Train Loss: 1.1132, Train RMSE: 1.0551\n",
      "Epoch [22/500], Validation Loss: 3.2294, Validation RMSE: 1.7970, Valid PR: -0.0553\n",
      "Epoch [23/500], Train Loss: 1.1088, Train RMSE: 1.0530\n",
      "Epoch [23/500], Validation Loss: 3.1773, Validation RMSE: 1.7825, Valid PR: -0.0694\n",
      "Epoch [24/500], Train Loss: 1.1560, Train RMSE: 1.0752\n",
      "Epoch [24/500], Validation Loss: 3.1282, Validation RMSE: 1.7687, Valid PR: -0.0766\n",
      "Epoch [25/500], Train Loss: 1.0773, Train RMSE: 1.0379\n",
      "Epoch [25/500], Validation Loss: 3.0824, Validation RMSE: 1.7557, Valid PR: -0.0932\n",
      "Epoch [26/500], Train Loss: 1.0376, Train RMSE: 1.0186\n",
      "Epoch [26/500], Validation Loss: 3.0379, Validation RMSE: 1.7430, Valid PR: -0.1070\n",
      "Epoch [27/500], Train Loss: 0.9310, Train RMSE: 0.9649\n",
      "Epoch [27/500], Validation Loss: 2.9965, Validation RMSE: 1.7310, Valid PR: -0.1253\n",
      "Epoch [28/500], Train Loss: 0.9745, Train RMSE: 0.9872\n",
      "Epoch [28/500], Validation Loss: 2.9569, Validation RMSE: 1.7196, Valid PR: -0.1445\n",
      "Epoch [29/500], Train Loss: 1.0691, Train RMSE: 1.0340\n",
      "Epoch [29/500], Validation Loss: 2.9192, Validation RMSE: 1.7086, Valid PR: -0.1551\n",
      "Epoch [30/500], Train Loss: 0.9310, Train RMSE: 0.9649\n",
      "Epoch [30/500], Validation Loss: 2.8837, Validation RMSE: 1.6982, Valid PR: -0.1755\n",
      "Epoch [31/500], Train Loss: 1.0334, Train RMSE: 1.0166\n",
      "Epoch [31/500], Validation Loss: 2.8495, Validation RMSE: 1.6881, Valid PR: -0.1948\n",
      "Epoch [32/500], Train Loss: 0.9445, Train RMSE: 0.9719\n",
      "Epoch [32/500], Validation Loss: 2.8163, Validation RMSE: 1.6782, Valid PR: -0.2203\n",
      "Epoch [33/500], Train Loss: 1.0067, Train RMSE: 1.0034\n",
      "Epoch [33/500], Validation Loss: 2.7847, Validation RMSE: 1.6687, Valid PR: -0.2444\n",
      "Epoch [34/500], Train Loss: 0.9860, Train RMSE: 0.9930\n",
      "Epoch [34/500], Validation Loss: 2.7538, Validation RMSE: 1.6594, Valid PR: -0.2661\n",
      "Epoch [35/500], Train Loss: 0.9585, Train RMSE: 0.9790\n",
      "Epoch [35/500], Validation Loss: 2.7237, Validation RMSE: 1.6504, Valid PR: -0.2846\n",
      "Epoch [36/500], Train Loss: 1.0024, Train RMSE: 1.0012\n",
      "Epoch [36/500], Validation Loss: 2.6953, Validation RMSE: 1.6417, Valid PR: -0.3109\n",
      "Epoch [37/500], Train Loss: 0.9228, Train RMSE: 0.9606\n",
      "Epoch [37/500], Validation Loss: 2.6682, Validation RMSE: 1.6335, Valid PR: -0.3261\n",
      "Epoch [38/500], Train Loss: 0.8619, Train RMSE: 0.9284\n",
      "Epoch [38/500], Validation Loss: 2.6424, Validation RMSE: 1.6255, Valid PR: -0.3357\n",
      "Epoch [39/500], Train Loss: 0.9113, Train RMSE: 0.9546\n",
      "Epoch [39/500], Validation Loss: 2.6169, Validation RMSE: 1.6177, Valid PR: -0.3353\n",
      "Epoch [40/500], Train Loss: 0.8825, Train RMSE: 0.9394\n",
      "Epoch [40/500], Validation Loss: 2.5922, Validation RMSE: 1.6100, Valid PR: -0.3324\n",
      "Epoch [41/500], Train Loss: 0.8886, Train RMSE: 0.9427\n",
      "Epoch [41/500], Validation Loss: 2.5685, Validation RMSE: 1.6027, Valid PR: -0.3131\n",
      "Epoch [42/500], Train Loss: 0.9141, Train RMSE: 0.9561\n",
      "Epoch [42/500], Validation Loss: 2.5451, Validation RMSE: 1.5954, Valid PR: -0.2860\n",
      "Epoch [43/500], Train Loss: 0.8443, Train RMSE: 0.9189\n",
      "Epoch [43/500], Validation Loss: 2.5230, Validation RMSE: 1.5884, Valid PR: -0.2510\n",
      "Epoch [44/500], Train Loss: 0.8481, Train RMSE: 0.9209\n",
      "Epoch [44/500], Validation Loss: 2.5018, Validation RMSE: 1.5817, Valid PR: -0.2167\n",
      "Epoch [45/500], Train Loss: 0.8519, Train RMSE: 0.9230\n",
      "Epoch [45/500], Validation Loss: 2.4820, Validation RMSE: 1.5754, Valid PR: -0.1773\n",
      "Epoch [46/500], Train Loss: 0.8434, Train RMSE: 0.9184\n",
      "Epoch [46/500], Validation Loss: 2.4631, Validation RMSE: 1.5694, Valid PR: -0.1290\n",
      "Epoch [47/500], Train Loss: 0.7995, Train RMSE: 0.8941\n",
      "Epoch [47/500], Validation Loss: 2.4452, Validation RMSE: 1.5637, Valid PR: -0.0789\n",
      "Epoch [48/500], Train Loss: 0.8779, Train RMSE: 0.9370\n",
      "Epoch [48/500], Validation Loss: 2.4282, Validation RMSE: 1.5583, Valid PR: -0.0316\n",
      "Epoch [49/500], Train Loss: 0.9045, Train RMSE: 0.9510\n",
      "Epoch [49/500], Validation Loss: 2.4122, Validation RMSE: 1.5531, Valid PR: 0.0177\n",
      "Epoch [50/500], Train Loss: 0.8962, Train RMSE: 0.9467\n",
      "Epoch [50/500], Validation Loss: 2.3968, Validation RMSE: 1.5482, Valid PR: 0.0674\n",
      "Epoch [51/500], Train Loss: 0.8234, Train RMSE: 0.9074\n",
      "Epoch [51/500], Validation Loss: 2.3826, Validation RMSE: 1.5436, Valid PR: 0.1107\n",
      "Epoch [52/500], Train Loss: 0.8356, Train RMSE: 0.9141\n",
      "Epoch [52/500], Validation Loss: 2.3690, Validation RMSE: 1.5392, Valid PR: 0.1694\n",
      "Epoch [53/500], Train Loss: 0.7769, Train RMSE: 0.8814\n",
      "Epoch [53/500], Validation Loss: 2.3559, Validation RMSE: 1.5349, Valid PR: 0.2334\n",
      "Epoch [54/500], Train Loss: 0.7945, Train RMSE: 0.8914\n",
      "Epoch [54/500], Validation Loss: 2.3438, Validation RMSE: 1.5310, Valid PR: 0.2757\n",
      "Epoch [55/500], Train Loss: 0.8175, Train RMSE: 0.9042\n",
      "Epoch [55/500], Validation Loss: 2.3323, Validation RMSE: 1.5272, Valid PR: 0.3120\n",
      "Epoch [56/500], Train Loss: 0.8489, Train RMSE: 0.9214\n",
      "Epoch [56/500], Validation Loss: 2.3214, Validation RMSE: 1.5236, Valid PR: 0.3433\n",
      "Epoch [57/500], Train Loss: 0.8431, Train RMSE: 0.9182\n",
      "Epoch [57/500], Validation Loss: 2.3111, Validation RMSE: 1.5202, Valid PR: 0.3682\n",
      "Epoch [58/500], Train Loss: 0.8295, Train RMSE: 0.9108\n",
      "Epoch [58/500], Validation Loss: 2.3012, Validation RMSE: 1.5170, Valid PR: 0.3996\n",
      "Epoch [59/500], Train Loss: 0.8015, Train RMSE: 0.8952\n",
      "Epoch [59/500], Validation Loss: 2.2918, Validation RMSE: 1.5139, Valid PR: 0.4270\n",
      "Epoch [60/500], Train Loss: 0.6814, Train RMSE: 0.8255\n",
      "Epoch [60/500], Validation Loss: 2.2829, Validation RMSE: 1.5109, Valid PR: 0.4472\n",
      "Epoch [61/500], Train Loss: 0.7401, Train RMSE: 0.8603\n",
      "Epoch [61/500], Validation Loss: 2.2746, Validation RMSE: 1.5082, Valid PR: 0.4661\n",
      "Epoch [62/500], Train Loss: 0.8127, Train RMSE: 0.9015\n",
      "Epoch [62/500], Validation Loss: 2.2668, Validation RMSE: 1.5056, Valid PR: 0.4865\n",
      "Epoch [63/500], Train Loss: 0.8007, Train RMSE: 0.8948\n",
      "Epoch [63/500], Validation Loss: 2.2595, Validation RMSE: 1.5032, Valid PR: 0.5001\n",
      "Epoch [64/500], Train Loss: 0.8281, Train RMSE: 0.9100\n",
      "Epoch [64/500], Validation Loss: 2.2526, Validation RMSE: 1.5008, Valid PR: 0.5093\n",
      "Epoch [65/500], Train Loss: 0.7764, Train RMSE: 0.8811\n",
      "Epoch [65/500], Validation Loss: 2.2460, Validation RMSE: 1.4987, Valid PR: 0.5272\n",
      "Epoch [66/500], Train Loss: 0.7497, Train RMSE: 0.8659\n",
      "Epoch [66/500], Validation Loss: 2.2397, Validation RMSE: 1.4966, Valid PR: 0.5512\n",
      "Epoch [67/500], Train Loss: 0.7077, Train RMSE: 0.8413\n",
      "Epoch [67/500], Validation Loss: 2.2338, Validation RMSE: 1.4946, Valid PR: 0.5764\n",
      "Epoch [68/500], Train Loss: 0.7416, Train RMSE: 0.8611\n",
      "Epoch [68/500], Validation Loss: 2.2280, Validation RMSE: 1.4926, Valid PR: 0.5991\n",
      "Epoch [69/500], Train Loss: 0.7141, Train RMSE: 0.8451\n",
      "Epoch [69/500], Validation Loss: 2.2225, Validation RMSE: 1.4908, Valid PR: 0.6181\n",
      "Epoch [70/500], Train Loss: 0.7067, Train RMSE: 0.8407\n",
      "Epoch [70/500], Validation Loss: 2.2174, Validation RMSE: 1.4891, Valid PR: 0.6381\n",
      "Epoch [71/500], Train Loss: 0.7709, Train RMSE: 0.8780\n",
      "Epoch [71/500], Validation Loss: 2.2128, Validation RMSE: 1.4875, Valid PR: 0.6510\n",
      "Epoch [72/500], Train Loss: 0.7836, Train RMSE: 0.8852\n",
      "Epoch [72/500], Validation Loss: 2.2085, Validation RMSE: 1.4861, Valid PR: 0.6599\n",
      "Epoch [73/500], Train Loss: 0.7862, Train RMSE: 0.8867\n",
      "Epoch [73/500], Validation Loss: 2.2045, Validation RMSE: 1.4848, Valid PR: 0.6641\n",
      "Epoch [74/500], Train Loss: 0.7691, Train RMSE: 0.8770\n",
      "Epoch [74/500], Validation Loss: 2.2009, Validation RMSE: 1.4835, Valid PR: 0.6567\n",
      "Epoch [75/500], Train Loss: 0.7479, Train RMSE: 0.8648\n",
      "Epoch [75/500], Validation Loss: 2.1976, Validation RMSE: 1.4824, Valid PR: 0.6446\n",
      "Epoch [76/500], Train Loss: 0.6598, Train RMSE: 0.8123\n",
      "Epoch [76/500], Validation Loss: 2.1945, Validation RMSE: 1.4814, Valid PR: 0.6441\n",
      "Epoch [77/500], Train Loss: 0.7447, Train RMSE: 0.8630\n",
      "Epoch [77/500], Validation Loss: 2.1917, Validation RMSE: 1.4804, Valid PR: 0.6428\n",
      "Epoch [78/500], Train Loss: 0.6685, Train RMSE: 0.8176\n",
      "Epoch [78/500], Validation Loss: 2.1892, Validation RMSE: 1.4796, Valid PR: 0.6364\n",
      "Epoch [79/500], Train Loss: 0.7975, Train RMSE: 0.8930\n",
      "Epoch [79/500], Validation Loss: 2.1868, Validation RMSE: 1.4788, Valid PR: 0.6361\n",
      "Epoch [80/500], Train Loss: 0.7232, Train RMSE: 0.8504\n",
      "Epoch [80/500], Validation Loss: 2.1848, Validation RMSE: 1.4781, Valid PR: 0.6380\n",
      "Epoch [81/500], Train Loss: 0.7234, Train RMSE: 0.8505\n",
      "Epoch [81/500], Validation Loss: 2.1832, Validation RMSE: 1.4776, Valid PR: 0.6353\n",
      "Epoch [82/500], Train Loss: 0.6720, Train RMSE: 0.8197\n",
      "Epoch [82/500], Validation Loss: 2.1819, Validation RMSE: 1.4771, Valid PR: 0.6274\n",
      "Epoch [83/500], Train Loss: 0.7059, Train RMSE: 0.8402\n",
      "Epoch [83/500], Validation Loss: 2.1811, Validation RMSE: 1.4769, Valid PR: 0.6096\n",
      "Epoch [84/500], Train Loss: 0.7938, Train RMSE: 0.8910\n",
      "Epoch [84/500], Validation Loss: 2.1809, Validation RMSE: 1.4768, Valid PR: 0.5836\n",
      "Epoch [85/500], Train Loss: 0.6946, Train RMSE: 0.8334\n",
      "Epoch [85/500], Validation Loss: 2.1806, Validation RMSE: 1.4767, Valid PR: 0.5609\n",
      "Epoch [86/500], Train Loss: 0.7279, Train RMSE: 0.8532\n",
      "Epoch [86/500], Validation Loss: 2.1801, Validation RMSE: 1.4765, Valid PR: 0.5401\n",
      "Epoch [87/500], Train Loss: 0.7662, Train RMSE: 0.8753\n",
      "Epoch [87/500], Validation Loss: 2.1795, Validation RMSE: 1.4763, Valid PR: 0.5321\n",
      "Epoch [88/500], Train Loss: 0.7225, Train RMSE: 0.8500\n",
      "Epoch [88/500], Validation Loss: 2.1788, Validation RMSE: 1.4761, Valid PR: 0.5335\n",
      "Epoch [89/500], Train Loss: 0.6834, Train RMSE: 0.8267\n",
      "Epoch [89/500], Validation Loss: 2.1778, Validation RMSE: 1.4757, Valid PR: 0.5450\n",
      "Epoch [90/500], Train Loss: 0.7168, Train RMSE: 0.8466\n",
      "Epoch [90/500], Validation Loss: 2.1767, Validation RMSE: 1.4754, Valid PR: 0.5598\n",
      "Epoch [91/500], Train Loss: 0.6592, Train RMSE: 0.8119\n",
      "Epoch [91/500], Validation Loss: 2.1758, Validation RMSE: 1.4751, Valid PR: 0.5749\n",
      "Epoch [92/500], Train Loss: 0.7475, Train RMSE: 0.8646\n",
      "Epoch [92/500], Validation Loss: 2.1744, Validation RMSE: 1.4746, Valid PR: 0.5981\n",
      "Epoch [93/500], Train Loss: 0.6918, Train RMSE: 0.8317\n",
      "Epoch [93/500], Validation Loss: 2.1733, Validation RMSE: 1.4742, Valid PR: 0.6218\n",
      "Epoch [94/500], Train Loss: 0.7173, Train RMSE: 0.8469\n",
      "Epoch [94/500], Validation Loss: 2.1722, Validation RMSE: 1.4738, Valid PR: 0.6495\n",
      "Epoch [95/500], Train Loss: 0.6749, Train RMSE: 0.8215\n",
      "Epoch [95/500], Validation Loss: 2.1709, Validation RMSE: 1.4734, Valid PR: 0.6723\n",
      "Epoch [96/500], Train Loss: 0.6952, Train RMSE: 0.8338\n",
      "Epoch [96/500], Validation Loss: 2.1696, Validation RMSE: 1.4730, Valid PR: 0.6909\n",
      "Epoch [97/500], Train Loss: 0.7719, Train RMSE: 0.8786\n",
      "Epoch [97/500], Validation Loss: 2.1683, Validation RMSE: 1.4725, Valid PR: 0.7080\n",
      "Epoch [98/500], Train Loss: 0.7157, Train RMSE: 0.8460\n",
      "Epoch [98/500], Validation Loss: 2.1670, Validation RMSE: 1.4721, Valid PR: 0.7181\n",
      "Epoch [99/500], Train Loss: 0.7521, Train RMSE: 0.8672\n",
      "Epoch [99/500], Validation Loss: 2.1655, Validation RMSE: 1.4716, Valid PR: 0.7291\n",
      "Epoch [100/500], Train Loss: 0.7846, Train RMSE: 0.8858\n",
      "Epoch [100/500], Validation Loss: 2.1639, Validation RMSE: 1.4710, Valid PR: 0.7389\n",
      "Epoch [101/500], Train Loss: 0.6887, Train RMSE: 0.8299\n",
      "Epoch [101/500], Validation Loss: 2.1626, Validation RMSE: 1.4706, Valid PR: 0.7471\n",
      "Epoch [102/500], Train Loss: 0.7201, Train RMSE: 0.8486\n",
      "Epoch [102/500], Validation Loss: 2.1617, Validation RMSE: 1.4703, Valid PR: 0.7496\n",
      "Epoch [103/500], Train Loss: 0.7260, Train RMSE: 0.8521\n",
      "Epoch [103/500], Validation Loss: 2.1603, Validation RMSE: 1.4698, Valid PR: 0.7547\n",
      "Epoch [104/500], Train Loss: 0.6924, Train RMSE: 0.8321\n",
      "Epoch [104/500], Validation Loss: 2.1591, Validation RMSE: 1.4694, Valid PR: 0.7559\n",
      "Epoch [105/500], Train Loss: 0.7130, Train RMSE: 0.8444\n",
      "Epoch [105/500], Validation Loss: 2.1577, Validation RMSE: 1.4689, Valid PR: 0.7579\n",
      "Epoch [106/500], Train Loss: 0.7573, Train RMSE: 0.8703\n",
      "Epoch [106/500], Validation Loss: 2.1555, Validation RMSE: 1.4682, Valid PR: 0.7631\n",
      "Epoch [107/500], Train Loss: 0.7536, Train RMSE: 0.8681\n",
      "Epoch [107/500], Validation Loss: 2.1526, Validation RMSE: 1.4672, Valid PR: 0.7711\n",
      "Epoch [108/500], Train Loss: 0.6944, Train RMSE: 0.8333\n",
      "Epoch [108/500], Validation Loss: 2.1496, Validation RMSE: 1.4661, Valid PR: 0.7790\n",
      "Epoch [109/500], Train Loss: 0.7496, Train RMSE: 0.8658\n",
      "Epoch [109/500], Validation Loss: 2.1466, Validation RMSE: 1.4651, Valid PR: 0.7884\n",
      "Epoch [110/500], Train Loss: 0.6697, Train RMSE: 0.8183\n",
      "Epoch [110/500], Validation Loss: 2.1436, Validation RMSE: 1.4641, Valid PR: 0.7992\n",
      "Epoch [111/500], Train Loss: 0.7320, Train RMSE: 0.8556\n",
      "Epoch [111/500], Validation Loss: 2.1398, Validation RMSE: 1.4628, Valid PR: 0.8105\n",
      "Epoch [112/500], Train Loss: 0.6991, Train RMSE: 0.8361\n",
      "Epoch [112/500], Validation Loss: 2.1359, Validation RMSE: 1.4615, Valid PR: 0.8195\n",
      "Epoch [113/500], Train Loss: 0.6645, Train RMSE: 0.8151\n",
      "Epoch [113/500], Validation Loss: 2.1314, Validation RMSE: 1.4599, Valid PR: 0.8293\n",
      "Epoch [114/500], Train Loss: 0.7697, Train RMSE: 0.8773\n",
      "Epoch [114/500], Validation Loss: 2.1268, Validation RMSE: 1.4584, Valid PR: 0.8374\n",
      "Epoch [115/500], Train Loss: 0.6710, Train RMSE: 0.8191\n",
      "Epoch [115/500], Validation Loss: 2.1213, Validation RMSE: 1.4565, Valid PR: 0.8446\n",
      "Epoch [116/500], Train Loss: 0.6615, Train RMSE: 0.8133\n",
      "Epoch [116/500], Validation Loss: 2.1148, Validation RMSE: 1.4542, Valid PR: 0.8512\n",
      "Epoch [117/500], Train Loss: 0.7332, Train RMSE: 0.8563\n",
      "Epoch [117/500], Validation Loss: 2.1084, Validation RMSE: 1.4520, Valid PR: 0.8587\n",
      "Epoch [118/500], Train Loss: 0.7500, Train RMSE: 0.8660\n",
      "Epoch [118/500], Validation Loss: 2.1018, Validation RMSE: 1.4497, Valid PR: 0.8647\n",
      "Epoch [119/500], Train Loss: 0.6774, Train RMSE: 0.8230\n",
      "Epoch [119/500], Validation Loss: 2.0945, Validation RMSE: 1.4472, Valid PR: 0.8700\n",
      "Epoch [120/500], Train Loss: 0.6837, Train RMSE: 0.8268\n",
      "Epoch [120/500], Validation Loss: 2.0870, Validation RMSE: 1.4446, Valid PR: 0.8750\n",
      "Epoch [121/500], Train Loss: 0.6831, Train RMSE: 0.8265\n",
      "Epoch [121/500], Validation Loss: 2.0789, Validation RMSE: 1.4418, Valid PR: 0.8794\n",
      "Epoch [122/500], Train Loss: 0.6484, Train RMSE: 0.8052\n",
      "Epoch [122/500], Validation Loss: 2.0704, Validation RMSE: 1.4389, Valid PR: 0.8830\n",
      "Epoch [123/500], Train Loss: 0.6869, Train RMSE: 0.8288\n",
      "Epoch [123/500], Validation Loss: 2.0608, Validation RMSE: 1.4355, Valid PR: 0.8865\n",
      "Epoch [124/500], Train Loss: 0.7363, Train RMSE: 0.8581\n",
      "Epoch [124/500], Validation Loss: 2.0499, Validation RMSE: 1.4317, Valid PR: 0.8902\n",
      "Epoch [125/500], Train Loss: 0.7488, Train RMSE: 0.8653\n",
      "Epoch [125/500], Validation Loss: 2.0384, Validation RMSE: 1.4277, Valid PR: 0.8935\n",
      "Epoch [126/500], Train Loss: 0.7100, Train RMSE: 0.8426\n",
      "Epoch [126/500], Validation Loss: 2.0257, Validation RMSE: 1.4233, Valid PR: 0.8971\n",
      "Epoch [127/500], Train Loss: 0.6955, Train RMSE: 0.8340\n",
      "Epoch [127/500], Validation Loss: 2.0124, Validation RMSE: 1.4186, Valid PR: 0.9007\n",
      "Epoch [128/500], Train Loss: 0.6167, Train RMSE: 0.7853\n",
      "Epoch [128/500], Validation Loss: 1.9976, Validation RMSE: 1.4134, Valid PR: 0.9046\n",
      "Epoch [129/500], Train Loss: 0.5930, Train RMSE: 0.7701\n",
      "Epoch [129/500], Validation Loss: 1.9810, Validation RMSE: 1.4075, Valid PR: 0.9080\n",
      "Epoch [130/500], Train Loss: 0.6809, Train RMSE: 0.8252\n",
      "Epoch [130/500], Validation Loss: 1.9631, Validation RMSE: 1.4011, Valid PR: 0.9105\n",
      "Epoch [131/500], Train Loss: 0.6801, Train RMSE: 0.8247\n",
      "Epoch [131/500], Validation Loss: 1.9424, Validation RMSE: 1.3937, Valid PR: 0.9128\n",
      "Epoch [132/500], Train Loss: 0.6419, Train RMSE: 0.8012\n",
      "Epoch [132/500], Validation Loss: 1.9207, Validation RMSE: 1.3859, Valid PR: 0.9146\n",
      "Epoch [133/500], Train Loss: 0.6117, Train RMSE: 0.7821\n",
      "Epoch [133/500], Validation Loss: 1.8969, Validation RMSE: 1.3773, Valid PR: 0.9161\n",
      "Epoch [134/500], Train Loss: 0.6814, Train RMSE: 0.8255\n",
      "Epoch [134/500], Validation Loss: 1.8679, Validation RMSE: 1.3667, Valid PR: 0.9170\n",
      "Epoch [135/500], Train Loss: 0.6856, Train RMSE: 0.8280\n",
      "Epoch [135/500], Validation Loss: 1.8359, Validation RMSE: 1.3550, Valid PR: 0.9174\n",
      "Epoch [136/500], Train Loss: 0.6647, Train RMSE: 0.8153\n",
      "Epoch [136/500], Validation Loss: 1.7991, Validation RMSE: 1.3413, Valid PR: 0.9177\n",
      "Epoch [137/500], Train Loss: 0.6716, Train RMSE: 0.8195\n",
      "Epoch [137/500], Validation Loss: 1.7574, Validation RMSE: 1.3257, Valid PR: 0.9181\n",
      "Epoch [138/500], Train Loss: 0.6021, Train RMSE: 0.7760\n",
      "Epoch [138/500], Validation Loss: 1.7138, Validation RMSE: 1.3091, Valid PR: 0.9181\n",
      "Epoch [139/500], Train Loss: 0.6313, Train RMSE: 0.7946\n",
      "Epoch [139/500], Validation Loss: 1.6661, Validation RMSE: 1.2908, Valid PR: 0.9185\n",
      "Epoch [140/500], Train Loss: 0.5990, Train RMSE: 0.7740\n",
      "Epoch [140/500], Validation Loss: 1.6121, Validation RMSE: 1.2697, Valid PR: 0.9192\n",
      "Epoch [141/500], Train Loss: 0.6441, Train RMSE: 0.8026\n",
      "Epoch [141/500], Validation Loss: 1.5549, Validation RMSE: 1.2470, Valid PR: 0.9196\n",
      "Epoch [142/500], Train Loss: 0.6473, Train RMSE: 0.8046\n",
      "Epoch [142/500], Validation Loss: 1.4910, Validation RMSE: 1.2210, Valid PR: 0.9203\n",
      "Epoch [143/500], Train Loss: 0.5922, Train RMSE: 0.7695\n",
      "Epoch [143/500], Validation Loss: 1.4297, Validation RMSE: 1.1957, Valid PR: 0.9204\n",
      "Epoch [144/500], Train Loss: 0.6161, Train RMSE: 0.7849\n",
      "Epoch [144/500], Validation Loss: 1.3671, Validation RMSE: 1.1692, Valid PR: 0.9206\n",
      "Epoch [145/500], Train Loss: 0.6389, Train RMSE: 0.7993\n",
      "Epoch [145/500], Validation Loss: 1.2988, Validation RMSE: 1.1396, Valid PR: 0.9208\n",
      "Epoch [146/500], Train Loss: 0.6063, Train RMSE: 0.7786\n",
      "Epoch [146/500], Validation Loss: 1.2266, Validation RMSE: 1.1075, Valid PR: 0.9208\n",
      "Epoch [147/500], Train Loss: 0.6301, Train RMSE: 0.7938\n",
      "Epoch [147/500], Validation Loss: 1.1562, Validation RMSE: 1.0753, Valid PR: 0.9207\n",
      "Epoch [148/500], Train Loss: 0.6250, Train RMSE: 0.7906\n",
      "Epoch [148/500], Validation Loss: 1.0893, Validation RMSE: 1.0437, Valid PR: 0.9206\n",
      "Epoch [149/500], Train Loss: 0.6110, Train RMSE: 0.7817\n",
      "Epoch [149/500], Validation Loss: 1.0341, Validation RMSE: 1.0169, Valid PR: 0.9203\n",
      "Epoch [150/500], Train Loss: 0.5639, Train RMSE: 0.7509\n",
      "Epoch [150/500], Validation Loss: 0.9818, Validation RMSE: 0.9909, Valid PR: 0.9201\n",
      "Epoch [151/500], Train Loss: 0.6877, Train RMSE: 0.8293\n",
      "Epoch [151/500], Validation Loss: 0.9287, Validation RMSE: 0.9637, Valid PR: 0.9201\n",
      "Epoch [152/500], Train Loss: 0.5501, Train RMSE: 0.7417\n",
      "Epoch [152/500], Validation Loss: 0.8850, Validation RMSE: 0.9407, Valid PR: 0.9199\n",
      "Epoch [153/500], Train Loss: 0.5881, Train RMSE: 0.7669\n",
      "Epoch [153/500], Validation Loss: 0.8426, Validation RMSE: 0.9179, Valid PR: 0.9196\n",
      "Epoch [154/500], Train Loss: 0.5858, Train RMSE: 0.7654\n",
      "Epoch [154/500], Validation Loss: 0.8056, Validation RMSE: 0.8975, Valid PR: 0.9193\n",
      "Epoch [155/500], Train Loss: 0.6081, Train RMSE: 0.7798\n",
      "Epoch [155/500], Validation Loss: 0.7664, Validation RMSE: 0.8754, Valid PR: 0.9192\n",
      "Epoch [156/500], Train Loss: 0.5004, Train RMSE: 0.7074\n",
      "Epoch [156/500], Validation Loss: 0.7295, Validation RMSE: 0.8541, Valid PR: 0.9190\n",
      "Epoch [157/500], Train Loss: 0.6431, Train RMSE: 0.8019\n",
      "Epoch [157/500], Validation Loss: 0.6958, Validation RMSE: 0.8342, Valid PR: 0.9189\n",
      "Epoch [158/500], Train Loss: 0.6091, Train RMSE: 0.7805\n",
      "Epoch [158/500], Validation Loss: 0.6649, Validation RMSE: 0.8154, Valid PR: 0.9188\n",
      "Epoch [159/500], Train Loss: 0.5875, Train RMSE: 0.7665\n",
      "Epoch [159/500], Validation Loss: 0.6381, Validation RMSE: 0.7988, Valid PR: 0.9188\n",
      "Epoch [160/500], Train Loss: 0.5515, Train RMSE: 0.7427\n",
      "Epoch [160/500], Validation Loss: 0.6154, Validation RMSE: 0.7845, Valid PR: 0.9188\n",
      "Epoch [161/500], Train Loss: 0.6461, Train RMSE: 0.8038\n",
      "Epoch [161/500], Validation Loss: 0.5928, Validation RMSE: 0.7699, Valid PR: 0.9187\n",
      "Epoch [162/500], Train Loss: 0.5494, Train RMSE: 0.7412\n",
      "Epoch [162/500], Validation Loss: 0.5707, Validation RMSE: 0.7554, Valid PR: 0.9186\n",
      "Epoch [163/500], Train Loss: 0.5874, Train RMSE: 0.7664\n",
      "Epoch [163/500], Validation Loss: 0.5480, Validation RMSE: 0.7403, Valid PR: 0.9188\n",
      "Epoch [164/500], Train Loss: 0.5094, Train RMSE: 0.7137\n",
      "Epoch [164/500], Validation Loss: 0.5271, Validation RMSE: 0.7260, Valid PR: 0.9189\n",
      "Epoch [165/500], Train Loss: 0.5904, Train RMSE: 0.7684\n",
      "Epoch [165/500], Validation Loss: 0.5100, Validation RMSE: 0.7141, Valid PR: 0.9189\n",
      "Epoch [166/500], Train Loss: 0.5481, Train RMSE: 0.7404\n",
      "Epoch [166/500], Validation Loss: 0.4962, Validation RMSE: 0.7044, Valid PR: 0.9188\n",
      "Epoch [167/500], Train Loss: 0.5143, Train RMSE: 0.7171\n",
      "Epoch [167/500], Validation Loss: 0.4880, Validation RMSE: 0.6986, Valid PR: 0.9183\n",
      "Epoch [168/500], Train Loss: 0.5368, Train RMSE: 0.7327\n",
      "Epoch [168/500], Validation Loss: 0.4811, Validation RMSE: 0.6936, Valid PR: 0.9176\n",
      "Epoch [169/500], Train Loss: 0.5387, Train RMSE: 0.7340\n",
      "Epoch [169/500], Validation Loss: 0.4778, Validation RMSE: 0.6912, Valid PR: 0.9167\n",
      "Epoch [170/500], Train Loss: 0.5717, Train RMSE: 0.7561\n",
      "Epoch [170/500], Validation Loss: 0.4773, Validation RMSE: 0.6909, Valid PR: 0.9160\n",
      "Epoch [171/500], Train Loss: 0.5595, Train RMSE: 0.7480\n",
      "Epoch [171/500], Validation Loss: 0.4786, Validation RMSE: 0.6918, Valid PR: 0.9151\n",
      "Epoch [172/500], Train Loss: 0.5219, Train RMSE: 0.7224\n",
      "Epoch [172/500], Validation Loss: 0.4805, Validation RMSE: 0.6932, Valid PR: 0.9143\n",
      "Epoch [173/500], Train Loss: 0.5671, Train RMSE: 0.7531\n",
      "Epoch [173/500], Validation Loss: 0.4850, Validation RMSE: 0.6964, Valid PR: 0.9130\n",
      "Epoch [174/500], Train Loss: 0.5041, Train RMSE: 0.7100\n",
      "Epoch [174/500], Validation Loss: 0.4876, Validation RMSE: 0.6983, Valid PR: 0.9118\n",
      "Epoch [175/500], Train Loss: 0.5496, Train RMSE: 0.7414\n",
      "Epoch [175/500], Validation Loss: 0.4929, Validation RMSE: 0.7021, Valid PR: 0.9102\n",
      "Epoch [176/500], Train Loss: 0.5872, Train RMSE: 0.7663\n",
      "Epoch [176/500], Validation Loss: 0.4970, Validation RMSE: 0.7050, Valid PR: 0.9082\n",
      "Epoch [177/500], Train Loss: 0.5213, Train RMSE: 0.7220\n",
      "Epoch [177/500], Validation Loss: 0.5034, Validation RMSE: 0.7095, Valid PR: 0.9062\n",
      "Epoch [178/500], Train Loss: 0.5095, Train RMSE: 0.7138\n",
      "Epoch [178/500], Validation Loss: 0.5129, Validation RMSE: 0.7161, Valid PR: 0.9040\n",
      "Epoch [179/500], Train Loss: 0.5265, Train RMSE: 0.7256\n",
      "Epoch [179/500], Validation Loss: 0.5236, Validation RMSE: 0.7236, Valid PR: 0.9013\n",
      "Epoch [180/500], Train Loss: 0.5225, Train RMSE: 0.7228\n",
      "Epoch [180/500], Validation Loss: 0.5379, Validation RMSE: 0.7334, Valid PR: 0.8985\n",
      "Epoch [181/500], Train Loss: 0.5185, Train RMSE: 0.7201\n",
      "Epoch [181/500], Validation Loss: 0.5482, Validation RMSE: 0.7404, Valid PR: 0.8967\n",
      "Epoch [182/500], Train Loss: 0.5248, Train RMSE: 0.7244\n",
      "Epoch [182/500], Validation Loss: 0.5568, Validation RMSE: 0.7462, Valid PR: 0.8961\n",
      "Epoch [183/500], Train Loss: 0.5406, Train RMSE: 0.7353\n",
      "Epoch [183/500], Validation Loss: 0.5617, Validation RMSE: 0.7494, Valid PR: 0.8958\n",
      "Epoch [184/500], Train Loss: 0.4458, Train RMSE: 0.6677\n",
      "Epoch [184/500], Validation Loss: 0.5606, Validation RMSE: 0.7488, Valid PR: 0.8966\n",
      "Epoch [185/500], Train Loss: 0.6121, Train RMSE: 0.7824\n",
      "Epoch [185/500], Validation Loss: 0.5529, Validation RMSE: 0.7436, Valid PR: 0.8978\n",
      "Epoch [186/500], Train Loss: 0.5138, Train RMSE: 0.7168\n",
      "Epoch [186/500], Validation Loss: 0.5448, Validation RMSE: 0.7381, Valid PR: 0.8991\n",
      "Epoch [187/500], Train Loss: 0.5028, Train RMSE: 0.7091\n",
      "Epoch [187/500], Validation Loss: 0.5411, Validation RMSE: 0.7356, Valid PR: 0.8999\n",
      "Epoch [188/500], Train Loss: 0.5496, Train RMSE: 0.7414\n",
      "Epoch [188/500], Validation Loss: 0.5366, Validation RMSE: 0.7325, Valid PR: 0.9009\n",
      "Epoch [189/500], Train Loss: 0.5290, Train RMSE: 0.7273\n",
      "Epoch [189/500], Validation Loss: 0.5299, Validation RMSE: 0.7279, Valid PR: 0.9021\n",
      "Epoch [190/500], Train Loss: 0.5155, Train RMSE: 0.7180\n",
      "Epoch [190/500], Validation Loss: 0.5226, Validation RMSE: 0.7229, Valid PR: 0.9040\n",
      "Epoch [191/500], Train Loss: 0.4504, Train RMSE: 0.6711\n",
      "Epoch [191/500], Validation Loss: 0.5162, Validation RMSE: 0.7185, Valid PR: 0.9059\n",
      "Epoch [192/500], Train Loss: 0.5124, Train RMSE: 0.7158\n",
      "Epoch [192/500], Validation Loss: 0.5069, Validation RMSE: 0.7120, Valid PR: 0.9085\n",
      "Epoch [193/500], Train Loss: 0.5308, Train RMSE: 0.7286\n",
      "Epoch [193/500], Validation Loss: 0.4926, Validation RMSE: 0.7019, Valid PR: 0.9126\n",
      "Epoch [194/500], Train Loss: 0.5299, Train RMSE: 0.7280\n",
      "Epoch [194/500], Validation Loss: 0.4748, Validation RMSE: 0.6891, Valid PR: 0.9177\n",
      "Epoch [195/500], Train Loss: 0.4881, Train RMSE: 0.6987\n",
      "Epoch [195/500], Validation Loss: 0.4586, Validation RMSE: 0.6772, Valid PR: 0.9219\n",
      "Epoch [196/500], Train Loss: 0.5360, Train RMSE: 0.7321\n",
      "Epoch [196/500], Validation Loss: 0.4459, Validation RMSE: 0.6678, Valid PR: 0.9244\n",
      "Epoch [197/500], Train Loss: 0.4218, Train RMSE: 0.6495\n",
      "Epoch [197/500], Validation Loss: 0.4348, Validation RMSE: 0.6594, Valid PR: 0.9243\n",
      "Epoch [198/500], Train Loss: 0.4995, Train RMSE: 0.7068\n",
      "Epoch [198/500], Validation Loss: 0.4296, Validation RMSE: 0.6555, Valid PR: 0.9224\n",
      "Epoch [199/500], Train Loss: 0.4818, Train RMSE: 0.6941\n",
      "Epoch [199/500], Validation Loss: 0.4330, Validation RMSE: 0.6580, Valid PR: 0.9202\n",
      "Epoch [200/500], Train Loss: 0.5018, Train RMSE: 0.7084\n",
      "Epoch [200/500], Validation Loss: 0.4399, Validation RMSE: 0.6633, Valid PR: 0.9173\n",
      "Epoch [201/500], Train Loss: 0.4757, Train RMSE: 0.6897\n",
      "Epoch [201/500], Validation Loss: 0.4467, Validation RMSE: 0.6684, Valid PR: 0.9149\n",
      "Epoch [202/500], Train Loss: 0.4636, Train RMSE: 0.6809\n",
      "Epoch [202/500], Validation Loss: 0.4565, Validation RMSE: 0.6757, Valid PR: 0.9123\n",
      "Epoch [203/500], Train Loss: 0.4799, Train RMSE: 0.6927\n",
      "Epoch [203/500], Validation Loss: 0.4698, Validation RMSE: 0.6854, Valid PR: 0.9094\n",
      "Epoch [204/500], Train Loss: 0.5315, Train RMSE: 0.7290\n",
      "Epoch [204/500], Validation Loss: 0.4829, Validation RMSE: 0.6949, Valid PR: 0.9061\n",
      "Epoch [205/500], Train Loss: 0.5122, Train RMSE: 0.7157\n",
      "Epoch [205/500], Validation Loss: 0.4963, Validation RMSE: 0.7045, Valid PR: 0.9033\n",
      "Epoch [206/500], Train Loss: 0.4550, Train RMSE: 0.6746\n",
      "Epoch [206/500], Validation Loss: 0.5032, Validation RMSE: 0.7094, Valid PR: 0.9027\n",
      "Epoch [207/500], Train Loss: 0.4483, Train RMSE: 0.6695\n",
      "Epoch [207/500], Validation Loss: 0.5098, Validation RMSE: 0.7140, Valid PR: 0.9024\n",
      "Epoch [208/500], Train Loss: 0.4739, Train RMSE: 0.6884\n",
      "Epoch [208/500], Validation Loss: 0.5164, Validation RMSE: 0.7186, Valid PR: 0.9011\n",
      "Epoch [209/500], Train Loss: 0.4788, Train RMSE: 0.6919\n",
      "Epoch [209/500], Validation Loss: 0.5192, Validation RMSE: 0.7206, Valid PR: 0.8997\n",
      "Epoch [210/500], Train Loss: 0.5188, Train RMSE: 0.7203\n",
      "Epoch [210/500], Validation Loss: 0.5270, Validation RMSE: 0.7259, Valid PR: 0.8976\n",
      "Epoch [211/500], Train Loss: 0.3572, Train RMSE: 0.5977\n",
      "Epoch [211/500], Validation Loss: 0.5383, Validation RMSE: 0.7337, Valid PR: 0.8947\n",
      "Epoch [212/500], Train Loss: 0.4899, Train RMSE: 0.6999\n",
      "Epoch [212/500], Validation Loss: 0.5571, Validation RMSE: 0.7464, Valid PR: 0.8903\n",
      "Epoch [213/500], Train Loss: 0.4187, Train RMSE: 0.6470\n",
      "Epoch [213/500], Validation Loss: 0.5746, Validation RMSE: 0.7580, Valid PR: 0.8848\n",
      "Epoch [214/500], Train Loss: 0.4495, Train RMSE: 0.6704\n",
      "Epoch [214/500], Validation Loss: 0.5903, Validation RMSE: 0.7683, Valid PR: 0.8785\n",
      "Epoch [215/500], Train Loss: 0.4444, Train RMSE: 0.6666\n",
      "Epoch [215/500], Validation Loss: 0.5987, Validation RMSE: 0.7737, Valid PR: 0.8739\n",
      "Epoch [216/500], Train Loss: 0.4374, Train RMSE: 0.6613\n",
      "Epoch [216/500], Validation Loss: 0.6037, Validation RMSE: 0.7770, Valid PR: 0.8702\n",
      "Epoch [217/500], Train Loss: 0.5043, Train RMSE: 0.7101\n",
      "Epoch [217/500], Validation Loss: 0.6136, Validation RMSE: 0.7833, Valid PR: 0.8660\n",
      "Epoch [218/500], Train Loss: 0.4561, Train RMSE: 0.6754\n",
      "Epoch [218/500], Validation Loss: 0.6310, Validation RMSE: 0.7944, Valid PR: 0.8600\n",
      "Epoch [219/500], Train Loss: 0.4601, Train RMSE: 0.6783\n",
      "Epoch [219/500], Validation Loss: 0.6540, Validation RMSE: 0.8087, Valid PR: 0.8526\n",
      "Epoch [220/500], Train Loss: 0.3882, Train RMSE: 0.6231\n",
      "Epoch [220/500], Validation Loss: 0.6682, Validation RMSE: 0.8174, Valid PR: 0.8480\n",
      "Epoch [221/500], Train Loss: 0.4769, Train RMSE: 0.6906\n",
      "Epoch [221/500], Validation Loss: 0.6843, Validation RMSE: 0.8272, Valid PR: 0.8435\n",
      "Epoch [222/500], Train Loss: 0.3980, Train RMSE: 0.6309\n",
      "Epoch [222/500], Validation Loss: 0.7068, Validation RMSE: 0.8407, Valid PR: 0.8373\n",
      "Epoch [223/500], Train Loss: 0.4756, Train RMSE: 0.6897\n",
      "Epoch [223/500], Validation Loss: 0.7231, Validation RMSE: 0.8504, Valid PR: 0.8335\n",
      "Epoch [224/500], Train Loss: 0.4553, Train RMSE: 0.6747\n",
      "Epoch [224/500], Validation Loss: 0.7292, Validation RMSE: 0.8539, Valid PR: 0.8328\n",
      "Epoch [225/500], Train Loss: 0.4559, Train RMSE: 0.6752\n",
      "Epoch [225/500], Validation Loss: 0.7340, Validation RMSE: 0.8567, Valid PR: 0.8323\n",
      "Epoch [226/500], Train Loss: 0.4594, Train RMSE: 0.6778\n",
      "Epoch [226/500], Validation Loss: 0.7363, Validation RMSE: 0.8581, Valid PR: 0.8324\n",
      "Epoch [227/500], Train Loss: 0.4082, Train RMSE: 0.6389\n",
      "Epoch [227/500], Validation Loss: 0.7342, Validation RMSE: 0.8568, Valid PR: 0.8336\n",
      "Epoch [228/500], Train Loss: 0.4338, Train RMSE: 0.6586\n",
      "Epoch [228/500], Validation Loss: 0.7329, Validation RMSE: 0.8561, Valid PR: 0.8348\n",
      "Epoch [229/500], Train Loss: 0.3580, Train RMSE: 0.5983\n",
      "Epoch [229/500], Validation Loss: 0.7348, Validation RMSE: 0.8572, Valid PR: 0.8355\n",
      "Epoch [230/500], Train Loss: 0.4718, Train RMSE: 0.6869\n",
      "Epoch [230/500], Validation Loss: 0.7363, Validation RMSE: 0.8581, Valid PR: 0.8354\n",
      "Epoch [231/500], Train Loss: 0.5098, Train RMSE: 0.7140\n",
      "Epoch [231/500], Validation Loss: 0.7416, Validation RMSE: 0.8612, Valid PR: 0.8344\n",
      "Epoch [232/500], Train Loss: 0.5110, Train RMSE: 0.7148\n",
      "Epoch [232/500], Validation Loss: 0.7550, Validation RMSE: 0.8689, Valid PR: 0.8303\n",
      "Epoch [233/500], Train Loss: 0.3676, Train RMSE: 0.6063\n",
      "Epoch [233/500], Validation Loss: 0.7762, Validation RMSE: 0.8810, Valid PR: 0.8240\n",
      "Epoch [234/500], Train Loss: 0.3986, Train RMSE: 0.6314\n",
      "Epoch [234/500], Validation Loss: 0.7928, Validation RMSE: 0.8904, Valid PR: 0.8180\n",
      "Epoch [235/500], Train Loss: 0.4336, Train RMSE: 0.6585\n",
      "Epoch [235/500], Validation Loss: 0.8047, Validation RMSE: 0.8970, Valid PR: 0.8131\n",
      "Epoch [236/500], Train Loss: 0.4282, Train RMSE: 0.6543\n",
      "Epoch [236/500], Validation Loss: 0.8173, Validation RMSE: 0.9040, Valid PR: 0.8098\n",
      "Epoch [237/500], Train Loss: 0.4289, Train RMSE: 0.6549\n",
      "Epoch [237/500], Validation Loss: 0.8240, Validation RMSE: 0.9077, Valid PR: 0.8094\n",
      "Epoch [238/500], Train Loss: 0.4048, Train RMSE: 0.6363\n",
      "Epoch [238/500], Validation Loss: 0.8307, Validation RMSE: 0.9114, Valid PR: 0.8094\n",
      "Epoch [239/500], Train Loss: 0.4596, Train RMSE: 0.6779\n",
      "Epoch [239/500], Validation Loss: 0.8397, Validation RMSE: 0.9164, Valid PR: 0.8094\n",
      "Epoch [240/500], Train Loss: 0.4493, Train RMSE: 0.6703\n",
      "Epoch [240/500], Validation Loss: 0.8537, Validation RMSE: 0.9240, Valid PR: 0.8054\n",
      "Epoch [241/500], Train Loss: 0.3621, Train RMSE: 0.6018\n",
      "Epoch [241/500], Validation Loss: 0.8617, Validation RMSE: 0.9283, Valid PR: 0.8011\n",
      "Epoch [242/500], Train Loss: 0.4284, Train RMSE: 0.6545\n",
      "Epoch [242/500], Validation Loss: 0.8682, Validation RMSE: 0.9318, Valid PR: 0.7959\n",
      "Epoch [243/500], Train Loss: 0.4213, Train RMSE: 0.6491\n",
      "Epoch [243/500], Validation Loss: 0.8796, Validation RMSE: 0.9379, Valid PR: 0.7894\n",
      "Epoch [244/500], Train Loss: 0.4060, Train RMSE: 0.6372\n",
      "Epoch [244/500], Validation Loss: 0.9049, Validation RMSE: 0.9513, Valid PR: 0.7823\n",
      "Epoch [245/500], Train Loss: 0.4189, Train RMSE: 0.6472\n",
      "Epoch [245/500], Validation Loss: 0.9333, Validation RMSE: 0.9661, Valid PR: 0.7761\n",
      "Epoch [246/500], Train Loss: 0.4017, Train RMSE: 0.6338\n",
      "Epoch [246/500], Validation Loss: 0.9456, Validation RMSE: 0.9724, Valid PR: 0.7746\n",
      "Epoch [247/500], Train Loss: 0.3932, Train RMSE: 0.6271\n",
      "Epoch [247/500], Validation Loss: 0.9480, Validation RMSE: 0.9736, Valid PR: 0.7757\n",
      "Epoch [248/500], Train Loss: 0.4249, Train RMSE: 0.6519\n",
      "Epoch [248/500], Validation Loss: 0.9396, Validation RMSE: 0.9693, Valid PR: 0.7792\n",
      "Early stopping triggered.\n",
      "Test Loss: 3.4566, Test RMSE: 1.8592, Test PR: 0.1221\n",
      "Replication 2 for method1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:282: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_summary = pd.concat([metrics_summary, best_metrics], ignore_index=True)\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:122: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 10.7757, Train RMSE: 3.2826\n",
      "Epoch [1/500], Validation Loss: 25.5035, Validation RMSE: 5.0501, Valid PR: -0.6463\n",
      "Epoch [2/500], Train Loss: 5.8029, Train RMSE: 2.4089\n",
      "Epoch [2/500], Validation Loss: 17.9131, Validation RMSE: 4.2324, Valid PR: -0.6892\n",
      "Epoch [3/500], Train Loss: 4.2249, Train RMSE: 2.0555\n",
      "Epoch [3/500], Validation Loss: 13.9664, Validation RMSE: 3.7372, Valid PR: -0.6262\n",
      "Epoch [4/500], Train Loss: 3.6464, Train RMSE: 1.9096\n",
      "Epoch [4/500], Validation Loss: 11.7866, Validation RMSE: 3.4332, Valid PR: -0.5572\n",
      "Epoch [5/500], Train Loss: 3.0932, Train RMSE: 1.7588\n",
      "Epoch [5/500], Validation Loss: 10.4093, Validation RMSE: 3.2264, Valid PR: -0.5385\n",
      "Epoch [6/500], Train Loss: 2.7990, Train RMSE: 1.6730\n",
      "Epoch [6/500], Validation Loss: 9.4211, Validation RMSE: 3.0694, Valid PR: -0.5663\n",
      "Epoch [7/500], Train Loss: 2.6604, Train RMSE: 1.6311\n",
      "Epoch [7/500], Validation Loss: 8.6611, Validation RMSE: 2.9430, Valid PR: -0.5584\n",
      "Epoch [8/500], Train Loss: 2.4736, Train RMSE: 1.5728\n",
      "Epoch [8/500], Validation Loss: 8.0395, Validation RMSE: 2.8354, Valid PR: -0.5965\n",
      "Epoch [9/500], Train Loss: 2.3325, Train RMSE: 1.5272\n",
      "Epoch [9/500], Validation Loss: 7.5247, Validation RMSE: 2.7431, Valid PR: -0.5972\n",
      "Epoch [10/500], Train Loss: 2.2939, Train RMSE: 1.5145\n",
      "Epoch [10/500], Validation Loss: 7.0951, Validation RMSE: 2.6637, Valid PR: -0.5532\n",
      "Epoch [11/500], Train Loss: 2.1702, Train RMSE: 1.4732\n",
      "Epoch [11/500], Validation Loss: 6.7458, Validation RMSE: 2.5973, Valid PR: -0.5436\n",
      "Epoch [12/500], Train Loss: 2.1764, Train RMSE: 1.4753\n",
      "Epoch [12/500], Validation Loss: 6.4559, Validation RMSE: 2.5409, Valid PR: -0.5462\n",
      "Epoch [13/500], Train Loss: 2.0213, Train RMSE: 1.4217\n",
      "Epoch [13/500], Validation Loss: 6.2051, Validation RMSE: 2.4910, Valid PR: -0.5472\n",
      "Epoch [14/500], Train Loss: 1.8693, Train RMSE: 1.3672\n",
      "Epoch [14/500], Validation Loss: 5.9752, Validation RMSE: 2.4444, Valid PR: -0.5236\n",
      "Epoch [15/500], Train Loss: 1.8947, Train RMSE: 1.3765\n",
      "Epoch [15/500], Validation Loss: 5.7707, Validation RMSE: 2.4022, Valid PR: -0.4760\n",
      "Epoch [16/500], Train Loss: 1.8169, Train RMSE: 1.3479\n",
      "Epoch [16/500], Validation Loss: 5.5919, Validation RMSE: 2.3647, Valid PR: -0.4019\n",
      "Epoch [17/500], Train Loss: 1.7707, Train RMSE: 1.3307\n",
      "Epoch [17/500], Validation Loss: 5.4350, Validation RMSE: 2.3313, Valid PR: -0.2851\n",
      "Epoch [18/500], Train Loss: 1.7957, Train RMSE: 1.3400\n",
      "Epoch [18/500], Validation Loss: 5.2955, Validation RMSE: 2.3012, Valid PR: -0.1431\n",
      "Epoch [19/500], Train Loss: 1.7557, Train RMSE: 1.3250\n",
      "Epoch [19/500], Validation Loss: 5.1713, Validation RMSE: 2.2740, Valid PR: -0.0793\n",
      "Epoch [20/500], Train Loss: 1.6239, Train RMSE: 1.2743\n",
      "Epoch [20/500], Validation Loss: 5.0550, Validation RMSE: 2.2483, Valid PR: -0.0310\n",
      "Epoch [21/500], Train Loss: 1.6892, Train RMSE: 1.2997\n",
      "Epoch [21/500], Validation Loss: 4.9491, Validation RMSE: 2.2247, Valid PR: -0.0162\n",
      "Epoch [22/500], Train Loss: 1.5998, Train RMSE: 1.2648\n",
      "Epoch [22/500], Validation Loss: 4.8538, Validation RMSE: 2.2031, Valid PR: -0.0233\n",
      "Epoch [23/500], Train Loss: 1.6535, Train RMSE: 1.2859\n",
      "Epoch [23/500], Validation Loss: 4.7639, Validation RMSE: 2.1826, Valid PR: -0.0347\n",
      "Epoch [24/500], Train Loss: 1.5203, Train RMSE: 1.2330\n",
      "Epoch [24/500], Validation Loss: 4.6802, Validation RMSE: 2.1634, Valid PR: -0.0368\n",
      "Epoch [25/500], Train Loss: 1.4809, Train RMSE: 1.2169\n",
      "Epoch [25/500], Validation Loss: 4.6010, Validation RMSE: 2.1450, Valid PR: -0.0277\n",
      "Epoch [26/500], Train Loss: 1.4989, Train RMSE: 1.2243\n",
      "Epoch [26/500], Validation Loss: 4.5271, Validation RMSE: 2.1277, Valid PR: -0.0084\n",
      "Epoch [27/500], Train Loss: 1.4956, Train RMSE: 1.2229\n",
      "Epoch [27/500], Validation Loss: 4.4573, Validation RMSE: 2.1112, Valid PR: 0.0217\n",
      "Epoch [28/500], Train Loss: 1.5616, Train RMSE: 1.2496\n",
      "Epoch [28/500], Validation Loss: 4.3911, Validation RMSE: 2.0955, Valid PR: 0.0479\n",
      "Epoch [29/500], Train Loss: 1.4342, Train RMSE: 1.1976\n",
      "Epoch [29/500], Validation Loss: 4.3289, Validation RMSE: 2.0806, Valid PR: 0.0275\n",
      "Epoch [30/500], Train Loss: 1.4341, Train RMSE: 1.1975\n",
      "Epoch [30/500], Validation Loss: 4.2695, Validation RMSE: 2.0663, Valid PR: 0.0013\n",
      "Epoch [31/500], Train Loss: 1.4441, Train RMSE: 1.2017\n",
      "Epoch [31/500], Validation Loss: 4.2121, Validation RMSE: 2.0523, Valid PR: -0.0281\n",
      "Epoch [32/500], Train Loss: 1.3877, Train RMSE: 1.1780\n",
      "Epoch [32/500], Validation Loss: 4.1564, Validation RMSE: 2.0387, Valid PR: -0.0537\n",
      "Epoch [33/500], Train Loss: 1.3976, Train RMSE: 1.1822\n",
      "Epoch [33/500], Validation Loss: 4.1025, Validation RMSE: 2.0255, Valid PR: -0.0835\n",
      "Epoch [34/500], Train Loss: 1.3629, Train RMSE: 1.1674\n",
      "Epoch [34/500], Validation Loss: 4.0505, Validation RMSE: 2.0126, Valid PR: -0.1110\n",
      "Epoch [35/500], Train Loss: 1.3593, Train RMSE: 1.1659\n",
      "Epoch [35/500], Validation Loss: 4.0001, Validation RMSE: 2.0000, Valid PR: -0.1333\n",
      "Epoch [36/500], Train Loss: 1.3688, Train RMSE: 1.1700\n",
      "Epoch [36/500], Validation Loss: 3.9507, Validation RMSE: 1.9876, Valid PR: -0.1449\n",
      "Epoch [37/500], Train Loss: 1.3708, Train RMSE: 1.1708\n",
      "Epoch [37/500], Validation Loss: 3.9024, Validation RMSE: 1.9754, Valid PR: -0.1515\n",
      "Epoch [38/500], Train Loss: 1.4025, Train RMSE: 1.1843\n",
      "Epoch [38/500], Validation Loss: 3.8551, Validation RMSE: 1.9634, Valid PR: -0.1495\n",
      "Epoch [39/500], Train Loss: 1.3329, Train RMSE: 1.1545\n",
      "Epoch [39/500], Validation Loss: 3.8090, Validation RMSE: 1.9517, Valid PR: -0.1452\n",
      "Epoch [40/500], Train Loss: 1.2378, Train RMSE: 1.1126\n",
      "Epoch [40/500], Validation Loss: 3.7640, Validation RMSE: 1.9401, Valid PR: -0.1332\n",
      "Epoch [41/500], Train Loss: 1.2547, Train RMSE: 1.1202\n",
      "Epoch [41/500], Validation Loss: 3.7201, Validation RMSE: 1.9288, Valid PR: -0.1127\n",
      "Epoch [42/500], Train Loss: 1.2287, Train RMSE: 1.1084\n",
      "Epoch [42/500], Validation Loss: 3.6772, Validation RMSE: 1.9176, Valid PR: -0.0960\n",
      "Epoch [43/500], Train Loss: 1.3402, Train RMSE: 1.1577\n",
      "Epoch [43/500], Validation Loss: 3.6348, Validation RMSE: 1.9065, Valid PR: -0.0821\n",
      "Epoch [44/500], Train Loss: 1.2656, Train RMSE: 1.1250\n",
      "Epoch [44/500], Validation Loss: 3.5936, Validation RMSE: 1.8957, Valid PR: -0.0568\n",
      "Epoch [45/500], Train Loss: 1.3324, Train RMSE: 1.1543\n",
      "Epoch [45/500], Validation Loss: 3.5534, Validation RMSE: 1.8851, Valid PR: -0.0367\n",
      "Epoch [46/500], Train Loss: 1.1366, Train RMSE: 1.0661\n",
      "Epoch [46/500], Validation Loss: 3.5144, Validation RMSE: 1.8747, Valid PR: -0.0226\n",
      "Epoch [47/500], Train Loss: 1.2480, Train RMSE: 1.1172\n",
      "Epoch [47/500], Validation Loss: 3.4760, Validation RMSE: 1.8644, Valid PR: -0.0116\n",
      "Epoch [48/500], Train Loss: 1.2121, Train RMSE: 1.1009\n",
      "Epoch [48/500], Validation Loss: 3.4385, Validation RMSE: 1.8543, Valid PR: 0.0085\n",
      "Epoch [49/500], Train Loss: 1.1976, Train RMSE: 1.0944\n",
      "Epoch [49/500], Validation Loss: 3.4018, Validation RMSE: 1.8444, Valid PR: 0.0319\n",
      "Epoch [50/500], Train Loss: 1.1613, Train RMSE: 1.0776\n",
      "Epoch [50/500], Validation Loss: 3.3657, Validation RMSE: 1.8346, Valid PR: 0.0608\n",
      "Epoch [51/500], Train Loss: 1.1682, Train RMSE: 1.0808\n",
      "Epoch [51/500], Validation Loss: 3.3302, Validation RMSE: 1.8249, Valid PR: 0.0940\n",
      "Epoch [52/500], Train Loss: 1.1499, Train RMSE: 1.0723\n",
      "Epoch [52/500], Validation Loss: 3.2955, Validation RMSE: 1.8153, Valid PR: 0.1255\n",
      "Epoch [53/500], Train Loss: 1.2219, Train RMSE: 1.1054\n",
      "Epoch [53/500], Validation Loss: 3.2611, Validation RMSE: 1.8058, Valid PR: 0.1628\n",
      "Epoch [54/500], Train Loss: 1.1185, Train RMSE: 1.0576\n",
      "Epoch [54/500], Validation Loss: 3.2274, Validation RMSE: 1.7965, Valid PR: 0.1984\n",
      "Epoch [55/500], Train Loss: 1.1540, Train RMSE: 1.0743\n",
      "Epoch [55/500], Validation Loss: 3.1948, Validation RMSE: 1.7874, Valid PR: 0.2303\n",
      "Epoch [56/500], Train Loss: 1.1275, Train RMSE: 1.0618\n",
      "Epoch [56/500], Validation Loss: 3.1629, Validation RMSE: 1.7785, Valid PR: 0.2590\n",
      "Epoch [57/500], Train Loss: 1.0678, Train RMSE: 1.0333\n",
      "Epoch [57/500], Validation Loss: 3.1321, Validation RMSE: 1.7698, Valid PR: 0.2811\n",
      "Epoch [58/500], Train Loss: 1.0941, Train RMSE: 1.0460\n",
      "Epoch [58/500], Validation Loss: 3.1019, Validation RMSE: 1.7612, Valid PR: 0.3004\n",
      "Epoch [59/500], Train Loss: 1.1078, Train RMSE: 1.0525\n",
      "Epoch [59/500], Validation Loss: 3.0727, Validation RMSE: 1.7529, Valid PR: 0.3098\n",
      "Epoch [60/500], Train Loss: 1.0731, Train RMSE: 1.0359\n",
      "Epoch [60/500], Validation Loss: 3.0442, Validation RMSE: 1.7448, Valid PR: 0.3165\n",
      "Epoch [61/500], Train Loss: 1.0839, Train RMSE: 1.0411\n",
      "Epoch [61/500], Validation Loss: 3.0162, Validation RMSE: 1.7367, Valid PR: 0.3274\n",
      "Epoch [62/500], Train Loss: 1.1217, Train RMSE: 1.0591\n",
      "Epoch [62/500], Validation Loss: 2.9890, Validation RMSE: 1.7289, Valid PR: 0.3302\n",
      "Epoch [63/500], Train Loss: 0.9965, Train RMSE: 0.9982\n",
      "Epoch [63/500], Validation Loss: 2.9625, Validation RMSE: 1.7212, Valid PR: 0.3221\n",
      "Epoch [64/500], Train Loss: 1.0300, Train RMSE: 1.0149\n",
      "Epoch [64/500], Validation Loss: 2.9364, Validation RMSE: 1.7136, Valid PR: 0.3172\n",
      "Epoch [65/500], Train Loss: 1.0192, Train RMSE: 1.0096\n",
      "Epoch [65/500], Validation Loss: 2.9109, Validation RMSE: 1.7061, Valid PR: 0.3113\n",
      "Epoch [66/500], Train Loss: 1.1444, Train RMSE: 1.0698\n",
      "Epoch [66/500], Validation Loss: 2.8862, Validation RMSE: 1.6989, Valid PR: 0.3039\n",
      "Epoch [67/500], Train Loss: 0.9947, Train RMSE: 0.9973\n",
      "Epoch [67/500], Validation Loss: 2.8620, Validation RMSE: 1.6917, Valid PR: 0.2969\n",
      "Epoch [68/500], Train Loss: 1.0536, Train RMSE: 1.0265\n",
      "Epoch [68/500], Validation Loss: 2.8385, Validation RMSE: 1.6848, Valid PR: 0.2944\n",
      "Epoch [69/500], Train Loss: 1.1068, Train RMSE: 1.0521\n",
      "Epoch [69/500], Validation Loss: 2.8155, Validation RMSE: 1.6779, Valid PR: 0.2943\n",
      "Epoch [70/500], Train Loss: 0.9376, Train RMSE: 0.9683\n",
      "Epoch [70/500], Validation Loss: 2.7933, Validation RMSE: 1.6713, Valid PR: 0.3016\n",
      "Epoch [71/500], Train Loss: 0.9625, Train RMSE: 0.9811\n",
      "Epoch [71/500], Validation Loss: 2.7718, Validation RMSE: 1.6649, Valid PR: 0.3044\n",
      "Epoch [72/500], Train Loss: 0.9828, Train RMSE: 0.9914\n",
      "Epoch [72/500], Validation Loss: 2.7510, Validation RMSE: 1.6586, Valid PR: 0.2992\n",
      "Epoch [73/500], Train Loss: 0.9580, Train RMSE: 0.9788\n",
      "Epoch [73/500], Validation Loss: 2.7309, Validation RMSE: 1.6525, Valid PR: 0.2940\n",
      "Epoch [74/500], Train Loss: 1.0406, Train RMSE: 1.0201\n",
      "Epoch [74/500], Validation Loss: 2.7111, Validation RMSE: 1.6465, Valid PR: 0.2861\n",
      "Epoch [75/500], Train Loss: 1.0147, Train RMSE: 1.0073\n",
      "Epoch [75/500], Validation Loss: 2.6918, Validation RMSE: 1.6407, Valid PR: 0.2760\n",
      "Epoch [76/500], Train Loss: 1.0171, Train RMSE: 1.0085\n",
      "Epoch [76/500], Validation Loss: 2.6732, Validation RMSE: 1.6350, Valid PR: 0.2630\n",
      "Epoch [77/500], Train Loss: 0.9343, Train RMSE: 0.9666\n",
      "Epoch [77/500], Validation Loss: 2.6551, Validation RMSE: 1.6294, Valid PR: 0.2510\n",
      "Epoch [78/500], Train Loss: 0.8696, Train RMSE: 0.9325\n",
      "Epoch [78/500], Validation Loss: 2.6375, Validation RMSE: 1.6241, Valid PR: 0.2414\n",
      "Epoch [79/500], Train Loss: 0.8850, Train RMSE: 0.9407\n",
      "Epoch [79/500], Validation Loss: 2.6203, Validation RMSE: 1.6187, Valid PR: 0.2448\n",
      "Epoch [80/500], Train Loss: 1.0219, Train RMSE: 1.0109\n",
      "Epoch [80/500], Validation Loss: 2.6036, Validation RMSE: 1.6136, Valid PR: 0.2443\n",
      "Epoch [81/500], Train Loss: 0.9882, Train RMSE: 0.9941\n",
      "Epoch [81/500], Validation Loss: 2.5873, Validation RMSE: 1.6085, Valid PR: 0.2440\n",
      "Epoch [82/500], Train Loss: 0.9136, Train RMSE: 0.9558\n",
      "Epoch [82/500], Validation Loss: 2.5714, Validation RMSE: 1.6036, Valid PR: 0.2391\n",
      "Epoch [83/500], Train Loss: 0.8977, Train RMSE: 0.9475\n",
      "Epoch [83/500], Validation Loss: 2.5557, Validation RMSE: 1.5986, Valid PR: 0.2446\n",
      "Epoch [84/500], Train Loss: 0.8961, Train RMSE: 0.9466\n",
      "Epoch [84/500], Validation Loss: 2.5405, Validation RMSE: 1.5939, Valid PR: 0.2534\n",
      "Epoch [85/500], Train Loss: 1.0198, Train RMSE: 1.0098\n",
      "Epoch [85/500], Validation Loss: 2.5258, Validation RMSE: 1.5893, Valid PR: 0.2617\n",
      "Epoch [86/500], Train Loss: 0.8730, Train RMSE: 0.9343\n",
      "Epoch [86/500], Validation Loss: 2.5115, Validation RMSE: 1.5848, Valid PR: 0.2726\n",
      "Epoch [87/500], Train Loss: 0.9126, Train RMSE: 0.9553\n",
      "Epoch [87/500], Validation Loss: 2.4977, Validation RMSE: 1.5804, Valid PR: 0.2807\n",
      "Epoch [88/500], Train Loss: 0.8920, Train RMSE: 0.9445\n",
      "Epoch [88/500], Validation Loss: 2.4842, Validation RMSE: 1.5761, Valid PR: 0.2903\n",
      "Epoch [89/500], Train Loss: 0.8012, Train RMSE: 0.8951\n",
      "Epoch [89/500], Validation Loss: 2.4712, Validation RMSE: 1.5720, Valid PR: 0.2977\n",
      "Epoch [90/500], Train Loss: 0.8706, Train RMSE: 0.9331\n",
      "Epoch [90/500], Validation Loss: 2.4587, Validation RMSE: 1.5680, Valid PR: 0.3002\n",
      "Epoch [91/500], Train Loss: 0.9645, Train RMSE: 0.9821\n",
      "Epoch [91/500], Validation Loss: 2.4467, Validation RMSE: 1.5642, Valid PR: 0.2994\n",
      "Epoch [92/500], Train Loss: 0.8297, Train RMSE: 0.9109\n",
      "Epoch [92/500], Validation Loss: 2.4346, Validation RMSE: 1.5603, Valid PR: 0.3015\n",
      "Epoch [93/500], Train Loss: 0.8988, Train RMSE: 0.9480\n",
      "Epoch [93/500], Validation Loss: 2.4229, Validation RMSE: 1.5566, Valid PR: 0.2966\n",
      "Epoch [94/500], Train Loss: 0.8574, Train RMSE: 0.9260\n",
      "Epoch [94/500], Validation Loss: 2.4115, Validation RMSE: 1.5529, Valid PR: 0.2915\n",
      "Epoch [95/500], Train Loss: 0.8502, Train RMSE: 0.9220\n",
      "Epoch [95/500], Validation Loss: 2.4008, Validation RMSE: 1.5494, Valid PR: 0.2812\n",
      "Epoch [96/500], Train Loss: 0.8744, Train RMSE: 0.9351\n",
      "Epoch [96/500], Validation Loss: 2.3905, Validation RMSE: 1.5461, Valid PR: 0.2650\n",
      "Epoch [97/500], Train Loss: 0.7706, Train RMSE: 0.8778\n",
      "Epoch [97/500], Validation Loss: 2.3804, Validation RMSE: 1.5428, Valid PR: 0.2600\n",
      "Epoch [98/500], Train Loss: 0.8790, Train RMSE: 0.9376\n",
      "Epoch [98/500], Validation Loss: 2.3706, Validation RMSE: 1.5397, Valid PR: 0.2546\n",
      "Epoch [99/500], Train Loss: 0.9380, Train RMSE: 0.9685\n",
      "Epoch [99/500], Validation Loss: 2.3611, Validation RMSE: 1.5366, Valid PR: 0.2549\n",
      "Epoch [100/500], Train Loss: 0.7931, Train RMSE: 0.8905\n",
      "Epoch [100/500], Validation Loss: 2.3519, Validation RMSE: 1.5336, Valid PR: 0.2534\n",
      "Epoch [101/500], Train Loss: 0.9675, Train RMSE: 0.9836\n",
      "Epoch [101/500], Validation Loss: 2.3431, Validation RMSE: 1.5307, Valid PR: 0.2525\n",
      "Epoch [102/500], Train Loss: 0.8723, Train RMSE: 0.9340\n",
      "Epoch [102/500], Validation Loss: 2.3349, Validation RMSE: 1.5280, Valid PR: 0.2515\n",
      "Epoch [103/500], Train Loss: 0.8023, Train RMSE: 0.8957\n",
      "Epoch [103/500], Validation Loss: 2.3269, Validation RMSE: 1.5254, Valid PR: 0.2538\n",
      "Epoch [104/500], Train Loss: 0.9363, Train RMSE: 0.9676\n",
      "Epoch [104/500], Validation Loss: 2.3191, Validation RMSE: 1.5228, Valid PR: 0.2616\n",
      "Epoch [105/500], Train Loss: 0.8979, Train RMSE: 0.9476\n",
      "Epoch [105/500], Validation Loss: 2.3115, Validation RMSE: 1.5204, Valid PR: 0.2724\n",
      "Epoch [106/500], Train Loss: 0.8824, Train RMSE: 0.9394\n",
      "Epoch [106/500], Validation Loss: 2.3041, Validation RMSE: 1.5179, Valid PR: 0.2871\n",
      "Epoch [107/500], Train Loss: 0.8064, Train RMSE: 0.8980\n",
      "Epoch [107/500], Validation Loss: 2.2965, Validation RMSE: 1.5154, Valid PR: 0.3211\n",
      "Epoch [108/500], Train Loss: 0.7770, Train RMSE: 0.8815\n",
      "Epoch [108/500], Validation Loss: 2.2894, Validation RMSE: 1.5131, Valid PR: 0.3496\n",
      "Epoch [109/500], Train Loss: 0.7472, Train RMSE: 0.8644\n",
      "Epoch [109/500], Validation Loss: 2.2824, Validation RMSE: 1.5107, Valid PR: 0.3780\n",
      "Epoch [110/500], Train Loss: 0.7475, Train RMSE: 0.8646\n",
      "Epoch [110/500], Validation Loss: 2.2755, Validation RMSE: 1.5085, Valid PR: 0.4080\n",
      "Epoch [111/500], Train Loss: 0.8194, Train RMSE: 0.9052\n",
      "Epoch [111/500], Validation Loss: 2.2693, Validation RMSE: 1.5064, Valid PR: 0.4179\n",
      "Epoch [112/500], Train Loss: 0.7638, Train RMSE: 0.8740\n",
      "Epoch [112/500], Validation Loss: 2.2637, Validation RMSE: 1.5045, Valid PR: 0.4218\n",
      "Epoch [113/500], Train Loss: 0.7691, Train RMSE: 0.8770\n",
      "Epoch [113/500], Validation Loss: 2.2583, Validation RMSE: 1.5028, Valid PR: 0.4221\n",
      "Epoch [114/500], Train Loss: 0.7692, Train RMSE: 0.8770\n",
      "Epoch [114/500], Validation Loss: 2.2533, Validation RMSE: 1.5011, Valid PR: 0.4131\n",
      "Epoch [115/500], Train Loss: 0.7637, Train RMSE: 0.8739\n",
      "Epoch [115/500], Validation Loss: 2.2485, Validation RMSE: 1.4995, Valid PR: 0.4024\n",
      "Epoch [116/500], Train Loss: 0.7782, Train RMSE: 0.8822\n",
      "Epoch [116/500], Validation Loss: 2.2439, Validation RMSE: 1.4980, Valid PR: 0.3927\n",
      "Epoch [117/500], Train Loss: 0.7397, Train RMSE: 0.8600\n",
      "Epoch [117/500], Validation Loss: 2.2393, Validation RMSE: 1.4964, Valid PR: 0.3853\n",
      "Epoch [118/500], Train Loss: 0.8086, Train RMSE: 0.8992\n",
      "Epoch [118/500], Validation Loss: 2.2350, Validation RMSE: 1.4950, Valid PR: 0.3761\n",
      "Epoch [119/500], Train Loss: 0.8315, Train RMSE: 0.9118\n",
      "Epoch [119/500], Validation Loss: 2.2309, Validation RMSE: 1.4936, Valid PR: 0.3660\n",
      "Epoch [120/500], Train Loss: 0.7228, Train RMSE: 0.8502\n",
      "Epoch [120/500], Validation Loss: 2.2269, Validation RMSE: 1.4923, Valid PR: 0.3630\n",
      "Epoch [121/500], Train Loss: 0.7918, Train RMSE: 0.8898\n",
      "Epoch [121/500], Validation Loss: 2.2230, Validation RMSE: 1.4910, Valid PR: 0.3634\n",
      "Epoch [122/500], Train Loss: 0.7960, Train RMSE: 0.8922\n",
      "Epoch [122/500], Validation Loss: 2.2192, Validation RMSE: 1.4897, Valid PR: 0.3642\n",
      "Epoch [123/500], Train Loss: 0.7496, Train RMSE: 0.8658\n",
      "Epoch [123/500], Validation Loss: 2.2155, Validation RMSE: 1.4885, Valid PR: 0.3613\n",
      "Epoch [124/500], Train Loss: 0.7489, Train RMSE: 0.8654\n",
      "Epoch [124/500], Validation Loss: 2.2119, Validation RMSE: 1.4872, Valid PR: 0.3599\n",
      "Epoch [125/500], Train Loss: 0.7297, Train RMSE: 0.8542\n",
      "Epoch [125/500], Validation Loss: 2.2084, Validation RMSE: 1.4861, Valid PR: 0.3607\n",
      "Epoch [126/500], Train Loss: 0.8451, Train RMSE: 0.9193\n",
      "Epoch [126/500], Validation Loss: 2.2053, Validation RMSE: 1.4850, Valid PR: 0.3591\n",
      "Epoch [127/500], Train Loss: 0.7871, Train RMSE: 0.8872\n",
      "Epoch [127/500], Validation Loss: 2.2022, Validation RMSE: 1.4840, Valid PR: 0.3643\n",
      "Epoch [128/500], Train Loss: 0.7580, Train RMSE: 0.8706\n",
      "Epoch [128/500], Validation Loss: 2.1993, Validation RMSE: 1.4830, Valid PR: 0.3672\n",
      "Epoch [129/500], Train Loss: 0.6809, Train RMSE: 0.8252\n",
      "Epoch [129/500], Validation Loss: 2.1965, Validation RMSE: 1.4821, Valid PR: 0.3719\n",
      "Epoch [130/500], Train Loss: 0.7525, Train RMSE: 0.8675\n",
      "Epoch [130/500], Validation Loss: 2.1939, Validation RMSE: 1.4812, Valid PR: 0.3769\n",
      "Epoch [131/500], Train Loss: 0.7266, Train RMSE: 0.8524\n",
      "Epoch [131/500], Validation Loss: 2.1913, Validation RMSE: 1.4803, Valid PR: 0.3876\n",
      "Epoch [132/500], Train Loss: 0.7378, Train RMSE: 0.8590\n",
      "Epoch [132/500], Validation Loss: 2.1890, Validation RMSE: 1.4795, Valid PR: 0.3965\n",
      "Epoch [133/500], Train Loss: 0.6756, Train RMSE: 0.8219\n",
      "Epoch [133/500], Validation Loss: 2.1868, Validation RMSE: 1.4788, Valid PR: 0.4079\n",
      "Epoch [134/500], Train Loss: 0.7480, Train RMSE: 0.8649\n",
      "Epoch [134/500], Validation Loss: 2.1846, Validation RMSE: 1.4780, Valid PR: 0.4219\n",
      "Epoch [135/500], Train Loss: 0.7166, Train RMSE: 0.8465\n",
      "Epoch [135/500], Validation Loss: 2.1827, Validation RMSE: 1.4774, Valid PR: 0.4328\n",
      "Epoch [136/500], Train Loss: 0.6608, Train RMSE: 0.8129\n",
      "Epoch [136/500], Validation Loss: 2.1811, Validation RMSE: 1.4768, Valid PR: 0.4431\n",
      "Epoch [137/500], Train Loss: 0.7781, Train RMSE: 0.8821\n",
      "Epoch [137/500], Validation Loss: 2.1792, Validation RMSE: 1.4762, Valid PR: 0.4589\n",
      "Epoch [138/500], Train Loss: 0.6804, Train RMSE: 0.8249\n",
      "Epoch [138/500], Validation Loss: 2.1775, Validation RMSE: 1.4757, Valid PR: 0.4756\n",
      "Epoch [139/500], Train Loss: 0.7724, Train RMSE: 0.8788\n",
      "Epoch [139/500], Validation Loss: 2.1762, Validation RMSE: 1.4752, Valid PR: 0.4909\n",
      "Epoch [140/500], Train Loss: 0.6999, Train RMSE: 0.8366\n",
      "Epoch [140/500], Validation Loss: 2.1749, Validation RMSE: 1.4748, Valid PR: 0.5069\n",
      "Epoch [141/500], Train Loss: 0.7055, Train RMSE: 0.8399\n",
      "Epoch [141/500], Validation Loss: 2.1738, Validation RMSE: 1.4744, Valid PR: 0.5218\n",
      "Epoch [142/500], Train Loss: 0.7093, Train RMSE: 0.8422\n",
      "Epoch [142/500], Validation Loss: 2.1730, Validation RMSE: 1.4741, Valid PR: 0.5354\n",
      "Epoch [143/500], Train Loss: 0.7281, Train RMSE: 0.8533\n",
      "Epoch [143/500], Validation Loss: 2.1721, Validation RMSE: 1.4738, Valid PR: 0.5509\n",
      "Epoch [144/500], Train Loss: 0.7948, Train RMSE: 0.8915\n",
      "Epoch [144/500], Validation Loss: 2.1713, Validation RMSE: 1.4735, Valid PR: 0.5669\n",
      "Epoch [145/500], Train Loss: 0.6951, Train RMSE: 0.8337\n",
      "Epoch [145/500], Validation Loss: 2.1703, Validation RMSE: 1.4732, Valid PR: 0.5836\n",
      "Epoch [146/500], Train Loss: 0.7673, Train RMSE: 0.8759\n",
      "Epoch [146/500], Validation Loss: 2.1693, Validation RMSE: 1.4728, Valid PR: 0.5985\n",
      "Epoch [147/500], Train Loss: 0.6916, Train RMSE: 0.8317\n",
      "Epoch [147/500], Validation Loss: 2.1681, Validation RMSE: 1.4725, Valid PR: 0.6109\n",
      "Epoch [148/500], Train Loss: 0.7412, Train RMSE: 0.8609\n",
      "Epoch [148/500], Validation Loss: 2.1669, Validation RMSE: 1.4720, Valid PR: 0.6253\n",
      "Epoch [149/500], Train Loss: 0.8030, Train RMSE: 0.8961\n",
      "Epoch [149/500], Validation Loss: 2.1655, Validation RMSE: 1.4716, Valid PR: 0.6358\n",
      "Epoch [150/500], Train Loss: 0.7741, Train RMSE: 0.8798\n",
      "Epoch [150/500], Validation Loss: 2.1644, Validation RMSE: 1.4712, Valid PR: 0.6462\n",
      "Epoch [151/500], Train Loss: 0.7434, Train RMSE: 0.8622\n",
      "Epoch [151/500], Validation Loss: 2.1631, Validation RMSE: 1.4707, Valid PR: 0.6602\n",
      "Epoch [152/500], Train Loss: 0.7643, Train RMSE: 0.8743\n",
      "Epoch [152/500], Validation Loss: 2.1618, Validation RMSE: 1.4703, Valid PR: 0.6756\n",
      "Epoch [153/500], Train Loss: 0.7120, Train RMSE: 0.8438\n",
      "Epoch [153/500], Validation Loss: 2.1605, Validation RMSE: 1.4699, Valid PR: 0.6906\n",
      "Epoch [154/500], Train Loss: 0.6479, Train RMSE: 0.8049\n",
      "Epoch [154/500], Validation Loss: 2.1594, Validation RMSE: 1.4695, Valid PR: 0.7037\n",
      "Epoch [155/500], Train Loss: 0.7700, Train RMSE: 0.8775\n",
      "Epoch [155/500], Validation Loss: 2.1579, Validation RMSE: 1.4690, Valid PR: 0.7178\n",
      "Epoch [156/500], Train Loss: 0.6561, Train RMSE: 0.8100\n",
      "Epoch [156/500], Validation Loss: 2.1563, Validation RMSE: 1.4684, Valid PR: 0.7301\n",
      "Epoch [157/500], Train Loss: 0.7631, Train RMSE: 0.8735\n",
      "Epoch [157/500], Validation Loss: 2.1546, Validation RMSE: 1.4678, Valid PR: 0.7415\n",
      "Epoch [158/500], Train Loss: 0.6931, Train RMSE: 0.8325\n",
      "Epoch [158/500], Validation Loss: 2.1527, Validation RMSE: 1.4672, Valid PR: 0.7507\n",
      "Epoch [159/500], Train Loss: 0.7114, Train RMSE: 0.8435\n",
      "Epoch [159/500], Validation Loss: 2.1502, Validation RMSE: 1.4664, Valid PR: 0.7606\n",
      "Epoch [160/500], Train Loss: 0.7370, Train RMSE: 0.8585\n",
      "Epoch [160/500], Validation Loss: 2.1481, Validation RMSE: 1.4656, Valid PR: 0.7694\n",
      "Epoch [161/500], Train Loss: 0.7328, Train RMSE: 0.8560\n",
      "Epoch [161/500], Validation Loss: 2.1457, Validation RMSE: 1.4648, Valid PR: 0.7780\n",
      "Epoch [162/500], Train Loss: 0.7218, Train RMSE: 0.8496\n",
      "Epoch [162/500], Validation Loss: 2.1431, Validation RMSE: 1.4639, Valid PR: 0.7876\n",
      "Epoch [163/500], Train Loss: 0.7415, Train RMSE: 0.8611\n",
      "Epoch [163/500], Validation Loss: 2.1401, Validation RMSE: 1.4629, Valid PR: 0.7991\n",
      "Epoch [164/500], Train Loss: 0.6934, Train RMSE: 0.8327\n",
      "Epoch [164/500], Validation Loss: 2.1376, Validation RMSE: 1.4620, Valid PR: 0.8086\n",
      "Epoch [165/500], Train Loss: 0.8131, Train RMSE: 0.9017\n",
      "Epoch [165/500], Validation Loss: 2.1347, Validation RMSE: 1.4611, Valid PR: 0.8173\n",
      "Epoch [166/500], Train Loss: 0.7764, Train RMSE: 0.8811\n",
      "Epoch [166/500], Validation Loss: 2.1314, Validation RMSE: 1.4599, Valid PR: 0.8247\n",
      "Epoch [167/500], Train Loss: 0.6935, Train RMSE: 0.8327\n",
      "Epoch [167/500], Validation Loss: 2.1275, Validation RMSE: 1.4586, Valid PR: 0.8328\n",
      "Epoch [168/500], Train Loss: 0.6951, Train RMSE: 0.8337\n",
      "Epoch [168/500], Validation Loss: 2.1230, Validation RMSE: 1.4571, Valid PR: 0.8408\n",
      "Epoch [169/500], Train Loss: 0.7545, Train RMSE: 0.8686\n",
      "Epoch [169/500], Validation Loss: 2.1186, Validation RMSE: 1.4555, Valid PR: 0.8501\n",
      "Epoch [170/500], Train Loss: 0.8091, Train RMSE: 0.8995\n",
      "Epoch [170/500], Validation Loss: 2.1135, Validation RMSE: 1.4538, Valid PR: 0.8580\n",
      "Epoch [171/500], Train Loss: 0.6403, Train RMSE: 0.8002\n",
      "Epoch [171/500], Validation Loss: 2.1086, Validation RMSE: 1.4521, Valid PR: 0.8668\n",
      "Epoch [172/500], Train Loss: 0.6838, Train RMSE: 0.8269\n",
      "Epoch [172/500], Validation Loss: 2.1031, Validation RMSE: 1.4502, Valid PR: 0.8738\n",
      "Epoch [173/500], Train Loss: 0.7170, Train RMSE: 0.8468\n",
      "Epoch [173/500], Validation Loss: 2.0971, Validation RMSE: 1.4481, Valid PR: 0.8794\n",
      "Epoch [174/500], Train Loss: 0.6764, Train RMSE: 0.8225\n",
      "Epoch [174/500], Validation Loss: 2.0905, Validation RMSE: 1.4459, Valid PR: 0.8834\n",
      "Epoch [175/500], Train Loss: 0.6257, Train RMSE: 0.7910\n",
      "Epoch [175/500], Validation Loss: 2.0834, Validation RMSE: 1.4434, Valid PR: 0.8868\n",
      "Epoch [176/500], Train Loss: 0.5695, Train RMSE: 0.7547\n",
      "Epoch [176/500], Validation Loss: 2.0755, Validation RMSE: 1.4407, Valid PR: 0.8899\n",
      "Epoch [177/500], Train Loss: 0.7075, Train RMSE: 0.8411\n",
      "Epoch [177/500], Validation Loss: 2.0659, Validation RMSE: 1.4373, Valid PR: 0.8924\n",
      "Epoch [178/500], Train Loss: 0.7067, Train RMSE: 0.8406\n",
      "Epoch [178/500], Validation Loss: 2.0541, Validation RMSE: 1.4332, Valid PR: 0.8952\n",
      "Epoch [179/500], Train Loss: 0.7089, Train RMSE: 0.8420\n",
      "Epoch [179/500], Validation Loss: 2.0402, Validation RMSE: 1.4284, Valid PR: 0.8978\n",
      "Epoch [180/500], Train Loss: 0.7240, Train RMSE: 0.8509\n",
      "Epoch [180/500], Validation Loss: 2.0267, Validation RMSE: 1.4236, Valid PR: 0.8997\n",
      "Epoch [181/500], Train Loss: 0.6408, Train RMSE: 0.8005\n",
      "Epoch [181/500], Validation Loss: 2.0133, Validation RMSE: 1.4189, Valid PR: 0.9017\n",
      "Epoch [182/500], Train Loss: 0.7900, Train RMSE: 0.8888\n",
      "Epoch [182/500], Validation Loss: 1.9998, Validation RMSE: 1.4141, Valid PR: 0.9031\n",
      "Epoch [183/500], Train Loss: 0.7659, Train RMSE: 0.8752\n",
      "Epoch [183/500], Validation Loss: 1.9830, Validation RMSE: 1.4082, Valid PR: 0.9047\n",
      "Epoch [184/500], Train Loss: 0.7657, Train RMSE: 0.8750\n",
      "Epoch [184/500], Validation Loss: 1.9639, Validation RMSE: 1.4014, Valid PR: 0.9065\n",
      "Epoch [185/500], Train Loss: 0.7493, Train RMSE: 0.8656\n",
      "Epoch [185/500], Validation Loss: 1.9406, Validation RMSE: 1.3931, Valid PR: 0.9084\n",
      "Epoch [186/500], Train Loss: 0.7192, Train RMSE: 0.8481\n",
      "Epoch [186/500], Validation Loss: 1.9140, Validation RMSE: 1.3835, Valid PR: 0.9105\n",
      "Epoch [187/500], Train Loss: 0.5920, Train RMSE: 0.7694\n",
      "Epoch [187/500], Validation Loss: 1.8825, Validation RMSE: 1.3720, Valid PR: 0.9125\n",
      "Epoch [188/500], Train Loss: 0.6798, Train RMSE: 0.8245\n",
      "Epoch [188/500], Validation Loss: 1.8471, Validation RMSE: 1.3591, Valid PR: 0.9142\n",
      "Epoch [189/500], Train Loss: 0.6936, Train RMSE: 0.8328\n",
      "Epoch [189/500], Validation Loss: 1.8067, Validation RMSE: 1.3442, Valid PR: 0.9157\n",
      "Epoch [190/500], Train Loss: 0.7382, Train RMSE: 0.8592\n",
      "Epoch [190/500], Validation Loss: 1.7621, Validation RMSE: 1.3275, Valid PR: 0.9168\n",
      "Epoch [191/500], Train Loss: 0.6507, Train RMSE: 0.8067\n",
      "Epoch [191/500], Validation Loss: 1.7154, Validation RMSE: 1.3097, Valid PR: 0.9177\n",
      "Epoch [192/500], Train Loss: 0.5982, Train RMSE: 0.7734\n",
      "Epoch [192/500], Validation Loss: 1.6663, Validation RMSE: 1.2909, Valid PR: 0.9184\n",
      "Epoch [193/500], Train Loss: 0.6165, Train RMSE: 0.7852\n",
      "Epoch [193/500], Validation Loss: 1.6140, Validation RMSE: 1.2704, Valid PR: 0.9187\n",
      "Epoch [194/500], Train Loss: 0.7049, Train RMSE: 0.8396\n",
      "Epoch [194/500], Validation Loss: 1.5577, Validation RMSE: 1.2481, Valid PR: 0.9186\n",
      "Epoch [195/500], Train Loss: 0.5887, Train RMSE: 0.7672\n",
      "Epoch [195/500], Validation Loss: 1.4955, Validation RMSE: 1.2229, Valid PR: 0.9186\n",
      "Epoch [196/500], Train Loss: 0.6880, Train RMSE: 0.8294\n",
      "Epoch [196/500], Validation Loss: 1.4298, Validation RMSE: 1.1957, Valid PR: 0.9184\n",
      "Epoch [197/500], Train Loss: 0.6153, Train RMSE: 0.7844\n",
      "Epoch [197/500], Validation Loss: 1.3659, Validation RMSE: 1.1687, Valid PR: 0.9183\n",
      "Epoch [198/500], Train Loss: 0.6196, Train RMSE: 0.7871\n",
      "Epoch [198/500], Validation Loss: 1.3037, Validation RMSE: 1.1418, Valid PR: 0.9181\n",
      "Epoch [199/500], Train Loss: 0.6314, Train RMSE: 0.7946\n",
      "Epoch [199/500], Validation Loss: 1.2376, Validation RMSE: 1.1125, Valid PR: 0.9181\n",
      "Epoch [200/500], Train Loss: 0.5899, Train RMSE: 0.7680\n",
      "Epoch [200/500], Validation Loss: 1.1708, Validation RMSE: 1.0821, Valid PR: 0.9183\n",
      "Epoch [201/500], Train Loss: 0.5905, Train RMSE: 0.7684\n",
      "Epoch [201/500], Validation Loss: 1.1095, Validation RMSE: 1.0533, Valid PR: 0.9185\n",
      "Epoch [202/500], Train Loss: 0.6472, Train RMSE: 0.8045\n",
      "Epoch [202/500], Validation Loss: 1.0514, Validation RMSE: 1.0254, Valid PR: 0.9186\n",
      "Epoch [203/500], Train Loss: 0.6551, Train RMSE: 0.8094\n",
      "Epoch [203/500], Validation Loss: 0.9962, Validation RMSE: 0.9981, Valid PR: 0.9186\n",
      "Epoch [204/500], Train Loss: 0.5869, Train RMSE: 0.7661\n",
      "Epoch [204/500], Validation Loss: 0.9400, Validation RMSE: 0.9696, Valid PR: 0.9184\n",
      "Epoch [205/500], Train Loss: 0.7069, Train RMSE: 0.8408\n",
      "Epoch [205/500], Validation Loss: 0.8875, Validation RMSE: 0.9420, Valid PR: 0.9182\n",
      "Epoch [206/500], Train Loss: 0.6265, Train RMSE: 0.7915\n",
      "Epoch [206/500], Validation Loss: 0.8408, Validation RMSE: 0.9170, Valid PR: 0.9180\n",
      "Epoch [207/500], Train Loss: 0.6075, Train RMSE: 0.7794\n",
      "Epoch [207/500], Validation Loss: 0.7944, Validation RMSE: 0.8913, Valid PR: 0.9177\n",
      "Epoch [208/500], Train Loss: 0.6259, Train RMSE: 0.7912\n",
      "Epoch [208/500], Validation Loss: 0.7521, Validation RMSE: 0.8672, Valid PR: 0.9174\n",
      "Epoch [209/500], Train Loss: 0.6333, Train RMSE: 0.7958\n",
      "Epoch [209/500], Validation Loss: 0.7089, Validation RMSE: 0.8420, Valid PR: 0.9171\n",
      "Epoch [210/500], Train Loss: 0.5548, Train RMSE: 0.7449\n",
      "Epoch [210/500], Validation Loss: 0.6721, Validation RMSE: 0.8198, Valid PR: 0.9169\n",
      "Epoch [211/500], Train Loss: 0.5814, Train RMSE: 0.7625\n",
      "Epoch [211/500], Validation Loss: 0.6419, Validation RMSE: 0.8012, Valid PR: 0.9166\n",
      "Epoch [212/500], Train Loss: 0.5571, Train RMSE: 0.7464\n",
      "Epoch [212/500], Validation Loss: 0.6193, Validation RMSE: 0.7870, Valid PR: 0.9163\n",
      "Epoch [213/500], Train Loss: 0.6710, Train RMSE: 0.8191\n",
      "Epoch [213/500], Validation Loss: 0.5967, Validation RMSE: 0.7724, Valid PR: 0.9159\n",
      "Epoch [214/500], Train Loss: 0.6431, Train RMSE: 0.8019\n",
      "Epoch [214/500], Validation Loss: 0.5786, Validation RMSE: 0.7606, Valid PR: 0.9155\n",
      "Epoch [215/500], Train Loss: 0.5481, Train RMSE: 0.7404\n",
      "Epoch [215/500], Validation Loss: 0.5663, Validation RMSE: 0.7525, Valid PR: 0.9151\n",
      "Epoch [216/500], Train Loss: 0.5563, Train RMSE: 0.7459\n",
      "Epoch [216/500], Validation Loss: 0.5589, Validation RMSE: 0.7476, Valid PR: 0.9147\n",
      "Epoch [217/500], Train Loss: 0.5836, Train RMSE: 0.7639\n",
      "Epoch [217/500], Validation Loss: 0.5523, Validation RMSE: 0.7432, Valid PR: 0.9143\n",
      "Epoch [218/500], Train Loss: 0.5851, Train RMSE: 0.7649\n",
      "Epoch [218/500], Validation Loss: 0.5486, Validation RMSE: 0.7407, Valid PR: 0.9138\n",
      "Epoch [219/500], Train Loss: 0.5837, Train RMSE: 0.7640\n",
      "Epoch [219/500], Validation Loss: 0.5421, Validation RMSE: 0.7363, Valid PR: 0.9133\n",
      "Epoch [220/500], Train Loss: 0.5284, Train RMSE: 0.7269\n",
      "Epoch [220/500], Validation Loss: 0.5378, Validation RMSE: 0.7334, Valid PR: 0.9125\n",
      "Epoch [221/500], Train Loss: 0.6845, Train RMSE: 0.8273\n",
      "Epoch [221/500], Validation Loss: 0.5345, Validation RMSE: 0.7311, Valid PR: 0.9117\n",
      "Epoch [222/500], Train Loss: 0.5520, Train RMSE: 0.7429\n",
      "Epoch [222/500], Validation Loss: 0.5321, Validation RMSE: 0.7294, Valid PR: 0.9107\n",
      "Epoch [223/500], Train Loss: 0.6413, Train RMSE: 0.8008\n",
      "Epoch [223/500], Validation Loss: 0.5305, Validation RMSE: 0.7283, Valid PR: 0.9094\n",
      "Epoch [224/500], Train Loss: 0.5150, Train RMSE: 0.7176\n",
      "Epoch [224/500], Validation Loss: 0.5315, Validation RMSE: 0.7290, Valid PR: 0.9080\n",
      "Epoch [225/500], Train Loss: 0.5653, Train RMSE: 0.7518\n",
      "Epoch [225/500], Validation Loss: 0.5337, Validation RMSE: 0.7305, Valid PR: 0.9064\n",
      "Epoch [226/500], Train Loss: 0.5938, Train RMSE: 0.7706\n",
      "Epoch [226/500], Validation Loss: 0.5369, Validation RMSE: 0.7327, Valid PR: 0.9046\n",
      "Epoch [227/500], Train Loss: 0.6569, Train RMSE: 0.8105\n",
      "Epoch [227/500], Validation Loss: 0.5414, Validation RMSE: 0.7358, Valid PR: 0.9027\n",
      "Epoch [228/500], Train Loss: 0.5537, Train RMSE: 0.7441\n",
      "Epoch [228/500], Validation Loss: 0.5485, Validation RMSE: 0.7406, Valid PR: 0.9005\n",
      "Epoch [229/500], Train Loss: 0.5235, Train RMSE: 0.7235\n",
      "Epoch [229/500], Validation Loss: 0.5589, Validation RMSE: 0.7476, Valid PR: 0.8980\n",
      "Epoch [230/500], Train Loss: 0.5272, Train RMSE: 0.7261\n",
      "Epoch [230/500], Validation Loss: 0.5687, Validation RMSE: 0.7541, Valid PR: 0.8959\n",
      "Epoch [231/500], Train Loss: 0.5563, Train RMSE: 0.7459\n",
      "Epoch [231/500], Validation Loss: 0.5829, Validation RMSE: 0.7635, Valid PR: 0.8931\n",
      "Epoch [232/500], Train Loss: 0.5434, Train RMSE: 0.7372\n",
      "Epoch [232/500], Validation Loss: 0.5950, Validation RMSE: 0.7713, Valid PR: 0.8904\n",
      "Epoch [233/500], Train Loss: 0.4962, Train RMSE: 0.7044\n",
      "Epoch [233/500], Validation Loss: 0.6113, Validation RMSE: 0.7818, Valid PR: 0.8873\n",
      "Epoch [234/500], Train Loss: 0.6058, Train RMSE: 0.7784\n",
      "Epoch [234/500], Validation Loss: 0.6261, Validation RMSE: 0.7912, Valid PR: 0.8841\n",
      "Epoch [235/500], Train Loss: 0.5803, Train RMSE: 0.7618\n",
      "Epoch [235/500], Validation Loss: 0.6409, Validation RMSE: 0.8006, Valid PR: 0.8815\n",
      "Epoch [236/500], Train Loss: 0.4974, Train RMSE: 0.7053\n",
      "Epoch [236/500], Validation Loss: 0.6459, Validation RMSE: 0.8037, Valid PR: 0.8804\n",
      "Epoch [237/500], Train Loss: 0.5450, Train RMSE: 0.7382\n",
      "Epoch [237/500], Validation Loss: 0.6473, Validation RMSE: 0.8046, Valid PR: 0.8798\n",
      "Epoch [238/500], Train Loss: 0.6408, Train RMSE: 0.8005\n",
      "Epoch [238/500], Validation Loss: 0.6477, Validation RMSE: 0.8048, Valid PR: 0.8795\n",
      "Epoch [239/500], Train Loss: 0.5635, Train RMSE: 0.7507\n",
      "Epoch [239/500], Validation Loss: 0.6561, Validation RMSE: 0.8100, Valid PR: 0.8781\n",
      "Epoch [240/500], Train Loss: 0.5485, Train RMSE: 0.7406\n",
      "Epoch [240/500], Validation Loss: 0.6651, Validation RMSE: 0.8155, Valid PR: 0.8771\n",
      "Epoch [241/500], Train Loss: 0.5076, Train RMSE: 0.7125\n",
      "Epoch [241/500], Validation Loss: 0.6738, Validation RMSE: 0.8209, Valid PR: 0.8761\n",
      "Epoch [242/500], Train Loss: 0.5603, Train RMSE: 0.7485\n",
      "Epoch [242/500], Validation Loss: 0.6812, Validation RMSE: 0.8254, Valid PR: 0.8763\n",
      "Epoch [243/500], Train Loss: 0.5757, Train RMSE: 0.7587\n",
      "Epoch [243/500], Validation Loss: 0.6839, Validation RMSE: 0.8270, Valid PR: 0.8771\n",
      "Epoch [244/500], Train Loss: 0.6105, Train RMSE: 0.7814\n",
      "Epoch [244/500], Validation Loss: 0.6861, Validation RMSE: 0.8283, Valid PR: 0.8781\n",
      "Epoch [245/500], Train Loss: 0.5735, Train RMSE: 0.7573\n",
      "Epoch [245/500], Validation Loss: 0.6880, Validation RMSE: 0.8295, Valid PR: 0.8777\n",
      "Epoch [246/500], Train Loss: 0.4927, Train RMSE: 0.7019\n",
      "Epoch [246/500], Validation Loss: 0.6828, Validation RMSE: 0.8263, Valid PR: 0.8785\n",
      "Epoch [247/500], Train Loss: 0.5525, Train RMSE: 0.7433\n",
      "Epoch [247/500], Validation Loss: 0.6759, Validation RMSE: 0.8221, Valid PR: 0.8800\n",
      "Epoch [248/500], Train Loss: 0.4728, Train RMSE: 0.6876\n",
      "Epoch [248/500], Validation Loss: 0.6664, Validation RMSE: 0.8163, Valid PR: 0.8821\n",
      "Epoch [249/500], Train Loss: 0.5575, Train RMSE: 0.7467\n",
      "Epoch [249/500], Validation Loss: 0.6518, Validation RMSE: 0.8074, Valid PR: 0.8858\n",
      "Epoch [250/500], Train Loss: 0.5759, Train RMSE: 0.7589\n",
      "Epoch [250/500], Validation Loss: 0.6346, Validation RMSE: 0.7966, Valid PR: 0.8916\n",
      "Epoch [251/500], Train Loss: 0.5071, Train RMSE: 0.7121\n",
      "Epoch [251/500], Validation Loss: 0.6119, Validation RMSE: 0.7822, Valid PR: 0.8985\n",
      "Epoch [252/500], Train Loss: 0.5162, Train RMSE: 0.7185\n",
      "Epoch [252/500], Validation Loss: 0.5877, Validation RMSE: 0.7666, Valid PR: 0.9044\n",
      "Epoch [253/500], Train Loss: 0.5955, Train RMSE: 0.7717\n",
      "Epoch [253/500], Validation Loss: 0.5716, Validation RMSE: 0.7560, Valid PR: 0.9093\n",
      "Epoch [254/500], Train Loss: 0.4604, Train RMSE: 0.6785\n",
      "Epoch [254/500], Validation Loss: 0.5591, Validation RMSE: 0.7477, Valid PR: 0.9137\n",
      "Epoch [255/500], Train Loss: 0.4946, Train RMSE: 0.7033\n",
      "Epoch [255/500], Validation Loss: 0.5508, Validation RMSE: 0.7422, Valid PR: 0.9177\n",
      "Epoch [256/500], Train Loss: 0.5580, Train RMSE: 0.7470\n",
      "Epoch [256/500], Validation Loss: 0.5454, Validation RMSE: 0.7385, Valid PR: 0.9220\n",
      "Epoch [257/500], Train Loss: 0.4841, Train RMSE: 0.6957\n",
      "Epoch [257/500], Validation Loss: 0.5426, Validation RMSE: 0.7366, Valid PR: 0.9256\n",
      "Epoch [258/500], Train Loss: 0.4949, Train RMSE: 0.7035\n",
      "Epoch [258/500], Validation Loss: 0.5375, Validation RMSE: 0.7332, Valid PR: 0.9288\n",
      "Epoch [259/500], Train Loss: 0.6215, Train RMSE: 0.7883\n",
      "Epoch [259/500], Validation Loss: 0.5367, Validation RMSE: 0.7326, Valid PR: 0.9314\n",
      "Epoch [260/500], Train Loss: 0.4884, Train RMSE: 0.6989\n",
      "Epoch [260/500], Validation Loss: 0.5351, Validation RMSE: 0.7315, Valid PR: 0.9330\n",
      "Epoch [261/500], Train Loss: 0.5256, Train RMSE: 0.7250\n",
      "Epoch [261/500], Validation Loss: 0.5270, Validation RMSE: 0.7259, Valid PR: 0.9338\n",
      "Epoch [262/500], Train Loss: 0.4898, Train RMSE: 0.6998\n",
      "Epoch [262/500], Validation Loss: 0.5223, Validation RMSE: 0.7227, Valid PR: 0.9332\n",
      "Epoch [263/500], Train Loss: 0.4972, Train RMSE: 0.7051\n",
      "Epoch [263/500], Validation Loss: 0.5199, Validation RMSE: 0.7211, Valid PR: 0.9324\n",
      "Epoch [264/500], Train Loss: 0.4413, Train RMSE: 0.6643\n",
      "Epoch [264/500], Validation Loss: 0.5176, Validation RMSE: 0.7195, Valid PR: 0.9316\n",
      "Epoch [265/500], Train Loss: 0.4716, Train RMSE: 0.6867\n",
      "Epoch [265/500], Validation Loss: 0.5176, Validation RMSE: 0.7195, Valid PR: 0.9306\n",
      "Epoch [266/500], Train Loss: 0.4274, Train RMSE: 0.6537\n",
      "Epoch [266/500], Validation Loss: 0.5154, Validation RMSE: 0.7179, Valid PR: 0.9296\n",
      "Epoch [267/500], Train Loss: 0.5208, Train RMSE: 0.7217\n",
      "Epoch [267/500], Validation Loss: 0.5199, Validation RMSE: 0.7211, Valid PR: 0.9288\n",
      "Epoch [268/500], Train Loss: 0.4576, Train RMSE: 0.6764\n",
      "Epoch [268/500], Validation Loss: 0.5283, Validation RMSE: 0.7268, Valid PR: 0.9283\n",
      "Epoch [269/500], Train Loss: 0.4860, Train RMSE: 0.6972\n",
      "Epoch [269/500], Validation Loss: 0.5409, Validation RMSE: 0.7355, Valid PR: 0.9276\n",
      "Epoch [270/500], Train Loss: 0.4983, Train RMSE: 0.7059\n",
      "Epoch [270/500], Validation Loss: 0.5545, Validation RMSE: 0.7446, Valid PR: 0.9265\n",
      "Epoch [271/500], Train Loss: 0.6202, Train RMSE: 0.7875\n",
      "Epoch [271/500], Validation Loss: 0.5663, Validation RMSE: 0.7525, Valid PR: 0.9234\n",
      "Epoch [272/500], Train Loss: 0.4742, Train RMSE: 0.6886\n",
      "Epoch [272/500], Validation Loss: 0.5702, Validation RMSE: 0.7551, Valid PR: 0.9195\n",
      "Epoch [273/500], Train Loss: 0.4724, Train RMSE: 0.6873\n",
      "Epoch [273/500], Validation Loss: 0.5732, Validation RMSE: 0.7571, Valid PR: 0.9156\n",
      "Epoch [274/500], Train Loss: 0.4875, Train RMSE: 0.6982\n",
      "Epoch [274/500], Validation Loss: 0.5726, Validation RMSE: 0.7567, Valid PR: 0.9128\n",
      "Epoch [275/500], Train Loss: 0.5570, Train RMSE: 0.7463\n",
      "Epoch [275/500], Validation Loss: 0.5818, Validation RMSE: 0.7627, Valid PR: 0.9089\n",
      "Epoch [276/500], Train Loss: 0.5076, Train RMSE: 0.7125\n",
      "Epoch [276/500], Validation Loss: 0.5877, Validation RMSE: 0.7666, Valid PR: 0.9064\n",
      "Epoch [277/500], Train Loss: 0.4520, Train RMSE: 0.6723\n",
      "Epoch [277/500], Validation Loss: 0.5819, Validation RMSE: 0.7628, Valid PR: 0.9074\n",
      "Epoch [278/500], Train Loss: 0.4477, Train RMSE: 0.6691\n",
      "Epoch [278/500], Validation Loss: 0.5793, Validation RMSE: 0.7611, Valid PR: 0.9077\n",
      "Epoch [279/500], Train Loss: 0.4854, Train RMSE: 0.6967\n",
      "Epoch [279/500], Validation Loss: 0.5729, Validation RMSE: 0.7569, Valid PR: 0.9088\n",
      "Epoch [280/500], Train Loss: 0.4307, Train RMSE: 0.6563\n",
      "Epoch [280/500], Validation Loss: 0.5757, Validation RMSE: 0.7588, Valid PR: 0.9064\n",
      "Epoch [281/500], Train Loss: 0.4608, Train RMSE: 0.6788\n",
      "Epoch [281/500], Validation Loss: 0.5864, Validation RMSE: 0.7658, Valid PR: 0.9027\n",
      "Epoch [282/500], Train Loss: 0.4418, Train RMSE: 0.6646\n",
      "Epoch [282/500], Validation Loss: 0.6025, Validation RMSE: 0.7762, Valid PR: 0.8967\n",
      "Epoch [283/500], Train Loss: 0.3840, Train RMSE: 0.6197\n",
      "Epoch [283/500], Validation Loss: 0.6140, Validation RMSE: 0.7836, Valid PR: 0.8903\n",
      "Epoch [284/500], Train Loss: 0.4435, Train RMSE: 0.6660\n",
      "Epoch [284/500], Validation Loss: 0.6187, Validation RMSE: 0.7866, Valid PR: 0.8875\n",
      "Epoch [285/500], Train Loss: 0.4784, Train RMSE: 0.6917\n",
      "Epoch [285/500], Validation Loss: 0.6213, Validation RMSE: 0.7882, Valid PR: 0.8852\n",
      "Epoch [286/500], Train Loss: 0.4217, Train RMSE: 0.6494\n",
      "Epoch [286/500], Validation Loss: 0.6302, Validation RMSE: 0.7939, Valid PR: 0.8812\n",
      "Epoch [287/500], Train Loss: 0.4784, Train RMSE: 0.6916\n",
      "Epoch [287/500], Validation Loss: 0.6506, Validation RMSE: 0.8066, Valid PR: 0.8760\n",
      "Epoch [288/500], Train Loss: 0.3992, Train RMSE: 0.6319\n",
      "Epoch [288/500], Validation Loss: 0.6732, Validation RMSE: 0.8205, Valid PR: 0.8700\n",
      "Epoch [289/500], Train Loss: 0.4568, Train RMSE: 0.6759\n",
      "Epoch [289/500], Validation Loss: 0.6867, Validation RMSE: 0.8287, Valid PR: 0.8648\n",
      "Epoch [290/500], Train Loss: 0.4681, Train RMSE: 0.6842\n",
      "Epoch [290/500], Validation Loss: 0.7026, Validation RMSE: 0.8382, Valid PR: 0.8599\n",
      "Epoch [291/500], Train Loss: 0.4814, Train RMSE: 0.6938\n",
      "Epoch [291/500], Validation Loss: 0.7127, Validation RMSE: 0.8442, Valid PR: 0.8570\n",
      "Epoch [292/500], Train Loss: 0.4260, Train RMSE: 0.6527\n",
      "Epoch [292/500], Validation Loss: 0.7271, Validation RMSE: 0.8527, Valid PR: 0.8502\n",
      "Epoch [293/500], Train Loss: 0.4443, Train RMSE: 0.6666\n",
      "Epoch [293/500], Validation Loss: 0.7472, Validation RMSE: 0.8644, Valid PR: 0.8429\n",
      "Epoch [294/500], Train Loss: 0.4693, Train RMSE: 0.6850\n",
      "Epoch [294/500], Validation Loss: 0.7764, Validation RMSE: 0.8811, Valid PR: 0.8340\n",
      "Epoch [295/500], Train Loss: 0.4736, Train RMSE: 0.6882\n",
      "Epoch [295/500], Validation Loss: 0.7954, Validation RMSE: 0.8918, Valid PR: 0.8294\n",
      "Epoch [296/500], Train Loss: 0.4401, Train RMSE: 0.6634\n",
      "Epoch [296/500], Validation Loss: 0.8204, Validation RMSE: 0.9058, Valid PR: 0.8233\n",
      "Epoch [297/500], Train Loss: 0.4530, Train RMSE: 0.6730\n",
      "Epoch [297/500], Validation Loss: 0.8491, Validation RMSE: 0.9215, Valid PR: 0.8142\n",
      "Epoch [298/500], Train Loss: 0.3938, Train RMSE: 0.6275\n",
      "Epoch [298/500], Validation Loss: 0.8645, Validation RMSE: 0.9298, Valid PR: 0.8091\n",
      "Epoch [299/500], Train Loss: 0.4715, Train RMSE: 0.6866\n",
      "Epoch [299/500], Validation Loss: 0.8669, Validation RMSE: 0.9311, Valid PR: 0.8085\n",
      "Epoch [300/500], Train Loss: 0.3971, Train RMSE: 0.6302\n",
      "Epoch [300/500], Validation Loss: 0.8685, Validation RMSE: 0.9319, Valid PR: 0.8072\n",
      "Epoch [301/500], Train Loss: 0.3750, Train RMSE: 0.6124\n",
      "Epoch [301/500], Validation Loss: 0.8732, Validation RMSE: 0.9344, Valid PR: 0.8047\n",
      "Epoch [302/500], Train Loss: 0.3920, Train RMSE: 0.6261\n",
      "Epoch [302/500], Validation Loss: 0.8896, Validation RMSE: 0.9432, Valid PR: 0.7992\n",
      "Epoch [303/500], Train Loss: 0.4067, Train RMSE: 0.6377\n",
      "Epoch [303/500], Validation Loss: 0.9156, Validation RMSE: 0.9569, Valid PR: 0.7915\n",
      "Epoch [304/500], Train Loss: 0.4113, Train RMSE: 0.6413\n",
      "Epoch [304/500], Validation Loss: 0.9339, Validation RMSE: 0.9664, Valid PR: 0.7839\n",
      "Epoch [305/500], Train Loss: 0.3996, Train RMSE: 0.6321\n",
      "Epoch [305/500], Validation Loss: 0.9590, Validation RMSE: 0.9793, Valid PR: 0.7719\n",
      "Epoch [306/500], Train Loss: 0.4742, Train RMSE: 0.6886\n",
      "Epoch [306/500], Validation Loss: 0.9904, Validation RMSE: 0.9952, Valid PR: 0.7573\n",
      "Epoch [307/500], Train Loss: 0.5033, Train RMSE: 0.7094\n",
      "Epoch [307/500], Validation Loss: 0.9901, Validation RMSE: 0.9951, Valid PR: 0.7586\n",
      "Epoch [308/500], Train Loss: 0.4152, Train RMSE: 0.6444\n",
      "Epoch [308/500], Validation Loss: 0.9880, Validation RMSE: 0.9940, Valid PR: 0.7632\n",
      "Epoch [309/500], Train Loss: 0.4647, Train RMSE: 0.6817\n",
      "Epoch [309/500], Validation Loss: 0.9804, Validation RMSE: 0.9902, Valid PR: 0.7690\n",
      "Epoch [310/500], Train Loss: 0.4230, Train RMSE: 0.6504\n",
      "Epoch [310/500], Validation Loss: 0.9668, Validation RMSE: 0.9833, Valid PR: 0.7782\n",
      "Epoch [311/500], Train Loss: 0.4237, Train RMSE: 0.6509\n",
      "Epoch [311/500], Validation Loss: 0.9620, Validation RMSE: 0.9808, Valid PR: 0.7840\n",
      "Epoch [312/500], Train Loss: 0.4085, Train RMSE: 0.6392\n",
      "Epoch [312/500], Validation Loss: 0.9703, Validation RMSE: 0.9851, Valid PR: 0.7863\n",
      "Epoch [313/500], Train Loss: 0.4388, Train RMSE: 0.6624\n",
      "Epoch [313/500], Validation Loss: 0.9888, Validation RMSE: 0.9944, Valid PR: 0.7842\n",
      "Epoch [314/500], Train Loss: 0.4713, Train RMSE: 0.6865\n",
      "Epoch [314/500], Validation Loss: 1.0024, Validation RMSE: 1.0012, Valid PR: 0.7827\n",
      "Epoch [315/500], Train Loss: 0.4153, Train RMSE: 0.6444\n",
      "Epoch [315/500], Validation Loss: 1.0250, Validation RMSE: 1.0124, Valid PR: 0.7769\n",
      "Epoch [316/500], Train Loss: 0.3299, Train RMSE: 0.5744\n",
      "Epoch [316/500], Validation Loss: 1.0341, Validation RMSE: 1.0169, Valid PR: 0.7730\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.2353, Test RMSE: 1.7987, Test PR: 0.0874\n",
      "Replication 3 for method1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:122: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 9.2155, Train RMSE: 3.0357\n",
      "Epoch [1/500], Validation Loss: 23.5362, Validation RMSE: 4.8514, Valid PR: -0.6936\n",
      "Epoch [2/500], Train Loss: 5.2078, Train RMSE: 2.2821\n",
      "Epoch [2/500], Validation Loss: 16.8607, Validation RMSE: 4.1062, Valid PR: -0.6458\n",
      "Epoch [3/500], Train Loss: 4.0268, Train RMSE: 2.0067\n",
      "Epoch [3/500], Validation Loss: 13.5433, Validation RMSE: 3.6801, Valid PR: -0.5474\n",
      "Epoch [4/500], Train Loss: 3.4302, Train RMSE: 1.8521\n",
      "Epoch [4/500], Validation Loss: 11.5554, Validation RMSE: 3.3993, Valid PR: -0.4526\n",
      "Epoch [5/500], Train Loss: 3.1069, Train RMSE: 1.7626\n",
      "Epoch [5/500], Validation Loss: 10.2936, Validation RMSE: 3.2084, Valid PR: -0.3971\n",
      "Epoch [6/500], Train Loss: 2.8520, Train RMSE: 1.6888\n",
      "Epoch [6/500], Validation Loss: 9.3930, Validation RMSE: 3.0648, Valid PR: -0.3574\n",
      "Epoch [7/500], Train Loss: 2.7563, Train RMSE: 1.6602\n",
      "Epoch [7/500], Validation Loss: 8.6926, Validation RMSE: 2.9483, Valid PR: -0.3447\n",
      "Epoch [8/500], Train Loss: 2.4370, Train RMSE: 1.5611\n",
      "Epoch [8/500], Validation Loss: 8.1401, Validation RMSE: 2.8531, Valid PR: -0.3363\n",
      "Epoch [9/500], Train Loss: 2.4159, Train RMSE: 1.5543\n",
      "Epoch [9/500], Validation Loss: 7.7012, Validation RMSE: 2.7751, Valid PR: -0.3413\n",
      "Epoch [10/500], Train Loss: 2.3438, Train RMSE: 1.5309\n",
      "Epoch [10/500], Validation Loss: 7.3452, Validation RMSE: 2.7102, Valid PR: -0.3546\n",
      "Epoch [11/500], Train Loss: 2.2508, Train RMSE: 1.5003\n",
      "Epoch [11/500], Validation Loss: 7.0293, Validation RMSE: 2.6513, Valid PR: -0.3710\n",
      "Epoch [12/500], Train Loss: 2.0365, Train RMSE: 1.4271\n",
      "Epoch [12/500], Validation Loss: 6.7578, Validation RMSE: 2.5996, Valid PR: -0.3861\n",
      "Epoch [13/500], Train Loss: 2.1580, Train RMSE: 1.4690\n",
      "Epoch [13/500], Validation Loss: 6.5059, Validation RMSE: 2.5507, Valid PR: -0.4062\n",
      "Epoch [14/500], Train Loss: 1.9344, Train RMSE: 1.3908\n",
      "Epoch [14/500], Validation Loss: 6.2842, Validation RMSE: 2.5068, Valid PR: -0.4390\n",
      "Epoch [15/500], Train Loss: 1.9700, Train RMSE: 1.4036\n",
      "Epoch [15/500], Validation Loss: 6.0913, Validation RMSE: 2.4681, Valid PR: -0.4780\n",
      "Epoch [16/500], Train Loss: 1.9038, Train RMSE: 1.3798\n",
      "Epoch [16/500], Validation Loss: 5.9182, Validation RMSE: 2.4327, Valid PR: -0.5072\n",
      "Epoch [17/500], Train Loss: 1.8677, Train RMSE: 1.3666\n",
      "Epoch [17/500], Validation Loss: 5.7637, Validation RMSE: 2.4008, Valid PR: -0.5046\n",
      "Epoch [18/500], Train Loss: 1.8194, Train RMSE: 1.3488\n",
      "Epoch [18/500], Validation Loss: 5.6240, Validation RMSE: 2.3715, Valid PR: -0.4459\n",
      "Epoch [19/500], Train Loss: 1.7955, Train RMSE: 1.3399\n",
      "Epoch [19/500], Validation Loss: 5.4968, Validation RMSE: 2.3445, Valid PR: -0.3702\n",
      "Epoch [20/500], Train Loss: 1.7268, Train RMSE: 1.3141\n",
      "Epoch [20/500], Validation Loss: 5.3802, Validation RMSE: 2.3195, Valid PR: -0.2883\n",
      "Epoch [21/500], Train Loss: 1.7340, Train RMSE: 1.3168\n",
      "Epoch [21/500], Validation Loss: 5.2741, Validation RMSE: 2.2965, Valid PR: -0.1945\n",
      "Epoch [22/500], Train Loss: 1.7549, Train RMSE: 1.3247\n",
      "Epoch [22/500], Validation Loss: 5.1752, Validation RMSE: 2.2749, Valid PR: -0.0635\n",
      "Epoch [23/500], Train Loss: 1.6121, Train RMSE: 1.2697\n",
      "Epoch [23/500], Validation Loss: 5.0841, Validation RMSE: 2.2548, Valid PR: 0.0840\n",
      "Epoch [24/500], Train Loss: 1.5690, Train RMSE: 1.2526\n",
      "Epoch [24/500], Validation Loss: 4.9985, Validation RMSE: 2.2357, Valid PR: 0.2391\n",
      "Epoch [25/500], Train Loss: 1.6569, Train RMSE: 1.2872\n",
      "Epoch [25/500], Validation Loss: 4.9150, Validation RMSE: 2.2170, Valid PR: 0.3784\n",
      "Epoch [26/500], Train Loss: 1.6307, Train RMSE: 1.2770\n",
      "Epoch [26/500], Validation Loss: 4.8361, Validation RMSE: 2.1991, Valid PR: 0.4420\n",
      "Epoch [27/500], Train Loss: 1.6135, Train RMSE: 1.2702\n",
      "Epoch [27/500], Validation Loss: 4.7604, Validation RMSE: 2.1818, Valid PR: 0.4618\n",
      "Epoch [28/500], Train Loss: 1.5196, Train RMSE: 1.2327\n",
      "Epoch [28/500], Validation Loss: 4.6877, Validation RMSE: 2.1651, Valid PR: 0.4704\n",
      "Epoch [29/500], Train Loss: 1.5433, Train RMSE: 1.2423\n",
      "Epoch [29/500], Validation Loss: 4.6174, Validation RMSE: 2.1488, Valid PR: 0.4656\n",
      "Epoch [30/500], Train Loss: 1.5724, Train RMSE: 1.2539\n",
      "Epoch [30/500], Validation Loss: 4.5497, Validation RMSE: 2.1330, Valid PR: 0.4445\n",
      "Epoch [31/500], Train Loss: 1.4349, Train RMSE: 1.1979\n",
      "Epoch [31/500], Validation Loss: 4.4847, Validation RMSE: 2.1177, Valid PR: 0.4080\n",
      "Epoch [32/500], Train Loss: 1.4957, Train RMSE: 1.2230\n",
      "Epoch [32/500], Validation Loss: 4.4216, Validation RMSE: 2.1028, Valid PR: 0.3716\n",
      "Epoch [33/500], Train Loss: 1.4861, Train RMSE: 1.2191\n",
      "Epoch [33/500], Validation Loss: 4.3612, Validation RMSE: 2.0883, Valid PR: 0.3192\n",
      "Epoch [34/500], Train Loss: 1.4233, Train RMSE: 1.1930\n",
      "Epoch [34/500], Validation Loss: 4.3029, Validation RMSE: 2.0744, Valid PR: 0.2650\n",
      "Epoch [35/500], Train Loss: 1.3444, Train RMSE: 1.1595\n",
      "Epoch [35/500], Validation Loss: 4.2467, Validation RMSE: 2.0607, Valid PR: 0.2078\n",
      "Epoch [36/500], Train Loss: 1.3482, Train RMSE: 1.1611\n",
      "Epoch [36/500], Validation Loss: 4.1923, Validation RMSE: 2.0475, Valid PR: 0.1536\n",
      "Epoch [37/500], Train Loss: 1.3356, Train RMSE: 1.1557\n",
      "Epoch [37/500], Validation Loss: 4.1397, Validation RMSE: 2.0346, Valid PR: 0.1140\n",
      "Epoch [38/500], Train Loss: 1.3381, Train RMSE: 1.1568\n",
      "Epoch [38/500], Validation Loss: 4.0887, Validation RMSE: 2.0221, Valid PR: 0.0793\n",
      "Epoch [39/500], Train Loss: 1.4433, Train RMSE: 1.2014\n",
      "Epoch [39/500], Validation Loss: 4.0390, Validation RMSE: 2.0097, Valid PR: 0.0548\n",
      "Epoch [40/500], Train Loss: 1.3361, Train RMSE: 1.1559\n",
      "Epoch [40/500], Validation Loss: 3.9908, Validation RMSE: 1.9977, Valid PR: 0.0335\n",
      "Epoch [41/500], Train Loss: 1.3015, Train RMSE: 1.1408\n",
      "Epoch [41/500], Validation Loss: 3.9433, Validation RMSE: 1.9858, Valid PR: 0.0209\n",
      "Epoch [42/500], Train Loss: 1.3179, Train RMSE: 1.1480\n",
      "Epoch [42/500], Validation Loss: 3.8963, Validation RMSE: 1.9739, Valid PR: 0.0180\n",
      "Epoch [43/500], Train Loss: 1.2326, Train RMSE: 1.1102\n",
      "Epoch [43/500], Validation Loss: 3.8503, Validation RMSE: 1.9622, Valid PR: 0.0286\n",
      "Epoch [44/500], Train Loss: 1.2816, Train RMSE: 1.1321\n",
      "Epoch [44/500], Validation Loss: 3.8052, Validation RMSE: 1.9507, Valid PR: 0.0418\n",
      "Epoch [45/500], Train Loss: 1.3400, Train RMSE: 1.1576\n",
      "Epoch [45/500], Validation Loss: 3.7609, Validation RMSE: 1.9393, Valid PR: 0.0602\n",
      "Epoch [46/500], Train Loss: 1.2339, Train RMSE: 1.1108\n",
      "Epoch [46/500], Validation Loss: 3.7175, Validation RMSE: 1.9281, Valid PR: 0.0804\n",
      "Epoch [47/500], Train Loss: 1.3067, Train RMSE: 1.1431\n",
      "Epoch [47/500], Validation Loss: 3.6750, Validation RMSE: 1.9170, Valid PR: 0.0941\n",
      "Epoch [48/500], Train Loss: 1.2652, Train RMSE: 1.1248\n",
      "Epoch [48/500], Validation Loss: 3.6334, Validation RMSE: 1.9062, Valid PR: 0.1081\n",
      "Epoch [49/500], Train Loss: 1.2003, Train RMSE: 1.0956\n",
      "Epoch [49/500], Validation Loss: 3.5931, Validation RMSE: 1.8956, Valid PR: 0.1213\n",
      "Epoch [50/500], Train Loss: 1.3002, Train RMSE: 1.1403\n",
      "Epoch [50/500], Validation Loss: 3.5539, Validation RMSE: 1.8852, Valid PR: 0.1324\n",
      "Epoch [51/500], Train Loss: 1.1978, Train RMSE: 1.0944\n",
      "Epoch [51/500], Validation Loss: 3.5155, Validation RMSE: 1.8750, Valid PR: 0.1421\n",
      "Epoch [52/500], Train Loss: 1.2272, Train RMSE: 1.1078\n",
      "Epoch [52/500], Validation Loss: 3.4779, Validation RMSE: 1.8649, Valid PR: 0.1545\n",
      "Epoch [53/500], Train Loss: 1.1533, Train RMSE: 1.0739\n",
      "Epoch [53/500], Validation Loss: 3.4406, Validation RMSE: 1.8549, Valid PR: 0.1807\n",
      "Epoch [54/500], Train Loss: 1.2234, Train RMSE: 1.1061\n",
      "Epoch [54/500], Validation Loss: 3.4043, Validation RMSE: 1.8451, Valid PR: 0.2101\n",
      "Epoch [55/500], Train Loss: 1.2187, Train RMSE: 1.1039\n",
      "Epoch [55/500], Validation Loss: 3.3692, Validation RMSE: 1.8355, Valid PR: 0.2264\n",
      "Epoch [56/500], Train Loss: 1.2380, Train RMSE: 1.1127\n",
      "Epoch [56/500], Validation Loss: 3.3349, Validation RMSE: 1.8262, Valid PR: 0.2381\n",
      "Epoch [57/500], Train Loss: 1.2663, Train RMSE: 1.1253\n",
      "Epoch [57/500], Validation Loss: 3.3014, Validation RMSE: 1.8170, Valid PR: 0.2591\n",
      "Epoch [58/500], Train Loss: 1.1535, Train RMSE: 1.0740\n",
      "Epoch [58/500], Validation Loss: 3.2691, Validation RMSE: 1.8081, Valid PR: 0.2726\n",
      "Epoch [59/500], Train Loss: 1.1549, Train RMSE: 1.0747\n",
      "Epoch [59/500], Validation Loss: 3.2372, Validation RMSE: 1.7992, Valid PR: 0.2837\n",
      "Epoch [60/500], Train Loss: 1.2606, Train RMSE: 1.1228\n",
      "Epoch [60/500], Validation Loss: 3.2057, Validation RMSE: 1.7904, Valid PR: 0.2989\n",
      "Epoch [61/500], Train Loss: 1.1476, Train RMSE: 1.0713\n",
      "Epoch [61/500], Validation Loss: 3.1748, Validation RMSE: 1.7818, Valid PR: 0.3129\n",
      "Epoch [62/500], Train Loss: 1.1143, Train RMSE: 1.0556\n",
      "Epoch [62/500], Validation Loss: 3.1448, Validation RMSE: 1.7733, Valid PR: 0.3122\n",
      "Epoch [63/500], Train Loss: 1.1225, Train RMSE: 1.0595\n",
      "Epoch [63/500], Validation Loss: 3.1157, Validation RMSE: 1.7651, Valid PR: 0.3118\n",
      "Epoch [64/500], Train Loss: 1.0337, Train RMSE: 1.0167\n",
      "Epoch [64/500], Validation Loss: 3.0871, Validation RMSE: 1.7570, Valid PR: 0.3156\n",
      "Epoch [65/500], Train Loss: 1.1221, Train RMSE: 1.0593\n",
      "Epoch [65/500], Validation Loss: 3.0590, Validation RMSE: 1.7490, Valid PR: 0.3227\n",
      "Epoch [66/500], Train Loss: 0.9992, Train RMSE: 0.9996\n",
      "Epoch [66/500], Validation Loss: 3.0314, Validation RMSE: 1.7411, Valid PR: 0.3260\n",
      "Epoch [67/500], Train Loss: 1.0213, Train RMSE: 1.0106\n",
      "Epoch [67/500], Validation Loss: 3.0043, Validation RMSE: 1.7333, Valid PR: 0.3297\n",
      "Epoch [68/500], Train Loss: 0.9865, Train RMSE: 0.9932\n",
      "Epoch [68/500], Validation Loss: 2.9779, Validation RMSE: 1.7256, Valid PR: 0.3432\n",
      "Epoch [69/500], Train Loss: 1.1215, Train RMSE: 1.0590\n",
      "Epoch [69/500], Validation Loss: 2.9520, Validation RMSE: 1.7181, Valid PR: 0.3535\n",
      "Epoch [70/500], Train Loss: 1.0913, Train RMSE: 1.0446\n",
      "Epoch [70/500], Validation Loss: 2.9268, Validation RMSE: 1.7108, Valid PR: 0.3686\n",
      "Epoch [71/500], Train Loss: 0.9756, Train RMSE: 0.9877\n",
      "Epoch [71/500], Validation Loss: 2.9024, Validation RMSE: 1.7036, Valid PR: 0.3752\n",
      "Epoch [72/500], Train Loss: 0.9646, Train RMSE: 0.9821\n",
      "Epoch [72/500], Validation Loss: 2.8788, Validation RMSE: 1.6967, Valid PR: 0.3788\n",
      "Epoch [73/500], Train Loss: 0.9848, Train RMSE: 0.9924\n",
      "Epoch [73/500], Validation Loss: 2.8558, Validation RMSE: 1.6899, Valid PR: 0.3804\n",
      "Epoch [74/500], Train Loss: 1.0478, Train RMSE: 1.0236\n",
      "Epoch [74/500], Validation Loss: 2.8332, Validation RMSE: 1.6832, Valid PR: 0.3707\n",
      "Epoch [75/500], Train Loss: 1.0327, Train RMSE: 1.0162\n",
      "Epoch [75/500], Validation Loss: 2.8109, Validation RMSE: 1.6766, Valid PR: 0.3652\n",
      "Epoch [76/500], Train Loss: 0.9723, Train RMSE: 0.9860\n",
      "Epoch [76/500], Validation Loss: 2.7891, Validation RMSE: 1.6701, Valid PR: 0.3548\n",
      "Epoch [77/500], Train Loss: 0.9885, Train RMSE: 0.9942\n",
      "Epoch [77/500], Validation Loss: 2.7678, Validation RMSE: 1.6637, Valid PR: 0.3478\n",
      "Epoch [78/500], Train Loss: 0.9583, Train RMSE: 0.9789\n",
      "Epoch [78/500], Validation Loss: 2.7471, Validation RMSE: 1.6574, Valid PR: 0.3491\n",
      "Epoch [79/500], Train Loss: 1.0147, Train RMSE: 1.0073\n",
      "Epoch [79/500], Validation Loss: 2.7267, Validation RMSE: 1.6513, Valid PR: 0.3458\n",
      "Epoch [80/500], Train Loss: 0.9487, Train RMSE: 0.9740\n",
      "Epoch [80/500], Validation Loss: 2.7069, Validation RMSE: 1.6453, Valid PR: 0.3326\n",
      "Epoch [81/500], Train Loss: 0.9017, Train RMSE: 0.9496\n",
      "Epoch [81/500], Validation Loss: 2.6875, Validation RMSE: 1.6394, Valid PR: 0.3235\n",
      "Epoch [82/500], Train Loss: 0.9915, Train RMSE: 0.9958\n",
      "Epoch [82/500], Validation Loss: 2.6688, Validation RMSE: 1.6336, Valid PR: 0.3127\n",
      "Epoch [83/500], Train Loss: 0.9025, Train RMSE: 0.9500\n",
      "Epoch [83/500], Validation Loss: 2.6506, Validation RMSE: 1.6281, Valid PR: 0.3002\n",
      "Epoch [84/500], Train Loss: 0.8732, Train RMSE: 0.9345\n",
      "Epoch [84/500], Validation Loss: 2.6330, Validation RMSE: 1.6227, Valid PR: 0.2859\n",
      "Epoch [85/500], Train Loss: 0.9587, Train RMSE: 0.9791\n",
      "Epoch [85/500], Validation Loss: 2.6160, Validation RMSE: 1.6174, Valid PR: 0.2735\n",
      "Epoch [86/500], Train Loss: 0.9374, Train RMSE: 0.9682\n",
      "Epoch [86/500], Validation Loss: 2.5994, Validation RMSE: 1.6123, Valid PR: 0.2651\n",
      "Epoch [87/500], Train Loss: 0.9956, Train RMSE: 0.9978\n",
      "Epoch [87/500], Validation Loss: 2.5833, Validation RMSE: 1.6073, Valid PR: 0.2508\n",
      "Epoch [88/500], Train Loss: 0.9408, Train RMSE: 0.9700\n",
      "Epoch [88/500], Validation Loss: 2.5677, Validation RMSE: 1.6024, Valid PR: 0.2367\n",
      "Epoch [89/500], Train Loss: 0.9558, Train RMSE: 0.9776\n",
      "Epoch [89/500], Validation Loss: 2.5526, Validation RMSE: 1.5977, Valid PR: 0.2402\n",
      "Epoch [90/500], Train Loss: 0.9189, Train RMSE: 0.9586\n",
      "Epoch [90/500], Validation Loss: 2.5379, Validation RMSE: 1.5931, Valid PR: 0.2490\n",
      "Epoch [91/500], Train Loss: 0.8789, Train RMSE: 0.9375\n",
      "Epoch [91/500], Validation Loss: 2.5233, Validation RMSE: 1.5885, Valid PR: 0.2752\n",
      "Epoch [92/500], Train Loss: 0.9332, Train RMSE: 0.9660\n",
      "Epoch [92/500], Validation Loss: 2.5091, Validation RMSE: 1.5840, Valid PR: 0.2984\n",
      "Epoch [93/500], Train Loss: 0.9168, Train RMSE: 0.9575\n",
      "Epoch [93/500], Validation Loss: 2.4951, Validation RMSE: 1.5796, Valid PR: 0.3355\n",
      "Epoch [94/500], Train Loss: 0.8810, Train RMSE: 0.9386\n",
      "Epoch [94/500], Validation Loss: 2.4817, Validation RMSE: 1.5754, Valid PR: 0.3705\n",
      "Epoch [95/500], Train Loss: 0.9075, Train RMSE: 0.9526\n",
      "Epoch [95/500], Validation Loss: 2.4688, Validation RMSE: 1.5712, Valid PR: 0.3946\n",
      "Epoch [96/500], Train Loss: 0.9488, Train RMSE: 0.9741\n",
      "Epoch [96/500], Validation Loss: 2.4561, Validation RMSE: 1.5672, Valid PR: 0.4159\n",
      "Epoch [97/500], Train Loss: 0.9067, Train RMSE: 0.9522\n",
      "Epoch [97/500], Validation Loss: 2.4437, Validation RMSE: 1.5632, Valid PR: 0.4424\n",
      "Epoch [98/500], Train Loss: 0.8649, Train RMSE: 0.9300\n",
      "Epoch [98/500], Validation Loss: 2.4317, Validation RMSE: 1.5594, Valid PR: 0.4727\n",
      "Epoch [99/500], Train Loss: 0.9421, Train RMSE: 0.9706\n",
      "Epoch [99/500], Validation Loss: 2.4202, Validation RMSE: 1.5557, Valid PR: 0.5018\n",
      "Epoch [100/500], Train Loss: 0.7365, Train RMSE: 0.8582\n",
      "Epoch [100/500], Validation Loss: 2.4091, Validation RMSE: 1.5521, Valid PR: 0.5229\n",
      "Epoch [101/500], Train Loss: 0.8361, Train RMSE: 0.9144\n",
      "Epoch [101/500], Validation Loss: 2.3983, Validation RMSE: 1.5486, Valid PR: 0.5389\n",
      "Epoch [102/500], Train Loss: 0.9243, Train RMSE: 0.9614\n",
      "Epoch [102/500], Validation Loss: 2.3879, Validation RMSE: 1.5453, Valid PR: 0.5554\n",
      "Epoch [103/500], Train Loss: 0.8813, Train RMSE: 0.9388\n",
      "Epoch [103/500], Validation Loss: 2.3781, Validation RMSE: 1.5421, Valid PR: 0.5666\n",
      "Epoch [104/500], Train Loss: 0.7916, Train RMSE: 0.8897\n",
      "Epoch [104/500], Validation Loss: 2.3686, Validation RMSE: 1.5390, Valid PR: 0.5696\n",
      "Epoch [105/500], Train Loss: 0.7721, Train RMSE: 0.8787\n",
      "Epoch [105/500], Validation Loss: 2.3594, Validation RMSE: 1.5360, Valid PR: 0.5737\n",
      "Epoch [106/500], Train Loss: 0.8661, Train RMSE: 0.9306\n",
      "Epoch [106/500], Validation Loss: 2.3505, Validation RMSE: 1.5331, Valid PR: 0.5690\n",
      "Epoch [107/500], Train Loss: 0.8785, Train RMSE: 0.9373\n",
      "Epoch [107/500], Validation Loss: 2.3419, Validation RMSE: 1.5303, Valid PR: 0.5596\n",
      "Epoch [108/500], Train Loss: 0.8553, Train RMSE: 0.9248\n",
      "Epoch [108/500], Validation Loss: 2.3338, Validation RMSE: 1.5277, Valid PR: 0.5389\n",
      "Epoch [109/500], Train Loss: 0.7597, Train RMSE: 0.8716\n",
      "Epoch [109/500], Validation Loss: 2.3261, Validation RMSE: 1.5251, Valid PR: 0.5233\n",
      "Epoch [110/500], Train Loss: 0.9021, Train RMSE: 0.9498\n",
      "Epoch [110/500], Validation Loss: 2.3185, Validation RMSE: 1.5227, Valid PR: 0.5194\n",
      "Epoch [111/500], Train Loss: 0.7638, Train RMSE: 0.8740\n",
      "Epoch [111/500], Validation Loss: 2.3111, Validation RMSE: 1.5202, Valid PR: 0.5205\n",
      "Epoch [112/500], Train Loss: 0.7677, Train RMSE: 0.8762\n",
      "Epoch [112/500], Validation Loss: 2.3039, Validation RMSE: 1.5178, Valid PR: 0.5195\n",
      "Epoch [113/500], Train Loss: 0.8476, Train RMSE: 0.9207\n",
      "Epoch [113/500], Validation Loss: 2.2969, Validation RMSE: 1.5156, Valid PR: 0.5164\n",
      "Epoch [114/500], Train Loss: 0.8336, Train RMSE: 0.9130\n",
      "Epoch [114/500], Validation Loss: 2.2902, Validation RMSE: 1.5134, Valid PR: 0.5105\n",
      "Epoch [115/500], Train Loss: 0.7709, Train RMSE: 0.8780\n",
      "Epoch [115/500], Validation Loss: 2.2837, Validation RMSE: 1.5112, Valid PR: 0.5144\n",
      "Epoch [116/500], Train Loss: 0.8053, Train RMSE: 0.8974\n",
      "Epoch [116/500], Validation Loss: 2.2773, Validation RMSE: 1.5091, Valid PR: 0.5207\n",
      "Epoch [117/500], Train Loss: 0.7975, Train RMSE: 0.8930\n",
      "Epoch [117/500], Validation Loss: 2.2710, Validation RMSE: 1.5070, Valid PR: 0.5324\n",
      "Epoch [118/500], Train Loss: 0.6991, Train RMSE: 0.8362\n",
      "Epoch [118/500], Validation Loss: 2.2649, Validation RMSE: 1.5050, Valid PR: 0.5449\n",
      "Epoch [119/500], Train Loss: 0.7874, Train RMSE: 0.8874\n",
      "Epoch [119/500], Validation Loss: 2.2593, Validation RMSE: 1.5031, Valid PR: 0.5527\n",
      "Epoch [120/500], Train Loss: 0.7695, Train RMSE: 0.8772\n",
      "Epoch [120/500], Validation Loss: 2.2540, Validation RMSE: 1.5013, Valid PR: 0.5569\n",
      "Epoch [121/500], Train Loss: 0.8687, Train RMSE: 0.9321\n",
      "Epoch [121/500], Validation Loss: 2.2487, Validation RMSE: 1.4996, Valid PR: 0.5657\n",
      "Epoch [122/500], Train Loss: 0.7934, Train RMSE: 0.8907\n",
      "Epoch [122/500], Validation Loss: 2.2438, Validation RMSE: 1.4979, Valid PR: 0.5706\n",
      "Epoch [123/500], Train Loss: 0.6925, Train RMSE: 0.8322\n",
      "Epoch [123/500], Validation Loss: 2.2392, Validation RMSE: 1.4964, Valid PR: 0.5747\n",
      "Epoch [124/500], Train Loss: 0.8130, Train RMSE: 0.9016\n",
      "Epoch [124/500], Validation Loss: 2.2349, Validation RMSE: 1.4949, Valid PR: 0.5726\n",
      "Epoch [125/500], Train Loss: 0.7490, Train RMSE: 0.8655\n",
      "Epoch [125/500], Validation Loss: 2.2308, Validation RMSE: 1.4936, Valid PR: 0.5742\n",
      "Epoch [126/500], Train Loss: 0.8787, Train RMSE: 0.9374\n",
      "Epoch [126/500], Validation Loss: 2.2272, Validation RMSE: 1.4924, Valid PR: 0.5698\n",
      "Epoch [127/500], Train Loss: 0.8485, Train RMSE: 0.9212\n",
      "Epoch [127/500], Validation Loss: 2.2239, Validation RMSE: 1.4913, Valid PR: 0.5564\n",
      "Epoch [128/500], Train Loss: 0.8161, Train RMSE: 0.9034\n",
      "Epoch [128/500], Validation Loss: 2.2208, Validation RMSE: 1.4902, Valid PR: 0.5405\n",
      "Epoch [129/500], Train Loss: 0.8326, Train RMSE: 0.9125\n",
      "Epoch [129/500], Validation Loss: 2.2178, Validation RMSE: 1.4892, Valid PR: 0.5236\n",
      "Epoch [130/500], Train Loss: 0.7211, Train RMSE: 0.8492\n",
      "Epoch [130/500], Validation Loss: 2.2150, Validation RMSE: 1.4883, Valid PR: 0.5088\n",
      "Epoch [131/500], Train Loss: 0.7744, Train RMSE: 0.8800\n",
      "Epoch [131/500], Validation Loss: 2.2123, Validation RMSE: 1.4874, Valid PR: 0.4956\n",
      "Epoch [132/500], Train Loss: 0.7971, Train RMSE: 0.8928\n",
      "Epoch [132/500], Validation Loss: 2.2097, Validation RMSE: 1.4865, Valid PR: 0.4879\n",
      "Epoch [133/500], Train Loss: 0.7370, Train RMSE: 0.8585\n",
      "Epoch [133/500], Validation Loss: 2.2071, Validation RMSE: 1.4856, Valid PR: 0.4849\n",
      "Epoch [134/500], Train Loss: 0.7177, Train RMSE: 0.8472\n",
      "Epoch [134/500], Validation Loss: 2.2043, Validation RMSE: 1.4847, Valid PR: 0.4930\n",
      "Epoch [135/500], Train Loss: 0.7533, Train RMSE: 0.8679\n",
      "Epoch [135/500], Validation Loss: 2.2016, Validation RMSE: 1.4838, Valid PR: 0.5077\n",
      "Epoch [136/500], Train Loss: 0.6800, Train RMSE: 0.8246\n",
      "Epoch [136/500], Validation Loss: 2.1988, Validation RMSE: 1.4828, Valid PR: 0.5262\n",
      "Epoch [137/500], Train Loss: 0.7832, Train RMSE: 0.8850\n",
      "Epoch [137/500], Validation Loss: 2.1961, Validation RMSE: 1.4819, Valid PR: 0.5441\n",
      "Epoch [138/500], Train Loss: 0.7367, Train RMSE: 0.8583\n",
      "Epoch [138/500], Validation Loss: 2.1934, Validation RMSE: 1.4810, Valid PR: 0.5598\n",
      "Epoch [139/500], Train Loss: 0.7625, Train RMSE: 0.8732\n",
      "Epoch [139/500], Validation Loss: 2.1908, Validation RMSE: 1.4801, Valid PR: 0.5724\n",
      "Epoch [140/500], Train Loss: 0.7162, Train RMSE: 0.8463\n",
      "Epoch [140/500], Validation Loss: 2.1884, Validation RMSE: 1.4793, Valid PR: 0.5768\n",
      "Epoch [141/500], Train Loss: 0.7637, Train RMSE: 0.8739\n",
      "Epoch [141/500], Validation Loss: 2.1856, Validation RMSE: 1.4784, Valid PR: 0.5994\n",
      "Epoch [142/500], Train Loss: 0.7372, Train RMSE: 0.8586\n",
      "Epoch [142/500], Validation Loss: 2.1831, Validation RMSE: 1.4775, Valid PR: 0.6167\n",
      "Epoch [143/500], Train Loss: 0.8161, Train RMSE: 0.9034\n",
      "Epoch [143/500], Validation Loss: 2.1805, Validation RMSE: 1.4767, Valid PR: 0.6328\n",
      "Epoch [144/500], Train Loss: 0.7102, Train RMSE: 0.8427\n",
      "Epoch [144/500], Validation Loss: 2.1786, Validation RMSE: 1.4760, Valid PR: 0.6402\n",
      "Epoch [145/500], Train Loss: 0.7355, Train RMSE: 0.8576\n",
      "Epoch [145/500], Validation Loss: 2.1774, Validation RMSE: 1.4756, Valid PR: 0.6383\n",
      "Epoch [146/500], Train Loss: 0.6861, Train RMSE: 0.8283\n",
      "Epoch [146/500], Validation Loss: 2.1764, Validation RMSE: 1.4753, Valid PR: 0.6336\n",
      "Epoch [147/500], Train Loss: 0.7538, Train RMSE: 0.8682\n",
      "Epoch [147/500], Validation Loss: 2.1760, Validation RMSE: 1.4751, Valid PR: 0.6250\n",
      "Epoch [148/500], Train Loss: 0.7482, Train RMSE: 0.8650\n",
      "Epoch [148/500], Validation Loss: 2.1755, Validation RMSE: 1.4750, Valid PR: 0.6196\n",
      "Epoch [149/500], Train Loss: 0.8438, Train RMSE: 0.9186\n",
      "Epoch [149/500], Validation Loss: 2.1751, Validation RMSE: 1.4748, Valid PR: 0.6160\n",
      "Epoch [150/500], Train Loss: 0.6802, Train RMSE: 0.8248\n",
      "Epoch [150/500], Validation Loss: 2.1746, Validation RMSE: 1.4746, Valid PR: 0.6132\n",
      "Epoch [151/500], Train Loss: 0.7646, Train RMSE: 0.8744\n",
      "Epoch [151/500], Validation Loss: 2.1742, Validation RMSE: 1.4745, Valid PR: 0.6105\n",
      "Epoch [152/500], Train Loss: 0.6954, Train RMSE: 0.8339\n",
      "Epoch [152/500], Validation Loss: 2.1738, Validation RMSE: 1.4744, Valid PR: 0.6091\n",
      "Epoch [153/500], Train Loss: 0.6357, Train RMSE: 0.7973\n",
      "Epoch [153/500], Validation Loss: 2.1735, Validation RMSE: 1.4743, Valid PR: 0.6057\n",
      "Epoch [154/500], Train Loss: 0.7204, Train RMSE: 0.8488\n",
      "Epoch [154/500], Validation Loss: 2.1733, Validation RMSE: 1.4742, Valid PR: 0.6026\n",
      "Epoch [155/500], Train Loss: 0.6939, Train RMSE: 0.8330\n",
      "Epoch [155/500], Validation Loss: 2.1731, Validation RMSE: 1.4741, Valid PR: 0.5973\n",
      "Epoch [156/500], Train Loss: 0.6584, Train RMSE: 0.8114\n",
      "Epoch [156/500], Validation Loss: 2.1729, Validation RMSE: 1.4741, Valid PR: 0.5930\n",
      "Epoch [157/500], Train Loss: 0.7182, Train RMSE: 0.8475\n",
      "Epoch [157/500], Validation Loss: 2.1725, Validation RMSE: 1.4739, Valid PR: 0.5942\n",
      "Epoch [158/500], Train Loss: 0.7186, Train RMSE: 0.8477\n",
      "Epoch [158/500], Validation Loss: 2.1716, Validation RMSE: 1.4736, Valid PR: 0.6052\n",
      "Epoch [159/500], Train Loss: 0.7813, Train RMSE: 0.8839\n",
      "Epoch [159/500], Validation Loss: 2.1706, Validation RMSE: 1.4733, Valid PR: 0.6152\n",
      "Epoch [160/500], Train Loss: 0.6460, Train RMSE: 0.8038\n",
      "Epoch [160/500], Validation Loss: 2.1696, Validation RMSE: 1.4729, Valid PR: 0.6258\n",
      "Epoch [161/500], Train Loss: 0.6586, Train RMSE: 0.8115\n",
      "Epoch [161/500], Validation Loss: 2.1684, Validation RMSE: 1.4725, Valid PR: 0.6365\n",
      "Epoch [162/500], Train Loss: 0.6781, Train RMSE: 0.8234\n",
      "Epoch [162/500], Validation Loss: 2.1678, Validation RMSE: 1.4724, Valid PR: 0.6391\n",
      "Epoch [163/500], Train Loss: 0.6759, Train RMSE: 0.8221\n",
      "Epoch [163/500], Validation Loss: 2.1677, Validation RMSE: 1.4723, Valid PR: 0.6375\n",
      "Epoch [164/500], Train Loss: 0.6928, Train RMSE: 0.8323\n",
      "Epoch [164/500], Validation Loss: 2.1673, Validation RMSE: 1.4722, Valid PR: 0.6395\n",
      "Epoch [165/500], Train Loss: 0.6976, Train RMSE: 0.8352\n",
      "Epoch [165/500], Validation Loss: 2.1669, Validation RMSE: 1.4720, Valid PR: 0.6431\n",
      "Epoch [166/500], Train Loss: 0.7730, Train RMSE: 0.8792\n",
      "Epoch [166/500], Validation Loss: 2.1665, Validation RMSE: 1.4719, Valid PR: 0.6452\n",
      "Epoch [167/500], Train Loss: 0.6852, Train RMSE: 0.8278\n",
      "Epoch [167/500], Validation Loss: 2.1660, Validation RMSE: 1.4717, Valid PR: 0.6503\n",
      "Epoch [168/500], Train Loss: 0.6752, Train RMSE: 0.8217\n",
      "Epoch [168/500], Validation Loss: 2.1655, Validation RMSE: 1.4716, Valid PR: 0.6594\n",
      "Epoch [169/500], Train Loss: 0.6336, Train RMSE: 0.7960\n",
      "Epoch [169/500], Validation Loss: 2.1652, Validation RMSE: 1.4714, Valid PR: 0.6677\n",
      "Epoch [170/500], Train Loss: 0.6966, Train RMSE: 0.8347\n",
      "Epoch [170/500], Validation Loss: 2.1643, Validation RMSE: 1.4712, Valid PR: 0.6791\n",
      "Epoch [171/500], Train Loss: 0.6845, Train RMSE: 0.8273\n",
      "Epoch [171/500], Validation Loss: 2.1628, Validation RMSE: 1.4707, Valid PR: 0.6909\n",
      "Epoch [172/500], Train Loss: 0.7382, Train RMSE: 0.8592\n",
      "Epoch [172/500], Validation Loss: 2.1606, Validation RMSE: 1.4699, Valid PR: 0.7051\n",
      "Epoch [173/500], Train Loss: 0.6738, Train RMSE: 0.8208\n",
      "Epoch [173/500], Validation Loss: 2.1586, Validation RMSE: 1.4692, Valid PR: 0.7150\n",
      "Epoch [174/500], Train Loss: 0.7340, Train RMSE: 0.8568\n",
      "Epoch [174/500], Validation Loss: 2.1563, Validation RMSE: 1.4684, Valid PR: 0.7234\n",
      "Epoch [175/500], Train Loss: 0.8110, Train RMSE: 0.9005\n",
      "Epoch [175/500], Validation Loss: 2.1533, Validation RMSE: 1.4674, Valid PR: 0.7345\n",
      "Epoch [176/500], Train Loss: 0.6988, Train RMSE: 0.8360\n",
      "Epoch [176/500], Validation Loss: 2.1506, Validation RMSE: 1.4665, Valid PR: 0.7442\n",
      "Epoch [177/500], Train Loss: 0.7160, Train RMSE: 0.8462\n",
      "Epoch [177/500], Validation Loss: 2.1473, Validation RMSE: 1.4654, Valid PR: 0.7550\n",
      "Epoch [178/500], Train Loss: 0.7746, Train RMSE: 0.8801\n",
      "Epoch [178/500], Validation Loss: 2.1433, Validation RMSE: 1.4640, Valid PR: 0.7656\n",
      "Epoch [179/500], Train Loss: 0.6734, Train RMSE: 0.8206\n",
      "Epoch [179/500], Validation Loss: 2.1389, Validation RMSE: 1.4625, Valid PR: 0.7765\n",
      "Epoch [180/500], Train Loss: 0.7363, Train RMSE: 0.8581\n",
      "Epoch [180/500], Validation Loss: 2.1340, Validation RMSE: 1.4608, Valid PR: 0.7862\n",
      "Epoch [181/500], Train Loss: 0.7261, Train RMSE: 0.8521\n",
      "Epoch [181/500], Validation Loss: 2.1281, Validation RMSE: 1.4588, Valid PR: 0.7977\n",
      "Epoch [182/500], Train Loss: 0.6597, Train RMSE: 0.8122\n",
      "Epoch [182/500], Validation Loss: 2.1221, Validation RMSE: 1.4567, Valid PR: 0.8081\n",
      "Epoch [183/500], Train Loss: 0.7158, Train RMSE: 0.8460\n",
      "Epoch [183/500], Validation Loss: 2.1154, Validation RMSE: 1.4545, Valid PR: 0.8181\n",
      "Epoch [184/500], Train Loss: 0.6179, Train RMSE: 0.7861\n",
      "Epoch [184/500], Validation Loss: 2.1087, Validation RMSE: 1.4521, Valid PR: 0.8265\n",
      "Epoch [185/500], Train Loss: 0.7069, Train RMSE: 0.8408\n",
      "Epoch [185/500], Validation Loss: 2.1009, Validation RMSE: 1.4494, Valid PR: 0.8339\n",
      "Epoch [186/500], Train Loss: 0.6295, Train RMSE: 0.7934\n",
      "Epoch [186/500], Validation Loss: 2.0930, Validation RMSE: 1.4467, Valid PR: 0.8384\n",
      "Epoch [187/500], Train Loss: 0.6675, Train RMSE: 0.8170\n",
      "Epoch [187/500], Validation Loss: 2.0837, Validation RMSE: 1.4435, Valid PR: 0.8428\n",
      "Epoch [188/500], Train Loss: 0.7232, Train RMSE: 0.8504\n",
      "Epoch [188/500], Validation Loss: 2.0738, Validation RMSE: 1.4401, Valid PR: 0.8460\n",
      "Epoch [189/500], Train Loss: 0.6338, Train RMSE: 0.7961\n",
      "Epoch [189/500], Validation Loss: 2.0629, Validation RMSE: 1.4363, Valid PR: 0.8474\n",
      "Epoch [190/500], Train Loss: 0.7335, Train RMSE: 0.8564\n",
      "Epoch [190/500], Validation Loss: 2.0521, Validation RMSE: 1.4325, Valid PR: 0.8474\n",
      "Epoch [191/500], Train Loss: 0.7261, Train RMSE: 0.8521\n",
      "Epoch [191/500], Validation Loss: 2.0397, Validation RMSE: 1.4282, Valid PR: 0.8484\n",
      "Epoch [192/500], Train Loss: 0.7586, Train RMSE: 0.8710\n",
      "Epoch [192/500], Validation Loss: 2.0243, Validation RMSE: 1.4228, Valid PR: 0.8510\n",
      "Epoch [193/500], Train Loss: 0.6822, Train RMSE: 0.8260\n",
      "Epoch [193/500], Validation Loss: 2.0076, Validation RMSE: 1.4169, Valid PR: 0.8527\n",
      "Epoch [194/500], Train Loss: 0.6433, Train RMSE: 0.8020\n",
      "Epoch [194/500], Validation Loss: 1.9874, Validation RMSE: 1.4097, Valid PR: 0.8569\n",
      "Epoch [195/500], Train Loss: 0.7042, Train RMSE: 0.8392\n",
      "Epoch [195/500], Validation Loss: 1.9649, Validation RMSE: 1.4018, Valid PR: 0.8601\n",
      "Epoch [196/500], Train Loss: 0.7726, Train RMSE: 0.8790\n",
      "Epoch [196/500], Validation Loss: 1.9390, Validation RMSE: 1.3925, Valid PR: 0.8635\n",
      "Epoch [197/500], Train Loss: 0.6790, Train RMSE: 0.8240\n",
      "Epoch [197/500], Validation Loss: 1.9083, Validation RMSE: 1.3814, Valid PR: 0.8685\n",
      "Epoch [198/500], Train Loss: 0.6174, Train RMSE: 0.7857\n",
      "Epoch [198/500], Validation Loss: 1.8727, Validation RMSE: 1.3685, Valid PR: 0.8744\n",
      "Epoch [199/500], Train Loss: 0.6626, Train RMSE: 0.8140\n",
      "Epoch [199/500], Validation Loss: 1.8317, Validation RMSE: 1.3534, Valid PR: 0.8823\n",
      "Epoch [200/500], Train Loss: 0.6675, Train RMSE: 0.8170\n",
      "Epoch [200/500], Validation Loss: 1.7863, Validation RMSE: 1.3365, Valid PR: 0.8900\n",
      "Epoch [201/500], Train Loss: 0.6886, Train RMSE: 0.8298\n",
      "Epoch [201/500], Validation Loss: 1.7372, Validation RMSE: 1.3180, Valid PR: 0.8972\n",
      "Epoch [202/500], Train Loss: 0.6584, Train RMSE: 0.8114\n",
      "Epoch [202/500], Validation Loss: 1.6813, Validation RMSE: 1.2967, Valid PR: 0.9038\n",
      "Epoch [203/500], Train Loss: 0.6414, Train RMSE: 0.8009\n",
      "Epoch [203/500], Validation Loss: 1.6208, Validation RMSE: 1.2731, Valid PR: 0.9091\n",
      "Epoch [204/500], Train Loss: 0.6862, Train RMSE: 0.8284\n",
      "Epoch [204/500], Validation Loss: 1.5504, Validation RMSE: 1.2452, Valid PR: 0.9147\n",
      "Epoch [205/500], Train Loss: 0.6288, Train RMSE: 0.7929\n",
      "Epoch [205/500], Validation Loss: 1.4812, Validation RMSE: 1.2170, Valid PR: 0.9183\n",
      "Epoch [206/500], Train Loss: 0.6752, Train RMSE: 0.8217\n",
      "Epoch [206/500], Validation Loss: 1.4072, Validation RMSE: 1.1863, Valid PR: 0.9211\n",
      "Epoch [207/500], Train Loss: 0.6986, Train RMSE: 0.8358\n",
      "Epoch [207/500], Validation Loss: 1.3252, Validation RMSE: 1.1512, Valid PR: 0.9235\n",
      "Epoch [208/500], Train Loss: 0.7663, Train RMSE: 0.8754\n",
      "Epoch [208/500], Validation Loss: 1.2431, Validation RMSE: 1.1150, Valid PR: 0.9247\n",
      "Epoch [209/500], Train Loss: 0.6031, Train RMSE: 0.7766\n",
      "Epoch [209/500], Validation Loss: 1.1660, Validation RMSE: 1.0798, Valid PR: 0.9254\n",
      "Epoch [210/500], Train Loss: 0.5416, Train RMSE: 0.7359\n",
      "Epoch [210/500], Validation Loss: 1.0874, Validation RMSE: 1.0428, Valid PR: 0.9254\n",
      "Epoch [211/500], Train Loss: 0.6339, Train RMSE: 0.7962\n",
      "Epoch [211/500], Validation Loss: 1.0078, Validation RMSE: 1.0039, Valid PR: 0.9250\n",
      "Epoch [212/500], Train Loss: 0.6268, Train RMSE: 0.7917\n",
      "Epoch [212/500], Validation Loss: 0.9359, Validation RMSE: 0.9674, Valid PR: 0.9243\n",
      "Epoch [213/500], Train Loss: 0.5578, Train RMSE: 0.7469\n",
      "Epoch [213/500], Validation Loss: 0.8597, Validation RMSE: 0.9272, Valid PR: 0.9239\n",
      "Epoch [214/500], Train Loss: 0.5626, Train RMSE: 0.7501\n",
      "Epoch [214/500], Validation Loss: 0.7813, Validation RMSE: 0.8839, Valid PR: 0.9237\n",
      "Epoch [215/500], Train Loss: 0.5595, Train RMSE: 0.7480\n",
      "Epoch [215/500], Validation Loss: 0.7171, Validation RMSE: 0.8468, Valid PR: 0.9235\n",
      "Epoch [216/500], Train Loss: 0.6557, Train RMSE: 0.8098\n",
      "Epoch [216/500], Validation Loss: 0.6596, Validation RMSE: 0.8121, Valid PR: 0.9232\n",
      "Epoch [217/500], Train Loss: 0.5792, Train RMSE: 0.7611\n",
      "Epoch [217/500], Validation Loss: 0.6128, Validation RMSE: 0.7828, Valid PR: 0.9230\n",
      "Epoch [218/500], Train Loss: 0.6724, Train RMSE: 0.8200\n",
      "Epoch [218/500], Validation Loss: 0.5840, Validation RMSE: 0.7642, Valid PR: 0.9227\n",
      "Epoch [219/500], Train Loss: 0.5923, Train RMSE: 0.7696\n",
      "Epoch [219/500], Validation Loss: 0.5644, Validation RMSE: 0.7513, Valid PR: 0.9226\n",
      "Epoch [220/500], Train Loss: 0.4817, Train RMSE: 0.6941\n",
      "Epoch [220/500], Validation Loss: 0.5437, Validation RMSE: 0.7373, Valid PR: 0.9226\n",
      "Epoch [221/500], Train Loss: 0.6139, Train RMSE: 0.7835\n",
      "Epoch [221/500], Validation Loss: 0.5222, Validation RMSE: 0.7226, Valid PR: 0.9228\n",
      "Epoch [222/500], Train Loss: 0.5781, Train RMSE: 0.7603\n",
      "Epoch [222/500], Validation Loss: 0.5057, Validation RMSE: 0.7112, Valid PR: 0.9230\n",
      "Epoch [223/500], Train Loss: 0.5074, Train RMSE: 0.7123\n",
      "Epoch [223/500], Validation Loss: 0.4925, Validation RMSE: 0.7018, Valid PR: 0.9232\n",
      "Epoch [224/500], Train Loss: 0.5962, Train RMSE: 0.7721\n",
      "Epoch [224/500], Validation Loss: 0.4797, Validation RMSE: 0.6926, Valid PR: 0.9235\n",
      "Epoch [225/500], Train Loss: 0.5887, Train RMSE: 0.7673\n",
      "Epoch [225/500], Validation Loss: 0.4701, Validation RMSE: 0.6856, Valid PR: 0.9239\n",
      "Epoch [226/500], Train Loss: 0.5470, Train RMSE: 0.7396\n",
      "Epoch [226/500], Validation Loss: 0.4647, Validation RMSE: 0.6817, Valid PR: 0.9243\n",
      "Epoch [227/500], Train Loss: 0.6284, Train RMSE: 0.7927\n",
      "Epoch [227/500], Validation Loss: 0.4606, Validation RMSE: 0.6787, Valid PR: 0.9249\n",
      "Epoch [228/500], Train Loss: 0.5417, Train RMSE: 0.7360\n",
      "Epoch [228/500], Validation Loss: 0.4599, Validation RMSE: 0.6782, Valid PR: 0.9256\n",
      "Epoch [229/500], Train Loss: 0.5899, Train RMSE: 0.7681\n",
      "Epoch [229/500], Validation Loss: 0.4638, Validation RMSE: 0.6810, Valid PR: 0.9260\n",
      "Epoch [230/500], Train Loss: 0.5819, Train RMSE: 0.7628\n",
      "Epoch [230/500], Validation Loss: 0.4678, Validation RMSE: 0.6840, Valid PR: 0.9263\n",
      "Epoch [231/500], Train Loss: 0.5475, Train RMSE: 0.7400\n",
      "Epoch [231/500], Validation Loss: 0.4741, Validation RMSE: 0.6885, Valid PR: 0.9265\n",
      "Epoch [232/500], Train Loss: 0.5740, Train RMSE: 0.7576\n",
      "Epoch [232/500], Validation Loss: 0.4809, Validation RMSE: 0.6934, Valid PR: 0.9267\n",
      "Epoch [233/500], Train Loss: 0.5510, Train RMSE: 0.7423\n",
      "Epoch [233/500], Validation Loss: 0.4875, Validation RMSE: 0.6982, Valid PR: 0.9268\n",
      "Epoch [234/500], Train Loss: 0.5754, Train RMSE: 0.7586\n",
      "Epoch [234/500], Validation Loss: 0.4932, Validation RMSE: 0.7023, Valid PR: 0.9266\n",
      "Epoch [235/500], Train Loss: 0.5381, Train RMSE: 0.7336\n",
      "Epoch [235/500], Validation Loss: 0.4982, Validation RMSE: 0.7058, Valid PR: 0.9265\n",
      "Epoch [236/500], Train Loss: 0.5235, Train RMSE: 0.7235\n",
      "Epoch [236/500], Validation Loss: 0.4993, Validation RMSE: 0.7066, Valid PR: 0.9266\n",
      "Epoch [237/500], Train Loss: 0.5316, Train RMSE: 0.7291\n",
      "Epoch [237/500], Validation Loss: 0.4970, Validation RMSE: 0.7049, Valid PR: 0.9264\n",
      "Epoch [238/500], Train Loss: 0.5736, Train RMSE: 0.7573\n",
      "Epoch [238/500], Validation Loss: 0.4935, Validation RMSE: 0.7025, Valid PR: 0.9263\n",
      "Epoch [239/500], Train Loss: 0.6288, Train RMSE: 0.7930\n",
      "Epoch [239/500], Validation Loss: 0.4884, Validation RMSE: 0.6989, Valid PR: 0.9263\n",
      "Epoch [240/500], Train Loss: 0.5269, Train RMSE: 0.7259\n",
      "Epoch [240/500], Validation Loss: 0.4811, Validation RMSE: 0.6936, Valid PR: 0.9265\n",
      "Epoch [241/500], Train Loss: 0.5499, Train RMSE: 0.7416\n",
      "Epoch [241/500], Validation Loss: 0.4753, Validation RMSE: 0.6894, Valid PR: 0.9269\n",
      "Epoch [242/500], Train Loss: 0.5670, Train RMSE: 0.7530\n",
      "Epoch [242/500], Validation Loss: 0.4709, Validation RMSE: 0.6862, Valid PR: 0.9273\n",
      "Epoch [243/500], Train Loss: 0.5083, Train RMSE: 0.7130\n",
      "Epoch [243/500], Validation Loss: 0.4650, Validation RMSE: 0.6819, Valid PR: 0.9274\n",
      "Epoch [244/500], Train Loss: 0.5452, Train RMSE: 0.7384\n",
      "Epoch [244/500], Validation Loss: 0.4605, Validation RMSE: 0.6786, Valid PR: 0.9275\n",
      "Epoch [245/500], Train Loss: 0.5249, Train RMSE: 0.7245\n",
      "Epoch [245/500], Validation Loss: 0.4562, Validation RMSE: 0.6754, Valid PR: 0.9277\n",
      "Epoch [246/500], Train Loss: 0.6224, Train RMSE: 0.7889\n",
      "Epoch [246/500], Validation Loss: 0.4539, Validation RMSE: 0.6737, Valid PR: 0.9276\n",
      "Epoch [247/500], Train Loss: 0.5613, Train RMSE: 0.7492\n",
      "Epoch [247/500], Validation Loss: 0.4501, Validation RMSE: 0.6709, Valid PR: 0.9275\n",
      "Epoch [248/500], Train Loss: 0.5158, Train RMSE: 0.7182\n",
      "Epoch [248/500], Validation Loss: 0.4470, Validation RMSE: 0.6685, Valid PR: 0.9276\n",
      "Epoch [249/500], Train Loss: 0.5118, Train RMSE: 0.7154\n",
      "Epoch [249/500], Validation Loss: 0.4417, Validation RMSE: 0.6646, Valid PR: 0.9278\n",
      "Epoch [250/500], Train Loss: 0.5062, Train RMSE: 0.7115\n",
      "Epoch [250/500], Validation Loss: 0.4327, Validation RMSE: 0.6578, Valid PR: 0.9284\n",
      "Epoch [251/500], Train Loss: 0.5508, Train RMSE: 0.7422\n",
      "Epoch [251/500], Validation Loss: 0.4262, Validation RMSE: 0.6528, Valid PR: 0.9287\n",
      "Epoch [252/500], Train Loss: 0.5151, Train RMSE: 0.7177\n",
      "Epoch [252/500], Validation Loss: 0.4208, Validation RMSE: 0.6487, Valid PR: 0.9286\n",
      "Epoch [253/500], Train Loss: 0.5343, Train RMSE: 0.7310\n",
      "Epoch [253/500], Validation Loss: 0.4153, Validation RMSE: 0.6444, Valid PR: 0.9287\n",
      "Epoch [254/500], Train Loss: 0.5100, Train RMSE: 0.7141\n",
      "Epoch [254/500], Validation Loss: 0.4106, Validation RMSE: 0.6408, Valid PR: 0.9287\n",
      "Epoch [255/500], Train Loss: 0.4999, Train RMSE: 0.7070\n",
      "Epoch [255/500], Validation Loss: 0.4038, Validation RMSE: 0.6354, Valid PR: 0.9292\n",
      "Epoch [256/500], Train Loss: 0.5565, Train RMSE: 0.7460\n",
      "Epoch [256/500], Validation Loss: 0.3969, Validation RMSE: 0.6300, Valid PR: 0.9302\n",
      "Epoch [257/500], Train Loss: 0.6294, Train RMSE: 0.7933\n",
      "Epoch [257/500], Validation Loss: 0.3902, Validation RMSE: 0.6247, Valid PR: 0.9317\n",
      "Epoch [258/500], Train Loss: 0.5972, Train RMSE: 0.7728\n",
      "Epoch [258/500], Validation Loss: 0.3853, Validation RMSE: 0.6207, Valid PR: 0.9334\n",
      "Epoch [259/500], Train Loss: 0.5507, Train RMSE: 0.7421\n",
      "Epoch [259/500], Validation Loss: 0.3823, Validation RMSE: 0.6183, Valid PR: 0.9351\n",
      "Epoch [260/500], Train Loss: 0.5242, Train RMSE: 0.7240\n",
      "Epoch [260/500], Validation Loss: 0.3854, Validation RMSE: 0.6208, Valid PR: 0.9363\n",
      "Epoch [261/500], Train Loss: 0.5106, Train RMSE: 0.7146\n",
      "Epoch [261/500], Validation Loss: 0.3890, Validation RMSE: 0.6237, Valid PR: 0.9378\n",
      "Epoch [262/500], Train Loss: 0.5339, Train RMSE: 0.7307\n",
      "Epoch [262/500], Validation Loss: 0.3926, Validation RMSE: 0.6265, Valid PR: 0.9383\n",
      "Epoch [263/500], Train Loss: 0.5188, Train RMSE: 0.7203\n",
      "Epoch [263/500], Validation Loss: 0.3975, Validation RMSE: 0.6305, Valid PR: 0.9381\n",
      "Epoch [264/500], Train Loss: 0.4945, Train RMSE: 0.7032\n",
      "Epoch [264/500], Validation Loss: 0.3998, Validation RMSE: 0.6323, Valid PR: 0.9375\n",
      "Epoch [265/500], Train Loss: 0.4901, Train RMSE: 0.7001\n",
      "Epoch [265/500], Validation Loss: 0.4006, Validation RMSE: 0.6330, Valid PR: 0.9370\n",
      "Epoch [266/500], Train Loss: 0.6396, Train RMSE: 0.7998\n",
      "Epoch [266/500], Validation Loss: 0.3980, Validation RMSE: 0.6309, Valid PR: 0.9373\n",
      "Epoch [267/500], Train Loss: 0.5191, Train RMSE: 0.7205\n",
      "Epoch [267/500], Validation Loss: 0.3962, Validation RMSE: 0.6294, Valid PR: 0.9372\n",
      "Epoch [268/500], Train Loss: 0.4548, Train RMSE: 0.6744\n",
      "Epoch [268/500], Validation Loss: 0.3932, Validation RMSE: 0.6271, Valid PR: 0.9368\n",
      "Epoch [269/500], Train Loss: 0.4465, Train RMSE: 0.6682\n",
      "Epoch [269/500], Validation Loss: 0.3918, Validation RMSE: 0.6259, Valid PR: 0.9358\n",
      "Epoch [270/500], Train Loss: 0.5176, Train RMSE: 0.7194\n",
      "Epoch [270/500], Validation Loss: 0.4012, Validation RMSE: 0.6334, Valid PR: 0.9334\n",
      "Epoch [271/500], Train Loss: 0.5726, Train RMSE: 0.7567\n",
      "Epoch [271/500], Validation Loss: 0.4158, Validation RMSE: 0.6448, Valid PR: 0.9297\n",
      "Epoch [272/500], Train Loss: 0.5136, Train RMSE: 0.7167\n",
      "Epoch [272/500], Validation Loss: 0.4334, Validation RMSE: 0.6583, Valid PR: 0.9256\n",
      "Epoch [273/500], Train Loss: 0.4108, Train RMSE: 0.6410\n",
      "Epoch [273/500], Validation Loss: 0.4450, Validation RMSE: 0.6671, Valid PR: 0.9228\n",
      "Epoch [274/500], Train Loss: 0.5018, Train RMSE: 0.7084\n",
      "Epoch [274/500], Validation Loss: 0.4548, Validation RMSE: 0.6744, Valid PR: 0.9192\n",
      "Epoch [275/500], Train Loss: 0.4557, Train RMSE: 0.6750\n",
      "Epoch [275/500], Validation Loss: 0.4637, Validation RMSE: 0.6810, Valid PR: 0.9160\n",
      "Epoch [276/500], Train Loss: 0.5608, Train RMSE: 0.7489\n",
      "Epoch [276/500], Validation Loss: 0.4807, Validation RMSE: 0.6933, Valid PR: 0.9123\n",
      "Epoch [277/500], Train Loss: 0.4900, Train RMSE: 0.7000\n",
      "Epoch [277/500], Validation Loss: 0.4945, Validation RMSE: 0.7032, Valid PR: 0.9082\n",
      "Epoch [278/500], Train Loss: 0.4550, Train RMSE: 0.6745\n",
      "Epoch [278/500], Validation Loss: 0.5052, Validation RMSE: 0.7108, Valid PR: 0.9048\n",
      "Epoch [279/500], Train Loss: 0.4287, Train RMSE: 0.6547\n",
      "Epoch [279/500], Validation Loss: 0.5120, Validation RMSE: 0.7155, Valid PR: 0.9023\n",
      "Epoch [280/500], Train Loss: 0.4328, Train RMSE: 0.6578\n",
      "Epoch [280/500], Validation Loss: 0.5161, Validation RMSE: 0.7184, Valid PR: 0.9003\n",
      "Epoch [281/500], Train Loss: 0.4942, Train RMSE: 0.7030\n",
      "Epoch [281/500], Validation Loss: 0.5230, Validation RMSE: 0.7232, Valid PR: 0.8987\n",
      "Epoch [282/500], Train Loss: 0.4702, Train RMSE: 0.6857\n",
      "Epoch [282/500], Validation Loss: 0.5350, Validation RMSE: 0.7314, Valid PR: 0.8957\n",
      "Epoch [283/500], Train Loss: 0.4724, Train RMSE: 0.6873\n",
      "Epoch [283/500], Validation Loss: 0.5418, Validation RMSE: 0.7360, Valid PR: 0.8936\n",
      "Epoch [284/500], Train Loss: 0.4335, Train RMSE: 0.6584\n",
      "Epoch [284/500], Validation Loss: 0.5420, Validation RMSE: 0.7362, Valid PR: 0.8932\n",
      "Epoch [285/500], Train Loss: 0.4336, Train RMSE: 0.6585\n",
      "Epoch [285/500], Validation Loss: 0.5426, Validation RMSE: 0.7366, Valid PR: 0.8925\n",
      "Epoch [286/500], Train Loss: 0.4864, Train RMSE: 0.6974\n",
      "Epoch [286/500], Validation Loss: 0.5466, Validation RMSE: 0.7393, Valid PR: 0.8908\n",
      "Epoch [287/500], Train Loss: 0.4261, Train RMSE: 0.6527\n",
      "Epoch [287/500], Validation Loss: 0.5531, Validation RMSE: 0.7437, Valid PR: 0.8890\n",
      "Epoch [288/500], Train Loss: 0.5772, Train RMSE: 0.7598\n",
      "Epoch [288/500], Validation Loss: 0.5691, Validation RMSE: 0.7544, Valid PR: 0.8856\n",
      "Epoch [289/500], Train Loss: 0.3912, Train RMSE: 0.6254\n",
      "Epoch [289/500], Validation Loss: 0.5930, Validation RMSE: 0.7701, Valid PR: 0.8798\n",
      "Epoch [290/500], Train Loss: 0.4812, Train RMSE: 0.6937\n",
      "Epoch [290/500], Validation Loss: 0.6230, Validation RMSE: 0.7893, Valid PR: 0.8710\n",
      "Epoch [291/500], Train Loss: 0.4497, Train RMSE: 0.6706\n",
      "Epoch [291/500], Validation Loss: 0.6453, Validation RMSE: 0.8033, Valid PR: 0.8639\n",
      "Epoch [292/500], Train Loss: 0.5109, Train RMSE: 0.7148\n",
      "Epoch [292/500], Validation Loss: 0.6718, Validation RMSE: 0.8196, Valid PR: 0.8559\n",
      "Epoch [293/500], Train Loss: 0.4508, Train RMSE: 0.6714\n",
      "Epoch [293/500], Validation Loss: 0.7071, Validation RMSE: 0.8409, Valid PR: 0.8476\n",
      "Epoch [294/500], Train Loss: 0.4417, Train RMSE: 0.6646\n",
      "Epoch [294/500], Validation Loss: 0.7391, Validation RMSE: 0.8597, Valid PR: 0.8408\n",
      "Epoch [295/500], Train Loss: 0.3943, Train RMSE: 0.6279\n",
      "Epoch [295/500], Validation Loss: 0.7668, Validation RMSE: 0.8757, Valid PR: 0.8353\n",
      "Epoch [296/500], Train Loss: 0.4112, Train RMSE: 0.6412\n",
      "Epoch [296/500], Validation Loss: 0.7823, Validation RMSE: 0.8845, Valid PR: 0.8314\n",
      "Epoch [297/500], Train Loss: 0.4168, Train RMSE: 0.6456\n",
      "Epoch [297/500], Validation Loss: 0.7785, Validation RMSE: 0.8823, Valid PR: 0.8321\n",
      "Epoch [298/500], Train Loss: 0.5027, Train RMSE: 0.7090\n",
      "Epoch [298/500], Validation Loss: 0.7627, Validation RMSE: 0.8733, Valid PR: 0.8353\n",
      "Epoch [299/500], Train Loss: 0.3959, Train RMSE: 0.6292\n",
      "Epoch [299/500], Validation Loss: 0.7473, Validation RMSE: 0.8645, Valid PR: 0.8393\n",
      "Epoch [300/500], Train Loss: 0.4399, Train RMSE: 0.6633\n",
      "Epoch [300/500], Validation Loss: 0.7381, Validation RMSE: 0.8592, Valid PR: 0.8426\n",
      "Epoch [301/500], Train Loss: 0.4398, Train RMSE: 0.6632\n",
      "Epoch [301/500], Validation Loss: 0.7413, Validation RMSE: 0.8610, Valid PR: 0.8431\n",
      "Epoch [302/500], Train Loss: 0.4206, Train RMSE: 0.6485\n",
      "Epoch [302/500], Validation Loss: 0.7581, Validation RMSE: 0.8707, Valid PR: 0.8406\n",
      "Epoch [303/500], Train Loss: 0.4531, Train RMSE: 0.6731\n",
      "Epoch [303/500], Validation Loss: 0.7818, Validation RMSE: 0.8842, Valid PR: 0.8377\n",
      "Epoch [304/500], Train Loss: 0.4143, Train RMSE: 0.6436\n",
      "Epoch [304/500], Validation Loss: 0.7880, Validation RMSE: 0.8877, Valid PR: 0.8384\n",
      "Epoch [305/500], Train Loss: 0.4883, Train RMSE: 0.6988\n",
      "Epoch [305/500], Validation Loss: 0.7824, Validation RMSE: 0.8845, Valid PR: 0.8404\n",
      "Epoch [306/500], Train Loss: 0.3568, Train RMSE: 0.5973\n",
      "Epoch [306/500], Validation Loss: 0.7834, Validation RMSE: 0.8851, Valid PR: 0.8407\n",
      "Epoch [307/500], Train Loss: 0.4473, Train RMSE: 0.6688\n",
      "Epoch [307/500], Validation Loss: 0.7827, Validation RMSE: 0.8847, Valid PR: 0.8443\n",
      "Epoch [308/500], Train Loss: 0.4961, Train RMSE: 0.7043\n",
      "Epoch [308/500], Validation Loss: 0.7997, Validation RMSE: 0.8943, Valid PR: 0.8438\n",
      "Epoch [309/500], Train Loss: 0.4311, Train RMSE: 0.6566\n",
      "Epoch [309/500], Validation Loss: 0.8087, Validation RMSE: 0.8993, Valid PR: 0.8420\n",
      "Early stopping triggered.\n",
      "Test Loss: 3.1768, Test RMSE: 1.7824, Test PR: 0.1257\n",
      "Testing method2...\n",
      "Replication 1 for method2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:122: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 7.9074, Train RMSE: 2.8120\n",
      "Epoch [1/500], Validation Loss: 11.4614, Validation RMSE: 3.3855, Valid PR: -0.3847\n",
      "Epoch [2/500], Train Loss: 3.4957, Train RMSE: 1.8697\n",
      "Epoch [2/500], Validation Loss: 8.8228, Validation RMSE: 2.9703, Valid PR: 0.5597\n",
      "Epoch [3/500], Train Loss: 2.7620, Train RMSE: 1.6619\n",
      "Epoch [3/500], Validation Loss: 7.6697, Validation RMSE: 2.7694, Valid PR: 0.3425\n",
      "Epoch [4/500], Train Loss: 2.4342, Train RMSE: 1.5602\n",
      "Epoch [4/500], Validation Loss: 6.8866, Validation RMSE: 2.6242, Valid PR: -0.1198\n",
      "Epoch [5/500], Train Loss: 2.2072, Train RMSE: 1.4857\n",
      "Epoch [5/500], Validation Loss: 6.3445, Validation RMSE: 2.5188, Valid PR: -0.2312\n",
      "Epoch [6/500], Train Loss: 2.1014, Train RMSE: 1.4496\n",
      "Epoch [6/500], Validation Loss: 5.9652, Validation RMSE: 2.4424, Valid PR: -0.5039\n",
      "Epoch [7/500], Train Loss: 1.9248, Train RMSE: 1.3874\n",
      "Epoch [7/500], Validation Loss: 5.7023, Validation RMSE: 2.3879, Valid PR: -0.6052\n",
      "Epoch [8/500], Train Loss: 1.9715, Train RMSE: 1.4041\n",
      "Epoch [8/500], Validation Loss: 5.4844, Validation RMSE: 2.3419, Valid PR: -0.6205\n",
      "Epoch [9/500], Train Loss: 1.7859, Train RMSE: 1.3364\n",
      "Epoch [9/500], Validation Loss: 5.3020, Validation RMSE: 2.3026, Valid PR: -0.6392\n",
      "Epoch [10/500], Train Loss: 1.8505, Train RMSE: 1.3603\n",
      "Epoch [10/500], Validation Loss: 5.1532, Validation RMSE: 2.2701, Valid PR: -0.6552\n",
      "Epoch [11/500], Train Loss: 1.6979, Train RMSE: 1.3030\n",
      "Epoch [11/500], Validation Loss: 5.0289, Validation RMSE: 2.2425, Valid PR: -0.6827\n",
      "Epoch [12/500], Train Loss: 1.6444, Train RMSE: 1.2823\n",
      "Epoch [12/500], Validation Loss: 4.9248, Validation RMSE: 2.2192, Valid PR: -0.7034\n",
      "Epoch [13/500], Train Loss: 1.6159, Train RMSE: 1.2712\n",
      "Epoch [13/500], Validation Loss: 4.8371, Validation RMSE: 2.1993, Valid PR: -0.6470\n",
      "Epoch [14/500], Train Loss: 1.7301, Train RMSE: 1.3153\n",
      "Epoch [14/500], Validation Loss: 4.7591, Validation RMSE: 2.1815, Valid PR: -0.2498\n",
      "Epoch [15/500], Train Loss: 1.5026, Train RMSE: 1.2258\n",
      "Epoch [15/500], Validation Loss: 4.6867, Validation RMSE: 2.1649, Valid PR: 0.1478\n",
      "Epoch [16/500], Train Loss: 1.6146, Train RMSE: 1.2707\n",
      "Epoch [16/500], Validation Loss: 4.6192, Validation RMSE: 2.1492, Valid PR: 0.3121\n",
      "Epoch [17/500], Train Loss: 1.5786, Train RMSE: 1.2564\n",
      "Epoch [17/500], Validation Loss: 4.5545, Validation RMSE: 2.1341, Valid PR: 0.3867\n",
      "Epoch [18/500], Train Loss: 1.6320, Train RMSE: 1.2775\n",
      "Epoch [18/500], Validation Loss: 4.4922, Validation RMSE: 2.1195, Valid PR: 0.4247\n",
      "Epoch [19/500], Train Loss: 1.6251, Train RMSE: 1.2748\n",
      "Epoch [19/500], Validation Loss: 4.4311, Validation RMSE: 2.1050, Valid PR: 0.4441\n",
      "Epoch [20/500], Train Loss: 1.4229, Train RMSE: 1.1929\n",
      "Epoch [20/500], Validation Loss: 4.3715, Validation RMSE: 2.0908, Valid PR: 0.4524\n",
      "Epoch [21/500], Train Loss: 1.4586, Train RMSE: 1.2077\n",
      "Epoch [21/500], Validation Loss: 4.3121, Validation RMSE: 2.0766, Valid PR: 0.4536\n",
      "Epoch [22/500], Train Loss: 1.5041, Train RMSE: 1.2264\n",
      "Epoch [22/500], Validation Loss: 4.2536, Validation RMSE: 2.0624, Valid PR: 0.4490\n",
      "Epoch [23/500], Train Loss: 1.4354, Train RMSE: 1.1981\n",
      "Epoch [23/500], Validation Loss: 4.1970, Validation RMSE: 2.0487, Valid PR: 0.4413\n",
      "Epoch [24/500], Train Loss: 1.3663, Train RMSE: 1.1689\n",
      "Epoch [24/500], Validation Loss: 4.1417, Validation RMSE: 2.0351, Valid PR: 0.4265\n",
      "Epoch [25/500], Train Loss: 1.4031, Train RMSE: 1.1845\n",
      "Epoch [25/500], Validation Loss: 4.0881, Validation RMSE: 2.0219, Valid PR: 0.4039\n",
      "Epoch [26/500], Train Loss: 1.3550, Train RMSE: 1.1640\n",
      "Epoch [26/500], Validation Loss: 4.0361, Validation RMSE: 2.0090, Valid PR: 0.3533\n",
      "Epoch [27/500], Train Loss: 1.4253, Train RMSE: 1.1939\n",
      "Epoch [27/500], Validation Loss: 3.9852, Validation RMSE: 1.9963, Valid PR: 0.2391\n",
      "Epoch [28/500], Train Loss: 1.3363, Train RMSE: 1.1560\n",
      "Epoch [28/500], Validation Loss: 3.9362, Validation RMSE: 1.9840, Valid PR: 0.0572\n",
      "Epoch [29/500], Train Loss: 1.3751, Train RMSE: 1.1726\n",
      "Epoch [29/500], Validation Loss: 3.8885, Validation RMSE: 1.9719, Valid PR: -0.1153\n",
      "Epoch [30/500], Train Loss: 1.3329, Train RMSE: 1.1545\n",
      "Epoch [30/500], Validation Loss: 3.8417, Validation RMSE: 1.9600, Valid PR: -0.2574\n",
      "Epoch [31/500], Train Loss: 1.3132, Train RMSE: 1.1460\n",
      "Epoch [31/500], Validation Loss: 3.7967, Validation RMSE: 1.9485, Valid PR: -0.2959\n",
      "Epoch [32/500], Train Loss: 1.2215, Train RMSE: 1.1052\n",
      "Epoch [32/500], Validation Loss: 3.7520, Validation RMSE: 1.9370, Valid PR: -0.4516\n",
      "Epoch [33/500], Train Loss: 1.2927, Train RMSE: 1.1370\n",
      "Epoch [33/500], Validation Loss: 3.7076, Validation RMSE: 1.9255, Valid PR: -0.4643\n",
      "Epoch [34/500], Train Loss: 1.2375, Train RMSE: 1.1124\n",
      "Epoch [34/500], Validation Loss: 3.6641, Validation RMSE: 1.9142, Valid PR: -0.4687\n",
      "Epoch [35/500], Train Loss: 1.1268, Train RMSE: 1.0615\n",
      "Epoch [35/500], Validation Loss: 3.6215, Validation RMSE: 1.9030, Valid PR: -0.4698\n",
      "Epoch [36/500], Train Loss: 1.2092, Train RMSE: 1.0996\n",
      "Epoch [36/500], Validation Loss: 3.5796, Validation RMSE: 1.8920, Valid PR: -0.4692\n",
      "Epoch [37/500], Train Loss: 1.1542, Train RMSE: 1.0744\n",
      "Epoch [37/500], Validation Loss: 3.5388, Validation RMSE: 1.8812, Valid PR: -0.4695\n",
      "Epoch [38/500], Train Loss: 1.2291, Train RMSE: 1.1086\n",
      "Epoch [38/500], Validation Loss: 3.4986, Validation RMSE: 1.8705, Valid PR: -0.4617\n",
      "Epoch [39/500], Train Loss: 1.1737, Train RMSE: 1.0834\n",
      "Epoch [39/500], Validation Loss: 3.4591, Validation RMSE: 1.8599, Valid PR: -0.3863\n",
      "Epoch [40/500], Train Loss: 1.2641, Train RMSE: 1.1243\n",
      "Epoch [40/500], Validation Loss: 3.4203, Validation RMSE: 1.8494, Valid PR: -0.1722\n",
      "Epoch [41/500], Train Loss: 1.2007, Train RMSE: 1.0958\n",
      "Epoch [41/500], Validation Loss: 3.3826, Validation RMSE: 1.8392, Valid PR: 0.0319\n",
      "Epoch [42/500], Train Loss: 1.0888, Train RMSE: 1.0435\n",
      "Epoch [42/500], Validation Loss: 3.3460, Validation RMSE: 1.8292, Valid PR: 0.0963\n",
      "Epoch [43/500], Train Loss: 1.1270, Train RMSE: 1.0616\n",
      "Epoch [43/500], Validation Loss: 3.3104, Validation RMSE: 1.8195, Valid PR: 0.1066\n",
      "Epoch [44/500], Train Loss: 1.0571, Train RMSE: 1.0281\n",
      "Epoch [44/500], Validation Loss: 3.2756, Validation RMSE: 1.8099, Valid PR: 0.0846\n",
      "Epoch [45/500], Train Loss: 1.0338, Train RMSE: 1.0168\n",
      "Epoch [45/500], Validation Loss: 3.2416, Validation RMSE: 1.8004, Valid PR: 0.0428\n",
      "Epoch [46/500], Train Loss: 1.0971, Train RMSE: 1.0474\n",
      "Epoch [46/500], Validation Loss: 3.2085, Validation RMSE: 1.7912, Valid PR: 0.0156\n",
      "Epoch [47/500], Train Loss: 1.0574, Train RMSE: 1.0283\n",
      "Epoch [47/500], Validation Loss: 3.1761, Validation RMSE: 1.7822, Valid PR: -0.0764\n",
      "Epoch [48/500], Train Loss: 1.0344, Train RMSE: 1.0171\n",
      "Epoch [48/500], Validation Loss: 3.1446, Validation RMSE: 1.7733, Valid PR: -0.1404\n",
      "Epoch [49/500], Train Loss: 1.1449, Train RMSE: 1.0700\n",
      "Epoch [49/500], Validation Loss: 3.1136, Validation RMSE: 1.7645, Valid PR: -0.1938\n",
      "Epoch [50/500], Train Loss: 1.0444, Train RMSE: 1.0220\n",
      "Epoch [50/500], Validation Loss: 3.0832, Validation RMSE: 1.7559, Valid PR: -0.2280\n",
      "Epoch [51/500], Train Loss: 1.0763, Train RMSE: 1.0375\n",
      "Epoch [51/500], Validation Loss: 3.0534, Validation RMSE: 1.7474, Valid PR: -0.2510\n",
      "Epoch [52/500], Train Loss: 1.0415, Train RMSE: 1.0205\n",
      "Epoch [52/500], Validation Loss: 3.0244, Validation RMSE: 1.7391, Valid PR: -0.2874\n",
      "Epoch [53/500], Train Loss: 1.0782, Train RMSE: 1.0384\n",
      "Epoch [53/500], Validation Loss: 2.9962, Validation RMSE: 1.7309, Valid PR: -0.2687\n",
      "Epoch [54/500], Train Loss: 1.0506, Train RMSE: 1.0250\n",
      "Epoch [54/500], Validation Loss: 2.9687, Validation RMSE: 1.7230, Valid PR: -0.2307\n",
      "Epoch [55/500], Train Loss: 1.0002, Train RMSE: 1.0001\n",
      "Epoch [55/500], Validation Loss: 2.9420, Validation RMSE: 1.7152, Valid PR: -0.1808\n",
      "Epoch [56/500], Train Loss: 0.9539, Train RMSE: 0.9767\n",
      "Epoch [56/500], Validation Loss: 2.9160, Validation RMSE: 1.7076, Valid PR: -0.0980\n",
      "Epoch [57/500], Train Loss: 1.0374, Train RMSE: 1.0185\n",
      "Epoch [57/500], Validation Loss: 2.8906, Validation RMSE: 1.7002, Valid PR: 0.0022\n",
      "Epoch [58/500], Train Loss: 0.9815, Train RMSE: 0.9907\n",
      "Epoch [58/500], Validation Loss: 2.8659, Validation RMSE: 1.6929, Valid PR: 0.0646\n",
      "Epoch [59/500], Train Loss: 1.0055, Train RMSE: 1.0028\n",
      "Epoch [59/500], Validation Loss: 2.8420, Validation RMSE: 1.6858, Valid PR: 0.1202\n",
      "Epoch [60/500], Train Loss: 0.9452, Train RMSE: 0.9722\n",
      "Epoch [60/500], Validation Loss: 2.8189, Validation RMSE: 1.6789, Valid PR: 0.2230\n",
      "Epoch [61/500], Train Loss: 1.0177, Train RMSE: 1.0088\n",
      "Epoch [61/500], Validation Loss: 2.7963, Validation RMSE: 1.6722, Valid PR: 0.2407\n",
      "Epoch [62/500], Train Loss: 1.0506, Train RMSE: 1.0250\n",
      "Epoch [62/500], Validation Loss: 2.7743, Validation RMSE: 1.6656, Valid PR: 0.2192\n",
      "Epoch [63/500], Train Loss: 0.8798, Train RMSE: 0.9380\n",
      "Epoch [63/500], Validation Loss: 2.7529, Validation RMSE: 1.6592, Valid PR: 0.0529\n",
      "Epoch [64/500], Train Loss: 0.9861, Train RMSE: 0.9930\n",
      "Epoch [64/500], Validation Loss: 2.7319, Validation RMSE: 1.6529, Valid PR: 0.0029\n",
      "Epoch [65/500], Train Loss: 1.0304, Train RMSE: 1.0151\n",
      "Epoch [65/500], Validation Loss: 2.7111, Validation RMSE: 1.6465, Valid PR: 0.0950\n",
      "Epoch [66/500], Train Loss: 0.9536, Train RMSE: 0.9765\n",
      "Epoch [66/500], Validation Loss: 2.6905, Validation RMSE: 1.6403, Valid PR: 0.1846\n",
      "Epoch [67/500], Train Loss: 0.9157, Train RMSE: 0.9569\n",
      "Epoch [67/500], Validation Loss: 2.6705, Validation RMSE: 1.6342, Valid PR: 0.2678\n",
      "Epoch [68/500], Train Loss: 0.9857, Train RMSE: 0.9928\n",
      "Epoch [68/500], Validation Loss: 2.6510, Validation RMSE: 1.6282, Valid PR: 0.2899\n",
      "Epoch [69/500], Train Loss: 0.9712, Train RMSE: 0.9855\n",
      "Epoch [69/500], Validation Loss: 2.6321, Validation RMSE: 1.6224, Valid PR: 0.2953\n",
      "Epoch [70/500], Train Loss: 0.9138, Train RMSE: 0.9560\n",
      "Epoch [70/500], Validation Loss: 2.6139, Validation RMSE: 1.6168, Valid PR: 0.2929\n",
      "Epoch [71/500], Train Loss: 0.8999, Train RMSE: 0.9486\n",
      "Epoch [71/500], Validation Loss: 2.5963, Validation RMSE: 1.6113, Valid PR: 0.2689\n",
      "Epoch [72/500], Train Loss: 0.9053, Train RMSE: 0.9515\n",
      "Epoch [72/500], Validation Loss: 2.5794, Validation RMSE: 1.6060, Valid PR: 0.2135\n",
      "Epoch [73/500], Train Loss: 0.8898, Train RMSE: 0.9433\n",
      "Epoch [73/500], Validation Loss: 2.5630, Validation RMSE: 1.6009, Valid PR: 0.1371\n",
      "Epoch [74/500], Train Loss: 0.8975, Train RMSE: 0.9474\n",
      "Epoch [74/500], Validation Loss: 2.5472, Validation RMSE: 1.5960, Valid PR: 0.0279\n",
      "Epoch [75/500], Train Loss: 0.7867, Train RMSE: 0.8870\n",
      "Epoch [75/500], Validation Loss: 2.5319, Validation RMSE: 1.5912, Valid PR: 0.0121\n",
      "Epoch [76/500], Train Loss: 0.9209, Train RMSE: 0.9596\n",
      "Epoch [76/500], Validation Loss: 2.5169, Validation RMSE: 1.5865, Valid PR: 0.0659\n",
      "Epoch [77/500], Train Loss: 0.8528, Train RMSE: 0.9235\n",
      "Epoch [77/500], Validation Loss: 2.5022, Validation RMSE: 1.5818, Valid PR: 0.1506\n",
      "Epoch [78/500], Train Loss: 0.8317, Train RMSE: 0.9120\n",
      "Epoch [78/500], Validation Loss: 2.4879, Validation RMSE: 1.5773, Valid PR: 0.2337\n",
      "Epoch [79/500], Train Loss: 0.9092, Train RMSE: 0.9535\n",
      "Epoch [79/500], Validation Loss: 2.4742, Validation RMSE: 1.5730, Valid PR: 0.2828\n",
      "Epoch [80/500], Train Loss: 0.9384, Train RMSE: 0.9687\n",
      "Epoch [80/500], Validation Loss: 2.4608, Validation RMSE: 1.5687, Valid PR: 0.3276\n",
      "Epoch [81/500], Train Loss: 0.8685, Train RMSE: 0.9320\n",
      "Epoch [81/500], Validation Loss: 2.4480, Validation RMSE: 1.5646, Valid PR: 0.3575\n",
      "Epoch [82/500], Train Loss: 0.8768, Train RMSE: 0.9364\n",
      "Epoch [82/500], Validation Loss: 2.4359, Validation RMSE: 1.5607, Valid PR: 0.3759\n",
      "Epoch [83/500], Train Loss: 0.8556, Train RMSE: 0.9250\n",
      "Epoch [83/500], Validation Loss: 2.4239, Validation RMSE: 1.5569, Valid PR: 0.3862\n",
      "Epoch [84/500], Train Loss: 0.8254, Train RMSE: 0.9085\n",
      "Epoch [84/500], Validation Loss: 2.4124, Validation RMSE: 1.5532, Valid PR: 0.3797\n",
      "Epoch [85/500], Train Loss: 0.8150, Train RMSE: 0.9028\n",
      "Epoch [85/500], Validation Loss: 2.4011, Validation RMSE: 1.5496, Valid PR: 0.3723\n",
      "Epoch [86/500], Train Loss: 0.9059, Train RMSE: 0.9518\n",
      "Epoch [86/500], Validation Loss: 2.3903, Validation RMSE: 1.5461, Valid PR: 0.3632\n",
      "Epoch [87/500], Train Loss: 0.8833, Train RMSE: 0.9399\n",
      "Epoch [87/500], Validation Loss: 2.3800, Validation RMSE: 1.5427, Valid PR: 0.3600\n",
      "Epoch [88/500], Train Loss: 0.8796, Train RMSE: 0.9379\n",
      "Epoch [88/500], Validation Loss: 2.3703, Validation RMSE: 1.5396, Valid PR: 0.3556\n",
      "Epoch [89/500], Train Loss: 0.8466, Train RMSE: 0.9201\n",
      "Epoch [89/500], Validation Loss: 2.3609, Validation RMSE: 1.5365, Valid PR: 0.3438\n",
      "Epoch [90/500], Train Loss: 0.7583, Train RMSE: 0.8708\n",
      "Epoch [90/500], Validation Loss: 2.3519, Validation RMSE: 1.5336, Valid PR: 0.3255\n",
      "Epoch [91/500], Train Loss: 0.8291, Train RMSE: 0.9105\n",
      "Epoch [91/500], Validation Loss: 2.3432, Validation RMSE: 1.5308, Valid PR: 0.3017\n",
      "Epoch [92/500], Train Loss: 0.8279, Train RMSE: 0.9099\n",
      "Epoch [92/500], Validation Loss: 2.3350, Validation RMSE: 1.5281, Valid PR: 0.2769\n",
      "Epoch [93/500], Train Loss: 0.7590, Train RMSE: 0.8712\n",
      "Epoch [93/500], Validation Loss: 2.3268, Validation RMSE: 1.5254, Valid PR: 0.2618\n",
      "Epoch [94/500], Train Loss: 0.7748, Train RMSE: 0.8802\n",
      "Epoch [94/500], Validation Loss: 2.3190, Validation RMSE: 1.5228, Valid PR: 0.2547\n",
      "Epoch [95/500], Train Loss: 0.8938, Train RMSE: 0.9454\n",
      "Epoch [95/500], Validation Loss: 2.3115, Validation RMSE: 1.5204, Valid PR: 0.2476\n",
      "Epoch [96/500], Train Loss: 0.7568, Train RMSE: 0.8699\n",
      "Epoch [96/500], Validation Loss: 2.3043, Validation RMSE: 1.5180, Valid PR: 0.2987\n",
      "Epoch [97/500], Train Loss: 0.7782, Train RMSE: 0.8821\n",
      "Epoch [97/500], Validation Loss: 2.2974, Validation RMSE: 1.5157, Valid PR: 0.3575\n",
      "Epoch [98/500], Train Loss: 0.8451, Train RMSE: 0.9193\n",
      "Epoch [98/500], Validation Loss: 2.2909, Validation RMSE: 1.5136, Valid PR: 0.3527\n",
      "Epoch [99/500], Train Loss: 0.6807, Train RMSE: 0.8251\n",
      "Epoch [99/500], Validation Loss: 2.2847, Validation RMSE: 1.5115, Valid PR: 0.3406\n",
      "Epoch [100/500], Train Loss: 0.7578, Train RMSE: 0.8705\n",
      "Epoch [100/500], Validation Loss: 2.2787, Validation RMSE: 1.5095, Valid PR: 0.3497\n",
      "Epoch [101/500], Train Loss: 0.8529, Train RMSE: 0.9235\n",
      "Epoch [101/500], Validation Loss: 2.2729, Validation RMSE: 1.5076, Valid PR: 0.3466\n",
      "Epoch [102/500], Train Loss: 0.8141, Train RMSE: 0.9023\n",
      "Epoch [102/500], Validation Loss: 2.2674, Validation RMSE: 1.5058, Valid PR: 0.3536\n",
      "Epoch [103/500], Train Loss: 0.7247, Train RMSE: 0.8513\n",
      "Epoch [103/500], Validation Loss: 2.2621, Validation RMSE: 1.5040, Valid PR: 0.3791\n",
      "Epoch [104/500], Train Loss: 0.8454, Train RMSE: 0.9194\n",
      "Epoch [104/500], Validation Loss: 2.2572, Validation RMSE: 1.5024, Valid PR: 0.3494\n",
      "Epoch [105/500], Train Loss: 0.7543, Train RMSE: 0.8685\n",
      "Epoch [105/500], Validation Loss: 2.2524, Validation RMSE: 1.5008, Valid PR: 0.2522\n",
      "Epoch [106/500], Train Loss: 0.7543, Train RMSE: 0.8685\n",
      "Epoch [106/500], Validation Loss: 2.2481, Validation RMSE: 1.4994, Valid PR: 0.0060\n",
      "Epoch [107/500], Train Loss: 0.7952, Train RMSE: 0.8918\n",
      "Epoch [107/500], Validation Loss: 2.2440, Validation RMSE: 1.4980, Valid PR: -0.2603\n",
      "Epoch [108/500], Train Loss: 0.8278, Train RMSE: 0.9098\n",
      "Epoch [108/500], Validation Loss: 2.2401, Validation RMSE: 1.4967, Valid PR: -0.4320\n",
      "Epoch [109/500], Train Loss: 0.8163, Train RMSE: 0.9035\n",
      "Epoch [109/500], Validation Loss: 2.2366, Validation RMSE: 1.4955, Valid PR: -0.5030\n",
      "Epoch [110/500], Train Loss: 0.8302, Train RMSE: 0.9111\n",
      "Epoch [110/500], Validation Loss: 2.2332, Validation RMSE: 1.4944, Valid PR: -0.5468\n",
      "Epoch [111/500], Train Loss: 0.7942, Train RMSE: 0.8912\n",
      "Epoch [111/500], Validation Loss: 2.2300, Validation RMSE: 1.4933, Valid PR: -0.5733\n",
      "Epoch [112/500], Train Loss: 0.7610, Train RMSE: 0.8724\n",
      "Epoch [112/500], Validation Loss: 2.2271, Validation RMSE: 1.4923, Valid PR: -0.5718\n",
      "Epoch [113/500], Train Loss: 0.7191, Train RMSE: 0.8480\n",
      "Epoch [113/500], Validation Loss: 2.2249, Validation RMSE: 1.4916, Valid PR: -0.5881\n",
      "Epoch [114/500], Train Loss: 0.7803, Train RMSE: 0.8834\n",
      "Epoch [114/500], Validation Loss: 2.2232, Validation RMSE: 1.4910, Valid PR: -0.6532\n",
      "Epoch [115/500], Train Loss: 0.7294, Train RMSE: 0.8541\n",
      "Epoch [115/500], Validation Loss: 2.2218, Validation RMSE: 1.4906, Valid PR: -0.6411\n",
      "Epoch [116/500], Train Loss: 0.6993, Train RMSE: 0.8362\n",
      "Epoch [116/500], Validation Loss: 2.2209, Validation RMSE: 1.4903, Valid PR: -0.5984\n",
      "Epoch [117/500], Train Loss: 0.7285, Train RMSE: 0.8535\n",
      "Epoch [117/500], Validation Loss: 2.2202, Validation RMSE: 1.4900, Valid PR: -0.5765\n",
      "Epoch [118/500], Train Loss: 0.8403, Train RMSE: 0.9167\n",
      "Epoch [118/500], Validation Loss: 2.2196, Validation RMSE: 1.4898, Valid PR: -0.5623\n",
      "Epoch [119/500], Train Loss: 0.7645, Train RMSE: 0.8743\n",
      "Epoch [119/500], Validation Loss: 2.2194, Validation RMSE: 1.4898, Valid PR: -0.5495\n",
      "Epoch [120/500], Train Loss: 0.7165, Train RMSE: 0.8465\n",
      "Epoch [120/500], Validation Loss: 2.2194, Validation RMSE: 1.4898, Valid PR: -0.5394\n",
      "Epoch [121/500], Train Loss: 0.8046, Train RMSE: 0.8970\n",
      "Epoch [121/500], Validation Loss: 2.2198, Validation RMSE: 1.4899, Valid PR: -0.5326\n",
      "Epoch [122/500], Train Loss: 0.7905, Train RMSE: 0.8891\n",
      "Epoch [122/500], Validation Loss: 2.2198, Validation RMSE: 1.4899, Valid PR: -0.5261\n",
      "Epoch [123/500], Train Loss: 0.7620, Train RMSE: 0.8729\n",
      "Epoch [123/500], Validation Loss: 2.2200, Validation RMSE: 1.4900, Valid PR: -0.5200\n",
      "Epoch [124/500], Train Loss: 0.8419, Train RMSE: 0.9176\n",
      "Epoch [124/500], Validation Loss: 2.2204, Validation RMSE: 1.4901, Valid PR: -0.5155\n",
      "Epoch [125/500], Train Loss: 0.7272, Train RMSE: 0.8528\n",
      "Epoch [125/500], Validation Loss: 2.2207, Validation RMSE: 1.4902, Valid PR: -0.5104\n",
      "Epoch [126/500], Train Loss: 0.7443, Train RMSE: 0.8627\n",
      "Epoch [126/500], Validation Loss: 2.2209, Validation RMSE: 1.4903, Valid PR: -0.5046\n",
      "Epoch [127/500], Train Loss: 0.7322, Train RMSE: 0.8557\n",
      "Epoch [127/500], Validation Loss: 2.2215, Validation RMSE: 1.4905, Valid PR: -0.4984\n",
      "Epoch [128/500], Train Loss: 0.7173, Train RMSE: 0.8469\n",
      "Epoch [128/500], Validation Loss: 2.2222, Validation RMSE: 1.4907, Valid PR: -0.4916\n",
      "Epoch [129/500], Train Loss: 0.7701, Train RMSE: 0.8776\n",
      "Epoch [129/500], Validation Loss: 2.2230, Validation RMSE: 1.4910, Valid PR: -0.4833\n",
      "Epoch [130/500], Train Loss: 0.7966, Train RMSE: 0.8925\n",
      "Epoch [130/500], Validation Loss: 2.2227, Validation RMSE: 1.4909, Valid PR: -0.4762\n",
      "Epoch [131/500], Train Loss: 0.7527, Train RMSE: 0.8676\n",
      "Epoch [131/500], Validation Loss: 2.2205, Validation RMSE: 1.4901, Valid PR: -0.4705\n",
      "Epoch [132/500], Train Loss: 0.7451, Train RMSE: 0.8632\n",
      "Epoch [132/500], Validation Loss: 2.2157, Validation RMSE: 1.4885, Valid PR: -0.4631\n",
      "Epoch [133/500], Train Loss: 0.7353, Train RMSE: 0.8575\n",
      "Epoch [133/500], Validation Loss: 2.2103, Validation RMSE: 1.4867, Valid PR: -0.4486\n",
      "Epoch [134/500], Train Loss: 0.7349, Train RMSE: 0.8572\n",
      "Epoch [134/500], Validation Loss: 2.2052, Validation RMSE: 1.4850, Valid PR: -0.4198\n",
      "Epoch [135/500], Train Loss: 0.6975, Train RMSE: 0.8352\n",
      "Epoch [135/500], Validation Loss: 2.1996, Validation RMSE: 1.4831, Valid PR: -0.3441\n",
      "Epoch [136/500], Train Loss: 0.7749, Train RMSE: 0.8803\n",
      "Epoch [136/500], Validation Loss: 2.1942, Validation RMSE: 1.4813, Valid PR: -0.0578\n",
      "Epoch [137/500], Train Loss: 0.6914, Train RMSE: 0.8315\n",
      "Epoch [137/500], Validation Loss: 2.1899, Validation RMSE: 1.4798, Valid PR: 0.3772\n",
      "Epoch [138/500], Train Loss: 0.7556, Train RMSE: 0.8693\n",
      "Epoch [138/500], Validation Loss: 2.1866, Validation RMSE: 1.4787, Valid PR: 0.4810\n",
      "Epoch [139/500], Train Loss: 0.7605, Train RMSE: 0.8721\n",
      "Epoch [139/500], Validation Loss: 2.1840, Validation RMSE: 1.4778, Valid PR: 0.5012\n",
      "Epoch [140/500], Train Loss: 0.6841, Train RMSE: 0.8271\n",
      "Epoch [140/500], Validation Loss: 2.1821, Validation RMSE: 1.4772, Valid PR: 0.5059\n",
      "Epoch [141/500], Train Loss: 0.7952, Train RMSE: 0.8917\n",
      "Epoch [141/500], Validation Loss: 2.1807, Validation RMSE: 1.4767, Valid PR: 0.5081\n",
      "Epoch [142/500], Train Loss: 0.7694, Train RMSE: 0.8772\n",
      "Epoch [142/500], Validation Loss: 2.1795, Validation RMSE: 1.4763, Valid PR: 0.5097\n",
      "Epoch [143/500], Train Loss: 0.7310, Train RMSE: 0.8550\n",
      "Epoch [143/500], Validation Loss: 2.1782, Validation RMSE: 1.4759, Valid PR: 0.5115\n",
      "Epoch [144/500], Train Loss: 0.7219, Train RMSE: 0.8497\n",
      "Epoch [144/500], Validation Loss: 2.1770, Validation RMSE: 1.4755, Valid PR: 0.5130\n",
      "Epoch [145/500], Train Loss: 0.7589, Train RMSE: 0.8711\n",
      "Epoch [145/500], Validation Loss: 2.1756, Validation RMSE: 1.4750, Valid PR: 0.5146\n",
      "Epoch [146/500], Train Loss: 0.6423, Train RMSE: 0.8014\n",
      "Epoch [146/500], Validation Loss: 2.1746, Validation RMSE: 1.4747, Valid PR: 0.5157\n",
      "Epoch [147/500], Train Loss: 0.7890, Train RMSE: 0.8883\n",
      "Epoch [147/500], Validation Loss: 2.1738, Validation RMSE: 1.4744, Valid PR: 0.5170\n",
      "Epoch [148/500], Train Loss: 0.6768, Train RMSE: 0.8227\n",
      "Epoch [148/500], Validation Loss: 2.1733, Validation RMSE: 1.4742, Valid PR: 0.5186\n",
      "Epoch [149/500], Train Loss: 0.7131, Train RMSE: 0.8445\n",
      "Epoch [149/500], Validation Loss: 2.1731, Validation RMSE: 1.4741, Valid PR: 0.5210\n",
      "Epoch [150/500], Train Loss: 0.6692, Train RMSE: 0.8180\n",
      "Epoch [150/500], Validation Loss: 2.1732, Validation RMSE: 1.4742, Valid PR: 0.5224\n",
      "Epoch [151/500], Train Loss: 0.7770, Train RMSE: 0.8815\n",
      "Epoch [151/500], Validation Loss: 2.1733, Validation RMSE: 1.4742, Valid PR: 0.5238\n",
      "Epoch [152/500], Train Loss: 0.6429, Train RMSE: 0.8018\n",
      "Epoch [152/500], Validation Loss: 2.1735, Validation RMSE: 1.4743, Valid PR: 0.5251\n",
      "Epoch [153/500], Train Loss: 0.6500, Train RMSE: 0.8062\n",
      "Epoch [153/500], Validation Loss: 2.1735, Validation RMSE: 1.4743, Valid PR: 0.5260\n",
      "Epoch [154/500], Train Loss: 0.6643, Train RMSE: 0.8151\n",
      "Epoch [154/500], Validation Loss: 2.1735, Validation RMSE: 1.4743, Valid PR: 0.5272\n",
      "Epoch [155/500], Train Loss: 0.7382, Train RMSE: 0.8592\n",
      "Epoch [155/500], Validation Loss: 2.1734, Validation RMSE: 1.4742, Valid PR: 0.5282\n",
      "Epoch [156/500], Train Loss: 0.6429, Train RMSE: 0.8018\n",
      "Epoch [156/500], Validation Loss: 2.1736, Validation RMSE: 1.4743, Valid PR: 0.5293\n",
      "Epoch [157/500], Train Loss: 0.7519, Train RMSE: 0.8671\n",
      "Epoch [157/500], Validation Loss: 2.1738, Validation RMSE: 1.4744, Valid PR: 0.5301\n",
      "Epoch [158/500], Train Loss: 0.6596, Train RMSE: 0.8121\n",
      "Epoch [158/500], Validation Loss: 2.1737, Validation RMSE: 1.4743, Valid PR: 0.5305\n",
      "Epoch [159/500], Train Loss: 0.7480, Train RMSE: 0.8649\n",
      "Epoch [159/500], Validation Loss: 2.1734, Validation RMSE: 1.4742, Valid PR: 0.5305\n",
      "Epoch [160/500], Train Loss: 0.7175, Train RMSE: 0.8471\n",
      "Epoch [160/500], Validation Loss: 2.1731, Validation RMSE: 1.4742, Valid PR: 0.5310\n",
      "Epoch [161/500], Train Loss: 0.7085, Train RMSE: 0.8417\n",
      "Epoch [161/500], Validation Loss: 2.1732, Validation RMSE: 1.4742, Valid PR: 0.5315\n",
      "Epoch [162/500], Train Loss: 0.6753, Train RMSE: 0.8218\n",
      "Epoch [162/500], Validation Loss: 2.1723, Validation RMSE: 1.4739, Valid PR: 0.5317\n",
      "Epoch [163/500], Train Loss: 0.6788, Train RMSE: 0.8239\n",
      "Epoch [163/500], Validation Loss: 2.1707, Validation RMSE: 1.4733, Valid PR: 0.5307\n",
      "Epoch [164/500], Train Loss: 0.6785, Train RMSE: 0.8237\n",
      "Epoch [164/500], Validation Loss: 2.1691, Validation RMSE: 1.4728, Valid PR: 0.5298\n",
      "Epoch [165/500], Train Loss: 0.7176, Train RMSE: 0.8471\n",
      "Epoch [165/500], Validation Loss: 2.1673, Validation RMSE: 1.4722, Valid PR: 0.5280\n",
      "Epoch [166/500], Train Loss: 0.6906, Train RMSE: 0.8311\n",
      "Epoch [166/500], Validation Loss: 2.1654, Validation RMSE: 1.4715, Valid PR: 0.5267\n",
      "Epoch [167/500], Train Loss: 0.7276, Train RMSE: 0.8530\n",
      "Epoch [167/500], Validation Loss: 2.1638, Validation RMSE: 1.4710, Valid PR: 0.5257\n",
      "Epoch [168/500], Train Loss: 0.7500, Train RMSE: 0.8660\n",
      "Epoch [168/500], Validation Loss: 2.1622, Validation RMSE: 1.4704, Valid PR: 0.5247\n",
      "Epoch [169/500], Train Loss: 0.6703, Train RMSE: 0.8187\n",
      "Epoch [169/500], Validation Loss: 2.1606, Validation RMSE: 1.4699, Valid PR: 0.5240\n",
      "Epoch [170/500], Train Loss: 0.6895, Train RMSE: 0.8303\n",
      "Epoch [170/500], Validation Loss: 2.1594, Validation RMSE: 1.4695, Valid PR: 0.5235\n",
      "Epoch [171/500], Train Loss: 0.7312, Train RMSE: 0.8551\n",
      "Epoch [171/500], Validation Loss: 2.1584, Validation RMSE: 1.4691, Valid PR: 0.5231\n",
      "Epoch [172/500], Train Loss: 0.7566, Train RMSE: 0.8698\n",
      "Epoch [172/500], Validation Loss: 2.1565, Validation RMSE: 1.4685, Valid PR: 0.5227\n",
      "Epoch [173/500], Train Loss: 0.7225, Train RMSE: 0.8500\n",
      "Epoch [173/500], Validation Loss: 2.1538, Validation RMSE: 1.4676, Valid PR: 0.5223\n",
      "Epoch [174/500], Train Loss: 0.6512, Train RMSE: 0.8070\n",
      "Epoch [174/500], Validation Loss: 2.1517, Validation RMSE: 1.4669, Valid PR: 0.5227\n",
      "Epoch [175/500], Train Loss: 0.6741, Train RMSE: 0.8210\n",
      "Epoch [175/500], Validation Loss: 2.1497, Validation RMSE: 1.4662, Valid PR: 0.5230\n",
      "Epoch [176/500], Train Loss: 0.6746, Train RMSE: 0.8213\n",
      "Epoch [176/500], Validation Loss: 2.1486, Validation RMSE: 1.4658, Valid PR: 0.5232\n",
      "Epoch [177/500], Train Loss: 0.7204, Train RMSE: 0.8488\n",
      "Epoch [177/500], Validation Loss: 2.1459, Validation RMSE: 1.4649, Valid PR: 0.5232\n",
      "Epoch [178/500], Train Loss: 0.6994, Train RMSE: 0.8363\n",
      "Epoch [178/500], Validation Loss: 2.1430, Validation RMSE: 1.4639, Valid PR: 0.5233\n",
      "Epoch [179/500], Train Loss: 0.6499, Train RMSE: 0.8061\n",
      "Epoch [179/500], Validation Loss: 2.1399, Validation RMSE: 1.4628, Valid PR: 0.5232\n",
      "Epoch [180/500], Train Loss: 0.7164, Train RMSE: 0.8464\n",
      "Epoch [180/500], Validation Loss: 2.1383, Validation RMSE: 1.4623, Valid PR: 0.5233\n",
      "Epoch [181/500], Train Loss: 0.6753, Train RMSE: 0.8217\n",
      "Epoch [181/500], Validation Loss: 2.1370, Validation RMSE: 1.4619, Valid PR: 0.5235\n",
      "Epoch [182/500], Train Loss: 0.7036, Train RMSE: 0.8388\n",
      "Epoch [182/500], Validation Loss: 2.1356, Validation RMSE: 1.4614, Valid PR: 0.5236\n",
      "Epoch [183/500], Train Loss: 0.6625, Train RMSE: 0.8140\n",
      "Epoch [183/500], Validation Loss: 2.1340, Validation RMSE: 1.4608, Valid PR: 0.5236\n",
      "Epoch [184/500], Train Loss: 0.6398, Train RMSE: 0.7999\n",
      "Epoch [184/500], Validation Loss: 2.1320, Validation RMSE: 1.4601, Valid PR: 0.5237\n",
      "Epoch [185/500], Train Loss: 0.7637, Train RMSE: 0.8739\n",
      "Epoch [185/500], Validation Loss: 2.1293, Validation RMSE: 1.4592, Valid PR: 0.5237\n",
      "Epoch [186/500], Train Loss: 0.6344, Train RMSE: 0.7965\n",
      "Epoch [186/500], Validation Loss: 2.1259, Validation RMSE: 1.4580, Valid PR: 0.5238\n",
      "Epoch [187/500], Train Loss: 0.6450, Train RMSE: 0.8031\n",
      "Epoch [187/500], Validation Loss: 2.1224, Validation RMSE: 1.4568, Valid PR: 0.5240\n",
      "Epoch [188/500], Train Loss: 0.7360, Train RMSE: 0.8579\n",
      "Epoch [188/500], Validation Loss: 2.1179, Validation RMSE: 1.4553, Valid PR: 0.5241\n",
      "Epoch [189/500], Train Loss: 0.7273, Train RMSE: 0.8528\n",
      "Epoch [189/500], Validation Loss: 2.1149, Validation RMSE: 1.4543, Valid PR: 0.5245\n",
      "Epoch [190/500], Train Loss: 0.7037, Train RMSE: 0.8389\n",
      "Epoch [190/500], Validation Loss: 2.1103, Validation RMSE: 1.4527, Valid PR: 0.5251\n",
      "Epoch [191/500], Train Loss: 0.6616, Train RMSE: 0.8134\n",
      "Epoch [191/500], Validation Loss: 2.1070, Validation RMSE: 1.4515, Valid PR: 0.5257\n",
      "Epoch [192/500], Train Loss: 0.6739, Train RMSE: 0.8209\n",
      "Epoch [192/500], Validation Loss: 2.1017, Validation RMSE: 1.4497, Valid PR: 0.5260\n",
      "Epoch [193/500], Train Loss: 0.6924, Train RMSE: 0.8321\n",
      "Epoch [193/500], Validation Loss: 2.0978, Validation RMSE: 1.4484, Valid PR: 0.5268\n",
      "Epoch [194/500], Train Loss: 0.7560, Train RMSE: 0.8695\n",
      "Epoch [194/500], Validation Loss: 2.0944, Validation RMSE: 1.4472, Valid PR: 0.5276\n",
      "Epoch [195/500], Train Loss: 0.6606, Train RMSE: 0.8128\n",
      "Epoch [195/500], Validation Loss: 2.0916, Validation RMSE: 1.4462, Valid PR: 0.5283\n",
      "Epoch [196/500], Train Loss: 0.7523, Train RMSE: 0.8673\n",
      "Epoch [196/500], Validation Loss: 2.0888, Validation RMSE: 1.4453, Valid PR: 0.5290\n",
      "Epoch [197/500], Train Loss: 0.6452, Train RMSE: 0.8032\n",
      "Epoch [197/500], Validation Loss: 2.0829, Validation RMSE: 1.4432, Valid PR: 0.5293\n",
      "Epoch [198/500], Train Loss: 0.6821, Train RMSE: 0.8259\n",
      "Epoch [198/500], Validation Loss: 2.0791, Validation RMSE: 1.4419, Valid PR: 0.5298\n",
      "Epoch [199/500], Train Loss: 0.7231, Train RMSE: 0.8503\n",
      "Epoch [199/500], Validation Loss: 2.0745, Validation RMSE: 1.4403, Valid PR: 0.5305\n",
      "Epoch [200/500], Train Loss: 0.6432, Train RMSE: 0.8020\n",
      "Epoch [200/500], Validation Loss: 2.0721, Validation RMSE: 1.4395, Valid PR: 0.5314\n",
      "Epoch [201/500], Train Loss: 0.6437, Train RMSE: 0.8023\n",
      "Epoch [201/500], Validation Loss: 2.0679, Validation RMSE: 1.4380, Valid PR: 0.5320\n",
      "Epoch [202/500], Train Loss: 0.6605, Train RMSE: 0.8127\n",
      "Epoch [202/500], Validation Loss: 2.0643, Validation RMSE: 1.4368, Valid PR: 0.5318\n",
      "Epoch [203/500], Train Loss: 0.6649, Train RMSE: 0.8154\n",
      "Epoch [203/500], Validation Loss: 2.0597, Validation RMSE: 1.4352, Valid PR: 0.5316\n",
      "Epoch [204/500], Train Loss: 0.7371, Train RMSE: 0.8586\n",
      "Epoch [204/500], Validation Loss: 2.0503, Validation RMSE: 1.4319, Valid PR: 0.5314\n",
      "Epoch [205/500], Train Loss: 0.6504, Train RMSE: 0.8065\n",
      "Epoch [205/500], Validation Loss: 2.0373, Validation RMSE: 1.4274, Valid PR: 0.5312\n",
      "Epoch [206/500], Train Loss: 0.6636, Train RMSE: 0.8146\n",
      "Epoch [206/500], Validation Loss: 2.0247, Validation RMSE: 1.4229, Valid PR: 0.5314\n",
      "Epoch [207/500], Train Loss: 0.6983, Train RMSE: 0.8357\n",
      "Epoch [207/500], Validation Loss: 2.0118, Validation RMSE: 1.4184, Valid PR: 0.5308\n",
      "Epoch [208/500], Train Loss: 0.7077, Train RMSE: 0.8412\n",
      "Epoch [208/500], Validation Loss: 1.9981, Validation RMSE: 1.4135, Valid PR: 0.5299\n",
      "Epoch [209/500], Train Loss: 0.7113, Train RMSE: 0.8434\n",
      "Epoch [209/500], Validation Loss: 1.9835, Validation RMSE: 1.4084, Valid PR: 0.5287\n",
      "Epoch [210/500], Train Loss: 0.7385, Train RMSE: 0.8594\n",
      "Epoch [210/500], Validation Loss: 1.9638, Validation RMSE: 1.4013, Valid PR: 0.5289\n",
      "Epoch [211/500], Train Loss: 0.7255, Train RMSE: 0.8518\n",
      "Epoch [211/500], Validation Loss: 1.9421, Validation RMSE: 1.3936, Valid PR: 0.5296\n",
      "Epoch [212/500], Train Loss: 0.7209, Train RMSE: 0.8491\n",
      "Epoch [212/500], Validation Loss: 1.9230, Validation RMSE: 1.3867, Valid PR: 0.5285\n",
      "Epoch [213/500], Train Loss: 0.6962, Train RMSE: 0.8344\n",
      "Epoch [213/500], Validation Loss: 1.9067, Validation RMSE: 1.3808, Valid PR: 0.5280\n",
      "Epoch [214/500], Train Loss: 0.6541, Train RMSE: 0.8087\n",
      "Epoch [214/500], Validation Loss: 1.8961, Validation RMSE: 1.3770, Valid PR: 0.5281\n",
      "Epoch [215/500], Train Loss: 0.6780, Train RMSE: 0.8234\n",
      "Epoch [215/500], Validation Loss: 1.8892, Validation RMSE: 1.3745, Valid PR: 0.5286\n",
      "Epoch [216/500], Train Loss: 0.7350, Train RMSE: 0.8573\n",
      "Epoch [216/500], Validation Loss: 1.8852, Validation RMSE: 1.3730, Valid PR: 0.5291\n",
      "Epoch [217/500], Train Loss: 0.6937, Train RMSE: 0.8329\n",
      "Epoch [217/500], Validation Loss: 1.8854, Validation RMSE: 1.3731, Valid PR: 0.5291\n",
      "Epoch [218/500], Train Loss: 0.6713, Train RMSE: 0.8193\n",
      "Epoch [218/500], Validation Loss: 1.8940, Validation RMSE: 1.3762, Valid PR: 0.5282\n",
      "Epoch [219/500], Train Loss: 0.6469, Train RMSE: 0.8043\n",
      "Epoch [219/500], Validation Loss: 1.9102, Validation RMSE: 1.3821, Valid PR: 0.5268\n",
      "Epoch [220/500], Train Loss: 0.7458, Train RMSE: 0.8636\n",
      "Epoch [220/500], Validation Loss: 1.9270, Validation RMSE: 1.3882, Valid PR: 0.5252\n",
      "Epoch [221/500], Train Loss: 0.6644, Train RMSE: 0.8151\n",
      "Epoch [221/500], Validation Loss: 1.9404, Validation RMSE: 1.3930, Valid PR: 0.5226\n",
      "Epoch [222/500], Train Loss: 0.6330, Train RMSE: 0.7956\n",
      "Epoch [222/500], Validation Loss: 1.9595, Validation RMSE: 1.3998, Valid PR: 0.5195\n",
      "Epoch [223/500], Train Loss: 0.6877, Train RMSE: 0.8293\n",
      "Epoch [223/500], Validation Loss: 1.9799, Validation RMSE: 1.4071, Valid PR: 0.5164\n",
      "Epoch [224/500], Train Loss: 0.7540, Train RMSE: 0.8683\n",
      "Epoch [224/500], Validation Loss: 1.9939, Validation RMSE: 1.4120, Valid PR: 0.5141\n",
      "Epoch [225/500], Train Loss: 0.7001, Train RMSE: 0.8367\n",
      "Epoch [225/500], Validation Loss: 1.9964, Validation RMSE: 1.4129, Valid PR: 0.5124\n",
      "Epoch [226/500], Train Loss: 0.6592, Train RMSE: 0.8119\n",
      "Epoch [226/500], Validation Loss: 1.9962, Validation RMSE: 1.4129, Valid PR: 0.5113\n",
      "Epoch [227/500], Train Loss: 0.6303, Train RMSE: 0.7939\n",
      "Epoch [227/500], Validation Loss: 1.9932, Validation RMSE: 1.4118, Valid PR: 0.5102\n",
      "Epoch [228/500], Train Loss: 0.6872, Train RMSE: 0.8290\n",
      "Epoch [228/500], Validation Loss: 1.9756, Validation RMSE: 1.4056, Valid PR: 0.5103\n",
      "Epoch [229/500], Train Loss: 0.6684, Train RMSE: 0.8176\n",
      "Epoch [229/500], Validation Loss: 1.9431, Validation RMSE: 1.3939, Valid PR: 0.5130\n",
      "Epoch [230/500], Train Loss: 0.6551, Train RMSE: 0.8094\n",
      "Epoch [230/500], Validation Loss: 1.9087, Validation RMSE: 1.3816, Valid PR: 0.5147\n",
      "Epoch [231/500], Train Loss: 0.7231, Train RMSE: 0.8503\n",
      "Epoch [231/500], Validation Loss: 1.8836, Validation RMSE: 1.3724, Valid PR: 0.5152\n",
      "Epoch [232/500], Train Loss: 0.6737, Train RMSE: 0.8208\n",
      "Epoch [232/500], Validation Loss: 1.8713, Validation RMSE: 1.3680, Valid PR: 0.5150\n",
      "Epoch [233/500], Train Loss: 0.6552, Train RMSE: 0.8094\n",
      "Epoch [233/500], Validation Loss: 1.8704, Validation RMSE: 1.3676, Valid PR: 0.5142\n",
      "Epoch [234/500], Train Loss: 0.6599, Train RMSE: 0.8123\n",
      "Epoch [234/500], Validation Loss: 1.8654, Validation RMSE: 1.3658, Valid PR: 0.5131\n",
      "Epoch [235/500], Train Loss: 0.6581, Train RMSE: 0.8113\n",
      "Epoch [235/500], Validation Loss: 1.8722, Validation RMSE: 1.3683, Valid PR: 0.5113\n",
      "Epoch [236/500], Train Loss: 0.5657, Train RMSE: 0.7521\n",
      "Epoch [236/500], Validation Loss: 1.8805, Validation RMSE: 1.3713, Valid PR: 0.5095\n",
      "Epoch [237/500], Train Loss: 0.6424, Train RMSE: 0.8015\n",
      "Epoch [237/500], Validation Loss: 1.8884, Validation RMSE: 1.3742, Valid PR: 0.5074\n",
      "Epoch [238/500], Train Loss: 0.6954, Train RMSE: 0.8339\n",
      "Epoch [238/500], Validation Loss: 1.9085, Validation RMSE: 1.3815, Valid PR: 0.5046\n",
      "Epoch [239/500], Train Loss: 0.6930, Train RMSE: 0.8325\n",
      "Epoch [239/500], Validation Loss: 1.9340, Validation RMSE: 1.3907, Valid PR: 0.5008\n",
      "Epoch [240/500], Train Loss: 0.6260, Train RMSE: 0.7912\n",
      "Epoch [240/500], Validation Loss: 1.9383, Validation RMSE: 1.3922, Valid PR: 0.4988\n",
      "Epoch [241/500], Train Loss: 0.7142, Train RMSE: 0.8451\n",
      "Epoch [241/500], Validation Loss: 1.9316, Validation RMSE: 1.3898, Valid PR: 0.4980\n",
      "Epoch [242/500], Train Loss: 0.6838, Train RMSE: 0.8269\n",
      "Epoch [242/500], Validation Loss: 1.9218, Validation RMSE: 1.3863, Valid PR: 0.4972\n",
      "Epoch [243/500], Train Loss: 0.6524, Train RMSE: 0.8077\n",
      "Epoch [243/500], Validation Loss: 1.8903, Validation RMSE: 1.3749, Valid PR: 0.4986\n",
      "Epoch [244/500], Train Loss: 0.6141, Train RMSE: 0.7837\n",
      "Epoch [244/500], Validation Loss: 1.8663, Validation RMSE: 1.3661, Valid PR: 0.4997\n",
      "Epoch [245/500], Train Loss: 0.7041, Train RMSE: 0.8391\n",
      "Epoch [245/500], Validation Loss: 1.8614, Validation RMSE: 1.3643, Valid PR: 0.4989\n",
      "Epoch [246/500], Train Loss: 0.6949, Train RMSE: 0.8336\n",
      "Epoch [246/500], Validation Loss: 1.8588, Validation RMSE: 1.3634, Valid PR: 0.4978\n",
      "Epoch [247/500], Train Loss: 0.6619, Train RMSE: 0.8136\n",
      "Epoch [247/500], Validation Loss: 1.8620, Validation RMSE: 1.3645, Valid PR: 0.4956\n",
      "Epoch [248/500], Train Loss: 0.5919, Train RMSE: 0.7694\n",
      "Epoch [248/500], Validation Loss: 1.8737, Validation RMSE: 1.3688, Valid PR: 0.4923\n",
      "Epoch [249/500], Train Loss: 0.6307, Train RMSE: 0.7942\n",
      "Epoch [249/500], Validation Loss: 1.8753, Validation RMSE: 1.3694, Valid PR: 0.4903\n",
      "Epoch [250/500], Train Loss: 0.6824, Train RMSE: 0.8261\n",
      "Epoch [250/500], Validation Loss: 1.8740, Validation RMSE: 1.3689, Valid PR: 0.4887\n",
      "Epoch [251/500], Train Loss: 0.5814, Train RMSE: 0.7625\n",
      "Epoch [251/500], Validation Loss: 1.8705, Validation RMSE: 1.3676, Valid PR: 0.4874\n",
      "Epoch [252/500], Train Loss: 0.6582, Train RMSE: 0.8113\n",
      "Epoch [252/500], Validation Loss: 1.8643, Validation RMSE: 1.3654, Valid PR: 0.4868\n",
      "Epoch [253/500], Train Loss: 0.6850, Train RMSE: 0.8277\n",
      "Epoch [253/500], Validation Loss: 1.8563, Validation RMSE: 1.3625, Valid PR: 0.4865\n",
      "Epoch [254/500], Train Loss: 0.6414, Train RMSE: 0.8009\n",
      "Epoch [254/500], Validation Loss: 1.8554, Validation RMSE: 1.3621, Valid PR: 0.4847\n",
      "Epoch [255/500], Train Loss: 0.6762, Train RMSE: 0.8223\n",
      "Epoch [255/500], Validation Loss: 1.8706, Validation RMSE: 1.3677, Valid PR: 0.4799\n",
      "Epoch [256/500], Train Loss: 0.6685, Train RMSE: 0.8176\n",
      "Epoch [256/500], Validation Loss: 1.8872, Validation RMSE: 1.3737, Valid PR: 0.4748\n",
      "Epoch [257/500], Train Loss: 0.6330, Train RMSE: 0.7956\n",
      "Epoch [257/500], Validation Loss: 1.8924, Validation RMSE: 1.3756, Valid PR: 0.4721\n",
      "Epoch [258/500], Train Loss: 0.5980, Train RMSE: 0.7733\n",
      "Epoch [258/500], Validation Loss: 1.8880, Validation RMSE: 1.3740, Valid PR: 0.4711\n",
      "Epoch [259/500], Train Loss: 0.6345, Train RMSE: 0.7966\n",
      "Epoch [259/500], Validation Loss: 1.8903, Validation RMSE: 1.3749, Valid PR: 0.4689\n",
      "Epoch [260/500], Train Loss: 0.6165, Train RMSE: 0.7852\n",
      "Epoch [260/500], Validation Loss: 1.8969, Validation RMSE: 1.3773, Valid PR: 0.4664\n",
      "Epoch [261/500], Train Loss: 0.5681, Train RMSE: 0.7537\n",
      "Epoch [261/500], Validation Loss: 1.9136, Validation RMSE: 1.3833, Valid PR: 0.4619\n",
      "Epoch [262/500], Train Loss: 0.5865, Train RMSE: 0.7658\n",
      "Epoch [262/500], Validation Loss: 1.9129, Validation RMSE: 1.3831, Valid PR: 0.4605\n",
      "Epoch [263/500], Train Loss: 0.6353, Train RMSE: 0.7971\n",
      "Epoch [263/500], Validation Loss: 1.9097, Validation RMSE: 1.3819, Valid PR: 0.4599\n",
      "Epoch [264/500], Train Loss: 0.6442, Train RMSE: 0.8026\n",
      "Epoch [264/500], Validation Loss: 1.8922, Validation RMSE: 1.3756, Valid PR: 0.4619\n",
      "Epoch [265/500], Train Loss: 0.6405, Train RMSE: 0.8003\n",
      "Epoch [265/500], Validation Loss: 1.8825, Validation RMSE: 1.3720, Valid PR: 0.4624\n",
      "Epoch [266/500], Train Loss: 0.6788, Train RMSE: 0.8239\n",
      "Epoch [266/500], Validation Loss: 1.8774, Validation RMSE: 1.3702, Valid PR: 0.4621\n",
      "Epoch [267/500], Train Loss: 0.5726, Train RMSE: 0.7567\n",
      "Epoch [267/500], Validation Loss: 1.8827, Validation RMSE: 1.3721, Valid PR: 0.4600\n",
      "Epoch [268/500], Train Loss: 0.5657, Train RMSE: 0.7521\n",
      "Epoch [268/500], Validation Loss: 1.8778, Validation RMSE: 1.3703, Valid PR: 0.4595\n",
      "Epoch [269/500], Train Loss: 0.6104, Train RMSE: 0.7813\n",
      "Epoch [269/500], Validation Loss: 1.8734, Validation RMSE: 1.3687, Valid PR: 0.4587\n",
      "Epoch [270/500], Train Loss: 0.6012, Train RMSE: 0.7754\n",
      "Epoch [270/500], Validation Loss: 1.8689, Validation RMSE: 1.3671, Valid PR: 0.4578\n",
      "Epoch [271/500], Train Loss: 0.6990, Train RMSE: 0.8360\n",
      "Epoch [271/500], Validation Loss: 1.8762, Validation RMSE: 1.3697, Valid PR: 0.4546\n",
      "Epoch [272/500], Train Loss: 0.6115, Train RMSE: 0.7820\n",
      "Epoch [272/500], Validation Loss: 1.8851, Validation RMSE: 1.3730, Valid PR: 0.4510\n",
      "Epoch [273/500], Train Loss: 0.6435, Train RMSE: 0.8022\n",
      "Epoch [273/500], Validation Loss: 1.9085, Validation RMSE: 1.3815, Valid PR: 0.4449\n",
      "Epoch [274/500], Train Loss: 0.6601, Train RMSE: 0.8125\n",
      "Epoch [274/500], Validation Loss: 1.9222, Validation RMSE: 1.3864, Valid PR: 0.4400\n",
      "Epoch [275/500], Train Loss: 0.5666, Train RMSE: 0.7527\n",
      "Epoch [275/500], Validation Loss: 1.9359, Validation RMSE: 1.3914, Valid PR: 0.4350\n",
      "Epoch [276/500], Train Loss: 0.6494, Train RMSE: 0.8058\n",
      "Epoch [276/500], Validation Loss: 1.9377, Validation RMSE: 1.3920, Valid PR: 0.4322\n",
      "Epoch [277/500], Train Loss: 0.6275, Train RMSE: 0.7921\n",
      "Epoch [277/500], Validation Loss: 1.9615, Validation RMSE: 1.4005, Valid PR: 0.4248\n",
      "Epoch [278/500], Train Loss: 0.5579, Train RMSE: 0.7469\n",
      "Epoch [278/500], Validation Loss: 1.9724, Validation RMSE: 1.4044, Valid PR: 0.4199\n",
      "Epoch [279/500], Train Loss: 0.6073, Train RMSE: 0.7793\n",
      "Epoch [279/500], Validation Loss: 1.9414, Validation RMSE: 1.3933, Valid PR: 0.4237\n",
      "Epoch [280/500], Train Loss: 0.5453, Train RMSE: 0.7384\n",
      "Epoch [280/500], Validation Loss: 1.9186, Validation RMSE: 1.3851, Valid PR: 0.4256\n",
      "Epoch [281/500], Train Loss: 0.6829, Train RMSE: 0.8264\n",
      "Epoch [281/500], Validation Loss: 1.9108, Validation RMSE: 1.3823, Valid PR: 0.4242\n",
      "Epoch [282/500], Train Loss: 0.6418, Train RMSE: 0.8011\n",
      "Epoch [282/500], Validation Loss: 1.9037, Validation RMSE: 1.3797, Valid PR: 0.4230\n",
      "Epoch [283/500], Train Loss: 0.6532, Train RMSE: 0.8082\n",
      "Epoch [283/500], Validation Loss: 1.8924, Validation RMSE: 1.3756, Valid PR: 0.4232\n",
      "Epoch [284/500], Train Loss: 0.6176, Train RMSE: 0.7859\n",
      "Epoch [284/500], Validation Loss: 1.8850, Validation RMSE: 1.3729, Valid PR: 0.4230\n",
      "Epoch [285/500], Train Loss: 0.6504, Train RMSE: 0.8065\n",
      "Epoch [285/500], Validation Loss: 1.8956, Validation RMSE: 1.3768, Valid PR: 0.4181\n",
      "Epoch [286/500], Train Loss: 0.5660, Train RMSE: 0.7524\n",
      "Epoch [286/500], Validation Loss: 1.9146, Validation RMSE: 1.3837, Valid PR: 0.4113\n",
      "Epoch [287/500], Train Loss: 0.6105, Train RMSE: 0.7813\n",
      "Epoch [287/500], Validation Loss: 1.9457, Validation RMSE: 1.3949, Valid PR: 0.4022\n",
      "Epoch [288/500], Train Loss: 0.7078, Train RMSE: 0.8413\n",
      "Epoch [288/500], Validation Loss: 1.9375, Validation RMSE: 1.3919, Valid PR: 0.4010\n",
      "Epoch [289/500], Train Loss: 0.5619, Train RMSE: 0.7496\n",
      "Epoch [289/500], Validation Loss: 1.9346, Validation RMSE: 1.3909, Valid PR: 0.3996\n",
      "Epoch [290/500], Train Loss: 0.5552, Train RMSE: 0.7452\n",
      "Epoch [290/500], Validation Loss: 1.9635, Validation RMSE: 1.4013, Valid PR: 0.3915\n",
      "Epoch [291/500], Train Loss: 0.5532, Train RMSE: 0.7438\n",
      "Epoch [291/500], Validation Loss: 2.0206, Validation RMSE: 1.4215, Valid PR: 0.3767\n",
      "Epoch [292/500], Train Loss: 0.6106, Train RMSE: 0.7814\n",
      "Epoch [292/500], Validation Loss: 2.0150, Validation RMSE: 1.4195, Valid PR: 0.3777\n",
      "Epoch [293/500], Train Loss: 0.5442, Train RMSE: 0.7377\n",
      "Epoch [293/500], Validation Loss: 1.9581, Validation RMSE: 1.3993, Valid PR: 0.3894\n",
      "Epoch [294/500], Train Loss: 0.5924, Train RMSE: 0.7697\n",
      "Epoch [294/500], Validation Loss: 1.9144, Validation RMSE: 1.3836, Valid PR: 0.3990\n",
      "Epoch [295/500], Train Loss: 0.4905, Train RMSE: 0.7003\n",
      "Epoch [295/500], Validation Loss: 1.9126, Validation RMSE: 1.3830, Valid PR: 0.3993\n",
      "Epoch [296/500], Train Loss: 0.6587, Train RMSE: 0.8116\n",
      "Epoch [296/500], Validation Loss: 1.9446, Validation RMSE: 1.3945, Valid PR: 0.3927\n",
      "Epoch [297/500], Train Loss: 0.4945, Train RMSE: 0.7032\n",
      "Epoch [297/500], Validation Loss: 1.9881, Validation RMSE: 1.4100, Valid PR: 0.3823\n",
      "Epoch [298/500], Train Loss: 0.6011, Train RMSE: 0.7753\n",
      "Epoch [298/500], Validation Loss: 1.9714, Validation RMSE: 1.4041, Valid PR: 0.3848\n",
      "Epoch [299/500], Train Loss: 0.6300, Train RMSE: 0.7937\n",
      "Epoch [299/500], Validation Loss: 1.9596, Validation RMSE: 1.3999, Valid PR: 0.3861\n",
      "Epoch [300/500], Train Loss: 0.5862, Train RMSE: 0.7656\n",
      "Epoch [300/500], Validation Loss: 1.9707, Validation RMSE: 1.4038, Valid PR: 0.3832\n",
      "Epoch [301/500], Train Loss: 0.6000, Train RMSE: 0.7746\n",
      "Epoch [301/500], Validation Loss: 1.9765, Validation RMSE: 1.4059, Valid PR: 0.3813\n",
      "Epoch [302/500], Train Loss: 0.5824, Train RMSE: 0.7631\n",
      "Epoch [302/500], Validation Loss: 1.9590, Validation RMSE: 1.3996, Valid PR: 0.3834\n",
      "Epoch [303/500], Train Loss: 0.5856, Train RMSE: 0.7652\n",
      "Epoch [303/500], Validation Loss: 1.9511, Validation RMSE: 1.3968, Valid PR: 0.3834\n",
      "Epoch [304/500], Train Loss: 0.6100, Train RMSE: 0.7810\n",
      "Epoch [304/500], Validation Loss: 1.8990, Validation RMSE: 1.3780, Valid PR: 0.3931\n",
      "Early stopping triggered.\n",
      "Test Loss: 3.0943, Test RMSE: 1.7591, Test PR: -0.1506\n",
      "Replication 2 for method2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:122: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 10.5718, Train RMSE: 3.2514\n",
      "Epoch [1/500], Validation Loss: 17.8629, Validation RMSE: 4.2265, Valid PR: 0.8980\n",
      "Epoch [2/500], Train Loss: 5.0817, Train RMSE: 2.2543\n",
      "Epoch [2/500], Validation Loss: 11.8746, Validation RMSE: 3.4460, Valid PR: 0.3433\n",
      "Epoch [3/500], Train Loss: 3.5044, Train RMSE: 1.8720\n",
      "Epoch [3/500], Validation Loss: 9.5249, Validation RMSE: 3.0862, Valid PR: -0.2880\n",
      "Epoch [4/500], Train Loss: 2.8648, Train RMSE: 1.6926\n",
      "Epoch [4/500], Validation Loss: 8.4119, Validation RMSE: 2.9003, Valid PR: -0.4929\n",
      "Epoch [5/500], Train Loss: 2.5523, Train RMSE: 1.5976\n",
      "Epoch [5/500], Validation Loss: 7.7863, Validation RMSE: 2.7904, Valid PR: -0.5541\n",
      "Epoch [6/500], Train Loss: 2.3717, Train RMSE: 1.5400\n",
      "Epoch [6/500], Validation Loss: 7.3659, Validation RMSE: 2.7140, Valid PR: -0.5789\n",
      "Epoch [7/500], Train Loss: 2.1921, Train RMSE: 1.4806\n",
      "Epoch [7/500], Validation Loss: 7.0602, Validation RMSE: 2.6571, Valid PR: -0.5947\n",
      "Epoch [8/500], Train Loss: 2.2100, Train RMSE: 1.4866\n",
      "Epoch [8/500], Validation Loss: 6.8343, Validation RMSE: 2.6143, Valid PR: -0.5286\n",
      "Epoch [9/500], Train Loss: 2.1380, Train RMSE: 1.4622\n",
      "Epoch [9/500], Validation Loss: 6.6643, Validation RMSE: 2.5815, Valid PR: -0.1030\n",
      "Epoch [10/500], Train Loss: 2.0363, Train RMSE: 1.4270\n",
      "Epoch [10/500], Validation Loss: 6.5340, Validation RMSE: 2.5562, Valid PR: 0.2157\n",
      "Epoch [11/500], Train Loss: 2.1253, Train RMSE: 1.4578\n",
      "Epoch [11/500], Validation Loss: 6.4183, Validation RMSE: 2.5334, Valid PR: 0.3533\n",
      "Epoch [12/500], Train Loss: 2.1101, Train RMSE: 1.4526\n",
      "Epoch [12/500], Validation Loss: 6.3059, Validation RMSE: 2.5112, Valid PR: 0.4144\n",
      "Epoch [13/500], Train Loss: 1.9855, Train RMSE: 1.4091\n",
      "Epoch [13/500], Validation Loss: 6.1887, Validation RMSE: 2.4877, Valid PR: 0.4422\n",
      "Epoch [14/500], Train Loss: 2.0403, Train RMSE: 1.4284\n",
      "Epoch [14/500], Validation Loss: 6.0723, Validation RMSE: 2.4642, Valid PR: 0.4461\n",
      "Epoch [15/500], Train Loss: 2.0120, Train RMSE: 1.4184\n",
      "Epoch [15/500], Validation Loss: 5.9618, Validation RMSE: 2.4417, Valid PR: 0.4430\n",
      "Epoch [16/500], Train Loss: 1.9253, Train RMSE: 1.3875\n",
      "Epoch [16/500], Validation Loss: 5.8604, Validation RMSE: 2.4208, Valid PR: 0.4299\n",
      "Epoch [17/500], Train Loss: 1.9354, Train RMSE: 1.3912\n",
      "Epoch [17/500], Validation Loss: 5.7679, Validation RMSE: 2.4017, Valid PR: 0.3688\n",
      "Epoch [18/500], Train Loss: 2.0021, Train RMSE: 1.4149\n",
      "Epoch [18/500], Validation Loss: 5.6841, Validation RMSE: 2.3841, Valid PR: 0.2649\n",
      "Epoch [19/500], Train Loss: 1.8271, Train RMSE: 1.3517\n",
      "Epoch [19/500], Validation Loss: 5.6061, Validation RMSE: 2.3677, Valid PR: 0.0803\n",
      "Epoch [20/500], Train Loss: 1.8407, Train RMSE: 1.3567\n",
      "Epoch [20/500], Validation Loss: 5.5334, Validation RMSE: 2.3523, Valid PR: -0.0412\n",
      "Epoch [21/500], Train Loss: 1.8778, Train RMSE: 1.3703\n",
      "Epoch [21/500], Validation Loss: 5.4640, Validation RMSE: 2.3375, Valid PR: -0.1817\n",
      "Epoch [22/500], Train Loss: 1.6973, Train RMSE: 1.3028\n",
      "Epoch [22/500], Validation Loss: 5.3964, Validation RMSE: 2.3230, Valid PR: -0.2955\n",
      "Epoch [23/500], Train Loss: 1.7835, Train RMSE: 1.3355\n",
      "Epoch [23/500], Validation Loss: 5.3289, Validation RMSE: 2.3084, Valid PR: -0.2750\n",
      "Epoch [24/500], Train Loss: 1.7110, Train RMSE: 1.3081\n",
      "Epoch [24/500], Validation Loss: 5.2613, Validation RMSE: 2.2938, Valid PR: -0.2343\n",
      "Epoch [25/500], Train Loss: 1.7167, Train RMSE: 1.3102\n",
      "Epoch [25/500], Validation Loss: 5.1944, Validation RMSE: 2.2791, Valid PR: -0.1658\n",
      "Epoch [26/500], Train Loss: 1.7676, Train RMSE: 1.3295\n",
      "Epoch [26/500], Validation Loss: 5.1287, Validation RMSE: 2.2647, Valid PR: -0.1663\n",
      "Epoch [27/500], Train Loss: 1.6350, Train RMSE: 1.2787\n",
      "Epoch [27/500], Validation Loss: 5.0636, Validation RMSE: 2.2502, Valid PR: -0.1721\n",
      "Epoch [28/500], Train Loss: 1.6059, Train RMSE: 1.2672\n",
      "Epoch [28/500], Validation Loss: 5.0007, Validation RMSE: 2.2362, Valid PR: -0.2349\n",
      "Epoch [29/500], Train Loss: 1.6134, Train RMSE: 1.2702\n",
      "Epoch [29/500], Validation Loss: 4.9389, Validation RMSE: 2.2224, Valid PR: -0.2411\n",
      "Epoch [30/500], Train Loss: 1.7205, Train RMSE: 1.3117\n",
      "Epoch [30/500], Validation Loss: 4.8784, Validation RMSE: 2.2087, Valid PR: -0.1776\n",
      "Epoch [31/500], Train Loss: 1.6743, Train RMSE: 1.2939\n",
      "Epoch [31/500], Validation Loss: 4.8195, Validation RMSE: 2.1953, Valid PR: -0.1052\n",
      "Epoch [32/500], Train Loss: 1.5646, Train RMSE: 1.2508\n",
      "Epoch [32/500], Validation Loss: 4.7614, Validation RMSE: 2.1821, Valid PR: -0.0642\n",
      "Epoch [33/500], Train Loss: 1.6384, Train RMSE: 1.2800\n",
      "Epoch [33/500], Validation Loss: 4.7046, Validation RMSE: 2.1690, Valid PR: -0.0246\n",
      "Epoch [34/500], Train Loss: 1.5845, Train RMSE: 1.2588\n",
      "Epoch [34/500], Validation Loss: 4.6488, Validation RMSE: 2.1561, Valid PR: 0.0330\n",
      "Epoch [35/500], Train Loss: 1.4199, Train RMSE: 1.1916\n",
      "Epoch [35/500], Validation Loss: 4.5938, Validation RMSE: 2.1433, Valid PR: 0.0391\n",
      "Epoch [36/500], Train Loss: 1.5481, Train RMSE: 1.2442\n",
      "Epoch [36/500], Validation Loss: 4.5398, Validation RMSE: 2.1307, Valid PR: 0.0118\n",
      "Epoch [37/500], Train Loss: 1.5475, Train RMSE: 1.2440\n",
      "Epoch [37/500], Validation Loss: 4.4862, Validation RMSE: 2.1181, Valid PR: -0.0437\n",
      "Epoch [38/500], Train Loss: 1.5109, Train RMSE: 1.2292\n",
      "Epoch [38/500], Validation Loss: 4.4338, Validation RMSE: 2.1057, Valid PR: -0.1930\n",
      "Epoch [39/500], Train Loss: 1.5080, Train RMSE: 1.2280\n",
      "Epoch [39/500], Validation Loss: 4.3821, Validation RMSE: 2.0933, Valid PR: -0.2941\n",
      "Epoch [40/500], Train Loss: 1.4097, Train RMSE: 1.1873\n",
      "Epoch [40/500], Validation Loss: 4.3312, Validation RMSE: 2.0811, Valid PR: -0.3523\n",
      "Epoch [41/500], Train Loss: 1.4137, Train RMSE: 1.1890\n",
      "Epoch [41/500], Validation Loss: 4.2810, Validation RMSE: 2.0691, Valid PR: -0.3964\n",
      "Epoch [42/500], Train Loss: 1.3721, Train RMSE: 1.1714\n",
      "Epoch [42/500], Validation Loss: 4.2316, Validation RMSE: 2.0571, Valid PR: -0.4022\n",
      "Epoch [43/500], Train Loss: 1.4050, Train RMSE: 1.1853\n",
      "Epoch [43/500], Validation Loss: 4.1833, Validation RMSE: 2.0453, Valid PR: -0.4055\n",
      "Epoch [44/500], Train Loss: 1.4043, Train RMSE: 1.1850\n",
      "Epoch [44/500], Validation Loss: 4.1356, Validation RMSE: 2.0336, Valid PR: -0.3893\n",
      "Epoch [45/500], Train Loss: 1.3292, Train RMSE: 1.1529\n",
      "Epoch [45/500], Validation Loss: 4.0890, Validation RMSE: 2.0221, Valid PR: -0.3816\n",
      "Epoch [46/500], Train Loss: 1.4282, Train RMSE: 1.1951\n",
      "Epoch [46/500], Validation Loss: 4.0429, Validation RMSE: 2.0107, Valid PR: -0.3656\n",
      "Epoch [47/500], Train Loss: 1.3775, Train RMSE: 1.1737\n",
      "Epoch [47/500], Validation Loss: 3.9978, Validation RMSE: 1.9994, Valid PR: -0.2898\n",
      "Epoch [48/500], Train Loss: 1.2822, Train RMSE: 1.1324\n",
      "Epoch [48/500], Validation Loss: 3.9535, Validation RMSE: 1.9883, Valid PR: -0.2059\n",
      "Epoch [49/500], Train Loss: 1.2968, Train RMSE: 1.1388\n",
      "Epoch [49/500], Validation Loss: 3.9101, Validation RMSE: 1.9774, Valid PR: -0.1700\n",
      "Epoch [50/500], Train Loss: 1.2423, Train RMSE: 1.1146\n",
      "Epoch [50/500], Validation Loss: 3.8674, Validation RMSE: 1.9666, Valid PR: -0.1674\n",
      "Epoch [51/500], Train Loss: 1.2739, Train RMSE: 1.1287\n",
      "Epoch [51/500], Validation Loss: 3.8255, Validation RMSE: 1.9559, Valid PR: 0.0257\n",
      "Epoch [52/500], Train Loss: 1.3527, Train RMSE: 1.1630\n",
      "Epoch [52/500], Validation Loss: 3.7844, Validation RMSE: 1.9454, Valid PR: 0.1945\n",
      "Epoch [53/500], Train Loss: 1.3183, Train RMSE: 1.1482\n",
      "Epoch [53/500], Validation Loss: 3.7443, Validation RMSE: 1.9350, Valid PR: 0.2880\n",
      "Epoch [54/500], Train Loss: 1.3906, Train RMSE: 1.1792\n",
      "Epoch [54/500], Validation Loss: 3.7050, Validation RMSE: 1.9248, Valid PR: 0.3415\n",
      "Epoch [55/500], Train Loss: 1.3098, Train RMSE: 1.1445\n",
      "Epoch [55/500], Validation Loss: 3.6664, Validation RMSE: 1.9148, Valid PR: 0.3708\n",
      "Epoch [56/500], Train Loss: 1.2642, Train RMSE: 1.1244\n",
      "Epoch [56/500], Validation Loss: 3.6286, Validation RMSE: 1.9049, Valid PR: 0.3820\n",
      "Epoch [57/500], Train Loss: 1.2932, Train RMSE: 1.1372\n",
      "Epoch [57/500], Validation Loss: 3.5912, Validation RMSE: 1.8951, Valid PR: 0.3799\n",
      "Epoch [58/500], Train Loss: 1.2549, Train RMSE: 1.1202\n",
      "Epoch [58/500], Validation Loss: 3.5545, Validation RMSE: 1.8853, Valid PR: 0.3770\n",
      "Epoch [59/500], Train Loss: 1.1113, Train RMSE: 1.0542\n",
      "Epoch [59/500], Validation Loss: 3.5182, Validation RMSE: 1.8757, Valid PR: 0.3741\n",
      "Epoch [60/500], Train Loss: 1.1966, Train RMSE: 1.0939\n",
      "Epoch [60/500], Validation Loss: 3.4821, Validation RMSE: 1.8660, Valid PR: 0.3657\n",
      "Epoch [61/500], Train Loss: 1.2135, Train RMSE: 1.1016\n",
      "Epoch [61/500], Validation Loss: 3.4464, Validation RMSE: 1.8565, Valid PR: 0.3505\n",
      "Epoch [62/500], Train Loss: 1.1235, Train RMSE: 1.0599\n",
      "Epoch [62/500], Validation Loss: 3.4117, Validation RMSE: 1.8471, Valid PR: 0.3408\n",
      "Epoch [63/500], Train Loss: 1.0704, Train RMSE: 1.0346\n",
      "Epoch [63/500], Validation Loss: 3.3775, Validation RMSE: 1.8378, Valid PR: 0.3377\n",
      "Epoch [64/500], Train Loss: 1.1742, Train RMSE: 1.0836\n",
      "Epoch [64/500], Validation Loss: 3.3441, Validation RMSE: 1.8287, Valid PR: 0.3541\n",
      "Epoch [65/500], Train Loss: 1.1847, Train RMSE: 1.0884\n",
      "Epoch [65/500], Validation Loss: 3.3115, Validation RMSE: 1.8198, Valid PR: 0.3707\n",
      "Epoch [66/500], Train Loss: 1.1862, Train RMSE: 1.0891\n",
      "Epoch [66/500], Validation Loss: 3.2798, Validation RMSE: 1.8110, Valid PR: 0.3802\n",
      "Epoch [67/500], Train Loss: 1.0838, Train RMSE: 1.0411\n",
      "Epoch [67/500], Validation Loss: 3.2485, Validation RMSE: 1.8024, Valid PR: 0.3816\n",
      "Epoch [68/500], Train Loss: 1.0667, Train RMSE: 1.0328\n",
      "Epoch [68/500], Validation Loss: 3.2179, Validation RMSE: 1.7938, Valid PR: 0.3720\n",
      "Epoch [69/500], Train Loss: 1.0832, Train RMSE: 1.0408\n",
      "Epoch [69/500], Validation Loss: 3.1878, Validation RMSE: 1.7855, Valid PR: 0.3673\n",
      "Epoch [70/500], Train Loss: 1.2357, Train RMSE: 1.1116\n",
      "Epoch [70/500], Validation Loss: 3.1584, Validation RMSE: 1.7772, Valid PR: 0.3612\n",
      "Epoch [71/500], Train Loss: 1.0658, Train RMSE: 1.0324\n",
      "Epoch [71/500], Validation Loss: 3.1297, Validation RMSE: 1.7691, Valid PR: 0.3281\n",
      "Epoch [72/500], Train Loss: 1.1448, Train RMSE: 1.0700\n",
      "Epoch [72/500], Validation Loss: 3.1016, Validation RMSE: 1.7611, Valid PR: 0.2532\n",
      "Epoch [73/500], Train Loss: 1.0189, Train RMSE: 1.0094\n",
      "Epoch [73/500], Validation Loss: 3.0744, Validation RMSE: 1.7534, Valid PR: 0.1489\n",
      "Epoch [74/500], Train Loss: 1.1122, Train RMSE: 1.0546\n",
      "Epoch [74/500], Validation Loss: 3.0476, Validation RMSE: 1.7457, Valid PR: 0.0915\n",
      "Epoch [75/500], Train Loss: 1.1333, Train RMSE: 1.0646\n",
      "Epoch [75/500], Validation Loss: 3.0212, Validation RMSE: 1.7381, Valid PR: 0.0339\n",
      "Epoch [76/500], Train Loss: 1.1377, Train RMSE: 1.0666\n",
      "Epoch [76/500], Validation Loss: 2.9955, Validation RMSE: 1.7308, Valid PR: 0.0105\n",
      "Epoch [77/500], Train Loss: 1.0606, Train RMSE: 1.0299\n",
      "Epoch [77/500], Validation Loss: 2.9702, Validation RMSE: 1.7234, Valid PR: -0.0632\n",
      "Epoch [78/500], Train Loss: 1.1321, Train RMSE: 1.0640\n",
      "Epoch [78/500], Validation Loss: 2.9451, Validation RMSE: 1.7161, Valid PR: -0.1558\n",
      "Epoch [79/500], Train Loss: 1.0525, Train RMSE: 1.0259\n",
      "Epoch [79/500], Validation Loss: 2.9204, Validation RMSE: 1.7089, Valid PR: -0.2689\n",
      "Epoch [80/500], Train Loss: 0.9816, Train RMSE: 0.9907\n",
      "Epoch [80/500], Validation Loss: 2.8962, Validation RMSE: 1.7018, Valid PR: -0.2857\n",
      "Epoch [81/500], Train Loss: 1.0028, Train RMSE: 1.0014\n",
      "Epoch [81/500], Validation Loss: 2.8727, Validation RMSE: 1.6949, Valid PR: -0.3037\n",
      "Epoch [82/500], Train Loss: 1.0633, Train RMSE: 1.0312\n",
      "Epoch [82/500], Validation Loss: 2.8496, Validation RMSE: 1.6881, Valid PR: -0.3312\n",
      "Epoch [83/500], Train Loss: 1.0020, Train RMSE: 1.0010\n",
      "Epoch [83/500], Validation Loss: 2.8270, Validation RMSE: 1.6814, Valid PR: -0.3380\n",
      "Epoch [84/500], Train Loss: 1.0335, Train RMSE: 1.0166\n",
      "Epoch [84/500], Validation Loss: 2.8051, Validation RMSE: 1.6749, Valid PR: -0.3094\n",
      "Epoch [85/500], Train Loss: 0.9690, Train RMSE: 0.9844\n",
      "Epoch [85/500], Validation Loss: 2.7834, Validation RMSE: 1.6684, Valid PR: -0.2947\n",
      "Epoch [86/500], Train Loss: 1.0209, Train RMSE: 1.0104\n",
      "Epoch [86/500], Validation Loss: 2.7621, Validation RMSE: 1.6620, Valid PR: -0.2674\n",
      "Epoch [87/500], Train Loss: 1.0144, Train RMSE: 1.0072\n",
      "Epoch [87/500], Validation Loss: 2.7416, Validation RMSE: 1.6558, Valid PR: -0.2431\n",
      "Epoch [88/500], Train Loss: 0.9363, Train RMSE: 0.9676\n",
      "Epoch [88/500], Validation Loss: 2.7216, Validation RMSE: 1.6497, Valid PR: -0.1167\n",
      "Epoch [89/500], Train Loss: 1.0039, Train RMSE: 1.0020\n",
      "Epoch [89/500], Validation Loss: 2.7021, Validation RMSE: 1.6438, Valid PR: 0.0234\n",
      "Epoch [90/500], Train Loss: 0.9688, Train RMSE: 0.9843\n",
      "Epoch [90/500], Validation Loss: 2.6832, Validation RMSE: 1.6381, Valid PR: 0.1750\n",
      "Epoch [91/500], Train Loss: 0.9948, Train RMSE: 0.9974\n",
      "Epoch [91/500], Validation Loss: 2.6649, Validation RMSE: 1.6325, Valid PR: 0.2486\n",
      "Epoch [92/500], Train Loss: 0.9832, Train RMSE: 0.9915\n",
      "Epoch [92/500], Validation Loss: 2.6471, Validation RMSE: 1.6270, Valid PR: 0.2949\n",
      "Epoch [93/500], Train Loss: 0.9579, Train RMSE: 0.9787\n",
      "Epoch [93/500], Validation Loss: 2.6299, Validation RMSE: 1.6217, Valid PR: 0.3367\n",
      "Epoch [94/500], Train Loss: 1.0150, Train RMSE: 1.0075\n",
      "Epoch [94/500], Validation Loss: 2.6135, Validation RMSE: 1.6166, Valid PR: 0.3340\n",
      "Epoch [95/500], Train Loss: 0.8862, Train RMSE: 0.9414\n",
      "Epoch [95/500], Validation Loss: 2.5975, Validation RMSE: 1.6117, Valid PR: 0.3122\n",
      "Epoch [96/500], Train Loss: 1.0049, Train RMSE: 1.0024\n",
      "Epoch [96/500], Validation Loss: 2.5822, Validation RMSE: 1.6069, Valid PR: 0.2964\n",
      "Epoch [97/500], Train Loss: 0.8907, Train RMSE: 0.9438\n",
      "Epoch [97/500], Validation Loss: 2.5673, Validation RMSE: 1.6023, Valid PR: 0.2660\n",
      "Epoch [98/500], Train Loss: 0.9288, Train RMSE: 0.9637\n",
      "Epoch [98/500], Validation Loss: 2.5528, Validation RMSE: 1.5978, Valid PR: 0.2386\n",
      "Epoch [99/500], Train Loss: 0.9258, Train RMSE: 0.9622\n",
      "Epoch [99/500], Validation Loss: 2.5386, Validation RMSE: 1.5933, Valid PR: 0.2092\n",
      "Epoch [100/500], Train Loss: 0.9449, Train RMSE: 0.9721\n",
      "Epoch [100/500], Validation Loss: 2.5245, Validation RMSE: 1.5889, Valid PR: 0.1334\n",
      "Epoch [101/500], Train Loss: 0.8784, Train RMSE: 0.9372\n",
      "Epoch [101/500], Validation Loss: 2.5106, Validation RMSE: 1.5845, Valid PR: 0.1127\n",
      "Epoch [102/500], Train Loss: 0.8013, Train RMSE: 0.8951\n",
      "Epoch [102/500], Validation Loss: 2.4972, Validation RMSE: 1.5803, Valid PR: 0.0944\n",
      "Epoch [103/500], Train Loss: 0.9117, Train RMSE: 0.9548\n",
      "Epoch [103/500], Validation Loss: 2.4842, Validation RMSE: 1.5761, Valid PR: 0.0733\n",
      "Epoch [104/500], Train Loss: 0.8763, Train RMSE: 0.9361\n",
      "Epoch [104/500], Validation Loss: 2.4716, Validation RMSE: 1.5721, Valid PR: 0.0433\n",
      "Epoch [105/500], Train Loss: 0.8754, Train RMSE: 0.9356\n",
      "Epoch [105/500], Validation Loss: 2.4595, Validation RMSE: 1.5683, Valid PR: -0.0121\n",
      "Epoch [106/500], Train Loss: 0.8514, Train RMSE: 0.9227\n",
      "Epoch [106/500], Validation Loss: 2.4478, Validation RMSE: 1.5645, Valid PR: -0.1241\n",
      "Epoch [107/500], Train Loss: 0.8932, Train RMSE: 0.9451\n",
      "Epoch [107/500], Validation Loss: 2.4364, Validation RMSE: 1.5609, Valid PR: -0.2461\n",
      "Epoch [108/500], Train Loss: 0.9193, Train RMSE: 0.9588\n",
      "Epoch [108/500], Validation Loss: 2.4254, Validation RMSE: 1.5574, Valid PR: -0.2481\n",
      "Epoch [109/500], Train Loss: 0.8105, Train RMSE: 0.9003\n",
      "Epoch [109/500], Validation Loss: 2.4148, Validation RMSE: 1.5539, Valid PR: -0.2515\n",
      "Epoch [110/500], Train Loss: 0.8764, Train RMSE: 0.9362\n",
      "Epoch [110/500], Validation Loss: 2.4046, Validation RMSE: 1.5507, Valid PR: -0.2350\n",
      "Epoch [111/500], Train Loss: 0.8225, Train RMSE: 0.9069\n",
      "Epoch [111/500], Validation Loss: 2.3947, Validation RMSE: 1.5475, Valid PR: -0.1685\n",
      "Epoch [112/500], Train Loss: 0.9080, Train RMSE: 0.9529\n",
      "Epoch [112/500], Validation Loss: 2.3850, Validation RMSE: 1.5443, Valid PR: -0.0318\n",
      "Epoch [113/500], Train Loss: 0.8608, Train RMSE: 0.9278\n",
      "Epoch [113/500], Validation Loss: 2.3759, Validation RMSE: 1.5414, Valid PR: 0.1215\n",
      "Epoch [114/500], Train Loss: 0.9060, Train RMSE: 0.9519\n",
      "Epoch [114/500], Validation Loss: 2.3670, Validation RMSE: 1.5385, Valid PR: 0.5014\n",
      "Epoch [115/500], Train Loss: 0.9888, Train RMSE: 0.9944\n",
      "Epoch [115/500], Validation Loss: 2.3585, Validation RMSE: 1.5357, Valid PR: 0.7058\n",
      "Epoch [116/500], Train Loss: 0.9754, Train RMSE: 0.9876\n",
      "Epoch [116/500], Validation Loss: 2.3502, Validation RMSE: 1.5330, Valid PR: 0.7464\n",
      "Epoch [117/500], Train Loss: 0.8313, Train RMSE: 0.9118\n",
      "Epoch [117/500], Validation Loss: 2.3423, Validation RMSE: 1.5305, Valid PR: 0.7070\n",
      "Epoch [118/500], Train Loss: 0.8386, Train RMSE: 0.9157\n",
      "Epoch [118/500], Validation Loss: 2.3345, Validation RMSE: 1.5279, Valid PR: 0.6594\n",
      "Epoch [119/500], Train Loss: 0.8507, Train RMSE: 0.9224\n",
      "Epoch [119/500], Validation Loss: 2.3269, Validation RMSE: 1.5254, Valid PR: 0.6284\n",
      "Epoch [120/500], Train Loss: 0.8006, Train RMSE: 0.8947\n",
      "Epoch [120/500], Validation Loss: 2.3196, Validation RMSE: 1.5230, Valid PR: 0.6088\n",
      "Epoch [121/500], Train Loss: 0.9118, Train RMSE: 0.9549\n",
      "Epoch [121/500], Validation Loss: 2.3126, Validation RMSE: 1.5207, Valid PR: 0.5926\n",
      "Epoch [122/500], Train Loss: 0.7033, Train RMSE: 0.8386\n",
      "Epoch [122/500], Validation Loss: 2.3059, Validation RMSE: 1.5185, Valid PR: 0.5784\n",
      "Epoch [123/500], Train Loss: 0.7823, Train RMSE: 0.8845\n",
      "Epoch [123/500], Validation Loss: 2.2993, Validation RMSE: 1.5163, Valid PR: 0.5632\n",
      "Epoch [124/500], Train Loss: 0.8822, Train RMSE: 0.9393\n",
      "Epoch [124/500], Validation Loss: 2.2931, Validation RMSE: 1.5143, Valid PR: 0.5441\n",
      "Epoch [125/500], Train Loss: 0.8070, Train RMSE: 0.8984\n",
      "Epoch [125/500], Validation Loss: 2.2873, Validation RMSE: 1.5124, Valid PR: 0.5382\n",
      "Epoch [126/500], Train Loss: 0.8263, Train RMSE: 0.9090\n",
      "Epoch [126/500], Validation Loss: 2.2817, Validation RMSE: 1.5105, Valid PR: 0.5347\n",
      "Epoch [127/500], Train Loss: 0.8430, Train RMSE: 0.9182\n",
      "Epoch [127/500], Validation Loss: 2.2767, Validation RMSE: 1.5089, Valid PR: 0.5413\n",
      "Epoch [128/500], Train Loss: 0.8280, Train RMSE: 0.9100\n",
      "Epoch [128/500], Validation Loss: 2.2722, Validation RMSE: 1.5074, Valid PR: 0.5611\n",
      "Epoch [129/500], Train Loss: 0.7955, Train RMSE: 0.8919\n",
      "Epoch [129/500], Validation Loss: 2.2678, Validation RMSE: 1.5059, Valid PR: 0.5759\n",
      "Epoch [130/500], Train Loss: 0.6634, Train RMSE: 0.8145\n",
      "Epoch [130/500], Validation Loss: 2.2635, Validation RMSE: 1.5045, Valid PR: 0.5878\n",
      "Epoch [131/500], Train Loss: 0.8232, Train RMSE: 0.9073\n",
      "Epoch [131/500], Validation Loss: 2.2593, Validation RMSE: 1.5031, Valid PR: 0.6186\n",
      "Epoch [132/500], Train Loss: 0.8528, Train RMSE: 0.9235\n",
      "Epoch [132/500], Validation Loss: 2.2554, Validation RMSE: 1.5018, Valid PR: 0.6630\n",
      "Epoch [133/500], Train Loss: 0.8571, Train RMSE: 0.9258\n",
      "Epoch [133/500], Validation Loss: 2.2515, Validation RMSE: 1.5005, Valid PR: 0.7139\n",
      "Epoch [134/500], Train Loss: 0.7365, Train RMSE: 0.8582\n",
      "Epoch [134/500], Validation Loss: 2.2477, Validation RMSE: 1.4992, Valid PR: 0.7159\n",
      "Epoch [135/500], Train Loss: 0.7522, Train RMSE: 0.8673\n",
      "Epoch [135/500], Validation Loss: 2.2442, Validation RMSE: 1.4981, Valid PR: 0.7639\n",
      "Epoch [136/500], Train Loss: 0.7493, Train RMSE: 0.8656\n",
      "Epoch [136/500], Validation Loss: 2.2409, Validation RMSE: 1.4969, Valid PR: 0.7237\n",
      "Epoch [137/500], Train Loss: 0.7523, Train RMSE: 0.8673\n",
      "Epoch [137/500], Validation Loss: 2.2376, Validation RMSE: 1.4959, Valid PR: -0.1168\n",
      "Epoch [138/500], Train Loss: 0.7438, Train RMSE: 0.8624\n",
      "Epoch [138/500], Validation Loss: 2.2348, Validation RMSE: 1.4949, Valid PR: -0.4291\n",
      "Epoch [139/500], Train Loss: 0.7744, Train RMSE: 0.8800\n",
      "Epoch [139/500], Validation Loss: 2.2320, Validation RMSE: 1.4940, Valid PR: -0.4888\n",
      "Epoch [140/500], Train Loss: 0.6719, Train RMSE: 0.8197\n",
      "Epoch [140/500], Validation Loss: 2.2294, Validation RMSE: 1.4931, Valid PR: -0.5145\n",
      "Epoch [141/500], Train Loss: 0.8093, Train RMSE: 0.8996\n",
      "Epoch [141/500], Validation Loss: 2.2269, Validation RMSE: 1.4923, Valid PR: -0.5291\n",
      "Epoch [142/500], Train Loss: 0.7696, Train RMSE: 0.8773\n",
      "Epoch [142/500], Validation Loss: 2.2244, Validation RMSE: 1.4914, Valid PR: -0.5428\n",
      "Epoch [143/500], Train Loss: 0.8801, Train RMSE: 0.9381\n",
      "Epoch [143/500], Validation Loss: 2.2218, Validation RMSE: 1.4906, Valid PR: -0.5439\n",
      "Epoch [144/500], Train Loss: 0.7926, Train RMSE: 0.8903\n",
      "Epoch [144/500], Validation Loss: 2.2193, Validation RMSE: 1.4897, Valid PR: -0.5468\n",
      "Epoch [145/500], Train Loss: 0.7457, Train RMSE: 0.8635\n",
      "Epoch [145/500], Validation Loss: 2.2169, Validation RMSE: 1.4889, Valid PR: -0.5483\n",
      "Epoch [146/500], Train Loss: 0.9027, Train RMSE: 0.9501\n",
      "Epoch [146/500], Validation Loss: 2.2147, Validation RMSE: 1.4882, Valid PR: -0.5426\n",
      "Epoch [147/500], Train Loss: 0.7861, Train RMSE: 0.8866\n",
      "Epoch [147/500], Validation Loss: 2.2126, Validation RMSE: 1.4875, Valid PR: -0.5329\n",
      "Epoch [148/500], Train Loss: 0.7587, Train RMSE: 0.8710\n",
      "Epoch [148/500], Validation Loss: 2.2106, Validation RMSE: 1.4868, Valid PR: -0.5239\n",
      "Epoch [149/500], Train Loss: 0.7197, Train RMSE: 0.8483\n",
      "Epoch [149/500], Validation Loss: 2.2088, Validation RMSE: 1.4862, Valid PR: -0.5174\n",
      "Epoch [150/500], Train Loss: 0.8298, Train RMSE: 0.9109\n",
      "Epoch [150/500], Validation Loss: 2.2071, Validation RMSE: 1.4856, Valid PR: -0.5048\n",
      "Epoch [151/500], Train Loss: 0.7041, Train RMSE: 0.8391\n",
      "Epoch [151/500], Validation Loss: 2.2055, Validation RMSE: 1.4851, Valid PR: -0.4864\n",
      "Epoch [152/500], Train Loss: 0.7812, Train RMSE: 0.8839\n",
      "Epoch [152/500], Validation Loss: 2.2041, Validation RMSE: 1.4846, Valid PR: -0.4663\n",
      "Epoch [153/500], Train Loss: 0.7601, Train RMSE: 0.8718\n",
      "Epoch [153/500], Validation Loss: 2.2028, Validation RMSE: 1.4842, Valid PR: -0.4450\n",
      "Epoch [154/500], Train Loss: 0.7462, Train RMSE: 0.8639\n",
      "Epoch [154/500], Validation Loss: 2.2015, Validation RMSE: 1.4838, Valid PR: -0.3746\n",
      "Epoch [155/500], Train Loss: 0.7435, Train RMSE: 0.8623\n",
      "Epoch [155/500], Validation Loss: 2.2003, Validation RMSE: 1.4833, Valid PR: -0.0745\n",
      "Epoch [156/500], Train Loss: 0.7746, Train RMSE: 0.8801\n",
      "Epoch [156/500], Validation Loss: 2.1992, Validation RMSE: 1.4830, Valid PR: 0.2042\n",
      "Epoch [157/500], Train Loss: 0.8329, Train RMSE: 0.9126\n",
      "Epoch [157/500], Validation Loss: 2.1982, Validation RMSE: 1.4826, Valid PR: 0.4924\n",
      "Epoch [158/500], Train Loss: 0.7376, Train RMSE: 0.8588\n",
      "Epoch [158/500], Validation Loss: 2.1973, Validation RMSE: 1.4823, Valid PR: 0.6050\n",
      "Epoch [159/500], Train Loss: 0.7285, Train RMSE: 0.8535\n",
      "Epoch [159/500], Validation Loss: 2.1962, Validation RMSE: 1.4820, Valid PR: 0.6172\n",
      "Epoch [160/500], Train Loss: 0.7078, Train RMSE: 0.8413\n",
      "Epoch [160/500], Validation Loss: 2.1952, Validation RMSE: 1.4816, Valid PR: 0.5774\n",
      "Epoch [161/500], Train Loss: 0.7996, Train RMSE: 0.8942\n",
      "Epoch [161/500], Validation Loss: 2.1944, Validation RMSE: 1.4814, Valid PR: 0.5649\n",
      "Epoch [162/500], Train Loss: 0.7596, Train RMSE: 0.8715\n",
      "Epoch [162/500], Validation Loss: 2.1936, Validation RMSE: 1.4811, Valid PR: 0.5482\n",
      "Epoch [163/500], Train Loss: 0.7209, Train RMSE: 0.8491\n",
      "Epoch [163/500], Validation Loss: 2.1930, Validation RMSE: 1.4809, Valid PR: 0.5448\n",
      "Epoch [164/500], Train Loss: 0.7789, Train RMSE: 0.8826\n",
      "Epoch [164/500], Validation Loss: 2.1923, Validation RMSE: 1.4806, Valid PR: 0.5480\n",
      "Epoch [165/500], Train Loss: 0.7727, Train RMSE: 0.8790\n",
      "Epoch [165/500], Validation Loss: 2.1924, Validation RMSE: 1.4807, Valid PR: 0.5292\n",
      "Epoch [166/500], Train Loss: 0.6856, Train RMSE: 0.8280\n",
      "Epoch [166/500], Validation Loss: 2.1926, Validation RMSE: 1.4808, Valid PR: 0.4590\n",
      "Epoch [167/500], Train Loss: 0.7525, Train RMSE: 0.8674\n",
      "Epoch [167/500], Validation Loss: 2.1930, Validation RMSE: 1.4809, Valid PR: 0.2027\n",
      "Epoch [168/500], Train Loss: 0.7401, Train RMSE: 0.8603\n",
      "Epoch [168/500], Validation Loss: 2.1932, Validation RMSE: 1.4809, Valid PR: 0.0805\n",
      "Epoch [169/500], Train Loss: 0.7700, Train RMSE: 0.8775\n",
      "Epoch [169/500], Validation Loss: 2.1931, Validation RMSE: 1.4809, Valid PR: 0.1325\n",
      "Epoch [170/500], Train Loss: 0.6769, Train RMSE: 0.8227\n",
      "Epoch [170/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.3928\n",
      "Epoch [171/500], Train Loss: 0.6938, Train RMSE: 0.8329\n",
      "Epoch [171/500], Validation Loss: 2.1906, Validation RMSE: 1.4801, Valid PR: 0.5319\n",
      "Epoch [172/500], Train Loss: 0.7546, Train RMSE: 0.8687\n",
      "Epoch [172/500], Validation Loss: 2.1882, Validation RMSE: 1.4793, Valid PR: 0.5737\n",
      "Epoch [173/500], Train Loss: 0.8642, Train RMSE: 0.9296\n",
      "Epoch [173/500], Validation Loss: 2.1848, Validation RMSE: 1.4781, Valid PR: 0.5911\n",
      "Epoch [174/500], Train Loss: 0.7709, Train RMSE: 0.8780\n",
      "Epoch [174/500], Validation Loss: 2.1808, Validation RMSE: 1.4768, Valid PR: 0.5908\n",
      "Epoch [175/500], Train Loss: 0.7571, Train RMSE: 0.8701\n",
      "Epoch [175/500], Validation Loss: 2.1763, Validation RMSE: 1.4752, Valid PR: 0.5953\n",
      "Epoch [176/500], Train Loss: 0.8037, Train RMSE: 0.8965\n",
      "Epoch [176/500], Validation Loss: 2.1723, Validation RMSE: 1.4739, Valid PR: 0.5954\n",
      "Epoch [177/500], Train Loss: 0.7370, Train RMSE: 0.8585\n",
      "Epoch [177/500], Validation Loss: 2.1681, Validation RMSE: 1.4724, Valid PR: 0.5977\n",
      "Epoch [178/500], Train Loss: 0.7737, Train RMSE: 0.8796\n",
      "Epoch [178/500], Validation Loss: 2.1647, Validation RMSE: 1.4713, Valid PR: 0.5994\n",
      "Epoch [179/500], Train Loss: 0.7020, Train RMSE: 0.8379\n",
      "Epoch [179/500], Validation Loss: 2.1616, Validation RMSE: 1.4702, Valid PR: 0.5969\n",
      "Epoch [180/500], Train Loss: 0.7883, Train RMSE: 0.8879\n",
      "Epoch [180/500], Validation Loss: 2.1595, Validation RMSE: 1.4695, Valid PR: 0.5910\n",
      "Epoch [181/500], Train Loss: 0.7249, Train RMSE: 0.8514\n",
      "Epoch [181/500], Validation Loss: 2.1572, Validation RMSE: 1.4687, Valid PR: 0.5838\n",
      "Epoch [182/500], Train Loss: 0.6808, Train RMSE: 0.8251\n",
      "Epoch [182/500], Validation Loss: 2.1560, Validation RMSE: 1.4683, Valid PR: 0.5743\n",
      "Epoch [183/500], Train Loss: 0.7228, Train RMSE: 0.8502\n",
      "Epoch [183/500], Validation Loss: 2.1539, Validation RMSE: 1.4676, Valid PR: 0.5649\n",
      "Epoch [184/500], Train Loss: 0.6993, Train RMSE: 0.8362\n",
      "Epoch [184/500], Validation Loss: 2.1499, Validation RMSE: 1.4663, Valid PR: 0.5543\n",
      "Epoch [185/500], Train Loss: 0.7559, Train RMSE: 0.8694\n",
      "Epoch [185/500], Validation Loss: 2.1460, Validation RMSE: 1.4649, Valid PR: 0.5489\n",
      "Epoch [186/500], Train Loss: 0.6957, Train RMSE: 0.8341\n",
      "Epoch [186/500], Validation Loss: 2.1393, Validation RMSE: 1.4626, Valid PR: 0.5454\n",
      "Epoch [187/500], Train Loss: 0.7694, Train RMSE: 0.8771\n",
      "Epoch [187/500], Validation Loss: 2.1322, Validation RMSE: 1.4602, Valid PR: 0.5452\n",
      "Epoch [188/500], Train Loss: 0.7009, Train RMSE: 0.8372\n",
      "Epoch [188/500], Validation Loss: 2.1271, Validation RMSE: 1.4585, Valid PR: 0.5428\n",
      "Epoch [189/500], Train Loss: 0.7222, Train RMSE: 0.8498\n",
      "Epoch [189/500], Validation Loss: 2.1258, Validation RMSE: 1.4580, Valid PR: 0.5423\n",
      "Epoch [190/500], Train Loss: 0.7989, Train RMSE: 0.8938\n",
      "Epoch [190/500], Validation Loss: 2.1243, Validation RMSE: 1.4575, Valid PR: 0.5407\n",
      "Epoch [191/500], Train Loss: 0.6702, Train RMSE: 0.8187\n",
      "Epoch [191/500], Validation Loss: 2.1254, Validation RMSE: 1.4579, Valid PR: 0.5372\n",
      "Epoch [192/500], Train Loss: 0.6940, Train RMSE: 0.8331\n",
      "Epoch [192/500], Validation Loss: 2.1292, Validation RMSE: 1.4592, Valid PR: 0.5378\n",
      "Epoch [193/500], Train Loss: 0.6800, Train RMSE: 0.8246\n",
      "Epoch [193/500], Validation Loss: 2.1336, Validation RMSE: 1.4607, Valid PR: 0.5374\n",
      "Epoch [194/500], Train Loss: 0.8197, Train RMSE: 0.9054\n",
      "Epoch [194/500], Validation Loss: 2.1351, Validation RMSE: 1.4612, Valid PR: 0.5384\n",
      "Epoch [195/500], Train Loss: 0.5993, Train RMSE: 0.7741\n",
      "Epoch [195/500], Validation Loss: 2.1337, Validation RMSE: 1.4607, Valid PR: 0.5380\n",
      "Epoch [196/500], Train Loss: 0.7650, Train RMSE: 0.8746\n",
      "Epoch [196/500], Validation Loss: 2.1339, Validation RMSE: 1.4608, Valid PR: 0.5362\n",
      "Epoch [197/500], Train Loss: 0.7181, Train RMSE: 0.8474\n",
      "Epoch [197/500], Validation Loss: 2.1279, Validation RMSE: 1.4587, Valid PR: 0.5366\n",
      "Epoch [198/500], Train Loss: 0.7077, Train RMSE: 0.8412\n",
      "Epoch [198/500], Validation Loss: 2.1217, Validation RMSE: 1.4566, Valid PR: 0.5387\n",
      "Epoch [199/500], Train Loss: 0.7853, Train RMSE: 0.8861\n",
      "Epoch [199/500], Validation Loss: 2.1110, Validation RMSE: 1.4529, Valid PR: 0.5393\n",
      "Epoch [200/500], Train Loss: 0.7261, Train RMSE: 0.8521\n",
      "Epoch [200/500], Validation Loss: 2.0996, Validation RMSE: 1.4490, Valid PR: 0.5383\n",
      "Epoch [201/500], Train Loss: 0.7215, Train RMSE: 0.8494\n",
      "Epoch [201/500], Validation Loss: 2.0897, Validation RMSE: 1.4456, Valid PR: 0.5369\n",
      "Epoch [202/500], Train Loss: 0.6779, Train RMSE: 0.8233\n",
      "Epoch [202/500], Validation Loss: 2.0845, Validation RMSE: 1.4438, Valid PR: 0.5340\n",
      "Epoch [203/500], Train Loss: 0.7339, Train RMSE: 0.8567\n",
      "Epoch [203/500], Validation Loss: 2.0836, Validation RMSE: 1.4435, Valid PR: 0.5313\n",
      "Epoch [204/500], Train Loss: 0.7074, Train RMSE: 0.8410\n",
      "Epoch [204/500], Validation Loss: 2.0843, Validation RMSE: 1.4437, Valid PR: 0.5285\n",
      "Epoch [205/500], Train Loss: 0.6332, Train RMSE: 0.7957\n",
      "Epoch [205/500], Validation Loss: 2.0858, Validation RMSE: 1.4442, Valid PR: 0.5248\n",
      "Epoch [206/500], Train Loss: 0.6606, Train RMSE: 0.8128\n",
      "Epoch [206/500], Validation Loss: 2.0823, Validation RMSE: 1.4430, Valid PR: 0.5219\n",
      "Epoch [207/500], Train Loss: 0.6686, Train RMSE: 0.8177\n",
      "Epoch [207/500], Validation Loss: 2.0755, Validation RMSE: 1.4407, Valid PR: 0.5201\n",
      "Epoch [208/500], Train Loss: 0.7782, Train RMSE: 0.8822\n",
      "Epoch [208/500], Validation Loss: 2.0688, Validation RMSE: 1.4383, Valid PR: 0.5186\n",
      "Epoch [209/500], Train Loss: 0.7787, Train RMSE: 0.8825\n",
      "Epoch [209/500], Validation Loss: 2.0613, Validation RMSE: 1.4357, Valid PR: 0.5175\n",
      "Epoch [210/500], Train Loss: 0.7631, Train RMSE: 0.8735\n",
      "Epoch [210/500], Validation Loss: 2.0577, Validation RMSE: 1.4345, Valid PR: 0.5161\n",
      "Epoch [211/500], Train Loss: 0.6790, Train RMSE: 0.8240\n",
      "Epoch [211/500], Validation Loss: 2.0563, Validation RMSE: 1.4340, Valid PR: 0.5136\n",
      "Epoch [212/500], Train Loss: 0.7416, Train RMSE: 0.8612\n",
      "Epoch [212/500], Validation Loss: 2.0543, Validation RMSE: 1.4333, Valid PR: 0.5106\n",
      "Epoch [213/500], Train Loss: 0.6711, Train RMSE: 0.8192\n",
      "Epoch [213/500], Validation Loss: 2.0500, Validation RMSE: 1.4318, Valid PR: 0.5095\n",
      "Epoch [214/500], Train Loss: 0.7035, Train RMSE: 0.8387\n",
      "Epoch [214/500], Validation Loss: 2.0437, Validation RMSE: 1.4296, Valid PR: 0.5077\n",
      "Epoch [215/500], Train Loss: 0.7296, Train RMSE: 0.8542\n",
      "Epoch [215/500], Validation Loss: 2.0313, Validation RMSE: 1.4252, Valid PR: 0.5067\n",
      "Epoch [216/500], Train Loss: 0.6663, Train RMSE: 0.8163\n",
      "Epoch [216/500], Validation Loss: 2.0264, Validation RMSE: 1.4235, Valid PR: 0.5028\n",
      "Epoch [217/500], Train Loss: 0.6958, Train RMSE: 0.8341\n",
      "Epoch [217/500], Validation Loss: 2.0211, Validation RMSE: 1.4217, Valid PR: 0.4993\n",
      "Epoch [218/500], Train Loss: 0.6760, Train RMSE: 0.8222\n",
      "Epoch [218/500], Validation Loss: 2.0187, Validation RMSE: 1.4208, Valid PR: 0.4946\n",
      "Epoch [219/500], Train Loss: 0.7194, Train RMSE: 0.8482\n",
      "Epoch [219/500], Validation Loss: 2.0044, Validation RMSE: 1.4158, Valid PR: 0.4929\n",
      "Epoch [220/500], Train Loss: 0.6690, Train RMSE: 0.8179\n",
      "Epoch [220/500], Validation Loss: 2.0020, Validation RMSE: 1.4149, Valid PR: 0.4895\n",
      "Epoch [221/500], Train Loss: 0.6770, Train RMSE: 0.8228\n",
      "Epoch [221/500], Validation Loss: 2.0010, Validation RMSE: 1.4146, Valid PR: 0.4855\n",
      "Epoch [222/500], Train Loss: 0.6857, Train RMSE: 0.8281\n",
      "Epoch [222/500], Validation Loss: 1.9930, Validation RMSE: 1.4117, Valid PR: 0.4826\n",
      "Epoch [223/500], Train Loss: 0.6760, Train RMSE: 0.8222\n",
      "Epoch [223/500], Validation Loss: 1.9900, Validation RMSE: 1.4107, Valid PR: 0.4786\n",
      "Epoch [224/500], Train Loss: 0.6597, Train RMSE: 0.8122\n",
      "Epoch [224/500], Validation Loss: 1.9737, Validation RMSE: 1.4049, Valid PR: 0.4781\n",
      "Epoch [225/500], Train Loss: 0.6765, Train RMSE: 0.8225\n",
      "Epoch [225/500], Validation Loss: 1.9818, Validation RMSE: 1.4077, Valid PR: 0.4715\n",
      "Epoch [226/500], Train Loss: 0.6427, Train RMSE: 0.8017\n",
      "Epoch [226/500], Validation Loss: 2.0067, Validation RMSE: 1.4166, Valid PR: 0.4577\n",
      "Epoch [227/500], Train Loss: 0.7046, Train RMSE: 0.8394\n",
      "Epoch [227/500], Validation Loss: 2.0281, Validation RMSE: 1.4241, Valid PR: 0.4442\n",
      "Epoch [228/500], Train Loss: 0.7777, Train RMSE: 0.8819\n",
      "Epoch [228/500], Validation Loss: 2.0425, Validation RMSE: 1.4292, Valid PR: 0.4317\n",
      "Epoch [229/500], Train Loss: 0.6648, Train RMSE: 0.8154\n",
      "Epoch [229/500], Validation Loss: 2.0516, Validation RMSE: 1.4324, Valid PR: 0.4201\n",
      "Epoch [230/500], Train Loss: 0.6382, Train RMSE: 0.7989\n",
      "Epoch [230/500], Validation Loss: 2.0403, Validation RMSE: 1.4284, Valid PR: 0.4177\n",
      "Epoch [231/500], Train Loss: 0.7039, Train RMSE: 0.8390\n",
      "Epoch [231/500], Validation Loss: 2.0270, Validation RMSE: 1.4237, Valid PR: 0.4165\n",
      "Epoch [232/500], Train Loss: 0.7193, Train RMSE: 0.8481\n",
      "Epoch [232/500], Validation Loss: 1.9948, Validation RMSE: 1.4124, Valid PR: 0.4228\n",
      "Epoch [233/500], Train Loss: 0.6983, Train RMSE: 0.8357\n",
      "Epoch [233/500], Validation Loss: 1.9756, Validation RMSE: 1.4055, Valid PR: 0.4222\n",
      "Epoch [234/500], Train Loss: 0.6839, Train RMSE: 0.8270\n",
      "Epoch [234/500], Validation Loss: 2.0025, Validation RMSE: 1.4151, Valid PR: 0.4099\n",
      "Epoch [235/500], Train Loss: 0.6905, Train RMSE: 0.8309\n",
      "Epoch [235/500], Validation Loss: 2.0327, Validation RMSE: 1.4257, Valid PR: 0.3960\n",
      "Epoch [236/500], Train Loss: 0.6878, Train RMSE: 0.8293\n",
      "Epoch [236/500], Validation Loss: 2.0514, Validation RMSE: 1.4323, Valid PR: 0.3846\n",
      "Epoch [237/500], Train Loss: 0.7049, Train RMSE: 0.8396\n",
      "Epoch [237/500], Validation Loss: 2.0458, Validation RMSE: 1.4303, Valid PR: 0.3836\n",
      "Epoch [238/500], Train Loss: 0.6985, Train RMSE: 0.8358\n",
      "Epoch [238/500], Validation Loss: 2.0302, Validation RMSE: 1.4249, Valid PR: 0.3826\n",
      "Epoch [239/500], Train Loss: 0.6591, Train RMSE: 0.8118\n",
      "Epoch [239/500], Validation Loss: 2.0131, Validation RMSE: 1.4188, Valid PR: 0.3797\n",
      "Epoch [240/500], Train Loss: 0.6591, Train RMSE: 0.8118\n",
      "Epoch [240/500], Validation Loss: 2.0161, Validation RMSE: 1.4199, Valid PR: 0.3740\n",
      "Epoch [241/500], Train Loss: 0.7616, Train RMSE: 0.8727\n",
      "Epoch [241/500], Validation Loss: 2.0003, Validation RMSE: 1.4143, Valid PR: 0.3805\n",
      "Epoch [242/500], Train Loss: 0.6780, Train RMSE: 0.8234\n",
      "Epoch [242/500], Validation Loss: 1.9943, Validation RMSE: 1.4122, Valid PR: 0.3828\n",
      "Epoch [243/500], Train Loss: 0.6318, Train RMSE: 0.7948\n",
      "Epoch [243/500], Validation Loss: 2.0088, Validation RMSE: 1.4173, Valid PR: 0.3764\n",
      "Epoch [244/500], Train Loss: 0.6478, Train RMSE: 0.8049\n",
      "Epoch [244/500], Validation Loss: 2.0221, Validation RMSE: 1.4220, Valid PR: 0.3685\n",
      "Epoch [245/500], Train Loss: 0.6439, Train RMSE: 0.8025\n",
      "Epoch [245/500], Validation Loss: 2.0367, Validation RMSE: 1.4271, Valid PR: 0.3585\n",
      "Epoch [246/500], Train Loss: 0.6375, Train RMSE: 0.7984\n",
      "Epoch [246/500], Validation Loss: 2.0546, Validation RMSE: 1.4334, Valid PR: 0.3448\n",
      "Epoch [247/500], Train Loss: 0.6525, Train RMSE: 0.8078\n",
      "Epoch [247/500], Validation Loss: 2.0529, Validation RMSE: 1.4328, Valid PR: 0.3420\n",
      "Epoch [248/500], Train Loss: 0.7008, Train RMSE: 0.8372\n",
      "Epoch [248/500], Validation Loss: 2.0356, Validation RMSE: 1.4267, Valid PR: 0.3476\n",
      "Epoch [249/500], Train Loss: 0.6478, Train RMSE: 0.8048\n",
      "Epoch [249/500], Validation Loss: 2.0071, Validation RMSE: 1.4167, Valid PR: 0.3541\n",
      "Epoch [250/500], Train Loss: 0.6953, Train RMSE: 0.8339\n",
      "Epoch [250/500], Validation Loss: 1.9794, Validation RMSE: 1.4069, Valid PR: 0.3598\n",
      "Epoch [251/500], Train Loss: 0.6514, Train RMSE: 0.8071\n",
      "Epoch [251/500], Validation Loss: 1.9609, Validation RMSE: 1.4003, Valid PR: 0.3634\n",
      "Epoch [252/500], Train Loss: 0.6525, Train RMSE: 0.8078\n",
      "Epoch [252/500], Validation Loss: 1.9515, Validation RMSE: 1.3970, Valid PR: 0.3646\n",
      "Epoch [253/500], Train Loss: 0.7811, Train RMSE: 0.8838\n",
      "Epoch [253/500], Validation Loss: 1.9483, Validation RMSE: 1.3958, Valid PR: 0.3644\n",
      "Epoch [254/500], Train Loss: 0.7907, Train RMSE: 0.8892\n",
      "Epoch [254/500], Validation Loss: 1.9816, Validation RMSE: 1.4077, Valid PR: 0.3589\n",
      "Epoch [255/500], Train Loss: 0.6695, Train RMSE: 0.8183\n",
      "Epoch [255/500], Validation Loss: 2.0250, Validation RMSE: 1.4230, Valid PR: 0.3527\n",
      "Epoch [256/500], Train Loss: 0.6595, Train RMSE: 0.8121\n",
      "Epoch [256/500], Validation Loss: 2.0745, Validation RMSE: 1.4403, Valid PR: 0.3394\n",
      "Epoch [257/500], Train Loss: 0.6740, Train RMSE: 0.8210\n",
      "Epoch [257/500], Validation Loss: 2.1066, Validation RMSE: 1.4514, Valid PR: 0.3277\n",
      "Epoch [258/500], Train Loss: 0.6455, Train RMSE: 0.8034\n",
      "Epoch [258/500], Validation Loss: 2.1272, Validation RMSE: 1.4585, Valid PR: 0.3186\n",
      "Epoch [259/500], Train Loss: 0.6964, Train RMSE: 0.8345\n",
      "Epoch [259/500], Validation Loss: 2.1263, Validation RMSE: 1.4582, Valid PR: 0.3195\n",
      "Epoch [260/500], Train Loss: 0.6763, Train RMSE: 0.8223\n",
      "Epoch [260/500], Validation Loss: 2.1075, Validation RMSE: 1.4517, Valid PR: 0.3278\n",
      "Epoch [261/500], Train Loss: 0.6783, Train RMSE: 0.8236\n",
      "Epoch [261/500], Validation Loss: 2.0660, Validation RMSE: 1.4374, Valid PR: 0.3426\n",
      "Epoch [262/500], Train Loss: 0.6746, Train RMSE: 0.8214\n",
      "Epoch [262/500], Validation Loss: 2.0200, Validation RMSE: 1.4213, Valid PR: 0.3558\n",
      "Epoch [263/500], Train Loss: 0.6405, Train RMSE: 0.8003\n",
      "Epoch [263/500], Validation Loss: 1.9873, Validation RMSE: 1.4097, Valid PR: 0.3618\n",
      "Epoch [264/500], Train Loss: 0.6847, Train RMSE: 0.8275\n",
      "Epoch [264/500], Validation Loss: 1.9597, Validation RMSE: 1.3999, Valid PR: 0.3658\n",
      "Epoch [265/500], Train Loss: 0.7126, Train RMSE: 0.8441\n",
      "Epoch [265/500], Validation Loss: 1.9458, Validation RMSE: 1.3949, Valid PR: 0.3669\n",
      "Epoch [266/500], Train Loss: 0.6324, Train RMSE: 0.7952\n",
      "Epoch [266/500], Validation Loss: 1.9543, Validation RMSE: 1.3979, Valid PR: 0.3606\n",
      "Epoch [267/500], Train Loss: 0.6911, Train RMSE: 0.8313\n",
      "Epoch [267/500], Validation Loss: 1.9787, Validation RMSE: 1.4067, Valid PR: 0.3495\n",
      "Epoch [268/500], Train Loss: 0.6163, Train RMSE: 0.7850\n",
      "Epoch [268/500], Validation Loss: 2.0096, Validation RMSE: 1.4176, Valid PR: 0.3379\n",
      "Epoch [269/500], Train Loss: 0.6854, Train RMSE: 0.8279\n",
      "Epoch [269/500], Validation Loss: 2.0327, Validation RMSE: 1.4257, Valid PR: 0.3287\n",
      "Epoch [270/500], Train Loss: 0.6749, Train RMSE: 0.8215\n",
      "Epoch [270/500], Validation Loss: 2.0484, Validation RMSE: 1.4312, Valid PR: 0.3209\n",
      "Epoch [271/500], Train Loss: 0.6712, Train RMSE: 0.8193\n",
      "Epoch [271/500], Validation Loss: 2.0583, Validation RMSE: 1.4347, Valid PR: 0.3149\n",
      "Epoch [272/500], Train Loss: 0.6906, Train RMSE: 0.8310\n",
      "Epoch [272/500], Validation Loss: 2.0656, Validation RMSE: 1.4372, Valid PR: 0.3095\n",
      "Epoch [273/500], Train Loss: 0.6376, Train RMSE: 0.7985\n",
      "Epoch [273/500], Validation Loss: 2.0788, Validation RMSE: 1.4418, Valid PR: 0.3012\n",
      "Epoch [274/500], Train Loss: 0.6120, Train RMSE: 0.7823\n",
      "Epoch [274/500], Validation Loss: 2.0733, Validation RMSE: 1.4399, Valid PR: 0.3002\n",
      "Epoch [275/500], Train Loss: 0.6846, Train RMSE: 0.8274\n",
      "Epoch [275/500], Validation Loss: 2.0429, Validation RMSE: 1.4293, Valid PR: 0.3084\n",
      "Epoch [276/500], Train Loss: 0.6665, Train RMSE: 0.8164\n",
      "Epoch [276/500], Validation Loss: 2.0121, Validation RMSE: 1.4185, Valid PR: 0.3176\n",
      "Epoch [277/500], Train Loss: 0.6507, Train RMSE: 0.8067\n",
      "Epoch [277/500], Validation Loss: 1.9945, Validation RMSE: 1.4123, Valid PR: 0.3217\n",
      "Epoch [278/500], Train Loss: 0.7679, Train RMSE: 0.8763\n",
      "Epoch [278/500], Validation Loss: 1.9991, Validation RMSE: 1.4139, Valid PR: 0.3184\n",
      "Epoch [279/500], Train Loss: 0.5870, Train RMSE: 0.7662\n",
      "Epoch [279/500], Validation Loss: 2.0001, Validation RMSE: 1.4143, Valid PR: 0.3165\n",
      "Epoch [280/500], Train Loss: 0.6444, Train RMSE: 0.8028\n",
      "Epoch [280/500], Validation Loss: 2.0202, Validation RMSE: 1.4213, Valid PR: 0.3088\n",
      "Epoch [281/500], Train Loss: 0.6631, Train RMSE: 0.8143\n",
      "Epoch [281/500], Validation Loss: 2.0567, Validation RMSE: 1.4341, Valid PR: 0.2962\n",
      "Epoch [282/500], Train Loss: 0.6644, Train RMSE: 0.8151\n",
      "Epoch [282/500], Validation Loss: 2.0995, Validation RMSE: 1.4490, Valid PR: 0.2823\n",
      "Epoch [283/500], Train Loss: 0.6401, Train RMSE: 0.8000\n",
      "Epoch [283/500], Validation Loss: 2.1176, Validation RMSE: 1.4552, Valid PR: 0.2747\n",
      "Epoch [284/500], Train Loss: 0.6072, Train RMSE: 0.7792\n",
      "Epoch [284/500], Validation Loss: 2.0991, Validation RMSE: 1.4488, Valid PR: 0.2782\n",
      "Epoch [285/500], Train Loss: 0.6491, Train RMSE: 0.8057\n",
      "Epoch [285/500], Validation Loss: 2.0582, Validation RMSE: 1.4346, Valid PR: 0.2875\n",
      "Epoch [286/500], Train Loss: 0.6852, Train RMSE: 0.8278\n",
      "Epoch [286/500], Validation Loss: 2.0060, Validation RMSE: 1.4163, Valid PR: 0.3045\n",
      "Epoch [287/500], Train Loss: 0.7187, Train RMSE: 0.8477\n",
      "Epoch [287/500], Validation Loss: 1.9844, Validation RMSE: 1.4087, Valid PR: 0.3135\n",
      "Epoch [288/500], Train Loss: 0.6964, Train RMSE: 0.8345\n",
      "Epoch [288/500], Validation Loss: 1.9759, Validation RMSE: 1.4057, Valid PR: 0.3183\n",
      "Epoch [289/500], Train Loss: 0.6187, Train RMSE: 0.7866\n",
      "Epoch [289/500], Validation Loss: 2.0072, Validation RMSE: 1.4167, Valid PR: 0.3073\n",
      "Epoch [290/500], Train Loss: 0.6392, Train RMSE: 0.7995\n",
      "Epoch [290/500], Validation Loss: 2.0680, Validation RMSE: 1.4380, Valid PR: 0.2914\n",
      "Epoch [291/500], Train Loss: 0.6007, Train RMSE: 0.7751\n",
      "Epoch [291/500], Validation Loss: 2.1089, Validation RMSE: 1.4522, Valid PR: 0.2837\n",
      "Epoch [292/500], Train Loss: 0.6018, Train RMSE: 0.7758\n",
      "Epoch [292/500], Validation Loss: 2.1103, Validation RMSE: 1.4527, Valid PR: 0.2859\n",
      "Epoch [293/500], Train Loss: 0.6431, Train RMSE: 0.8019\n",
      "Epoch [293/500], Validation Loss: 2.0949, Validation RMSE: 1.4474, Valid PR: 0.2905\n",
      "Epoch [294/500], Train Loss: 0.5787, Train RMSE: 0.7607\n",
      "Epoch [294/500], Validation Loss: 2.0752, Validation RMSE: 1.4406, Valid PR: 0.2962\n",
      "Epoch [295/500], Train Loss: 0.5924, Train RMSE: 0.7696\n",
      "Epoch [295/500], Validation Loss: 2.0618, Validation RMSE: 1.4359, Valid PR: 0.3007\n",
      "Epoch [296/500], Train Loss: 0.6130, Train RMSE: 0.7829\n",
      "Epoch [296/500], Validation Loss: 2.0394, Validation RMSE: 1.4281, Valid PR: 0.3062\n",
      "Epoch [297/500], Train Loss: 0.6321, Train RMSE: 0.7951\n",
      "Epoch [297/500], Validation Loss: 2.0110, Validation RMSE: 1.4181, Valid PR: 0.3148\n",
      "Epoch [298/500], Train Loss: 0.6217, Train RMSE: 0.7885\n",
      "Epoch [298/500], Validation Loss: 2.0010, Validation RMSE: 1.4146, Valid PR: 0.3183\n",
      "Epoch [299/500], Train Loss: 0.5648, Train RMSE: 0.7515\n",
      "Epoch [299/500], Validation Loss: 2.0243, Validation RMSE: 1.4228, Valid PR: 0.3114\n",
      "Epoch [300/500], Train Loss: 0.5910, Train RMSE: 0.7687\n",
      "Epoch [300/500], Validation Loss: 2.0666, Validation RMSE: 1.4376, Valid PR: 0.3002\n",
      "Epoch [301/500], Train Loss: 0.6270, Train RMSE: 0.7919\n",
      "Epoch [301/500], Validation Loss: 2.0868, Validation RMSE: 1.4446, Valid PR: 0.2971\n",
      "Epoch [302/500], Train Loss: 0.5909, Train RMSE: 0.7687\n",
      "Epoch [302/500], Validation Loss: 2.0648, Validation RMSE: 1.4370, Valid PR: 0.3081\n",
      "Epoch [303/500], Train Loss: 0.6145, Train RMSE: 0.7839\n",
      "Epoch [303/500], Validation Loss: 2.0253, Validation RMSE: 1.4231, Valid PR: 0.3220\n",
      "Epoch [304/500], Train Loss: 0.6388, Train RMSE: 0.7993\n",
      "Epoch [304/500], Validation Loss: 1.9774, Validation RMSE: 1.4062, Valid PR: 0.3375\n",
      "Epoch [305/500], Train Loss: 0.6545, Train RMSE: 0.8090\n",
      "Epoch [305/500], Validation Loss: 1.9497, Validation RMSE: 1.3963, Valid PR: 0.3479\n",
      "Epoch [306/500], Train Loss: 0.5869, Train RMSE: 0.7661\n",
      "Epoch [306/500], Validation Loss: 1.9434, Validation RMSE: 1.3941, Valid PR: 0.3514\n",
      "Epoch [307/500], Train Loss: 0.6895, Train RMSE: 0.8304\n",
      "Epoch [307/500], Validation Loss: 1.9624, Validation RMSE: 1.4008, Valid PR: 0.3470\n",
      "Epoch [308/500], Train Loss: 0.5650, Train RMSE: 0.7516\n",
      "Epoch [308/500], Validation Loss: 1.9847, Validation RMSE: 1.4088, Valid PR: 0.3412\n",
      "Epoch [309/500], Train Loss: 0.6855, Train RMSE: 0.8280\n",
      "Epoch [309/500], Validation Loss: 2.0322, Validation RMSE: 1.4256, Valid PR: 0.3274\n",
      "Epoch [310/500], Train Loss: 0.6507, Train RMSE: 0.8067\n",
      "Epoch [310/500], Validation Loss: 2.0773, Validation RMSE: 1.4413, Valid PR: 0.3151\n",
      "Epoch [311/500], Train Loss: 0.6369, Train RMSE: 0.7981\n",
      "Epoch [311/500], Validation Loss: 2.0992, Validation RMSE: 1.4489, Valid PR: 0.3083\n",
      "Epoch [312/500], Train Loss: 0.5959, Train RMSE: 0.7719\n",
      "Epoch [312/500], Validation Loss: 2.0835, Validation RMSE: 1.4434, Valid PR: 0.3137\n",
      "Epoch [313/500], Train Loss: 0.6145, Train RMSE: 0.7839\n",
      "Epoch [313/500], Validation Loss: 2.0684, Validation RMSE: 1.4382, Valid PR: 0.3193\n",
      "Epoch [314/500], Train Loss: 0.6142, Train RMSE: 0.7837\n",
      "Epoch [314/500], Validation Loss: 2.0044, Validation RMSE: 1.4158, Valid PR: 0.3384\n",
      "Epoch [315/500], Train Loss: 0.5446, Train RMSE: 0.7379\n",
      "Epoch [315/500], Validation Loss: 1.9645, Validation RMSE: 1.4016, Valid PR: 0.3487\n",
      "Epoch [316/500], Train Loss: 0.5893, Train RMSE: 0.7677\n",
      "Epoch [316/500], Validation Loss: 1.9775, Validation RMSE: 1.4062, Valid PR: 0.3436\n",
      "Epoch [317/500], Train Loss: 0.6143, Train RMSE: 0.7838\n",
      "Epoch [317/500], Validation Loss: 2.0146, Validation RMSE: 1.4194, Valid PR: 0.3318\n",
      "Epoch [318/500], Train Loss: 0.5756, Train RMSE: 0.7587\n",
      "Epoch [318/500], Validation Loss: 2.0584, Validation RMSE: 1.4347, Valid PR: 0.3175\n",
      "Epoch [319/500], Train Loss: 0.6526, Train RMSE: 0.8078\n",
      "Epoch [319/500], Validation Loss: 2.0818, Validation RMSE: 1.4429, Valid PR: 0.3089\n",
      "Epoch [320/500], Train Loss: 0.5620, Train RMSE: 0.7496\n",
      "Epoch [320/500], Validation Loss: 2.0816, Validation RMSE: 1.4428, Valid PR: 0.3061\n",
      "Epoch [321/500], Train Loss: 0.5034, Train RMSE: 0.7095\n",
      "Epoch [321/500], Validation Loss: 2.0440, Validation RMSE: 1.4297, Valid PR: 0.3148\n",
      "Epoch [322/500], Train Loss: 0.5667, Train RMSE: 0.7528\n",
      "Epoch [322/500], Validation Loss: 2.0391, Validation RMSE: 1.4280, Valid PR: 0.3129\n",
      "Epoch [323/500], Train Loss: 0.6269, Train RMSE: 0.7918\n",
      "Epoch [323/500], Validation Loss: 2.0392, Validation RMSE: 1.4280, Valid PR: 0.3120\n",
      "Epoch [324/500], Train Loss: 0.6102, Train RMSE: 0.7811\n",
      "Epoch [324/500], Validation Loss: 2.0673, Validation RMSE: 1.4378, Valid PR: 0.3036\n",
      "Epoch [325/500], Train Loss: 0.6518, Train RMSE: 0.8073\n",
      "Epoch [325/500], Validation Loss: 2.0625, Validation RMSE: 1.4361, Valid PR: 0.3044\n",
      "Epoch [326/500], Train Loss: 0.5982, Train RMSE: 0.7735\n",
      "Epoch [326/500], Validation Loss: 2.0398, Validation RMSE: 1.4282, Valid PR: 0.3111\n",
      "Epoch [327/500], Train Loss: 0.6783, Train RMSE: 0.8236\n",
      "Epoch [327/500], Validation Loss: 1.9920, Validation RMSE: 1.4114, Valid PR: 0.3264\n",
      "Epoch [328/500], Train Loss: 0.6331, Train RMSE: 0.7957\n",
      "Epoch [328/500], Validation Loss: 1.9764, Validation RMSE: 1.4058, Valid PR: 0.3323\n",
      "Epoch [329/500], Train Loss: 0.5887, Train RMSE: 0.7673\n",
      "Epoch [329/500], Validation Loss: 2.0265, Validation RMSE: 1.4235, Valid PR: 0.3168\n",
      "Epoch [330/500], Train Loss: 0.5679, Train RMSE: 0.7536\n",
      "Epoch [330/500], Validation Loss: 2.0595, Validation RMSE: 1.4351, Valid PR: 0.3078\n",
      "Epoch [331/500], Train Loss: 0.5485, Train RMSE: 0.7406\n",
      "Epoch [331/500], Validation Loss: 2.1036, Validation RMSE: 1.4504, Valid PR: 0.2949\n",
      "Epoch [332/500], Train Loss: 0.5699, Train RMSE: 0.7549\n",
      "Epoch [332/500], Validation Loss: 2.1041, Validation RMSE: 1.4505, Valid PR: 0.2947\n",
      "Epoch [333/500], Train Loss: 0.6559, Train RMSE: 0.8099\n",
      "Epoch [333/500], Validation Loss: 2.0819, Validation RMSE: 1.4429, Valid PR: 0.3004\n",
      "Epoch [334/500], Train Loss: 0.6168, Train RMSE: 0.7854\n",
      "Epoch [334/500], Validation Loss: 2.0493, Validation RMSE: 1.4315, Valid PR: 0.3086\n",
      "Epoch [335/500], Train Loss: 0.5458, Train RMSE: 0.7388\n",
      "Epoch [335/500], Validation Loss: 2.0258, Validation RMSE: 1.4233, Valid PR: 0.3172\n",
      "Epoch [336/500], Train Loss: 0.6083, Train RMSE: 0.7800\n",
      "Epoch [336/500], Validation Loss: 2.0222, Validation RMSE: 1.4220, Valid PR: 0.3188\n",
      "Epoch [337/500], Train Loss: 0.6672, Train RMSE: 0.8168\n",
      "Epoch [337/500], Validation Loss: 2.0285, Validation RMSE: 1.4243, Valid PR: 0.3173\n",
      "Epoch [338/500], Train Loss: 0.6063, Train RMSE: 0.7786\n",
      "Epoch [338/500], Validation Loss: 2.0264, Validation RMSE: 1.4235, Valid PR: 0.3179\n",
      "Epoch [339/500], Train Loss: 0.5925, Train RMSE: 0.7697\n",
      "Epoch [339/500], Validation Loss: 2.0164, Validation RMSE: 1.4200, Valid PR: 0.3215\n",
      "Epoch [340/500], Train Loss: 0.5792, Train RMSE: 0.7611\n",
      "Epoch [340/500], Validation Loss: 2.1143, Validation RMSE: 1.4541, Valid PR: 0.2948\n",
      "Epoch [341/500], Train Loss: 0.6029, Train RMSE: 0.7765\n",
      "Epoch [341/500], Validation Loss: 2.2028, Validation RMSE: 1.4842, Valid PR: 0.2727\n",
      "Epoch [342/500], Train Loss: 0.5896, Train RMSE: 0.7679\n",
      "Epoch [342/500], Validation Loss: 2.1572, Validation RMSE: 1.4688, Valid PR: 0.2905\n",
      "Epoch [343/500], Train Loss: 0.5704, Train RMSE: 0.7552\n",
      "Epoch [343/500], Validation Loss: 1.9884, Validation RMSE: 1.4101, Valid PR: 0.3401\n",
      "Epoch [344/500], Train Loss: 0.5318, Train RMSE: 0.7292\n",
      "Epoch [344/500], Validation Loss: 1.9151, Validation RMSE: 1.3839, Valid PR: 0.3660\n",
      "Epoch [345/500], Train Loss: 0.6149, Train RMSE: 0.7842\n",
      "Epoch [345/500], Validation Loss: 1.9020, Validation RMSE: 1.3791, Valid PR: 0.3723\n",
      "Epoch [346/500], Train Loss: 0.5914, Train RMSE: 0.7690\n",
      "Epoch [346/500], Validation Loss: 1.9740, Validation RMSE: 1.4050, Valid PR: 0.3541\n",
      "Epoch [347/500], Train Loss: 0.5629, Train RMSE: 0.7502\n",
      "Epoch [347/500], Validation Loss: 2.1367, Validation RMSE: 1.4617, Valid PR: 0.3190\n",
      "Epoch [348/500], Train Loss: 0.5692, Train RMSE: 0.7545\n",
      "Epoch [348/500], Validation Loss: 2.1782, Validation RMSE: 1.4759, Valid PR: 0.3121\n",
      "Epoch [349/500], Train Loss: 0.6371, Train RMSE: 0.7982\n",
      "Epoch [349/500], Validation Loss: 2.1341, Validation RMSE: 1.4609, Valid PR: 0.3239\n",
      "Epoch [350/500], Train Loss: 0.5443, Train RMSE: 0.7378\n",
      "Epoch [350/500], Validation Loss: 2.0130, Validation RMSE: 1.4188, Valid PR: 0.3514\n",
      "Epoch [351/500], Train Loss: 0.5692, Train RMSE: 0.7545\n",
      "Epoch [351/500], Validation Loss: 1.9099, Validation RMSE: 1.3820, Valid PR: 0.3753\n",
      "Epoch [352/500], Train Loss: 0.6234, Train RMSE: 0.7896\n",
      "Epoch [352/500], Validation Loss: 1.8882, Validation RMSE: 1.3741, Valid PR: 0.3812\n",
      "Epoch [353/500], Train Loss: 0.6143, Train RMSE: 0.7838\n",
      "Epoch [353/500], Validation Loss: 1.9571, Validation RMSE: 1.3990, Valid PR: 0.3635\n",
      "Epoch [354/500], Train Loss: 0.5807, Train RMSE: 0.7620\n",
      "Epoch [354/500], Validation Loss: 2.1334, Validation RMSE: 1.4606, Valid PR: 0.3237\n",
      "Epoch [355/500], Train Loss: 0.5838, Train RMSE: 0.7641\n",
      "Epoch [355/500], Validation Loss: 2.1827, Validation RMSE: 1.4774, Valid PR: 0.3107\n",
      "Epoch [356/500], Train Loss: 0.6323, Train RMSE: 0.7952\n",
      "Epoch [356/500], Validation Loss: 2.1757, Validation RMSE: 1.4750, Valid PR: 0.3115\n",
      "Epoch [357/500], Train Loss: 0.5798, Train RMSE: 0.7614\n",
      "Epoch [357/500], Validation Loss: 2.0007, Validation RMSE: 1.4145, Valid PR: 0.3514\n",
      "Epoch [358/500], Train Loss: 0.4897, Train RMSE: 0.6998\n",
      "Epoch [358/500], Validation Loss: 1.8928, Validation RMSE: 1.3758, Valid PR: 0.3788\n",
      "Epoch [359/500], Train Loss: 0.6895, Train RMSE: 0.8303\n",
      "Epoch [359/500], Validation Loss: 1.8942, Validation RMSE: 1.3763, Valid PR: 0.3774\n",
      "Epoch [360/500], Train Loss: 0.6106, Train RMSE: 0.7814\n",
      "Epoch [360/500], Validation Loss: 2.0492, Validation RMSE: 1.4315, Valid PR: 0.3334\n",
      "Epoch [361/500], Train Loss: 0.6091, Train RMSE: 0.7805\n",
      "Epoch [361/500], Validation Loss: 2.1002, Validation RMSE: 1.4492, Valid PR: 0.3174\n",
      "Epoch [362/500], Train Loss: 0.5980, Train RMSE: 0.7733\n",
      "Epoch [362/500], Validation Loss: 2.0522, Validation RMSE: 1.4325, Valid PR: 0.3249\n",
      "Epoch [363/500], Train Loss: 0.5314, Train RMSE: 0.7290\n",
      "Epoch [363/500], Validation Loss: 2.0345, Validation RMSE: 1.4264, Valid PR: 0.3252\n",
      "Epoch [364/500], Train Loss: 0.5515, Train RMSE: 0.7426\n",
      "Epoch [364/500], Validation Loss: 1.9892, Validation RMSE: 1.4104, Valid PR: 0.3353\n",
      "Epoch [365/500], Train Loss: 0.5554, Train RMSE: 0.7452\n",
      "Epoch [365/500], Validation Loss: 2.0356, Validation RMSE: 1.4268, Valid PR: 0.3165\n",
      "Epoch [366/500], Train Loss: 0.6459, Train RMSE: 0.8037\n",
      "Epoch [366/500], Validation Loss: 2.1228, Validation RMSE: 1.4570, Valid PR: 0.2866\n",
      "Epoch [367/500], Train Loss: 0.5377, Train RMSE: 0.7333\n",
      "Epoch [367/500], Validation Loss: 2.0890, Validation RMSE: 1.4453, Valid PR: 0.2937\n",
      "Epoch [368/500], Train Loss: 0.5488, Train RMSE: 0.7408\n",
      "Epoch [368/500], Validation Loss: 1.9938, Validation RMSE: 1.4120, Valid PR: 0.3282\n",
      "Epoch [369/500], Train Loss: 0.5644, Train RMSE: 0.7513\n",
      "Epoch [369/500], Validation Loss: 2.1200, Validation RMSE: 1.4560, Valid PR: 0.2817\n",
      "Epoch [370/500], Train Loss: 0.4588, Train RMSE: 0.6774\n",
      "Epoch [370/500], Validation Loss: 2.3369, Validation RMSE: 1.5287, Valid PR: 0.2236\n",
      "Epoch [371/500], Train Loss: 0.5719, Train RMSE: 0.7563\n",
      "Epoch [371/500], Validation Loss: 2.2415, Validation RMSE: 1.4972, Valid PR: 0.2504\n",
      "Epoch [372/500], Train Loss: 0.5480, Train RMSE: 0.7402\n",
      "Epoch [372/500], Validation Loss: 1.9916, Validation RMSE: 1.4112, Valid PR: 0.3275\n",
      "Epoch [373/500], Train Loss: 0.5128, Train RMSE: 0.7161\n",
      "Epoch [373/500], Validation Loss: 1.9838, Validation RMSE: 1.4085, Valid PR: 0.3605\n",
      "Epoch [374/500], Train Loss: 0.6521, Train RMSE: 0.8075\n",
      "Epoch [374/500], Validation Loss: 2.1575, Validation RMSE: 1.4688, Valid PR: 0.2711\n",
      "Epoch [375/500], Train Loss: 0.5979, Train RMSE: 0.7732\n",
      "Epoch [375/500], Validation Loss: 2.3996, Validation RMSE: 1.5490, Valid PR: 0.2068\n",
      "Epoch [376/500], Train Loss: 0.5881, Train RMSE: 0.7669\n",
      "Epoch [376/500], Validation Loss: 2.2394, Validation RMSE: 1.4964, Valid PR: 0.2479\n",
      "Epoch [377/500], Train Loss: 0.6595, Train RMSE: 0.8121\n",
      "Epoch [377/500], Validation Loss: 1.9940, Validation RMSE: 1.4121, Valid PR: 0.3767\n",
      "Epoch [378/500], Train Loss: 0.6134, Train RMSE: 0.7832\n",
      "Epoch [378/500], Validation Loss: 1.9680, Validation RMSE: 1.4029, Valid PR: 0.3560\n",
      "Epoch [379/500], Train Loss: 0.5603, Train RMSE: 0.7485\n",
      "Epoch [379/500], Validation Loss: 2.3847, Validation RMSE: 1.5443, Valid PR: 0.2051\n",
      "Epoch [380/500], Train Loss: 0.5424, Train RMSE: 0.7365\n",
      "Epoch [380/500], Validation Loss: 2.5344, Validation RMSE: 1.5920, Valid PR: 0.1593\n",
      "Epoch [381/500], Train Loss: 0.4922, Train RMSE: 0.7016\n",
      "Epoch [381/500], Validation Loss: 2.3229, Validation RMSE: 1.5241, Valid PR: 0.2266\n",
      "Epoch [382/500], Train Loss: 0.5750, Train RMSE: 0.7583\n",
      "Epoch [382/500], Validation Loss: 1.9622, Validation RMSE: 1.4008, Valid PR: 0.3672\n",
      "Epoch [383/500], Train Loss: 0.5550, Train RMSE: 0.7450\n",
      "Epoch [383/500], Validation Loss: 1.9883, Validation RMSE: 1.4101, Valid PR: 0.3791\n",
      "Epoch [384/500], Train Loss: 0.7285, Train RMSE: 0.8535\n",
      "Epoch [384/500], Validation Loss: 2.1423, Validation RMSE: 1.4637, Valid PR: 0.2830\n",
      "Epoch [385/500], Train Loss: 0.5754, Train RMSE: 0.7585\n",
      "Epoch [385/500], Validation Loss: 2.3393, Validation RMSE: 1.5295, Valid PR: 0.2270\n",
      "Epoch [386/500], Train Loss: 0.6625, Train RMSE: 0.8139\n",
      "Epoch [386/500], Validation Loss: 2.1612, Validation RMSE: 1.4701, Valid PR: 0.2778\n",
      "Epoch [387/500], Train Loss: 0.4862, Train RMSE: 0.6973\n",
      "Epoch [387/500], Validation Loss: 1.9888, Validation RMSE: 1.4102, Valid PR: 0.3469\n",
      "Epoch [388/500], Train Loss: 0.5090, Train RMSE: 0.7134\n",
      "Epoch [388/500], Validation Loss: 1.9966, Validation RMSE: 1.4130, Valid PR: 0.3492\n",
      "Epoch [389/500], Train Loss: 0.5430, Train RMSE: 0.7369\n",
      "Epoch [389/500], Validation Loss: 2.1348, Validation RMSE: 1.4611, Valid PR: 0.2851\n",
      "Epoch [390/500], Train Loss: 0.5658, Train RMSE: 0.7522\n",
      "Epoch [390/500], Validation Loss: 2.2757, Validation RMSE: 1.5085, Valid PR: 0.2404\n",
      "Epoch [391/500], Train Loss: 0.4893, Train RMSE: 0.6995\n",
      "Epoch [391/500], Validation Loss: 2.1509, Validation RMSE: 1.4666, Valid PR: 0.2757\n",
      "Epoch [392/500], Train Loss: 0.4416, Train RMSE: 0.6645\n",
      "Epoch [392/500], Validation Loss: 2.0797, Validation RMSE: 1.4421, Valid PR: 0.3027\n",
      "Epoch [393/500], Train Loss: 0.4974, Train RMSE: 0.7053\n",
      "Epoch [393/500], Validation Loss: 2.0688, Validation RMSE: 1.4383, Valid PR: 0.3188\n",
      "Epoch [394/500], Train Loss: 0.4952, Train RMSE: 0.7037\n",
      "Epoch [394/500], Validation Loss: 2.1133, Validation RMSE: 1.4537, Valid PR: 0.2895\n",
      "Epoch [395/500], Train Loss: 0.4578, Train RMSE: 0.6766\n",
      "Epoch [395/500], Validation Loss: 2.2655, Validation RMSE: 1.5052, Valid PR: 0.2278\n",
      "Epoch [396/500], Train Loss: 0.4602, Train RMSE: 0.6784\n",
      "Epoch [396/500], Validation Loss: 2.3261, Validation RMSE: 1.5251, Valid PR: 0.2030\n",
      "Epoch [397/500], Train Loss: 0.5421, Train RMSE: 0.7363\n",
      "Epoch [397/500], Validation Loss: 2.1931, Validation RMSE: 1.4809, Valid PR: 0.2547\n",
      "Epoch [398/500], Train Loss: 0.4635, Train RMSE: 0.6808\n",
      "Epoch [398/500], Validation Loss: 2.1752, Validation RMSE: 1.4748, Valid PR: 0.3037\n",
      "Epoch [399/500], Train Loss: 0.5641, Train RMSE: 0.7511\n",
      "Epoch [399/500], Validation Loss: 2.2448, Validation RMSE: 1.4983, Valid PR: 0.2326\n",
      "Epoch [400/500], Train Loss: 0.5644, Train RMSE: 0.7512\n",
      "Epoch [400/500], Validation Loss: 2.4075, Validation RMSE: 1.5516, Valid PR: 0.1589\n",
      "Epoch [401/500], Train Loss: 0.5356, Train RMSE: 0.7319\n",
      "Epoch [401/500], Validation Loss: 2.3114, Validation RMSE: 1.5203, Valid PR: 0.2056\n",
      "Epoch [402/500], Train Loss: 0.5441, Train RMSE: 0.7376\n",
      "Epoch [402/500], Validation Loss: 2.3227, Validation RMSE: 1.5240, Valid PR: 0.2921\n",
      "Early stopping triggered.\n",
      "Test Loss: 3.4548, Test RMSE: 1.8587, Test PR: -0.1143\n",
      "Replication 3 for method2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:122: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 11.4360, Train RMSE: 3.3817\n",
      "Epoch [1/500], Validation Loss: 20.0828, Validation RMSE: 4.4814, Valid PR: 0.8253\n",
      "Epoch [2/500], Train Loss: 5.6826, Train RMSE: 2.3838\n",
      "Epoch [2/500], Validation Loss: 14.9857, Validation RMSE: 3.8711, Valid PR: 0.2111\n",
      "Epoch [3/500], Train Loss: 4.3959, Train RMSE: 2.0966\n",
      "Epoch [3/500], Validation Loss: 12.6134, Validation RMSE: 3.5515, Valid PR: 0.0708\n",
      "Epoch [4/500], Train Loss: 3.7374, Train RMSE: 1.9332\n",
      "Epoch [4/500], Validation Loss: 11.2464, Validation RMSE: 3.3536, Valid PR: -0.0818\n",
      "Epoch [5/500], Train Loss: 3.2896, Train RMSE: 1.8137\n",
      "Epoch [5/500], Validation Loss: 10.3516, Validation RMSE: 3.2174, Valid PR: 0.1605\n",
      "Epoch [6/500], Train Loss: 3.0816, Train RMSE: 1.7554\n",
      "Epoch [6/500], Validation Loss: 9.6448, Validation RMSE: 3.1056, Valid PR: 0.3397\n",
      "Epoch [7/500], Train Loss: 2.9244, Train RMSE: 1.7101\n",
      "Epoch [7/500], Validation Loss: 9.1260, Validation RMSE: 3.0209, Valid PR: 0.4761\n",
      "Epoch [8/500], Train Loss: 2.7768, Train RMSE: 1.6664\n",
      "Epoch [8/500], Validation Loss: 8.7493, Validation RMSE: 2.9579, Valid PR: 0.4843\n",
      "Epoch [9/500], Train Loss: 2.7752, Train RMSE: 1.6659\n",
      "Epoch [9/500], Validation Loss: 8.4533, Validation RMSE: 2.9075, Valid PR: 0.4836\n",
      "Epoch [10/500], Train Loss: 2.6347, Train RMSE: 1.6232\n",
      "Epoch [10/500], Validation Loss: 8.2079, Validation RMSE: 2.8649, Valid PR: 0.4404\n",
      "Epoch [11/500], Train Loss: 2.5170, Train RMSE: 1.5865\n",
      "Epoch [11/500], Validation Loss: 8.0097, Validation RMSE: 2.8301, Valid PR: 0.4012\n",
      "Epoch [12/500], Train Loss: 2.4526, Train RMSE: 1.5661\n",
      "Epoch [12/500], Validation Loss: 7.8441, Validation RMSE: 2.8007, Valid PR: 0.3006\n",
      "Epoch [13/500], Train Loss: 2.4568, Train RMSE: 1.5674\n",
      "Epoch [13/500], Validation Loss: 7.6975, Validation RMSE: 2.7744, Valid PR: 0.2661\n",
      "Epoch [14/500], Train Loss: 2.3326, Train RMSE: 1.5273\n",
      "Epoch [14/500], Validation Loss: 7.5656, Validation RMSE: 2.7506, Valid PR: 0.1802\n",
      "Epoch [15/500], Train Loss: 2.3529, Train RMSE: 1.5339\n",
      "Epoch [15/500], Validation Loss: 7.4531, Validation RMSE: 2.7300, Valid PR: 0.0201\n",
      "Epoch [16/500], Train Loss: 2.4297, Train RMSE: 1.5588\n",
      "Epoch [16/500], Validation Loss: 7.3575, Validation RMSE: 2.7125, Valid PR: -0.1808\n",
      "Epoch [17/500], Train Loss: 2.3169, Train RMSE: 1.5221\n",
      "Epoch [17/500], Validation Loss: 7.2744, Validation RMSE: 2.6971, Valid PR: -0.3530\n",
      "Epoch [18/500], Train Loss: 2.3603, Train RMSE: 1.5363\n",
      "Epoch [18/500], Validation Loss: 7.1987, Validation RMSE: 2.6830, Valid PR: -0.4600\n",
      "Epoch [19/500], Train Loss: 2.3340, Train RMSE: 1.5278\n",
      "Epoch [19/500], Validation Loss: 7.1266, Validation RMSE: 2.6696, Valid PR: -0.5214\n",
      "Epoch [20/500], Train Loss: 2.2174, Train RMSE: 1.4891\n",
      "Epoch [20/500], Validation Loss: 7.0525, Validation RMSE: 2.6557, Valid PR: -0.5521\n",
      "Epoch [21/500], Train Loss: 2.1931, Train RMSE: 1.4809\n",
      "Epoch [21/500], Validation Loss: 6.9749, Validation RMSE: 2.6410, Valid PR: -0.5674\n",
      "Epoch [22/500], Train Loss: 2.1629, Train RMSE: 1.4707\n",
      "Epoch [22/500], Validation Loss: 6.8934, Validation RMSE: 2.6255, Valid PR: -0.5732\n",
      "Epoch [23/500], Train Loss: 2.1735, Train RMSE: 1.4743\n",
      "Epoch [23/500], Validation Loss: 6.8085, Validation RMSE: 2.6093, Valid PR: -0.5680\n",
      "Epoch [24/500], Train Loss: 2.2158, Train RMSE: 1.4886\n",
      "Epoch [24/500], Validation Loss: 6.7228, Validation RMSE: 2.5928, Valid PR: -0.5650\n",
      "Epoch [25/500], Train Loss: 2.0062, Train RMSE: 1.4164\n",
      "Epoch [25/500], Validation Loss: 6.6371, Validation RMSE: 2.5763, Valid PR: -0.5616\n",
      "Epoch [26/500], Train Loss: 2.0820, Train RMSE: 1.4429\n",
      "Epoch [26/500], Validation Loss: 6.5534, Validation RMSE: 2.5600, Valid PR: -0.5555\n",
      "Epoch [27/500], Train Loss: 2.1418, Train RMSE: 1.4635\n",
      "Epoch [27/500], Validation Loss: 6.4728, Validation RMSE: 2.5442, Valid PR: -0.5519\n",
      "Epoch [28/500], Train Loss: 2.0874, Train RMSE: 1.4448\n",
      "Epoch [28/500], Validation Loss: 6.3953, Validation RMSE: 2.5289, Valid PR: -0.5451\n",
      "Epoch [29/500], Train Loss: 2.0150, Train RMSE: 1.4195\n",
      "Epoch [29/500], Validation Loss: 6.3205, Validation RMSE: 2.5141, Valid PR: -0.5388\n",
      "Epoch [30/500], Train Loss: 2.0245, Train RMSE: 1.4229\n",
      "Epoch [30/500], Validation Loss: 6.2486, Validation RMSE: 2.4997, Valid PR: -0.5323\n",
      "Epoch [31/500], Train Loss: 1.9692, Train RMSE: 1.4033\n",
      "Epoch [31/500], Validation Loss: 6.1787, Validation RMSE: 2.4857, Valid PR: -0.5242\n",
      "Epoch [32/500], Train Loss: 1.9965, Train RMSE: 1.4130\n",
      "Epoch [32/500], Validation Loss: 6.1105, Validation RMSE: 2.4719, Valid PR: -0.5118\n",
      "Epoch [33/500], Train Loss: 1.9317, Train RMSE: 1.3899\n",
      "Epoch [33/500], Validation Loss: 6.0435, Validation RMSE: 2.4583, Valid PR: -0.4873\n",
      "Epoch [34/500], Train Loss: 1.9125, Train RMSE: 1.3829\n",
      "Epoch [34/500], Validation Loss: 5.9772, Validation RMSE: 2.4448, Valid PR: -0.3959\n",
      "Epoch [35/500], Train Loss: 2.0007, Train RMSE: 1.4144\n",
      "Epoch [35/500], Validation Loss: 5.9113, Validation RMSE: 2.4313, Valid PR: -0.1971\n",
      "Epoch [36/500], Train Loss: 2.0760, Train RMSE: 1.4408\n",
      "Epoch [36/500], Validation Loss: 5.8461, Validation RMSE: 2.4179, Valid PR: 0.0446\n",
      "Epoch [37/500], Train Loss: 1.9372, Train RMSE: 1.3918\n",
      "Epoch [37/500], Validation Loss: 5.7817, Validation RMSE: 2.4045, Valid PR: 0.1725\n",
      "Epoch [38/500], Train Loss: 2.0038, Train RMSE: 1.4155\n",
      "Epoch [38/500], Validation Loss: 5.7179, Validation RMSE: 2.3912, Valid PR: 0.2958\n",
      "Epoch [39/500], Train Loss: 1.8032, Train RMSE: 1.3428\n",
      "Epoch [39/500], Validation Loss: 5.6548, Validation RMSE: 2.3780, Valid PR: 0.3569\n",
      "Epoch [40/500], Train Loss: 1.8714, Train RMSE: 1.3680\n",
      "Epoch [40/500], Validation Loss: 5.5929, Validation RMSE: 2.3649, Valid PR: 0.3934\n",
      "Epoch [41/500], Train Loss: 1.8264, Train RMSE: 1.3514\n",
      "Epoch [41/500], Validation Loss: 5.5323, Validation RMSE: 2.3521, Valid PR: 0.4273\n",
      "Epoch [42/500], Train Loss: 1.7977, Train RMSE: 1.3408\n",
      "Epoch [42/500], Validation Loss: 5.4725, Validation RMSE: 2.3393, Valid PR: 0.4552\n",
      "Epoch [43/500], Train Loss: 1.8644, Train RMSE: 1.3654\n",
      "Epoch [43/500], Validation Loss: 5.4129, Validation RMSE: 2.3266, Valid PR: 0.4673\n",
      "Epoch [44/500], Train Loss: 1.6559, Train RMSE: 1.2868\n",
      "Epoch [44/500], Validation Loss: 5.3541, Validation RMSE: 2.3139, Valid PR: 0.4730\n",
      "Epoch [45/500], Train Loss: 1.7108, Train RMSE: 1.3080\n",
      "Epoch [45/500], Validation Loss: 5.2961, Validation RMSE: 2.3013, Valid PR: 0.4761\n",
      "Epoch [46/500], Train Loss: 1.7028, Train RMSE: 1.3049\n",
      "Epoch [46/500], Validation Loss: 5.2390, Validation RMSE: 2.2889, Valid PR: 0.4794\n",
      "Epoch [47/500], Train Loss: 1.6900, Train RMSE: 1.3000\n",
      "Epoch [47/500], Validation Loss: 5.1828, Validation RMSE: 2.2766, Valid PR: 0.4837\n",
      "Epoch [48/500], Train Loss: 1.7733, Train RMSE: 1.3316\n",
      "Epoch [48/500], Validation Loss: 5.1268, Validation RMSE: 2.2643, Valid PR: 0.4804\n",
      "Epoch [49/500], Train Loss: 1.7500, Train RMSE: 1.3229\n",
      "Epoch [49/500], Validation Loss: 5.0715, Validation RMSE: 2.2520, Valid PR: 0.4820\n",
      "Epoch [50/500], Train Loss: 1.6670, Train RMSE: 1.2911\n",
      "Epoch [50/500], Validation Loss: 5.0168, Validation RMSE: 2.2398, Valid PR: 0.4835\n",
      "Epoch [51/500], Train Loss: 1.6403, Train RMSE: 1.2807\n",
      "Epoch [51/500], Validation Loss: 4.9628, Validation RMSE: 2.2277, Valid PR: 0.4805\n",
      "Epoch [52/500], Train Loss: 1.7433, Train RMSE: 1.3203\n",
      "Epoch [52/500], Validation Loss: 4.9096, Validation RMSE: 2.2158, Valid PR: 0.4502\n",
      "Epoch [53/500], Train Loss: 1.5751, Train RMSE: 1.2550\n",
      "Epoch [53/500], Validation Loss: 4.8569, Validation RMSE: 2.2038, Valid PR: 0.3595\n",
      "Epoch [54/500], Train Loss: 1.6819, Train RMSE: 1.2969\n",
      "Epoch [54/500], Validation Loss: 4.8050, Validation RMSE: 2.1920, Valid PR: 0.0723\n",
      "Epoch [55/500], Train Loss: 1.6187, Train RMSE: 1.2723\n",
      "Epoch [55/500], Validation Loss: 4.7540, Validation RMSE: 2.1804, Valid PR: -0.3058\n",
      "Epoch [56/500], Train Loss: 1.6109, Train RMSE: 1.2692\n",
      "Epoch [56/500], Validation Loss: 4.7037, Validation RMSE: 2.1688, Valid PR: -0.4202\n",
      "Epoch [57/500], Train Loss: 1.6094, Train RMSE: 1.2686\n",
      "Epoch [57/500], Validation Loss: 4.6543, Validation RMSE: 2.1574, Valid PR: -0.4488\n",
      "Epoch [58/500], Train Loss: 1.4375, Train RMSE: 1.1990\n",
      "Epoch [58/500], Validation Loss: 4.6053, Validation RMSE: 2.1460, Valid PR: -0.4559\n",
      "Epoch [59/500], Train Loss: 1.5302, Train RMSE: 1.2370\n",
      "Epoch [59/500], Validation Loss: 4.5568, Validation RMSE: 2.1347, Valid PR: -0.4539\n",
      "Epoch [60/500], Train Loss: 1.5840, Train RMSE: 1.2586\n",
      "Epoch [60/500], Validation Loss: 4.5086, Validation RMSE: 2.1234, Valid PR: -0.4358\n",
      "Epoch [61/500], Train Loss: 1.3479, Train RMSE: 1.1610\n",
      "Epoch [61/500], Validation Loss: 4.4607, Validation RMSE: 2.1120, Valid PR: -0.4131\n",
      "Epoch [62/500], Train Loss: 1.4965, Train RMSE: 1.2233\n",
      "Epoch [62/500], Validation Loss: 4.4138, Validation RMSE: 2.1009, Valid PR: -0.3755\n",
      "Epoch [63/500], Train Loss: 1.5517, Train RMSE: 1.2457\n",
      "Epoch [63/500], Validation Loss: 4.3679, Validation RMSE: 2.0899, Valid PR: -0.3008\n",
      "Epoch [64/500], Train Loss: 1.5338, Train RMSE: 1.2385\n",
      "Epoch [64/500], Validation Loss: 4.3224, Validation RMSE: 2.0790, Valid PR: -0.1599\n",
      "Epoch [65/500], Train Loss: 1.3853, Train RMSE: 1.1770\n",
      "Epoch [65/500], Validation Loss: 4.2776, Validation RMSE: 2.0682, Valid PR: 0.5454\n",
      "Epoch [66/500], Train Loss: 1.4425, Train RMSE: 1.2010\n",
      "Epoch [66/500], Validation Loss: 4.2336, Validation RMSE: 2.0576, Valid PR: 0.7206\n",
      "Epoch [67/500], Train Loss: 1.4116, Train RMSE: 1.1881\n",
      "Epoch [67/500], Validation Loss: 4.1903, Validation RMSE: 2.0470, Valid PR: 0.5936\n",
      "Epoch [68/500], Train Loss: 1.3700, Train RMSE: 1.1705\n",
      "Epoch [68/500], Validation Loss: 4.1477, Validation RMSE: 2.0366, Valid PR: 0.5484\n",
      "Epoch [69/500], Train Loss: 1.4418, Train RMSE: 1.2007\n",
      "Epoch [69/500], Validation Loss: 4.1057, Validation RMSE: 2.0263, Valid PR: 0.5133\n",
      "Epoch [70/500], Train Loss: 1.4124, Train RMSE: 1.1885\n",
      "Epoch [70/500], Validation Loss: 4.0643, Validation RMSE: 2.0160, Valid PR: 0.4944\n",
      "Epoch [71/500], Train Loss: 1.3787, Train RMSE: 1.1742\n",
      "Epoch [71/500], Validation Loss: 4.0233, Validation RMSE: 2.0058, Valid PR: 0.4835\n",
      "Epoch [72/500], Train Loss: 1.3979, Train RMSE: 1.1823\n",
      "Epoch [72/500], Validation Loss: 3.9825, Validation RMSE: 1.9956, Valid PR: 0.4665\n",
      "Epoch [73/500], Train Loss: 1.4267, Train RMSE: 1.1945\n",
      "Epoch [73/500], Validation Loss: 3.9425, Validation RMSE: 1.9856, Valid PR: 0.4586\n",
      "Epoch [74/500], Train Loss: 1.3414, Train RMSE: 1.1582\n",
      "Epoch [74/500], Validation Loss: 3.9030, Validation RMSE: 1.9756, Valid PR: 0.4435\n",
      "Epoch [75/500], Train Loss: 1.3177, Train RMSE: 1.1479\n",
      "Epoch [75/500], Validation Loss: 3.8641, Validation RMSE: 1.9657, Valid PR: 0.4297\n",
      "Epoch [76/500], Train Loss: 1.2596, Train RMSE: 1.1223\n",
      "Epoch [76/500], Validation Loss: 3.8259, Validation RMSE: 1.9560, Valid PR: 0.4066\n",
      "Epoch [77/500], Train Loss: 1.3053, Train RMSE: 1.1425\n",
      "Epoch [77/500], Validation Loss: 3.7884, Validation RMSE: 1.9464, Valid PR: 0.3803\n",
      "Epoch [78/500], Train Loss: 1.3241, Train RMSE: 1.1507\n",
      "Epoch [78/500], Validation Loss: 3.7514, Validation RMSE: 1.9369, Valid PR: 0.3709\n",
      "Epoch [79/500], Train Loss: 1.2512, Train RMSE: 1.1186\n",
      "Epoch [79/500], Validation Loss: 3.7150, Validation RMSE: 1.9274, Valid PR: 0.3631\n",
      "Epoch [80/500], Train Loss: 1.2111, Train RMSE: 1.1005\n",
      "Epoch [80/500], Validation Loss: 3.6792, Validation RMSE: 1.9181, Valid PR: 0.3163\n",
      "Epoch [81/500], Train Loss: 1.2487, Train RMSE: 1.1175\n",
      "Epoch [81/500], Validation Loss: 3.6441, Validation RMSE: 1.9090, Valid PR: 0.2134\n",
      "Epoch [82/500], Train Loss: 1.2399, Train RMSE: 1.1135\n",
      "Epoch [82/500], Validation Loss: 3.6097, Validation RMSE: 1.8999, Valid PR: 0.1199\n",
      "Epoch [83/500], Train Loss: 1.1542, Train RMSE: 1.0743\n",
      "Epoch [83/500], Validation Loss: 3.5760, Validation RMSE: 1.8910, Valid PR: -0.1576\n",
      "Epoch [84/500], Train Loss: 1.3166, Train RMSE: 1.1474\n",
      "Epoch [84/500], Validation Loss: 3.5427, Validation RMSE: 1.8822, Valid PR: -0.2671\n",
      "Epoch [85/500], Train Loss: 1.2497, Train RMSE: 1.1179\n",
      "Epoch [85/500], Validation Loss: 3.5102, Validation RMSE: 1.8735, Valid PR: -0.3432\n",
      "Epoch [86/500], Train Loss: 1.2526, Train RMSE: 1.1192\n",
      "Epoch [86/500], Validation Loss: 3.4786, Validation RMSE: 1.8651, Valid PR: -0.3738\n",
      "Epoch [87/500], Train Loss: 1.2792, Train RMSE: 1.1310\n",
      "Epoch [87/500], Validation Loss: 3.4479, Validation RMSE: 1.8568, Valid PR: -0.3201\n",
      "Epoch [88/500], Train Loss: 1.3413, Train RMSE: 1.1581\n",
      "Epoch [88/500], Validation Loss: 3.4175, Validation RMSE: 1.8487, Valid PR: -0.1191\n",
      "Epoch [89/500], Train Loss: 1.1599, Train RMSE: 1.0770\n",
      "Epoch [89/500], Validation Loss: 3.3873, Validation RMSE: 1.8405, Valid PR: -0.0257\n",
      "Epoch [90/500], Train Loss: 1.0768, Train RMSE: 1.0377\n",
      "Epoch [90/500], Validation Loss: 3.3572, Validation RMSE: 1.8323, Valid PR: 0.0739\n",
      "Epoch [91/500], Train Loss: 1.1702, Train RMSE: 1.0818\n",
      "Epoch [91/500], Validation Loss: 3.3274, Validation RMSE: 1.8241, Valid PR: 0.1383\n",
      "Epoch [92/500], Train Loss: 1.2880, Train RMSE: 1.1349\n",
      "Epoch [92/500], Validation Loss: 3.2983, Validation RMSE: 1.8161, Valid PR: 0.2058\n",
      "Epoch [93/500], Train Loss: 1.1631, Train RMSE: 1.0785\n",
      "Epoch [93/500], Validation Loss: 3.2696, Validation RMSE: 1.8082, Valid PR: 0.2092\n",
      "Epoch [94/500], Train Loss: 1.1704, Train RMSE: 1.0818\n",
      "Epoch [94/500], Validation Loss: 3.2417, Validation RMSE: 1.8005, Valid PR: 0.2631\n",
      "Epoch [95/500], Train Loss: 1.1402, Train RMSE: 1.0678\n",
      "Epoch [95/500], Validation Loss: 3.2145, Validation RMSE: 1.7929, Valid PR: 0.3004\n",
      "Epoch [96/500], Train Loss: 1.1393, Train RMSE: 1.0674\n",
      "Epoch [96/500], Validation Loss: 3.1881, Validation RMSE: 1.7855, Valid PR: 0.3659\n",
      "Epoch [97/500], Train Loss: 1.0464, Train RMSE: 1.0230\n",
      "Epoch [97/500], Validation Loss: 3.1618, Validation RMSE: 1.7781, Valid PR: 0.4081\n",
      "Epoch [98/500], Train Loss: 1.1286, Train RMSE: 1.0624\n",
      "Epoch [98/500], Validation Loss: 3.1361, Validation RMSE: 1.7709, Valid PR: 0.4421\n",
      "Epoch [99/500], Train Loss: 1.1037, Train RMSE: 1.0505\n",
      "Epoch [99/500], Validation Loss: 3.1108, Validation RMSE: 1.7637, Valid PR: 0.4792\n",
      "Epoch [100/500], Train Loss: 1.0898, Train RMSE: 1.0439\n",
      "Epoch [100/500], Validation Loss: 3.0857, Validation RMSE: 1.7566, Valid PR: 0.4755\n",
      "Epoch [101/500], Train Loss: 1.0928, Train RMSE: 1.0454\n",
      "Epoch [101/500], Validation Loss: 3.0610, Validation RMSE: 1.7496, Valid PR: 0.4817\n",
      "Epoch [102/500], Train Loss: 1.0321, Train RMSE: 1.0159\n",
      "Epoch [102/500], Validation Loss: 3.0369, Validation RMSE: 1.7427, Valid PR: 0.4745\n",
      "Epoch [103/500], Train Loss: 1.0398, Train RMSE: 1.0197\n",
      "Epoch [103/500], Validation Loss: 3.0133, Validation RMSE: 1.7359, Valid PR: 0.4655\n",
      "Epoch [104/500], Train Loss: 1.0647, Train RMSE: 1.0318\n",
      "Epoch [104/500], Validation Loss: 2.9899, Validation RMSE: 1.7291, Valid PR: 0.4555\n",
      "Epoch [105/500], Train Loss: 0.9759, Train RMSE: 0.9879\n",
      "Epoch [105/500], Validation Loss: 2.9672, Validation RMSE: 1.7225, Valid PR: 0.4430\n",
      "Epoch [106/500], Train Loss: 1.0428, Train RMSE: 1.0212\n",
      "Epoch [106/500], Validation Loss: 2.9447, Validation RMSE: 1.7160, Valid PR: 0.4242\n",
      "Epoch [107/500], Train Loss: 1.0948, Train RMSE: 1.0463\n",
      "Epoch [107/500], Validation Loss: 2.9230, Validation RMSE: 1.7097, Valid PR: 0.4254\n",
      "Epoch [108/500], Train Loss: 1.0255, Train RMSE: 1.0127\n",
      "Epoch [108/500], Validation Loss: 2.9017, Validation RMSE: 1.7034, Valid PR: 0.4305\n",
      "Epoch [109/500], Train Loss: 0.9300, Train RMSE: 0.9644\n",
      "Epoch [109/500], Validation Loss: 2.8811, Validation RMSE: 1.6974, Valid PR: 0.4198\n",
      "Epoch [110/500], Train Loss: 0.9727, Train RMSE: 0.9863\n",
      "Epoch [110/500], Validation Loss: 2.8606, Validation RMSE: 1.6913, Valid PR: 0.3986\n",
      "Epoch [111/500], Train Loss: 1.0196, Train RMSE: 1.0097\n",
      "Epoch [111/500], Validation Loss: 2.8405, Validation RMSE: 1.6854, Valid PR: 0.3764\n",
      "Epoch [112/500], Train Loss: 0.9832, Train RMSE: 0.9916\n",
      "Epoch [112/500], Validation Loss: 2.8210, Validation RMSE: 1.6796, Valid PR: 0.3223\n",
      "Epoch [113/500], Train Loss: 1.0769, Train RMSE: 1.0377\n",
      "Epoch [113/500], Validation Loss: 2.8020, Validation RMSE: 1.6739, Valid PR: 0.2543\n",
      "Epoch [114/500], Train Loss: 1.0599, Train RMSE: 1.0295\n",
      "Epoch [114/500], Validation Loss: 2.7831, Validation RMSE: 1.6683, Valid PR: 0.2821\n",
      "Epoch [115/500], Train Loss: 0.9697, Train RMSE: 0.9847\n",
      "Epoch [115/500], Validation Loss: 2.7648, Validation RMSE: 1.6628, Valid PR: 0.3290\n",
      "Epoch [116/500], Train Loss: 0.8666, Train RMSE: 0.9309\n",
      "Epoch [116/500], Validation Loss: 2.7472, Validation RMSE: 1.6575, Valid PR: 0.3612\n",
      "Epoch [117/500], Train Loss: 1.0524, Train RMSE: 1.0259\n",
      "Epoch [117/500], Validation Loss: 2.7297, Validation RMSE: 1.6522, Valid PR: 0.3863\n",
      "Epoch [118/500], Train Loss: 0.9900, Train RMSE: 0.9950\n",
      "Epoch [118/500], Validation Loss: 2.7129, Validation RMSE: 1.6471, Valid PR: 0.3875\n",
      "Epoch [119/500], Train Loss: 0.9689, Train RMSE: 0.9843\n",
      "Epoch [119/500], Validation Loss: 2.6965, Validation RMSE: 1.6421, Valid PR: 0.4095\n",
      "Epoch [120/500], Train Loss: 0.9931, Train RMSE: 0.9965\n",
      "Epoch [120/500], Validation Loss: 2.6808, Validation RMSE: 1.6373, Valid PR: 0.4373\n",
      "Epoch [121/500], Train Loss: 0.9742, Train RMSE: 0.9870\n",
      "Epoch [121/500], Validation Loss: 2.6656, Validation RMSE: 1.6327, Valid PR: 0.4593\n",
      "Epoch [122/500], Train Loss: 0.9621, Train RMSE: 0.9809\n",
      "Epoch [122/500], Validation Loss: 2.6505, Validation RMSE: 1.6280, Valid PR: 0.4842\n",
      "Epoch [123/500], Train Loss: 0.8636, Train RMSE: 0.9293\n",
      "Epoch [123/500], Validation Loss: 2.6353, Validation RMSE: 1.6234, Valid PR: 0.4972\n",
      "Epoch [124/500], Train Loss: 1.0138, Train RMSE: 1.0069\n",
      "Epoch [124/500], Validation Loss: 2.6205, Validation RMSE: 1.6188, Valid PR: 0.5142\n",
      "Epoch [125/500], Train Loss: 0.9337, Train RMSE: 0.9663\n",
      "Epoch [125/500], Validation Loss: 2.6060, Validation RMSE: 1.6143, Valid PR: 0.5347\n",
      "Epoch [126/500], Train Loss: 0.8788, Train RMSE: 0.9375\n",
      "Epoch [126/500], Validation Loss: 2.5919, Validation RMSE: 1.6100, Valid PR: 0.5561\n",
      "Epoch [127/500], Train Loss: 0.9112, Train RMSE: 0.9546\n",
      "Epoch [127/500], Validation Loss: 2.5780, Validation RMSE: 1.6056, Valid PR: 0.5755\n",
      "Epoch [128/500], Train Loss: 0.9069, Train RMSE: 0.9523\n",
      "Epoch [128/500], Validation Loss: 2.5645, Validation RMSE: 1.6014, Valid PR: 0.5906\n",
      "Epoch [129/500], Train Loss: 0.9160, Train RMSE: 0.9571\n",
      "Epoch [129/500], Validation Loss: 2.5513, Validation RMSE: 1.5973, Valid PR: 0.5908\n",
      "Epoch [130/500], Train Loss: 0.8908, Train RMSE: 0.9438\n",
      "Epoch [130/500], Validation Loss: 2.5386, Validation RMSE: 1.5933, Valid PR: 0.5908\n",
      "Epoch [131/500], Train Loss: 0.8067, Train RMSE: 0.8982\n",
      "Epoch [131/500], Validation Loss: 2.5263, Validation RMSE: 1.5894, Valid PR: 0.5915\n",
      "Epoch [132/500], Train Loss: 0.9202, Train RMSE: 0.9593\n",
      "Epoch [132/500], Validation Loss: 2.5142, Validation RMSE: 1.5856, Valid PR: 0.6019\n",
      "Epoch [133/500], Train Loss: 0.8911, Train RMSE: 0.9440\n",
      "Epoch [133/500], Validation Loss: 2.5025, Validation RMSE: 1.5819, Valid PR: 0.6088\n",
      "Epoch [134/500], Train Loss: 0.9263, Train RMSE: 0.9624\n",
      "Epoch [134/500], Validation Loss: 2.4908, Validation RMSE: 1.5782, Valid PR: 0.6123\n",
      "Epoch [135/500], Train Loss: 0.9066, Train RMSE: 0.9522\n",
      "Epoch [135/500], Validation Loss: 2.4789, Validation RMSE: 1.5745, Valid PR: 0.6151\n",
      "Epoch [136/500], Train Loss: 0.8431, Train RMSE: 0.9182\n",
      "Epoch [136/500], Validation Loss: 2.4672, Validation RMSE: 1.5707, Valid PR: 0.6230\n",
      "Epoch [137/500], Train Loss: 0.8427, Train RMSE: 0.9180\n",
      "Epoch [137/500], Validation Loss: 2.4559, Validation RMSE: 1.5671, Valid PR: 0.6319\n",
      "Epoch [138/500], Train Loss: 0.8998, Train RMSE: 0.9486\n",
      "Epoch [138/500], Validation Loss: 2.4450, Validation RMSE: 1.5636, Valid PR: 0.6271\n",
      "Epoch [139/500], Train Loss: 0.8377, Train RMSE: 0.9152\n",
      "Epoch [139/500], Validation Loss: 2.4346, Validation RMSE: 1.5603, Valid PR: 0.6112\n",
      "Epoch [140/500], Train Loss: 0.8399, Train RMSE: 0.9165\n",
      "Epoch [140/500], Validation Loss: 2.4245, Validation RMSE: 1.5571, Valid PR: 0.5872\n",
      "Epoch [141/500], Train Loss: 0.9095, Train RMSE: 0.9537\n",
      "Epoch [141/500], Validation Loss: 2.4150, Validation RMSE: 1.5540, Valid PR: 0.5610\n",
      "Epoch [142/500], Train Loss: 0.8235, Train RMSE: 0.9075\n",
      "Epoch [142/500], Validation Loss: 2.4061, Validation RMSE: 1.5512, Valid PR: 0.5357\n",
      "Epoch [143/500], Train Loss: 0.8701, Train RMSE: 0.9328\n",
      "Epoch [143/500], Validation Loss: 2.3977, Validation RMSE: 1.5485, Valid PR: 0.5135\n",
      "Epoch [144/500], Train Loss: 0.7849, Train RMSE: 0.8859\n",
      "Epoch [144/500], Validation Loss: 2.3897, Validation RMSE: 1.5459, Valid PR: 0.4815\n",
      "Epoch [145/500], Train Loss: 0.9147, Train RMSE: 0.9564\n",
      "Epoch [145/500], Validation Loss: 2.3820, Validation RMSE: 1.5434, Valid PR: 0.4401\n",
      "Epoch [146/500], Train Loss: 0.9632, Train RMSE: 0.9814\n",
      "Epoch [146/500], Validation Loss: 2.3746, Validation RMSE: 1.5410, Valid PR: 0.4115\n",
      "Epoch [147/500], Train Loss: 0.8380, Train RMSE: 0.9154\n",
      "Epoch [147/500], Validation Loss: 2.3674, Validation RMSE: 1.5386, Valid PR: 0.3857\n",
      "Epoch [148/500], Train Loss: 0.8668, Train RMSE: 0.9310\n",
      "Epoch [148/500], Validation Loss: 2.3602, Validation RMSE: 1.5363, Valid PR: 0.3805\n",
      "Epoch [149/500], Train Loss: 0.8840, Train RMSE: 0.9402\n",
      "Epoch [149/500], Validation Loss: 2.3531, Validation RMSE: 1.5340, Valid PR: 0.3919\n",
      "Epoch [150/500], Train Loss: 0.8391, Train RMSE: 0.9160\n",
      "Epoch [150/500], Validation Loss: 2.3462, Validation RMSE: 1.5317, Valid PR: 0.4104\n",
      "Epoch [151/500], Train Loss: 0.9100, Train RMSE: 0.9539\n",
      "Epoch [151/500], Validation Loss: 2.3393, Validation RMSE: 1.5295, Valid PR: 0.4200\n",
      "Epoch [152/500], Train Loss: 0.8167, Train RMSE: 0.9037\n",
      "Epoch [152/500], Validation Loss: 2.3326, Validation RMSE: 1.5273, Valid PR: 0.4255\n",
      "Epoch [153/500], Train Loss: 0.8353, Train RMSE: 0.9140\n",
      "Epoch [153/500], Validation Loss: 2.3263, Validation RMSE: 1.5252, Valid PR: 0.4330\n",
      "Epoch [154/500], Train Loss: 0.8067, Train RMSE: 0.8981\n",
      "Epoch [154/500], Validation Loss: 2.3200, Validation RMSE: 1.5232, Valid PR: 0.4464\n",
      "Epoch [155/500], Train Loss: 0.8142, Train RMSE: 0.9023\n",
      "Epoch [155/500], Validation Loss: 2.3140, Validation RMSE: 1.5212, Valid PR: 0.4622\n",
      "Epoch [156/500], Train Loss: 0.8302, Train RMSE: 0.9111\n",
      "Epoch [156/500], Validation Loss: 2.3082, Validation RMSE: 1.5193, Valid PR: 0.4747\n",
      "Epoch [157/500], Train Loss: 0.8534, Train RMSE: 0.9238\n",
      "Epoch [157/500], Validation Loss: 2.3025, Validation RMSE: 1.5174, Valid PR: 0.4820\n",
      "Epoch [158/500], Train Loss: 0.8772, Train RMSE: 0.9366\n",
      "Epoch [158/500], Validation Loss: 2.2971, Validation RMSE: 1.5156, Valid PR: 0.4948\n",
      "Epoch [159/500], Train Loss: 0.7797, Train RMSE: 0.8830\n",
      "Epoch [159/500], Validation Loss: 2.2919, Validation RMSE: 1.5139, Valid PR: 0.5051\n",
      "Epoch [160/500], Train Loss: 0.7926, Train RMSE: 0.8903\n",
      "Epoch [160/500], Validation Loss: 2.2871, Validation RMSE: 1.5123, Valid PR: 0.5142\n",
      "Epoch [161/500], Train Loss: 0.8184, Train RMSE: 0.9047\n",
      "Epoch [161/500], Validation Loss: 2.2824, Validation RMSE: 1.5108, Valid PR: 0.5195\n",
      "Epoch [162/500], Train Loss: 0.8018, Train RMSE: 0.8955\n",
      "Epoch [162/500], Validation Loss: 2.2777, Validation RMSE: 1.5092, Valid PR: 0.5236\n",
      "Epoch [163/500], Train Loss: 0.8142, Train RMSE: 0.9024\n",
      "Epoch [163/500], Validation Loss: 2.2734, Validation RMSE: 1.5078, Valid PR: 0.5243\n",
      "Epoch [164/500], Train Loss: 0.7816, Train RMSE: 0.8841\n",
      "Epoch [164/500], Validation Loss: 2.2693, Validation RMSE: 1.5064, Valid PR: 0.5190\n",
      "Epoch [165/500], Train Loss: 0.7781, Train RMSE: 0.8821\n",
      "Epoch [165/500], Validation Loss: 2.2653, Validation RMSE: 1.5051, Valid PR: 0.5135\n",
      "Epoch [166/500], Train Loss: 0.7549, Train RMSE: 0.8688\n",
      "Epoch [166/500], Validation Loss: 2.2616, Validation RMSE: 1.5039, Valid PR: 0.5021\n",
      "Epoch [167/500], Train Loss: 0.7683, Train RMSE: 0.8765\n",
      "Epoch [167/500], Validation Loss: 2.2580, Validation RMSE: 1.5027, Valid PR: 0.4926\n",
      "Epoch [168/500], Train Loss: 0.8003, Train RMSE: 0.8946\n",
      "Epoch [168/500], Validation Loss: 2.2544, Validation RMSE: 1.5015, Valid PR: 0.4859\n",
      "Epoch [169/500], Train Loss: 0.7812, Train RMSE: 0.8838\n",
      "Epoch [169/500], Validation Loss: 2.2510, Validation RMSE: 1.5003, Valid PR: 0.4792\n",
      "Epoch [170/500], Train Loss: 0.8420, Train RMSE: 0.9176\n",
      "Epoch [170/500], Validation Loss: 2.2474, Validation RMSE: 1.4991, Valid PR: 0.4776\n",
      "Epoch [171/500], Train Loss: 0.8175, Train RMSE: 0.9042\n",
      "Epoch [171/500], Validation Loss: 2.2439, Validation RMSE: 1.4980, Valid PR: 0.4765\n",
      "Epoch [172/500], Train Loss: 0.7609, Train RMSE: 0.8723\n",
      "Epoch [172/500], Validation Loss: 2.2405, Validation RMSE: 1.4968, Valid PR: 0.4771\n",
      "Epoch [173/500], Train Loss: 0.7182, Train RMSE: 0.8475\n",
      "Epoch [173/500], Validation Loss: 2.2371, Validation RMSE: 1.4957, Valid PR: 0.4775\n",
      "Epoch [174/500], Train Loss: 0.7756, Train RMSE: 0.8807\n",
      "Epoch [174/500], Validation Loss: 2.2341, Validation RMSE: 1.4947, Valid PR: 0.4731\n",
      "Epoch [175/500], Train Loss: 0.7775, Train RMSE: 0.8817\n",
      "Epoch [175/500], Validation Loss: 2.2313, Validation RMSE: 1.4938, Valid PR: 0.4676\n",
      "Epoch [176/500], Train Loss: 0.7510, Train RMSE: 0.8666\n",
      "Epoch [176/500], Validation Loss: 2.2287, Validation RMSE: 1.4929, Valid PR: 0.4615\n",
      "Epoch [177/500], Train Loss: 0.7701, Train RMSE: 0.8775\n",
      "Epoch [177/500], Validation Loss: 2.2262, Validation RMSE: 1.4920, Valid PR: 0.4575\n",
      "Epoch [178/500], Train Loss: 0.7337, Train RMSE: 0.8566\n",
      "Epoch [178/500], Validation Loss: 2.2238, Validation RMSE: 1.4912, Valid PR: 0.4555\n",
      "Epoch [179/500], Train Loss: 0.8137, Train RMSE: 0.9021\n",
      "Epoch [179/500], Validation Loss: 2.2214, Validation RMSE: 1.4904, Valid PR: 0.4559\n",
      "Epoch [180/500], Train Loss: 0.7475, Train RMSE: 0.8646\n",
      "Epoch [180/500], Validation Loss: 2.2191, Validation RMSE: 1.4897, Valid PR: 0.4569\n",
      "Epoch [181/500], Train Loss: 0.7222, Train RMSE: 0.8498\n",
      "Epoch [181/500], Validation Loss: 2.2169, Validation RMSE: 1.4889, Valid PR: 0.4618\n",
      "Epoch [182/500], Train Loss: 0.7236, Train RMSE: 0.8507\n",
      "Epoch [182/500], Validation Loss: 2.2150, Validation RMSE: 1.4883, Valid PR: 0.4650\n",
      "Epoch [183/500], Train Loss: 0.7486, Train RMSE: 0.8652\n",
      "Epoch [183/500], Validation Loss: 2.2131, Validation RMSE: 1.4877, Valid PR: 0.4691\n",
      "Epoch [184/500], Train Loss: 0.7102, Train RMSE: 0.8427\n",
      "Epoch [184/500], Validation Loss: 2.2113, Validation RMSE: 1.4871, Valid PR: 0.4740\n",
      "Epoch [185/500], Train Loss: 0.6702, Train RMSE: 0.8186\n",
      "Epoch [185/500], Validation Loss: 2.2095, Validation RMSE: 1.4864, Valid PR: 0.4763\n",
      "Epoch [186/500], Train Loss: 0.7889, Train RMSE: 0.8882\n",
      "Epoch [186/500], Validation Loss: 2.2078, Validation RMSE: 1.4859, Valid PR: 0.4767\n",
      "Epoch [187/500], Train Loss: 0.6760, Train RMSE: 0.8222\n",
      "Epoch [187/500], Validation Loss: 2.2062, Validation RMSE: 1.4853, Valid PR: 0.4718\n",
      "Epoch [188/500], Train Loss: 0.7162, Train RMSE: 0.8463\n",
      "Epoch [188/500], Validation Loss: 2.2047, Validation RMSE: 1.4848, Valid PR: 0.4614\n",
      "Epoch [189/500], Train Loss: 0.6935, Train RMSE: 0.8328\n",
      "Epoch [189/500], Validation Loss: 2.2034, Validation RMSE: 1.4844, Valid PR: 0.4525\n",
      "Epoch [190/500], Train Loss: 0.7931, Train RMSE: 0.8906\n",
      "Epoch [190/500], Validation Loss: 2.2021, Validation RMSE: 1.4839, Valid PR: 0.4450\n",
      "Epoch [191/500], Train Loss: 0.6971, Train RMSE: 0.8349\n",
      "Epoch [191/500], Validation Loss: 2.2009, Validation RMSE: 1.4835, Valid PR: 0.4350\n",
      "Epoch [192/500], Train Loss: 0.7622, Train RMSE: 0.8730\n",
      "Epoch [192/500], Validation Loss: 2.1999, Validation RMSE: 1.4832, Valid PR: 0.4256\n",
      "Epoch [193/500], Train Loss: 0.7415, Train RMSE: 0.8611\n",
      "Epoch [193/500], Validation Loss: 2.1988, Validation RMSE: 1.4828, Valid PR: 0.4178\n",
      "Epoch [194/500], Train Loss: 0.8078, Train RMSE: 0.8988\n",
      "Epoch [194/500], Validation Loss: 2.1978, Validation RMSE: 1.4825, Valid PR: 0.4016\n",
      "Epoch [195/500], Train Loss: 0.7067, Train RMSE: 0.8407\n",
      "Epoch [195/500], Validation Loss: 2.1970, Validation RMSE: 1.4822, Valid PR: 0.3885\n",
      "Epoch [196/500], Train Loss: 0.8124, Train RMSE: 0.9013\n",
      "Epoch [196/500], Validation Loss: 2.1962, Validation RMSE: 1.4820, Valid PR: 0.3840\n",
      "Epoch [197/500], Train Loss: 0.9145, Train RMSE: 0.9563\n",
      "Epoch [197/500], Validation Loss: 2.1954, Validation RMSE: 1.4817, Valid PR: 0.3846\n",
      "Epoch [198/500], Train Loss: 0.6942, Train RMSE: 0.8332\n",
      "Epoch [198/500], Validation Loss: 2.1948, Validation RMSE: 1.4815, Valid PR: 0.3845\n",
      "Epoch [199/500], Train Loss: 0.8325, Train RMSE: 0.9124\n",
      "Epoch [199/500], Validation Loss: 2.1942, Validation RMSE: 1.4813, Valid PR: 0.3914\n",
      "Epoch [200/500], Train Loss: 0.7319, Train RMSE: 0.8555\n",
      "Epoch [200/500], Validation Loss: 2.1936, Validation RMSE: 1.4811, Valid PR: 0.4043\n",
      "Epoch [201/500], Train Loss: 0.6707, Train RMSE: 0.8189\n",
      "Epoch [201/500], Validation Loss: 2.1930, Validation RMSE: 1.4809, Valid PR: 0.4129\n",
      "Epoch [202/500], Train Loss: 0.6814, Train RMSE: 0.8254\n",
      "Epoch [202/500], Validation Loss: 2.1925, Validation RMSE: 1.4807, Valid PR: 0.4211\n",
      "Epoch [203/500], Train Loss: 0.8348, Train RMSE: 0.9137\n",
      "Epoch [203/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.4304\n",
      "Epoch [204/500], Train Loss: 0.6905, Train RMSE: 0.8310\n",
      "Epoch [204/500], Validation Loss: 2.1917, Validation RMSE: 1.4804, Valid PR: 0.4386\n",
      "Epoch [205/500], Train Loss: 0.6985, Train RMSE: 0.8358\n",
      "Epoch [205/500], Validation Loss: 2.1912, Validation RMSE: 1.4803, Valid PR: 0.4488\n",
      "Epoch [206/500], Train Loss: 0.7335, Train RMSE: 0.8565\n",
      "Epoch [206/500], Validation Loss: 2.1908, Validation RMSE: 1.4801, Valid PR: 0.4605\n",
      "Epoch [207/500], Train Loss: 0.7391, Train RMSE: 0.8597\n",
      "Epoch [207/500], Validation Loss: 2.1905, Validation RMSE: 1.4800, Valid PR: 0.4720\n",
      "Epoch [208/500], Train Loss: 0.7541, Train RMSE: 0.8684\n",
      "Epoch [208/500], Validation Loss: 2.1902, Validation RMSE: 1.4799, Valid PR: 0.4827\n",
      "Epoch [209/500], Train Loss: 0.7155, Train RMSE: 0.8459\n",
      "Epoch [209/500], Validation Loss: 2.1900, Validation RMSE: 1.4799, Valid PR: 0.4918\n",
      "Epoch [210/500], Train Loss: 0.8217, Train RMSE: 0.9065\n",
      "Epoch [210/500], Validation Loss: 2.1897, Validation RMSE: 1.4798, Valid PR: 0.4968\n",
      "Epoch [211/500], Train Loss: 0.7267, Train RMSE: 0.8525\n",
      "Epoch [211/500], Validation Loss: 2.1895, Validation RMSE: 1.4797, Valid PR: 0.4999\n",
      "Epoch [212/500], Train Loss: 0.7742, Train RMSE: 0.8799\n",
      "Epoch [212/500], Validation Loss: 2.1893, Validation RMSE: 1.4796, Valid PR: 0.5009\n",
      "Epoch [213/500], Train Loss: 0.7476, Train RMSE: 0.8646\n",
      "Epoch [213/500], Validation Loss: 2.1890, Validation RMSE: 1.4795, Valid PR: 0.5018\n",
      "Epoch [214/500], Train Loss: 0.7737, Train RMSE: 0.8796\n",
      "Epoch [214/500], Validation Loss: 2.1888, Validation RMSE: 1.4795, Valid PR: 0.5028\n",
      "Epoch [215/500], Train Loss: 0.6888, Train RMSE: 0.8299\n",
      "Epoch [215/500], Validation Loss: 2.1886, Validation RMSE: 1.4794, Valid PR: 0.5043\n",
      "Epoch [216/500], Train Loss: 0.6778, Train RMSE: 0.8233\n",
      "Epoch [216/500], Validation Loss: 2.1884, Validation RMSE: 1.4793, Valid PR: 0.5049\n",
      "Epoch [217/500], Train Loss: 0.7773, Train RMSE: 0.8816\n",
      "Epoch [217/500], Validation Loss: 2.1882, Validation RMSE: 1.4793, Valid PR: 0.5066\n",
      "Epoch [218/500], Train Loss: 0.6701, Train RMSE: 0.8186\n",
      "Epoch [218/500], Validation Loss: 2.1880, Validation RMSE: 1.4792, Valid PR: 0.5076\n",
      "Epoch [219/500], Train Loss: 0.7153, Train RMSE: 0.8458\n",
      "Epoch [219/500], Validation Loss: 2.1878, Validation RMSE: 1.4791, Valid PR: 0.5085\n",
      "Epoch [220/500], Train Loss: 0.8134, Train RMSE: 0.9019\n",
      "Epoch [220/500], Validation Loss: 2.1876, Validation RMSE: 1.4790, Valid PR: 0.5096\n",
      "Epoch [221/500], Train Loss: 0.7660, Train RMSE: 0.8752\n",
      "Epoch [221/500], Validation Loss: 2.1872, Validation RMSE: 1.4789, Valid PR: 0.5119\n",
      "Epoch [222/500], Train Loss: 0.7732, Train RMSE: 0.8793\n",
      "Epoch [222/500], Validation Loss: 2.1868, Validation RMSE: 1.4788, Valid PR: 0.5137\n",
      "Epoch [223/500], Train Loss: 0.7119, Train RMSE: 0.8437\n",
      "Epoch [223/500], Validation Loss: 2.1865, Validation RMSE: 1.4787, Valid PR: 0.5135\n",
      "Epoch [224/500], Train Loss: 0.7128, Train RMSE: 0.8443\n",
      "Epoch [224/500], Validation Loss: 2.1862, Validation RMSE: 1.4786, Valid PR: 0.5132\n",
      "Epoch [225/500], Train Loss: 0.7459, Train RMSE: 0.8637\n",
      "Epoch [225/500], Validation Loss: 2.1860, Validation RMSE: 1.4785, Valid PR: 0.5126\n",
      "Epoch [226/500], Train Loss: 0.8175, Train RMSE: 0.9041\n",
      "Epoch [226/500], Validation Loss: 2.1858, Validation RMSE: 1.4784, Valid PR: 0.5116\n",
      "Epoch [227/500], Train Loss: 0.7664, Train RMSE: 0.8755\n",
      "Epoch [227/500], Validation Loss: 2.1855, Validation RMSE: 1.4783, Valid PR: 0.5110\n",
      "Epoch [228/500], Train Loss: 0.6857, Train RMSE: 0.8280\n",
      "Epoch [228/500], Validation Loss: 2.1853, Validation RMSE: 1.4783, Valid PR: 0.5104\n",
      "Epoch [229/500], Train Loss: 0.8049, Train RMSE: 0.8971\n",
      "Epoch [229/500], Validation Loss: 2.1853, Validation RMSE: 1.4783, Valid PR: 0.5094\n",
      "Epoch [230/500], Train Loss: 0.7980, Train RMSE: 0.8933\n",
      "Epoch [230/500], Validation Loss: 2.1852, Validation RMSE: 1.4783, Valid PR: 0.5075\n",
      "Epoch [231/500], Train Loss: 0.7448, Train RMSE: 0.8630\n",
      "Epoch [231/500], Validation Loss: 2.1853, Validation RMSE: 1.4783, Valid PR: 0.5069\n",
      "Epoch [232/500], Train Loss: 0.7488, Train RMSE: 0.8653\n",
      "Epoch [232/500], Validation Loss: 2.1855, Validation RMSE: 1.4784, Valid PR: 0.5061\n",
      "Epoch [233/500], Train Loss: 0.7848, Train RMSE: 0.8859\n",
      "Epoch [233/500], Validation Loss: 2.1857, Validation RMSE: 1.4784, Valid PR: 0.5040\n",
      "Epoch [234/500], Train Loss: 0.7684, Train RMSE: 0.8766\n",
      "Epoch [234/500], Validation Loss: 2.1860, Validation RMSE: 1.4785, Valid PR: 0.5016\n",
      "Epoch [235/500], Train Loss: 0.7887, Train RMSE: 0.8881\n",
      "Epoch [235/500], Validation Loss: 2.1861, Validation RMSE: 1.4786, Valid PR: 0.4990\n",
      "Epoch [236/500], Train Loss: 0.7655, Train RMSE: 0.8749\n",
      "Epoch [236/500], Validation Loss: 2.1862, Validation RMSE: 1.4786, Valid PR: 0.4960\n",
      "Epoch [237/500], Train Loss: 0.7219, Train RMSE: 0.8496\n",
      "Epoch [237/500], Validation Loss: 2.1866, Validation RMSE: 1.4787, Valid PR: 0.4939\n",
      "Epoch [238/500], Train Loss: 0.7600, Train RMSE: 0.8718\n",
      "Epoch [238/500], Validation Loss: 2.1869, Validation RMSE: 1.4788, Valid PR: 0.4902\n",
      "Epoch [239/500], Train Loss: 0.7244, Train RMSE: 0.8511\n",
      "Epoch [239/500], Validation Loss: 2.1872, Validation RMSE: 1.4789, Valid PR: 0.4867\n",
      "Epoch [240/500], Train Loss: 0.7469, Train RMSE: 0.8643\n",
      "Epoch [240/500], Validation Loss: 2.1876, Validation RMSE: 1.4790, Valid PR: 0.4844\n",
      "Epoch [241/500], Train Loss: 0.6910, Train RMSE: 0.8313\n",
      "Epoch [241/500], Validation Loss: 2.1882, Validation RMSE: 1.4792, Valid PR: 0.4820\n",
      "Epoch [242/500], Train Loss: 0.8079, Train RMSE: 0.8988\n",
      "Epoch [242/500], Validation Loss: 2.1889, Validation RMSE: 1.4795, Valid PR: 0.4801\n",
      "Epoch [243/500], Train Loss: 0.6329, Train RMSE: 0.7956\n",
      "Epoch [243/500], Validation Loss: 2.1894, Validation RMSE: 1.4796, Valid PR: 0.4793\n",
      "Epoch [244/500], Train Loss: 0.7841, Train RMSE: 0.8855\n",
      "Epoch [244/500], Validation Loss: 2.1901, Validation RMSE: 1.4799, Valid PR: 0.4778\n",
      "Epoch [245/500], Train Loss: 0.7858, Train RMSE: 0.8864\n",
      "Epoch [245/500], Validation Loss: 2.1910, Validation RMSE: 1.4802, Valid PR: 0.4762\n",
      "Epoch [246/500], Train Loss: 0.7395, Train RMSE: 0.8599\n",
      "Epoch [246/500], Validation Loss: 2.1923, Validation RMSE: 1.4806, Valid PR: 0.4744\n",
      "Epoch [247/500], Train Loss: 0.8128, Train RMSE: 0.9015\n",
      "Epoch [247/500], Validation Loss: 2.1933, Validation RMSE: 1.4810, Valid PR: 0.4743\n",
      "Epoch [248/500], Train Loss: 0.6847, Train RMSE: 0.8275\n",
      "Epoch [248/500], Validation Loss: 2.1940, Validation RMSE: 1.4812, Valid PR: 0.4736\n",
      "Epoch [249/500], Train Loss: 0.6682, Train RMSE: 0.8174\n",
      "Epoch [249/500], Validation Loss: 2.1951, Validation RMSE: 1.4816, Valid PR: 0.4730\n",
      "Epoch [250/500], Train Loss: 0.7242, Train RMSE: 0.8510\n",
      "Epoch [250/500], Validation Loss: 2.1959, Validation RMSE: 1.4819, Valid PR: 0.4731\n",
      "Epoch [251/500], Train Loss: 0.7906, Train RMSE: 0.8892\n",
      "Epoch [251/500], Validation Loss: 2.1964, Validation RMSE: 1.4820, Valid PR: 0.4727\n",
      "Epoch [252/500], Train Loss: 0.7554, Train RMSE: 0.8691\n",
      "Epoch [252/500], Validation Loss: 2.1965, Validation RMSE: 1.4821, Valid PR: 0.4732\n",
      "Epoch [253/500], Train Loss: 0.6258, Train RMSE: 0.7911\n",
      "Epoch [253/500], Validation Loss: 2.1964, Validation RMSE: 1.4820, Valid PR: 0.4738\n",
      "Epoch [254/500], Train Loss: 0.7164, Train RMSE: 0.8464\n",
      "Epoch [254/500], Validation Loss: 2.1961, Validation RMSE: 1.4819, Valid PR: 0.4747\n",
      "Epoch [255/500], Train Loss: 0.7113, Train RMSE: 0.8434\n",
      "Epoch [255/500], Validation Loss: 2.1956, Validation RMSE: 1.4818, Valid PR: 0.4755\n",
      "Epoch [256/500], Train Loss: 0.7122, Train RMSE: 0.8439\n",
      "Epoch [256/500], Validation Loss: 2.1951, Validation RMSE: 1.4816, Valid PR: 0.4769\n",
      "Epoch [257/500], Train Loss: 0.7886, Train RMSE: 0.8880\n",
      "Epoch [257/500], Validation Loss: 2.1944, Validation RMSE: 1.4814, Valid PR: 0.4787\n",
      "Epoch [258/500], Train Loss: 0.6376, Train RMSE: 0.7985\n",
      "Epoch [258/500], Validation Loss: 2.1942, Validation RMSE: 1.4813, Valid PR: 0.4798\n",
      "Epoch [259/500], Train Loss: 0.7211, Train RMSE: 0.8492\n",
      "Epoch [259/500], Validation Loss: 2.1943, Validation RMSE: 1.4813, Valid PR: 0.4806\n",
      "Epoch [260/500], Train Loss: 0.7346, Train RMSE: 0.8571\n",
      "Epoch [260/500], Validation Loss: 2.1943, Validation RMSE: 1.4813, Valid PR: 0.4797\n",
      "Epoch [261/500], Train Loss: 0.7294, Train RMSE: 0.8540\n",
      "Epoch [261/500], Validation Loss: 2.1950, Validation RMSE: 1.4815, Valid PR: 0.4787\n",
      "Epoch [262/500], Train Loss: 0.7321, Train RMSE: 0.8556\n",
      "Epoch [262/500], Validation Loss: 2.1955, Validation RMSE: 1.4817, Valid PR: 0.4784\n",
      "Epoch [263/500], Train Loss: 0.7222, Train RMSE: 0.8498\n",
      "Epoch [263/500], Validation Loss: 2.1961, Validation RMSE: 1.4819, Valid PR: 0.4773\n",
      "Epoch [264/500], Train Loss: 0.7666, Train RMSE: 0.8756\n",
      "Epoch [264/500], Validation Loss: 2.1961, Validation RMSE: 1.4819, Valid PR: 0.4774\n",
      "Epoch [265/500], Train Loss: 0.8398, Train RMSE: 0.9164\n",
      "Epoch [265/500], Validation Loss: 2.1958, Validation RMSE: 1.4818, Valid PR: 0.4769\n",
      "Epoch [266/500], Train Loss: 0.7095, Train RMSE: 0.8423\n",
      "Epoch [266/500], Validation Loss: 2.1951, Validation RMSE: 1.4816, Valid PR: 0.4765\n",
      "Epoch [267/500], Train Loss: 0.7180, Train RMSE: 0.8474\n",
      "Epoch [267/500], Validation Loss: 2.1941, Validation RMSE: 1.4813, Valid PR: 0.4766\n",
      "Epoch [268/500], Train Loss: 0.7282, Train RMSE: 0.8533\n",
      "Epoch [268/500], Validation Loss: 2.1930, Validation RMSE: 1.4809, Valid PR: 0.4765\n",
      "Epoch [269/500], Train Loss: 0.7551, Train RMSE: 0.8690\n",
      "Epoch [269/500], Validation Loss: 2.1922, Validation RMSE: 1.4806, Valid PR: 0.4767\n",
      "Epoch [270/500], Train Loss: 0.7143, Train RMSE: 0.8451\n",
      "Epoch [270/500], Validation Loss: 2.1906, Validation RMSE: 1.4801, Valid PR: 0.4765\n",
      "Epoch [271/500], Train Loss: 0.7626, Train RMSE: 0.8733\n",
      "Epoch [271/500], Validation Loss: 2.1889, Validation RMSE: 1.4795, Valid PR: 0.4765\n",
      "Epoch [272/500], Train Loss: 0.7607, Train RMSE: 0.8722\n",
      "Epoch [272/500], Validation Loss: 2.1869, Validation RMSE: 1.4788, Valid PR: 0.4765\n",
      "Epoch [273/500], Train Loss: 0.7747, Train RMSE: 0.8802\n",
      "Epoch [273/500], Validation Loss: 2.1845, Validation RMSE: 1.4780, Valid PR: 0.4769\n",
      "Epoch [274/500], Train Loss: 0.7581, Train RMSE: 0.8707\n",
      "Epoch [274/500], Validation Loss: 2.1815, Validation RMSE: 1.4770, Valid PR: 0.4776\n",
      "Epoch [275/500], Train Loss: 0.7332, Train RMSE: 0.8562\n",
      "Epoch [275/500], Validation Loss: 2.1791, Validation RMSE: 1.4762, Valid PR: 0.4784\n",
      "Epoch [276/500], Train Loss: 0.8880, Train RMSE: 0.9424\n",
      "Epoch [276/500], Validation Loss: 2.1763, Validation RMSE: 1.4752, Valid PR: 0.4788\n",
      "Epoch [277/500], Train Loss: 0.7006, Train RMSE: 0.8370\n",
      "Epoch [277/500], Validation Loss: 2.1745, Validation RMSE: 1.4746, Valid PR: 0.4791\n",
      "Epoch [278/500], Train Loss: 0.7423, Train RMSE: 0.8615\n",
      "Epoch [278/500], Validation Loss: 2.1725, Validation RMSE: 1.4739, Valid PR: 0.4793\n",
      "Epoch [279/500], Train Loss: 0.7869, Train RMSE: 0.8871\n",
      "Epoch [279/500], Validation Loss: 2.1710, Validation RMSE: 1.4734, Valid PR: 0.4792\n",
      "Epoch [280/500], Train Loss: 0.6464, Train RMSE: 0.8040\n",
      "Epoch [280/500], Validation Loss: 2.1686, Validation RMSE: 1.4726, Valid PR: 0.4793\n",
      "Epoch [281/500], Train Loss: 0.7164, Train RMSE: 0.8464\n",
      "Epoch [281/500], Validation Loss: 2.1668, Validation RMSE: 1.4720, Valid PR: 0.4796\n",
      "Epoch [282/500], Train Loss: 0.7264, Train RMSE: 0.8523\n",
      "Epoch [282/500], Validation Loss: 2.1642, Validation RMSE: 1.4711, Valid PR: 0.4799\n",
      "Epoch [283/500], Train Loss: 0.6888, Train RMSE: 0.8300\n",
      "Epoch [283/500], Validation Loss: 2.1615, Validation RMSE: 1.4702, Valid PR: 0.4803\n",
      "Epoch [284/500], Train Loss: 0.7643, Train RMSE: 0.8743\n",
      "Epoch [284/500], Validation Loss: 2.1600, Validation RMSE: 1.4697, Valid PR: 0.4804\n",
      "Epoch [285/500], Train Loss: 0.7091, Train RMSE: 0.8421\n",
      "Epoch [285/500], Validation Loss: 2.1592, Validation RMSE: 1.4694, Valid PR: 0.4804\n",
      "Epoch [286/500], Train Loss: 0.7876, Train RMSE: 0.8875\n",
      "Epoch [286/500], Validation Loss: 2.1579, Validation RMSE: 1.4690, Valid PR: 0.4808\n",
      "Epoch [287/500], Train Loss: 0.7679, Train RMSE: 0.8763\n",
      "Epoch [287/500], Validation Loss: 2.1577, Validation RMSE: 1.4689, Valid PR: 0.4808\n",
      "Epoch [288/500], Train Loss: 0.6815, Train RMSE: 0.8255\n",
      "Epoch [288/500], Validation Loss: 2.1580, Validation RMSE: 1.4690, Valid PR: 0.4806\n",
      "Epoch [289/500], Train Loss: 0.8219, Train RMSE: 0.9066\n",
      "Epoch [289/500], Validation Loss: 2.1580, Validation RMSE: 1.4690, Valid PR: 0.4803\n",
      "Epoch [290/500], Train Loss: 0.7726, Train RMSE: 0.8790\n",
      "Epoch [290/500], Validation Loss: 2.1583, Validation RMSE: 1.4691, Valid PR: 0.4804\n",
      "Epoch [291/500], Train Loss: 0.6565, Train RMSE: 0.8103\n",
      "Epoch [291/500], Validation Loss: 2.1597, Validation RMSE: 1.4696, Valid PR: 0.4803\n",
      "Epoch [292/500], Train Loss: 0.7975, Train RMSE: 0.8930\n",
      "Epoch [292/500], Validation Loss: 2.1609, Validation RMSE: 1.4700, Valid PR: 0.4799\n",
      "Epoch [293/500], Train Loss: 0.6892, Train RMSE: 0.8302\n",
      "Epoch [293/500], Validation Loss: 2.1614, Validation RMSE: 1.4702, Valid PR: 0.4795\n",
      "Epoch [294/500], Train Loss: 0.7524, Train RMSE: 0.8674\n",
      "Epoch [294/500], Validation Loss: 2.1610, Validation RMSE: 1.4700, Valid PR: 0.4792\n",
      "Epoch [295/500], Train Loss: 0.7002, Train RMSE: 0.8368\n",
      "Epoch [295/500], Validation Loss: 2.1627, Validation RMSE: 1.4706, Valid PR: 0.4787\n",
      "Epoch [296/500], Train Loss: 0.8319, Train RMSE: 0.9121\n",
      "Epoch [296/500], Validation Loss: 2.1614, Validation RMSE: 1.4702, Valid PR: 0.4784\n",
      "Epoch [297/500], Train Loss: 0.8326, Train RMSE: 0.9125\n",
      "Epoch [297/500], Validation Loss: 2.1591, Validation RMSE: 1.4694, Valid PR: 0.4780\n",
      "Epoch [298/500], Train Loss: 0.7529, Train RMSE: 0.8677\n",
      "Epoch [298/500], Validation Loss: 2.1570, Validation RMSE: 1.4687, Valid PR: 0.4776\n",
      "Epoch [299/500], Train Loss: 0.7243, Train RMSE: 0.8510\n",
      "Epoch [299/500], Validation Loss: 2.1538, Validation RMSE: 1.4676, Valid PR: 0.4771\n",
      "Epoch [300/500], Train Loss: 0.6817, Train RMSE: 0.8257\n",
      "Epoch [300/500], Validation Loss: 2.1484, Validation RMSE: 1.4657, Valid PR: 0.4769\n",
      "Epoch [301/500], Train Loss: 0.7679, Train RMSE: 0.8763\n",
      "Epoch [301/500], Validation Loss: 2.1432, Validation RMSE: 1.4640, Valid PR: 0.4768\n",
      "Epoch [302/500], Train Loss: 0.7796, Train RMSE: 0.8830\n",
      "Epoch [302/500], Validation Loss: 2.1390, Validation RMSE: 1.4625, Valid PR: 0.4768\n",
      "Epoch [303/500], Train Loss: 0.6565, Train RMSE: 0.8103\n",
      "Epoch [303/500], Validation Loss: 2.1359, Validation RMSE: 1.4615, Valid PR: 0.4763\n",
      "Epoch [304/500], Train Loss: 0.6221, Train RMSE: 0.7887\n",
      "Epoch [304/500], Validation Loss: 2.1340, Validation RMSE: 1.4608, Valid PR: 0.4758\n",
      "Epoch [305/500], Train Loss: 0.6933, Train RMSE: 0.8327\n",
      "Epoch [305/500], Validation Loss: 2.1295, Validation RMSE: 1.4593, Valid PR: 0.4756\n",
      "Epoch [306/500], Train Loss: 0.7911, Train RMSE: 0.8894\n",
      "Epoch [306/500], Validation Loss: 2.1237, Validation RMSE: 1.4573, Valid PR: 0.4757\n",
      "Epoch [307/500], Train Loss: 0.7284, Train RMSE: 0.8535\n",
      "Epoch [307/500], Validation Loss: 2.1208, Validation RMSE: 1.4563, Valid PR: 0.4751\n",
      "Epoch [308/500], Train Loss: 0.7025, Train RMSE: 0.8382\n",
      "Epoch [308/500], Validation Loss: 2.1176, Validation RMSE: 1.4552, Valid PR: 0.4746\n",
      "Epoch [309/500], Train Loss: 0.7010, Train RMSE: 0.8373\n",
      "Epoch [309/500], Validation Loss: 2.1129, Validation RMSE: 1.4536, Valid PR: 0.4739\n",
      "Epoch [310/500], Train Loss: 0.6944, Train RMSE: 0.8333\n",
      "Epoch [310/500], Validation Loss: 2.1069, Validation RMSE: 1.4515, Valid PR: 0.4736\n",
      "Epoch [311/500], Train Loss: 0.7110, Train RMSE: 0.8432\n",
      "Epoch [311/500], Validation Loss: 2.1022, Validation RMSE: 1.4499, Valid PR: 0.4732\n",
      "Epoch [312/500], Train Loss: 0.6015, Train RMSE: 0.7756\n",
      "Epoch [312/500], Validation Loss: 2.1016, Validation RMSE: 1.4497, Valid PR: 0.4719\n",
      "Epoch [313/500], Train Loss: 0.6868, Train RMSE: 0.8287\n",
      "Epoch [313/500], Validation Loss: 2.0980, Validation RMSE: 1.4484, Valid PR: 0.4713\n",
      "Epoch [314/500], Train Loss: 0.6650, Train RMSE: 0.8155\n",
      "Epoch [314/500], Validation Loss: 2.0935, Validation RMSE: 1.4469, Valid PR: 0.4705\n",
      "Epoch [315/500], Train Loss: 0.7912, Train RMSE: 0.8895\n",
      "Epoch [315/500], Validation Loss: 2.0869, Validation RMSE: 1.4446, Valid PR: 0.4698\n",
      "Epoch [316/500], Train Loss: 0.7535, Train RMSE: 0.8680\n",
      "Epoch [316/500], Validation Loss: 2.0766, Validation RMSE: 1.4410, Valid PR: 0.4701\n",
      "Epoch [317/500], Train Loss: 0.7126, Train RMSE: 0.8442\n",
      "Epoch [317/500], Validation Loss: 2.0668, Validation RMSE: 1.4376, Valid PR: 0.4696\n",
      "Epoch [318/500], Train Loss: 0.7269, Train RMSE: 0.8526\n",
      "Epoch [318/500], Validation Loss: 2.0552, Validation RMSE: 1.4336, Valid PR: 0.4694\n",
      "Epoch [319/500], Train Loss: 0.6982, Train RMSE: 0.8356\n",
      "Epoch [319/500], Validation Loss: 2.0401, Validation RMSE: 1.4283, Valid PR: 0.4695\n",
      "Epoch [320/500], Train Loss: 0.8071, Train RMSE: 0.8984\n",
      "Epoch [320/500], Validation Loss: 2.0250, Validation RMSE: 1.4230, Valid PR: 0.4689\n",
      "Epoch [321/500], Train Loss: 0.7681, Train RMSE: 0.8764\n",
      "Epoch [321/500], Validation Loss: 2.0128, Validation RMSE: 1.4187, Valid PR: 0.4674\n",
      "Epoch [322/500], Train Loss: 0.6169, Train RMSE: 0.7855\n",
      "Epoch [322/500], Validation Loss: 2.0110, Validation RMSE: 1.4181, Valid PR: 0.4643\n",
      "Epoch [323/500], Train Loss: 0.6521, Train RMSE: 0.8075\n",
      "Epoch [323/500], Validation Loss: 2.0202, Validation RMSE: 1.4213, Valid PR: 0.4600\n",
      "Epoch [324/500], Train Loss: 0.6994, Train RMSE: 0.8363\n",
      "Epoch [324/500], Validation Loss: 2.0300, Validation RMSE: 1.4248, Valid PR: 0.4553\n",
      "Epoch [325/500], Train Loss: 0.7086, Train RMSE: 0.8418\n",
      "Epoch [325/500], Validation Loss: 2.0437, Validation RMSE: 1.4296, Valid PR: 0.4493\n",
      "Epoch [326/500], Train Loss: 0.6309, Train RMSE: 0.7943\n",
      "Epoch [326/500], Validation Loss: 2.0487, Validation RMSE: 1.4313, Valid PR: 0.4455\n",
      "Epoch [327/500], Train Loss: 0.6884, Train RMSE: 0.8297\n",
      "Epoch [327/500], Validation Loss: 2.0444, Validation RMSE: 1.4298, Valid PR: 0.4434\n",
      "Epoch [328/500], Train Loss: 0.6367, Train RMSE: 0.7979\n",
      "Epoch [328/500], Validation Loss: 2.0311, Validation RMSE: 1.4252, Valid PR: 0.4437\n",
      "Epoch [329/500], Train Loss: 0.7291, Train RMSE: 0.8539\n",
      "Epoch [329/500], Validation Loss: 2.0300, Validation RMSE: 1.4248, Valid PR: 0.4402\n",
      "Epoch [330/500], Train Loss: 0.6960, Train RMSE: 0.8343\n",
      "Epoch [330/500], Validation Loss: 2.0205, Validation RMSE: 1.4214, Valid PR: 0.4389\n",
      "Epoch [331/500], Train Loss: 0.7556, Train RMSE: 0.8693\n",
      "Epoch [331/500], Validation Loss: 1.9970, Validation RMSE: 1.4132, Valid PR: 0.4392\n",
      "Epoch [332/500], Train Loss: 0.7112, Train RMSE: 0.8433\n",
      "Epoch [332/500], Validation Loss: 1.9613, Validation RMSE: 1.4005, Valid PR: 0.4432\n",
      "Epoch [333/500], Train Loss: 0.7668, Train RMSE: 0.8757\n",
      "Epoch [333/500], Validation Loss: 1.9313, Validation RMSE: 1.3897, Valid PR: 0.4451\n",
      "Epoch [334/500], Train Loss: 0.6557, Train RMSE: 0.8097\n",
      "Epoch [334/500], Validation Loss: 1.9155, Validation RMSE: 1.3840, Valid PR: 0.4448\n",
      "Epoch [335/500], Train Loss: 0.8002, Train RMSE: 0.8945\n",
      "Epoch [335/500], Validation Loss: 1.9226, Validation RMSE: 1.3866, Valid PR: 0.4410\n",
      "Epoch [336/500], Train Loss: 0.7316, Train RMSE: 0.8554\n",
      "Epoch [336/500], Validation Loss: 1.9410, Validation RMSE: 1.3932, Valid PR: 0.4362\n",
      "Epoch [337/500], Train Loss: 0.7062, Train RMSE: 0.8403\n",
      "Epoch [337/500], Validation Loss: 1.9719, Validation RMSE: 1.4042, Valid PR: 0.4267\n",
      "Epoch [338/500], Train Loss: 0.6625, Train RMSE: 0.8139\n",
      "Epoch [338/500], Validation Loss: 2.0068, Validation RMSE: 1.4166, Valid PR: 0.4131\n",
      "Epoch [339/500], Train Loss: 0.6121, Train RMSE: 0.7823\n",
      "Epoch [339/500], Validation Loss: 2.0399, Validation RMSE: 1.4283, Valid PR: 0.3986\n",
      "Epoch [340/500], Train Loss: 0.6573, Train RMSE: 0.8108\n",
      "Epoch [340/500], Validation Loss: 2.0507, Validation RMSE: 1.4320, Valid PR: 0.3917\n",
      "Epoch [341/500], Train Loss: 0.6175, Train RMSE: 0.7858\n",
      "Epoch [341/500], Validation Loss: 2.0380, Validation RMSE: 1.4276, Valid PR: 0.3939\n",
      "Epoch [342/500], Train Loss: 0.6707, Train RMSE: 0.8189\n",
      "Epoch [342/500], Validation Loss: 2.0290, Validation RMSE: 1.4244, Valid PR: 0.3946\n",
      "Epoch [343/500], Train Loss: 0.7502, Train RMSE: 0.8661\n",
      "Epoch [343/500], Validation Loss: 2.0026, Validation RMSE: 1.4151, Valid PR: 0.3999\n",
      "Epoch [344/500], Train Loss: 0.6313, Train RMSE: 0.7945\n",
      "Epoch [344/500], Validation Loss: 1.9586, Validation RMSE: 1.3995, Valid PR: 0.4074\n",
      "Epoch [345/500], Train Loss: 0.6382, Train RMSE: 0.7989\n",
      "Epoch [345/500], Validation Loss: 1.9150, Validation RMSE: 1.3838, Valid PR: 0.4162\n",
      "Epoch [346/500], Train Loss: 0.6368, Train RMSE: 0.7980\n",
      "Epoch [346/500], Validation Loss: 1.8886, Validation RMSE: 1.3743, Valid PR: 0.4244\n",
      "Epoch [347/500], Train Loss: 0.7890, Train RMSE: 0.8882\n",
      "Epoch [347/500], Validation Loss: 1.9003, Validation RMSE: 1.3785, Valid PR: 0.4218\n",
      "Epoch [348/500], Train Loss: 0.6035, Train RMSE: 0.7769\n",
      "Epoch [348/500], Validation Loss: 1.9325, Validation RMSE: 1.3901, Valid PR: 0.4146\n",
      "Epoch [349/500], Train Loss: 0.7030, Train RMSE: 0.8384\n",
      "Epoch [349/500], Validation Loss: 1.9967, Validation RMSE: 1.4130, Valid PR: 0.3997\n",
      "Epoch [350/500], Train Loss: 0.7638, Train RMSE: 0.8740\n",
      "Epoch [350/500], Validation Loss: 2.0462, Validation RMSE: 1.4305, Valid PR: 0.3836\n",
      "Epoch [351/500], Train Loss: 0.6869, Train RMSE: 0.8288\n",
      "Epoch [351/500], Validation Loss: 2.0719, Validation RMSE: 1.4394, Valid PR: 0.3758\n",
      "Epoch [352/500], Train Loss: 0.7478, Train RMSE: 0.8647\n",
      "Epoch [352/500], Validation Loss: 2.0781, Validation RMSE: 1.4416, Valid PR: 0.3741\n",
      "Epoch [353/500], Train Loss: 0.6749, Train RMSE: 0.8215\n",
      "Epoch [353/500], Validation Loss: 2.0682, Validation RMSE: 1.4381, Valid PR: 0.3793\n",
      "Epoch [354/500], Train Loss: 0.6834, Train RMSE: 0.8267\n",
      "Epoch [354/500], Validation Loss: 2.0540, Validation RMSE: 1.4332, Valid PR: 0.3844\n",
      "Epoch [355/500], Train Loss: 0.7005, Train RMSE: 0.8370\n",
      "Epoch [355/500], Validation Loss: 2.0374, Validation RMSE: 1.4274, Valid PR: 0.3887\n",
      "Epoch [356/500], Train Loss: 0.6136, Train RMSE: 0.7833\n",
      "Epoch [356/500], Validation Loss: 1.9874, Validation RMSE: 1.4098, Valid PR: 0.4054\n",
      "Epoch [357/500], Train Loss: 0.5944, Train RMSE: 0.7710\n",
      "Epoch [357/500], Validation Loss: 1.9354, Validation RMSE: 1.3912, Valid PR: 0.4218\n",
      "Epoch [358/500], Train Loss: 0.6416, Train RMSE: 0.8010\n",
      "Epoch [358/500], Validation Loss: 1.8902, Validation RMSE: 1.3748, Valid PR: 0.4351\n",
      "Epoch [359/500], Train Loss: 0.6099, Train RMSE: 0.7809\n",
      "Epoch [359/500], Validation Loss: 1.8751, Validation RMSE: 1.3693, Valid PR: 0.4390\n",
      "Epoch [360/500], Train Loss: 0.6949, Train RMSE: 0.8336\n",
      "Epoch [360/500], Validation Loss: 1.8765, Validation RMSE: 1.3699, Valid PR: 0.4393\n",
      "Epoch [361/500], Train Loss: 0.7469, Train RMSE: 0.8642\n",
      "Epoch [361/500], Validation Loss: 1.8985, Validation RMSE: 1.3779, Valid PR: 0.4347\n",
      "Epoch [362/500], Train Loss: 0.7475, Train RMSE: 0.8646\n",
      "Epoch [362/500], Validation Loss: 1.9192, Validation RMSE: 1.3854, Valid PR: 0.4299\n",
      "Epoch [363/500], Train Loss: 0.6950, Train RMSE: 0.8337\n",
      "Epoch [363/500], Validation Loss: 1.9404, Validation RMSE: 1.3930, Valid PR: 0.4241\n",
      "Epoch [364/500], Train Loss: 0.7047, Train RMSE: 0.8395\n",
      "Epoch [364/500], Validation Loss: 1.9504, Validation RMSE: 1.3966, Valid PR: 0.4208\n",
      "Epoch [365/500], Train Loss: 0.7159, Train RMSE: 0.8461\n",
      "Epoch [365/500], Validation Loss: 1.9639, Validation RMSE: 1.4014, Valid PR: 0.4151\n",
      "Epoch [366/500], Train Loss: 0.7142, Train RMSE: 0.8451\n",
      "Epoch [366/500], Validation Loss: 1.9594, Validation RMSE: 1.3998, Valid PR: 0.4172\n",
      "Epoch [367/500], Train Loss: 0.7072, Train RMSE: 0.8410\n",
      "Epoch [367/500], Validation Loss: 1.9539, Validation RMSE: 1.3978, Valid PR: 0.4203\n",
      "Epoch [368/500], Train Loss: 0.6878, Train RMSE: 0.8294\n",
      "Epoch [368/500], Validation Loss: 1.9524, Validation RMSE: 1.3973, Valid PR: 0.4202\n",
      "Epoch [369/500], Train Loss: 0.6660, Train RMSE: 0.8161\n",
      "Epoch [369/500], Validation Loss: 1.9542, Validation RMSE: 1.3979, Valid PR: 0.4178\n",
      "Epoch [370/500], Train Loss: 0.7039, Train RMSE: 0.8390\n",
      "Epoch [370/500], Validation Loss: 2.0087, Validation RMSE: 1.4173, Valid PR: 0.3936\n",
      "Epoch [371/500], Train Loss: 0.7102, Train RMSE: 0.8427\n",
      "Epoch [371/500], Validation Loss: 2.0968, Validation RMSE: 1.4480, Valid PR: 0.3462\n",
      "Epoch [372/500], Train Loss: 0.6730, Train RMSE: 0.8204\n",
      "Epoch [372/500], Validation Loss: 2.1328, Validation RMSE: 1.4604, Valid PR: 0.3155\n",
      "Epoch [373/500], Train Loss: 0.7075, Train RMSE: 0.8412\n",
      "Epoch [373/500], Validation Loss: 2.1682, Validation RMSE: 1.4725, Valid PR: 0.2787\n",
      "Epoch [374/500], Train Loss: 0.7259, Train RMSE: 0.8520\n",
      "Epoch [374/500], Validation Loss: 2.1531, Validation RMSE: 1.4673, Valid PR: 0.2823\n",
      "Epoch [375/500], Train Loss: 0.6863, Train RMSE: 0.8284\n",
      "Epoch [375/500], Validation Loss: 2.0920, Validation RMSE: 1.4464, Valid PR: 0.3167\n",
      "Epoch [376/500], Train Loss: 0.7179, Train RMSE: 0.8473\n",
      "Epoch [376/500], Validation Loss: 2.0028, Validation RMSE: 1.4152, Valid PR: 0.3566\n",
      "Epoch [377/500], Train Loss: 0.6470, Train RMSE: 0.8043\n",
      "Epoch [377/500], Validation Loss: 1.9172, Validation RMSE: 1.3846, Valid PR: 0.3849\n",
      "Epoch [378/500], Train Loss: 0.5763, Train RMSE: 0.7592\n",
      "Epoch [378/500], Validation Loss: 1.8759, Validation RMSE: 1.3696, Valid PR: 0.3990\n",
      "Epoch [379/500], Train Loss: 0.6578, Train RMSE: 0.8110\n",
      "Epoch [379/500], Validation Loss: 1.8556, Validation RMSE: 1.3622, Valid PR: 0.4078\n",
      "Epoch [380/500], Train Loss: 0.6690, Train RMSE: 0.8179\n",
      "Epoch [380/500], Validation Loss: 1.8728, Validation RMSE: 1.3685, Valid PR: 0.3984\n",
      "Epoch [381/500], Train Loss: 0.5606, Train RMSE: 0.7487\n",
      "Epoch [381/500], Validation Loss: 1.9587, Validation RMSE: 1.3996, Valid PR: 0.3591\n",
      "Epoch [382/500], Train Loss: 0.6548, Train RMSE: 0.8092\n",
      "Epoch [382/500], Validation Loss: 2.0576, Validation RMSE: 1.4344, Valid PR: 0.3079\n",
      "Epoch [383/500], Train Loss: 0.7345, Train RMSE: 0.8571\n",
      "Epoch [383/500], Validation Loss: 2.1313, Validation RMSE: 1.4599, Valid PR: 0.2616\n",
      "Epoch [384/500], Train Loss: 0.7068, Train RMSE: 0.8407\n",
      "Epoch [384/500], Validation Loss: 2.1839, Validation RMSE: 1.4778, Valid PR: 0.2228\n",
      "Epoch [385/500], Train Loss: 0.6919, Train RMSE: 0.8318\n",
      "Epoch [385/500], Validation Loss: 2.1793, Validation RMSE: 1.4762, Valid PR: 0.2302\n",
      "Epoch [386/500], Train Loss: 0.6895, Train RMSE: 0.8303\n",
      "Epoch [386/500], Validation Loss: 2.1303, Validation RMSE: 1.4595, Valid PR: 0.2713\n",
      "Epoch [387/500], Train Loss: 0.5877, Train RMSE: 0.7666\n",
      "Epoch [387/500], Validation Loss: 2.0500, Validation RMSE: 1.4318, Valid PR: 0.3204\n",
      "Epoch [388/500], Train Loss: 0.6442, Train RMSE: 0.8026\n",
      "Epoch [388/500], Validation Loss: 1.9601, Validation RMSE: 1.4000, Valid PR: 0.3598\n",
      "Epoch [389/500], Train Loss: 0.7306, Train RMSE: 0.8547\n",
      "Epoch [389/500], Validation Loss: 1.8963, Validation RMSE: 1.3771, Valid PR: 0.3830\n",
      "Epoch [390/500], Train Loss: 0.6546, Train RMSE: 0.8091\n",
      "Epoch [390/500], Validation Loss: 1.8941, Validation RMSE: 1.3762, Valid PR: 0.3842\n",
      "Epoch [391/500], Train Loss: 0.6536, Train RMSE: 0.8085\n",
      "Epoch [391/500], Validation Loss: 1.9082, Validation RMSE: 1.3814, Valid PR: 0.3802\n",
      "Epoch [392/500], Train Loss: 0.7333, Train RMSE: 0.8563\n",
      "Epoch [392/500], Validation Loss: 1.9548, Validation RMSE: 1.3981, Valid PR: 0.3656\n",
      "Epoch [393/500], Train Loss: 0.6740, Train RMSE: 0.8210\n",
      "Epoch [393/500], Validation Loss: 1.9989, Validation RMSE: 1.4138, Valid PR: 0.3509\n",
      "Epoch [394/500], Train Loss: 0.7859, Train RMSE: 0.8865\n",
      "Epoch [394/500], Validation Loss: 2.0290, Validation RMSE: 1.4244, Valid PR: 0.3402\n",
      "Epoch [395/500], Train Loss: 0.6327, Train RMSE: 0.7954\n",
      "Epoch [395/500], Validation Loss: 2.0233, Validation RMSE: 1.4224, Valid PR: 0.3438\n",
      "Epoch [396/500], Train Loss: 0.6814, Train RMSE: 0.8255\n",
      "Epoch [396/500], Validation Loss: 2.0031, Validation RMSE: 1.4153, Valid PR: 0.3514\n",
      "Epoch [397/500], Train Loss: 0.7002, Train RMSE: 0.8368\n",
      "Epoch [397/500], Validation Loss: 1.9786, Validation RMSE: 1.4066, Valid PR: 0.3586\n",
      "Epoch [398/500], Train Loss: 0.5738, Train RMSE: 0.7575\n",
      "Epoch [398/500], Validation Loss: 1.9537, Validation RMSE: 1.3977, Valid PR: 0.3670\n",
      "Epoch [399/500], Train Loss: 0.6702, Train RMSE: 0.8187\n",
      "Epoch [399/500], Validation Loss: 1.9480, Validation RMSE: 1.3957, Valid PR: 0.3676\n",
      "Epoch [400/500], Train Loss: 0.6600, Train RMSE: 0.8124\n",
      "Epoch [400/500], Validation Loss: 1.9478, Validation RMSE: 1.3956, Valid PR: 0.3656\n",
      "Epoch [401/500], Train Loss: 0.6198, Train RMSE: 0.7873\n",
      "Epoch [401/500], Validation Loss: 1.9375, Validation RMSE: 1.3919, Valid PR: 0.3677\n",
      "Epoch [402/500], Train Loss: 0.7442, Train RMSE: 0.8627\n",
      "Epoch [402/500], Validation Loss: 1.9183, Validation RMSE: 1.3850, Valid PR: 0.3734\n",
      "Epoch [403/500], Train Loss: 0.6599, Train RMSE: 0.8123\n",
      "Epoch [403/500], Validation Loss: 1.9318, Validation RMSE: 1.3899, Valid PR: 0.3665\n",
      "Epoch [404/500], Train Loss: 0.6067, Train RMSE: 0.7789\n",
      "Epoch [404/500], Validation Loss: 1.9516, Validation RMSE: 1.3970, Valid PR: 0.3586\n",
      "Epoch [405/500], Train Loss: 0.6306, Train RMSE: 0.7941\n",
      "Epoch [405/500], Validation Loss: 1.9855, Validation RMSE: 1.4091, Valid PR: 0.3446\n",
      "Epoch [406/500], Train Loss: 0.6351, Train RMSE: 0.7970\n",
      "Epoch [406/500], Validation Loss: 2.0049, Validation RMSE: 1.4159, Valid PR: 0.3373\n",
      "Epoch [407/500], Train Loss: 0.5887, Train RMSE: 0.7672\n",
      "Epoch [407/500], Validation Loss: 2.0191, Validation RMSE: 1.4209, Valid PR: 0.3323\n",
      "Epoch [408/500], Train Loss: 0.6593, Train RMSE: 0.8120\n",
      "Epoch [408/500], Validation Loss: 2.0439, Validation RMSE: 1.4296, Valid PR: 0.3237\n",
      "Epoch [409/500], Train Loss: 0.6401, Train RMSE: 0.8000\n",
      "Epoch [409/500], Validation Loss: 2.0497, Validation RMSE: 1.4317, Valid PR: 0.3227\n",
      "Epoch [410/500], Train Loss: 0.7378, Train RMSE: 0.8590\n",
      "Epoch [410/500], Validation Loss: 2.0162, Validation RMSE: 1.4199, Valid PR: 0.3357\n",
      "Epoch [411/500], Train Loss: 0.6756, Train RMSE: 0.8219\n",
      "Epoch [411/500], Validation Loss: 1.9786, Validation RMSE: 1.4066, Valid PR: 0.3498\n",
      "Epoch [412/500], Train Loss: 0.6442, Train RMSE: 0.8026\n",
      "Epoch [412/500], Validation Loss: 1.9428, Validation RMSE: 1.3938, Valid PR: 0.3617\n",
      "Epoch [413/500], Train Loss: 0.6348, Train RMSE: 0.7968\n",
      "Epoch [413/500], Validation Loss: 1.9482, Validation RMSE: 1.3958, Valid PR: 0.3590\n",
      "Epoch [414/500], Train Loss: 0.5828, Train RMSE: 0.7634\n",
      "Epoch [414/500], Validation Loss: 1.9825, Validation RMSE: 1.4080, Valid PR: 0.3462\n",
      "Epoch [415/500], Train Loss: 0.6631, Train RMSE: 0.8143\n",
      "Epoch [415/500], Validation Loss: 2.0302, Validation RMSE: 1.4248, Valid PR: 0.3308\n",
      "Epoch [416/500], Train Loss: 0.7028, Train RMSE: 0.8383\n",
      "Epoch [416/500], Validation Loss: 2.0841, Validation RMSE: 1.4436, Valid PR: 0.3125\n",
      "Epoch [417/500], Train Loss: 0.6904, Train RMSE: 0.8309\n",
      "Epoch [417/500], Validation Loss: 2.1007, Validation RMSE: 1.4494, Valid PR: 0.3054\n",
      "Epoch [418/500], Train Loss: 0.6404, Train RMSE: 0.8002\n",
      "Epoch [418/500], Validation Loss: 2.0916, Validation RMSE: 1.4462, Valid PR: 0.3069\n",
      "Epoch [419/500], Train Loss: 0.6553, Train RMSE: 0.8095\n",
      "Epoch [419/500], Validation Loss: 2.1001, Validation RMSE: 1.4492, Valid PR: 0.3043\n",
      "Epoch [420/500], Train Loss: 0.5826, Train RMSE: 0.7633\n",
      "Epoch [420/500], Validation Loss: 2.0804, Validation RMSE: 1.4424, Valid PR: 0.3103\n",
      "Epoch [421/500], Train Loss: 0.6604, Train RMSE: 0.8127\n",
      "Epoch [421/500], Validation Loss: 2.0235, Validation RMSE: 1.4225, Valid PR: 0.3269\n",
      "Epoch [422/500], Train Loss: 0.5766, Train RMSE: 0.7593\n",
      "Epoch [422/500], Validation Loss: 1.9884, Validation RMSE: 1.4101, Valid PR: 0.3382\n",
      "Epoch [423/500], Train Loss: 0.5603, Train RMSE: 0.7486\n",
      "Epoch [423/500], Validation Loss: 1.9571, Validation RMSE: 1.3990, Valid PR: 0.3487\n",
      "Epoch [424/500], Train Loss: 0.5123, Train RMSE: 0.7157\n",
      "Epoch [424/500], Validation Loss: 1.9484, Validation RMSE: 1.3959, Valid PR: 0.3515\n",
      "Epoch [425/500], Train Loss: 0.6396, Train RMSE: 0.7997\n",
      "Epoch [425/500], Validation Loss: 1.9584, Validation RMSE: 1.3994, Valid PR: 0.3486\n",
      "Epoch [426/500], Train Loss: 0.6651, Train RMSE: 0.8155\n",
      "Epoch [426/500], Validation Loss: 2.0156, Validation RMSE: 1.4197, Valid PR: 0.3316\n",
      "Epoch [427/500], Train Loss: 0.6125, Train RMSE: 0.7826\n",
      "Epoch [427/500], Validation Loss: 2.0440, Validation RMSE: 1.4297, Valid PR: 0.3236\n",
      "Epoch [428/500], Train Loss: 0.5926, Train RMSE: 0.7698\n",
      "Epoch [428/500], Validation Loss: 2.0525, Validation RMSE: 1.4327, Valid PR: 0.3206\n",
      "Epoch [429/500], Train Loss: 0.6402, Train RMSE: 0.8001\n",
      "Epoch [429/500], Validation Loss: 2.0948, Validation RMSE: 1.4473, Valid PR: 0.3057\n",
      "Early stopping triggered.\n",
      "Test Loss: 3.5698, Test RMSE: 1.8894, Test PR: -0.1626\n",
      "Testing method3...\n",
      "Replication 1 for method3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:122: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 9.0195, Train RMSE: 3.0032\n",
      "Epoch [1/500], Validation Loss: 13.9802, Validation RMSE: 3.7390, Valid PR: -0.4310\n",
      "Epoch [2/500], Train Loss: 4.1304, Train RMSE: 2.0323\n",
      "Epoch [2/500], Validation Loss: 9.9246, Validation RMSE: 3.1503, Valid PR: 0.1135\n",
      "Epoch [3/500], Train Loss: 3.0812, Train RMSE: 1.7553\n",
      "Epoch [3/500], Validation Loss: 8.5526, Validation RMSE: 2.9245, Valid PR: 0.2939\n",
      "Epoch [4/500], Train Loss: 2.7680, Train RMSE: 1.6637\n",
      "Epoch [4/500], Validation Loss: 7.5928, Validation RMSE: 2.7555, Valid PR: 0.4786\n",
      "Epoch [5/500], Train Loss: 2.3506, Train RMSE: 1.5332\n",
      "Epoch [5/500], Validation Loss: 6.8718, Validation RMSE: 2.6214, Valid PR: -0.1180\n",
      "Epoch [6/500], Train Loss: 2.1902, Train RMSE: 1.4799\n",
      "Epoch [6/500], Validation Loss: 6.2948, Validation RMSE: 2.5089, Valid PR: -0.5543\n",
      "Epoch [7/500], Train Loss: 1.9020, Train RMSE: 1.3791\n",
      "Epoch [7/500], Validation Loss: 5.8556, Validation RMSE: 2.4198, Valid PR: -0.5246\n",
      "Epoch [8/500], Train Loss: 1.8673, Train RMSE: 1.3665\n",
      "Epoch [8/500], Validation Loss: 5.5397, Validation RMSE: 2.3537, Valid PR: -0.4328\n",
      "Epoch [9/500], Train Loss: 1.8243, Train RMSE: 1.3507\n",
      "Epoch [9/500], Validation Loss: 5.3097, Validation RMSE: 2.3043, Valid PR: -0.4300\n",
      "Epoch [10/500], Train Loss: 1.7153, Train RMSE: 1.3097\n",
      "Epoch [10/500], Validation Loss: 5.1321, Validation RMSE: 2.2654, Valid PR: -0.3749\n",
      "Epoch [11/500], Train Loss: 1.7756, Train RMSE: 1.3325\n",
      "Epoch [11/500], Validation Loss: 4.9873, Validation RMSE: 2.2332, Valid PR: -0.1831\n",
      "Epoch [12/500], Train Loss: 1.6773, Train RMSE: 1.2951\n",
      "Epoch [12/500], Validation Loss: 4.8628, Validation RMSE: 2.2052, Valid PR: 0.5635\n",
      "Epoch [13/500], Train Loss: 1.5887, Train RMSE: 1.2604\n",
      "Epoch [13/500], Validation Loss: 4.7592, Validation RMSE: 2.1816, Valid PR: 0.6006\n",
      "Epoch [14/500], Train Loss: 1.6683, Train RMSE: 1.2916\n",
      "Epoch [14/500], Validation Loss: 4.6700, Validation RMSE: 2.1610, Valid PR: 0.5656\n",
      "Epoch [15/500], Train Loss: 1.5345, Train RMSE: 1.2387\n",
      "Epoch [15/500], Validation Loss: 4.5893, Validation RMSE: 2.1423, Valid PR: 0.5419\n",
      "Epoch [16/500], Train Loss: 1.5205, Train RMSE: 1.2331\n",
      "Epoch [16/500], Validation Loss: 4.5156, Validation RMSE: 2.1250, Valid PR: 0.5282\n",
      "Epoch [17/500], Train Loss: 1.5240, Train RMSE: 1.2345\n",
      "Epoch [17/500], Validation Loss: 4.4470, Validation RMSE: 2.1088, Valid PR: 0.5105\n",
      "Epoch [18/500], Train Loss: 1.5946, Train RMSE: 1.2628\n",
      "Epoch [18/500], Validation Loss: 4.3832, Validation RMSE: 2.0936, Valid PR: 0.4918\n",
      "Epoch [19/500], Train Loss: 1.5104, Train RMSE: 1.2290\n",
      "Epoch [19/500], Validation Loss: 4.3226, Validation RMSE: 2.0791, Valid PR: 0.4727\n",
      "Epoch [20/500], Train Loss: 1.4064, Train RMSE: 1.1859\n",
      "Epoch [20/500], Validation Loss: 4.2654, Validation RMSE: 2.0653, Valid PR: 0.4396\n",
      "Epoch [21/500], Train Loss: 1.4499, Train RMSE: 1.2041\n",
      "Epoch [21/500], Validation Loss: 4.2105, Validation RMSE: 2.0520, Valid PR: 0.4004\n",
      "Epoch [22/500], Train Loss: 1.4756, Train RMSE: 1.2147\n",
      "Epoch [22/500], Validation Loss: 4.1566, Validation RMSE: 2.0388, Valid PR: 0.3318\n",
      "Epoch [23/500], Train Loss: 1.4343, Train RMSE: 1.1976\n",
      "Epoch [23/500], Validation Loss: 4.1041, Validation RMSE: 2.0259, Valid PR: 0.2228\n",
      "Epoch [24/500], Train Loss: 1.4036, Train RMSE: 1.1847\n",
      "Epoch [24/500], Validation Loss: 4.0517, Validation RMSE: 2.0129, Valid PR: 0.0503\n",
      "Epoch [25/500], Train Loss: 1.3765, Train RMSE: 1.1733\n",
      "Epoch [25/500], Validation Loss: 4.0004, Validation RMSE: 2.0001, Valid PR: -0.1544\n",
      "Epoch [26/500], Train Loss: 1.3952, Train RMSE: 1.1812\n",
      "Epoch [26/500], Validation Loss: 3.9505, Validation RMSE: 1.9876, Valid PR: -0.3445\n",
      "Epoch [27/500], Train Loss: 1.2256, Train RMSE: 1.1071\n",
      "Epoch [27/500], Validation Loss: 3.9014, Validation RMSE: 1.9752, Valid PR: -0.4428\n",
      "Epoch [28/500], Train Loss: 1.3040, Train RMSE: 1.1419\n",
      "Epoch [28/500], Validation Loss: 3.8531, Validation RMSE: 1.9629, Valid PR: -0.4910\n",
      "Epoch [29/500], Train Loss: 1.2156, Train RMSE: 1.1025\n",
      "Epoch [29/500], Validation Loss: 3.8059, Validation RMSE: 1.9509, Valid PR: -0.5303\n",
      "Epoch [30/500], Train Loss: 1.2697, Train RMSE: 1.1268\n",
      "Epoch [30/500], Validation Loss: 3.7598, Validation RMSE: 1.9390, Valid PR: -0.5573\n",
      "Epoch [31/500], Train Loss: 1.3355, Train RMSE: 1.1556\n",
      "Epoch [31/500], Validation Loss: 3.7149, Validation RMSE: 1.9274, Valid PR: -0.5811\n",
      "Epoch [32/500], Train Loss: 1.3461, Train RMSE: 1.1602\n",
      "Epoch [32/500], Validation Loss: 3.6711, Validation RMSE: 1.9160, Valid PR: -0.5937\n",
      "Epoch [33/500], Train Loss: 1.2782, Train RMSE: 1.1306\n",
      "Epoch [33/500], Validation Loss: 3.6287, Validation RMSE: 1.9049, Valid PR: -0.6053\n",
      "Epoch [34/500], Train Loss: 1.1448, Train RMSE: 1.0699\n",
      "Epoch [34/500], Validation Loss: 3.5876, Validation RMSE: 1.8941, Valid PR: -0.6140\n",
      "Epoch [35/500], Train Loss: 1.2154, Train RMSE: 1.1025\n",
      "Epoch [35/500], Validation Loss: 3.5478, Validation RMSE: 1.8836, Valid PR: -0.6112\n",
      "Epoch [36/500], Train Loss: 1.2288, Train RMSE: 1.1085\n",
      "Epoch [36/500], Validation Loss: 3.5088, Validation RMSE: 1.8732, Valid PR: -0.6020\n",
      "Epoch [37/500], Train Loss: 1.2493, Train RMSE: 1.1177\n",
      "Epoch [37/500], Validation Loss: 3.4708, Validation RMSE: 1.8630, Valid PR: -0.5899\n",
      "Epoch [38/500], Train Loss: 1.2537, Train RMSE: 1.1197\n",
      "Epoch [38/500], Validation Loss: 3.4338, Validation RMSE: 1.8530, Valid PR: -0.5927\n",
      "Epoch [39/500], Train Loss: 1.1249, Train RMSE: 1.0606\n",
      "Epoch [39/500], Validation Loss: 3.3974, Validation RMSE: 1.8432, Valid PR: -0.5785\n",
      "Epoch [40/500], Train Loss: 1.1938, Train RMSE: 1.0926\n",
      "Epoch [40/500], Validation Loss: 3.3618, Validation RMSE: 1.8335, Valid PR: -0.5567\n",
      "Epoch [41/500], Train Loss: 1.1389, Train RMSE: 1.0672\n",
      "Epoch [41/500], Validation Loss: 3.3272, Validation RMSE: 1.8240, Valid PR: -0.5252\n",
      "Epoch [42/500], Train Loss: 1.1698, Train RMSE: 1.0816\n",
      "Epoch [42/500], Validation Loss: 3.2935, Validation RMSE: 1.8148, Valid PR: -0.4886\n",
      "Epoch [43/500], Train Loss: 1.1455, Train RMSE: 1.0703\n",
      "Epoch [43/500], Validation Loss: 3.2606, Validation RMSE: 1.8057, Valid PR: -0.4096\n",
      "Epoch [44/500], Train Loss: 1.0238, Train RMSE: 1.0119\n",
      "Epoch [44/500], Validation Loss: 3.2287, Validation RMSE: 1.7969, Valid PR: -0.2306\n",
      "Epoch [45/500], Train Loss: 1.2307, Train RMSE: 1.1094\n",
      "Epoch [45/500], Validation Loss: 3.1976, Validation RMSE: 1.7882, Valid PR: -0.0066\n",
      "Epoch [46/500], Train Loss: 1.1134, Train RMSE: 1.0552\n",
      "Epoch [46/500], Validation Loss: 3.1675, Validation RMSE: 1.7798, Valid PR: 0.1703\n",
      "Epoch [47/500], Train Loss: 1.1302, Train RMSE: 1.0631\n",
      "Epoch [47/500], Validation Loss: 3.1380, Validation RMSE: 1.7714, Valid PR: 0.3113\n",
      "Epoch [48/500], Train Loss: 1.1152, Train RMSE: 1.0560\n",
      "Epoch [48/500], Validation Loss: 3.1093, Validation RMSE: 1.7633, Valid PR: 0.4106\n",
      "Epoch [49/500], Train Loss: 1.0547, Train RMSE: 1.0270\n",
      "Epoch [49/500], Validation Loss: 3.0812, Validation RMSE: 1.7553, Valid PR: 0.4438\n",
      "Epoch [50/500], Train Loss: 1.0439, Train RMSE: 1.0217\n",
      "Epoch [50/500], Validation Loss: 3.0536, Validation RMSE: 1.7475, Valid PR: 0.4501\n",
      "Epoch [51/500], Train Loss: 1.1599, Train RMSE: 1.0770\n",
      "Epoch [51/500], Validation Loss: 3.0268, Validation RMSE: 1.7398, Valid PR: 0.4345\n",
      "Epoch [52/500], Train Loss: 1.0671, Train RMSE: 1.0330\n",
      "Epoch [52/500], Validation Loss: 3.0003, Validation RMSE: 1.7321, Valid PR: 0.4273\n",
      "Epoch [53/500], Train Loss: 1.0351, Train RMSE: 1.0174\n",
      "Epoch [53/500], Validation Loss: 2.9739, Validation RMSE: 1.7245, Valid PR: 0.4088\n",
      "Epoch [54/500], Train Loss: 1.0285, Train RMSE: 1.0141\n",
      "Epoch [54/500], Validation Loss: 2.9479, Validation RMSE: 1.7170, Valid PR: 0.3773\n",
      "Epoch [55/500], Train Loss: 1.1490, Train RMSE: 1.0719\n",
      "Epoch [55/500], Validation Loss: 2.9224, Validation RMSE: 1.7095, Valid PR: 0.3287\n",
      "Epoch [56/500], Train Loss: 0.9886, Train RMSE: 0.9943\n",
      "Epoch [56/500], Validation Loss: 2.8974, Validation RMSE: 1.7022, Valid PR: 0.2862\n",
      "Epoch [57/500], Train Loss: 1.0841, Train RMSE: 1.0412\n",
      "Epoch [57/500], Validation Loss: 2.8726, Validation RMSE: 1.6949, Valid PR: 0.3003\n",
      "Epoch [58/500], Train Loss: 0.9822, Train RMSE: 0.9911\n",
      "Epoch [58/500], Validation Loss: 2.8482, Validation RMSE: 1.6877, Valid PR: 0.2509\n",
      "Epoch [59/500], Train Loss: 0.9677, Train RMSE: 0.9837\n",
      "Epoch [59/500], Validation Loss: 2.8248, Validation RMSE: 1.6807, Valid PR: 0.2265\n",
      "Epoch [60/500], Train Loss: 1.0946, Train RMSE: 1.0462\n",
      "Epoch [60/500], Validation Loss: 2.8021, Validation RMSE: 1.6739, Valid PR: 0.2364\n",
      "Epoch [61/500], Train Loss: 1.0215, Train RMSE: 1.0107\n",
      "Epoch [61/500], Validation Loss: 2.7802, Validation RMSE: 1.6674, Valid PR: 0.2249\n",
      "Epoch [62/500], Train Loss: 1.0186, Train RMSE: 1.0093\n",
      "Epoch [62/500], Validation Loss: 2.7590, Validation RMSE: 1.6610, Valid PR: 0.1841\n",
      "Epoch [63/500], Train Loss: 0.9492, Train RMSE: 0.9743\n",
      "Epoch [63/500], Validation Loss: 2.7382, Validation RMSE: 1.6548, Valid PR: 0.1599\n",
      "Epoch [64/500], Train Loss: 0.9514, Train RMSE: 0.9754\n",
      "Epoch [64/500], Validation Loss: 2.7179, Validation RMSE: 1.6486, Valid PR: 0.1600\n",
      "Epoch [65/500], Train Loss: 0.9663, Train RMSE: 0.9830\n",
      "Epoch [65/500], Validation Loss: 2.6981, Validation RMSE: 1.6426, Valid PR: 0.2372\n",
      "Epoch [66/500], Train Loss: 1.0057, Train RMSE: 1.0029\n",
      "Epoch [66/500], Validation Loss: 2.6791, Validation RMSE: 1.6368, Valid PR: 0.3006\n",
      "Epoch [67/500], Train Loss: 0.9454, Train RMSE: 0.9723\n",
      "Epoch [67/500], Validation Loss: 2.6611, Validation RMSE: 1.6313, Valid PR: 0.3547\n",
      "Epoch [68/500], Train Loss: 0.9399, Train RMSE: 0.9695\n",
      "Epoch [68/500], Validation Loss: 2.6437, Validation RMSE: 1.6260, Valid PR: 0.3800\n",
      "Epoch [69/500], Train Loss: 0.9130, Train RMSE: 0.9555\n",
      "Epoch [69/500], Validation Loss: 2.6267, Validation RMSE: 1.6207, Valid PR: 0.3851\n",
      "Epoch [70/500], Train Loss: 0.9596, Train RMSE: 0.9796\n",
      "Epoch [70/500], Validation Loss: 2.6103, Validation RMSE: 1.6156, Valid PR: 0.3905\n",
      "Epoch [71/500], Train Loss: 0.9477, Train RMSE: 0.9735\n",
      "Epoch [71/500], Validation Loss: 2.5944, Validation RMSE: 1.6107, Valid PR: 0.3828\n",
      "Epoch [72/500], Train Loss: 0.9099, Train RMSE: 0.9539\n",
      "Epoch [72/500], Validation Loss: 2.5790, Validation RMSE: 1.6059, Valid PR: 0.3757\n",
      "Epoch [73/500], Train Loss: 0.8632, Train RMSE: 0.9291\n",
      "Epoch [73/500], Validation Loss: 2.5639, Validation RMSE: 1.6012, Valid PR: 0.3677\n",
      "Epoch [74/500], Train Loss: 0.9261, Train RMSE: 0.9624\n",
      "Epoch [74/500], Validation Loss: 2.5488, Validation RMSE: 1.5965, Valid PR: 0.3597\n",
      "Epoch [75/500], Train Loss: 0.8268, Train RMSE: 0.9093\n",
      "Epoch [75/500], Validation Loss: 2.5342, Validation RMSE: 1.5919, Valid PR: 0.3569\n",
      "Epoch [76/500], Train Loss: 0.9585, Train RMSE: 0.9790\n",
      "Epoch [76/500], Validation Loss: 2.5202, Validation RMSE: 1.5875, Valid PR: 0.3545\n",
      "Epoch [77/500], Train Loss: 0.8281, Train RMSE: 0.9100\n",
      "Epoch [77/500], Validation Loss: 2.5062, Validation RMSE: 1.5831, Valid PR: 0.3488\n",
      "Epoch [78/500], Train Loss: 0.9590, Train RMSE: 0.9793\n",
      "Epoch [78/500], Validation Loss: 2.4924, Validation RMSE: 1.5787, Valid PR: 0.3549\n",
      "Epoch [79/500], Train Loss: 0.8494, Train RMSE: 0.9216\n",
      "Epoch [79/500], Validation Loss: 2.4791, Validation RMSE: 1.5745, Valid PR: 0.3588\n",
      "Epoch [80/500], Train Loss: 0.8787, Train RMSE: 0.9374\n",
      "Epoch [80/500], Validation Loss: 2.4663, Validation RMSE: 1.5704, Valid PR: 0.3637\n",
      "Epoch [81/500], Train Loss: 0.9076, Train RMSE: 0.9527\n",
      "Epoch [81/500], Validation Loss: 2.4537, Validation RMSE: 1.5664, Valid PR: 0.3674\n",
      "Epoch [82/500], Train Loss: 0.8654, Train RMSE: 0.9303\n",
      "Epoch [82/500], Validation Loss: 2.4412, Validation RMSE: 1.5624, Valid PR: 0.3696\n",
      "Epoch [83/500], Train Loss: 0.8770, Train RMSE: 0.9365\n",
      "Epoch [83/500], Validation Loss: 2.4292, Validation RMSE: 1.5586, Valid PR: 0.3766\n",
      "Epoch [84/500], Train Loss: 0.8634, Train RMSE: 0.9292\n",
      "Epoch [84/500], Validation Loss: 2.4178, Validation RMSE: 1.5549, Valid PR: 0.3768\n",
      "Epoch [85/500], Train Loss: 0.9141, Train RMSE: 0.9561\n",
      "Epoch [85/500], Validation Loss: 2.4066, Validation RMSE: 1.5513, Valid PR: 0.3761\n",
      "Epoch [86/500], Train Loss: 0.8051, Train RMSE: 0.8973\n",
      "Epoch [86/500], Validation Loss: 2.3959, Validation RMSE: 1.5479, Valid PR: 0.3731\n",
      "Epoch [87/500], Train Loss: 0.8629, Train RMSE: 0.9289\n",
      "Epoch [87/500], Validation Loss: 2.3858, Validation RMSE: 1.5446, Valid PR: 0.3842\n",
      "Epoch [88/500], Train Loss: 0.7926, Train RMSE: 0.8903\n",
      "Epoch [88/500], Validation Loss: 2.3761, Validation RMSE: 1.5415, Valid PR: 0.4084\n",
      "Epoch [89/500], Train Loss: 0.8117, Train RMSE: 0.9009\n",
      "Epoch [89/500], Validation Loss: 2.3668, Validation RMSE: 1.5384, Valid PR: 0.4238\n",
      "Epoch [90/500], Train Loss: 0.9623, Train RMSE: 0.9810\n",
      "Epoch [90/500], Validation Loss: 2.3580, Validation RMSE: 1.5356, Valid PR: 0.4405\n",
      "Epoch [91/500], Train Loss: 0.8570, Train RMSE: 0.9257\n",
      "Epoch [91/500], Validation Loss: 2.3498, Validation RMSE: 1.5329, Valid PR: 0.4632\n",
      "Epoch [92/500], Train Loss: 0.7481, Train RMSE: 0.8650\n",
      "Epoch [92/500], Validation Loss: 2.3421, Validation RMSE: 1.5304, Valid PR: 0.4832\n",
      "Epoch [93/500], Train Loss: 0.7240, Train RMSE: 0.8509\n",
      "Epoch [93/500], Validation Loss: 2.3347, Validation RMSE: 1.5280, Valid PR: 0.4982\n",
      "Epoch [94/500], Train Loss: 0.8336, Train RMSE: 0.9130\n",
      "Epoch [94/500], Validation Loss: 2.3274, Validation RMSE: 1.5256, Valid PR: 0.4837\n",
      "Epoch [95/500], Train Loss: 0.8595, Train RMSE: 0.9271\n",
      "Epoch [95/500], Validation Loss: 2.3203, Validation RMSE: 1.5232, Valid PR: 0.3941\n",
      "Epoch [96/500], Train Loss: 0.8169, Train RMSE: 0.9038\n",
      "Epoch [96/500], Validation Loss: 2.3132, Validation RMSE: 1.5209, Valid PR: 0.3044\n",
      "Epoch [97/500], Train Loss: 0.8305, Train RMSE: 0.9113\n",
      "Epoch [97/500], Validation Loss: 2.3065, Validation RMSE: 1.5187, Valid PR: 0.3664\n",
      "Epoch [98/500], Train Loss: 0.8096, Train RMSE: 0.8998\n",
      "Epoch [98/500], Validation Loss: 2.2999, Validation RMSE: 1.5165, Valid PR: 0.4445\n",
      "Epoch [99/500], Train Loss: 0.7891, Train RMSE: 0.8883\n",
      "Epoch [99/500], Validation Loss: 2.2936, Validation RMSE: 1.5145, Valid PR: 0.4873\n",
      "Epoch [100/500], Train Loss: 0.8125, Train RMSE: 0.9014\n",
      "Epoch [100/500], Validation Loss: 2.2875, Validation RMSE: 1.5124, Valid PR: 0.5238\n",
      "Epoch [101/500], Train Loss: 0.8274, Train RMSE: 0.9096\n",
      "Epoch [101/500], Validation Loss: 2.2815, Validation RMSE: 1.5104, Valid PR: 0.5576\n",
      "Epoch [102/500], Train Loss: 0.7347, Train RMSE: 0.8571\n",
      "Epoch [102/500], Validation Loss: 2.2756, Validation RMSE: 1.5085, Valid PR: 0.5777\n",
      "Epoch [103/500], Train Loss: 0.7622, Train RMSE: 0.8730\n",
      "Epoch [103/500], Validation Loss: 2.2700, Validation RMSE: 1.5067, Valid PR: 0.5278\n",
      "Epoch [104/500], Train Loss: 0.7850, Train RMSE: 0.8860\n",
      "Epoch [104/500], Validation Loss: 2.2649, Validation RMSE: 1.5050, Valid PR: 0.4224\n",
      "Epoch [105/500], Train Loss: 0.8145, Train RMSE: 0.9025\n",
      "Epoch [105/500], Validation Loss: 2.2600, Validation RMSE: 1.5033, Valid PR: 0.2153\n",
      "Epoch [106/500], Train Loss: 0.7324, Train RMSE: 0.8558\n",
      "Epoch [106/500], Validation Loss: 2.2554, Validation RMSE: 1.5018, Valid PR: 0.0397\n",
      "Epoch [107/500], Train Loss: 0.7817, Train RMSE: 0.8841\n",
      "Epoch [107/500], Validation Loss: 2.2511, Validation RMSE: 1.5004, Valid PR: -0.0799\n",
      "Epoch [108/500], Train Loss: 0.7800, Train RMSE: 0.8832\n",
      "Epoch [108/500], Validation Loss: 2.2469, Validation RMSE: 1.4990, Valid PR: -0.1525\n",
      "Epoch [109/500], Train Loss: 0.7671, Train RMSE: 0.8759\n",
      "Epoch [109/500], Validation Loss: 2.2428, Validation RMSE: 1.4976, Valid PR: -0.2016\n",
      "Epoch [110/500], Train Loss: 0.7478, Train RMSE: 0.8647\n",
      "Epoch [110/500], Validation Loss: 2.2388, Validation RMSE: 1.4963, Valid PR: -0.2124\n",
      "Epoch [111/500], Train Loss: 0.8344, Train RMSE: 0.9135\n",
      "Epoch [111/500], Validation Loss: 2.2351, Validation RMSE: 1.4950, Valid PR: -0.1815\n",
      "Epoch [112/500], Train Loss: 0.7587, Train RMSE: 0.8710\n",
      "Epoch [112/500], Validation Loss: 2.2317, Validation RMSE: 1.4939, Valid PR: -0.1555\n",
      "Epoch [113/500], Train Loss: 0.6870, Train RMSE: 0.8288\n",
      "Epoch [113/500], Validation Loss: 2.2284, Validation RMSE: 1.4928, Valid PR: -0.1350\n",
      "Epoch [114/500], Train Loss: 0.7299, Train RMSE: 0.8543\n",
      "Epoch [114/500], Validation Loss: 2.2254, Validation RMSE: 1.4918, Valid PR: -0.1456\n",
      "Epoch [115/500], Train Loss: 0.7357, Train RMSE: 0.8577\n",
      "Epoch [115/500], Validation Loss: 2.2225, Validation RMSE: 1.4908, Valid PR: -0.1719\n",
      "Epoch [116/500], Train Loss: 0.7551, Train RMSE: 0.8690\n",
      "Epoch [116/500], Validation Loss: 2.2199, Validation RMSE: 1.4899, Valid PR: -0.2036\n",
      "Epoch [117/500], Train Loss: 0.7895, Train RMSE: 0.8885\n",
      "Epoch [117/500], Validation Loss: 2.2174, Validation RMSE: 1.4891, Valid PR: -0.2538\n",
      "Epoch [118/500], Train Loss: 0.7482, Train RMSE: 0.8650\n",
      "Epoch [118/500], Validation Loss: 2.2151, Validation RMSE: 1.4883, Valid PR: -0.3048\n",
      "Epoch [119/500], Train Loss: 0.7594, Train RMSE: 0.8714\n",
      "Epoch [119/500], Validation Loss: 2.2131, Validation RMSE: 1.4876, Valid PR: -0.3317\n",
      "Epoch [120/500], Train Loss: 0.8246, Train RMSE: 0.9081\n",
      "Epoch [120/500], Validation Loss: 2.2112, Validation RMSE: 1.4870, Valid PR: -0.3629\n",
      "Epoch [121/500], Train Loss: 0.9308, Train RMSE: 0.9648\n",
      "Epoch [121/500], Validation Loss: 2.2094, Validation RMSE: 1.4864, Valid PR: -0.3704\n",
      "Epoch [122/500], Train Loss: 0.7595, Train RMSE: 0.8715\n",
      "Epoch [122/500], Validation Loss: 2.2076, Validation RMSE: 1.4858, Valid PR: -0.3655\n",
      "Epoch [123/500], Train Loss: 0.7465, Train RMSE: 0.8640\n",
      "Epoch [123/500], Validation Loss: 2.2060, Validation RMSE: 1.4853, Valid PR: -0.3674\n",
      "Epoch [124/500], Train Loss: 0.7779, Train RMSE: 0.8820\n",
      "Epoch [124/500], Validation Loss: 2.2045, Validation RMSE: 1.4847, Valid PR: -0.3651\n",
      "Epoch [125/500], Train Loss: 0.8205, Train RMSE: 0.9058\n",
      "Epoch [125/500], Validation Loss: 2.2030, Validation RMSE: 1.4842, Valid PR: -0.3345\n",
      "Epoch [126/500], Train Loss: 0.7783, Train RMSE: 0.8822\n",
      "Epoch [126/500], Validation Loss: 2.2017, Validation RMSE: 1.4838, Valid PR: -0.2935\n",
      "Epoch [127/500], Train Loss: 0.6901, Train RMSE: 0.8307\n",
      "Epoch [127/500], Validation Loss: 2.2005, Validation RMSE: 1.4834, Valid PR: -0.2459\n",
      "Epoch [128/500], Train Loss: 0.7664, Train RMSE: 0.8754\n",
      "Epoch [128/500], Validation Loss: 2.1994, Validation RMSE: 1.4830, Valid PR: -0.1852\n",
      "Epoch [129/500], Train Loss: 0.8071, Train RMSE: 0.8984\n",
      "Epoch [129/500], Validation Loss: 2.1984, Validation RMSE: 1.4827, Valid PR: -0.1460\n",
      "Epoch [130/500], Train Loss: 0.7574, Train RMSE: 0.8703\n",
      "Epoch [130/500], Validation Loss: 2.1974, Validation RMSE: 1.4824, Valid PR: -0.1053\n",
      "Epoch [131/500], Train Loss: 0.7754, Train RMSE: 0.8805\n",
      "Epoch [131/500], Validation Loss: 2.1965, Validation RMSE: 1.4821, Valid PR: -0.0538\n",
      "Epoch [132/500], Train Loss: 0.7917, Train RMSE: 0.8898\n",
      "Epoch [132/500], Validation Loss: 2.1957, Validation RMSE: 1.4818, Valid PR: -0.0216\n",
      "Epoch [133/500], Train Loss: 0.7654, Train RMSE: 0.8749\n",
      "Epoch [133/500], Validation Loss: 2.1950, Validation RMSE: 1.4816, Valid PR: 0.0158\n",
      "Epoch [134/500], Train Loss: 0.7663, Train RMSE: 0.8754\n",
      "Epoch [134/500], Validation Loss: 2.1945, Validation RMSE: 1.4814, Valid PR: 0.0530\n",
      "Epoch [135/500], Train Loss: 0.6857, Train RMSE: 0.8281\n",
      "Epoch [135/500], Validation Loss: 2.1939, Validation RMSE: 1.4812, Valid PR: 0.1011\n",
      "Epoch [136/500], Train Loss: 0.7917, Train RMSE: 0.8898\n",
      "Epoch [136/500], Validation Loss: 2.1934, Validation RMSE: 1.4810, Valid PR: 0.1621\n",
      "Epoch [137/500], Train Loss: 0.8077, Train RMSE: 0.8987\n",
      "Epoch [137/500], Validation Loss: 2.1930, Validation RMSE: 1.4809, Valid PR: 0.2246\n",
      "Epoch [138/500], Train Loss: 0.7799, Train RMSE: 0.8831\n",
      "Epoch [138/500], Validation Loss: 2.1927, Validation RMSE: 1.4808, Valid PR: 0.2635\n",
      "Epoch [139/500], Train Loss: 0.7523, Train RMSE: 0.8673\n",
      "Epoch [139/500], Validation Loss: 2.1923, Validation RMSE: 1.4806, Valid PR: 0.3084\n",
      "Epoch [140/500], Train Loss: 0.6915, Train RMSE: 0.8316\n",
      "Epoch [140/500], Validation Loss: 2.1920, Validation RMSE: 1.4805, Valid PR: 0.3384\n",
      "Epoch [141/500], Train Loss: 0.7087, Train RMSE: 0.8418\n",
      "Epoch [141/500], Validation Loss: 2.1917, Validation RMSE: 1.4805, Valid PR: 0.3611\n",
      "Epoch [142/500], Train Loss: 0.8230, Train RMSE: 0.9072\n",
      "Epoch [142/500], Validation Loss: 2.1915, Validation RMSE: 1.4804, Valid PR: 0.3782\n",
      "Epoch [143/500], Train Loss: 0.7355, Train RMSE: 0.8576\n",
      "Epoch [143/500], Validation Loss: 2.1914, Validation RMSE: 1.4803, Valid PR: 0.3853\n",
      "Epoch [144/500], Train Loss: 0.7297, Train RMSE: 0.8542\n",
      "Epoch [144/500], Validation Loss: 2.1912, Validation RMSE: 1.4803, Valid PR: 0.3894\n",
      "Epoch [145/500], Train Loss: 0.7541, Train RMSE: 0.8684\n",
      "Epoch [145/500], Validation Loss: 2.1911, Validation RMSE: 1.4802, Valid PR: 0.3929\n",
      "Epoch [146/500], Train Loss: 0.6931, Train RMSE: 0.8325\n",
      "Epoch [146/500], Validation Loss: 2.1911, Validation RMSE: 1.4802, Valid PR: 0.3919\n",
      "Epoch [147/500], Train Loss: 0.7655, Train RMSE: 0.8749\n",
      "Epoch [147/500], Validation Loss: 2.1912, Validation RMSE: 1.4803, Valid PR: 0.3904\n",
      "Epoch [148/500], Train Loss: 0.8325, Train RMSE: 0.9124\n",
      "Epoch [148/500], Validation Loss: 2.1913, Validation RMSE: 1.4803, Valid PR: 0.3928\n",
      "Epoch [149/500], Train Loss: 0.7060, Train RMSE: 0.8402\n",
      "Epoch [149/500], Validation Loss: 2.1913, Validation RMSE: 1.4803, Valid PR: 0.3973\n",
      "Epoch [150/500], Train Loss: 0.7067, Train RMSE: 0.8406\n",
      "Epoch [150/500], Validation Loss: 2.1914, Validation RMSE: 1.4803, Valid PR: 0.4029\n",
      "Epoch [151/500], Train Loss: 0.6723, Train RMSE: 0.8199\n",
      "Epoch [151/500], Validation Loss: 2.1915, Validation RMSE: 1.4804, Valid PR: 0.4031\n",
      "Epoch [152/500], Train Loss: 0.7693, Train RMSE: 0.8771\n",
      "Epoch [152/500], Validation Loss: 2.1918, Validation RMSE: 1.4805, Valid PR: 0.4026\n",
      "Epoch [153/500], Train Loss: 0.8230, Train RMSE: 0.9072\n",
      "Epoch [153/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.3989\n",
      "Epoch [154/500], Train Loss: 0.7981, Train RMSE: 0.8934\n",
      "Epoch [154/500], Validation Loss: 2.1923, Validation RMSE: 1.4806, Valid PR: 0.3955\n",
      "Epoch [155/500], Train Loss: 0.7706, Train RMSE: 0.8779\n",
      "Epoch [155/500], Validation Loss: 2.1924, Validation RMSE: 1.4807, Valid PR: 0.3855\n",
      "Epoch [156/500], Train Loss: 0.7877, Train RMSE: 0.8875\n",
      "Epoch [156/500], Validation Loss: 2.1926, Validation RMSE: 1.4807, Valid PR: 0.3761\n",
      "Epoch [157/500], Train Loss: 0.7617, Train RMSE: 0.8727\n",
      "Epoch [157/500], Validation Loss: 2.1928, Validation RMSE: 1.4808, Valid PR: 0.3698\n",
      "Epoch [158/500], Train Loss: 0.7378, Train RMSE: 0.8589\n",
      "Epoch [158/500], Validation Loss: 2.1931, Validation RMSE: 1.4809, Valid PR: 0.3670\n",
      "Epoch [159/500], Train Loss: 0.7613, Train RMSE: 0.8725\n",
      "Epoch [159/500], Validation Loss: 2.1933, Validation RMSE: 1.4810, Valid PR: 0.3663\n",
      "Epoch [160/500], Train Loss: 0.7172, Train RMSE: 0.8469\n",
      "Epoch [160/500], Validation Loss: 2.1935, Validation RMSE: 1.4811, Valid PR: 0.3660\n",
      "Epoch [161/500], Train Loss: 0.6882, Train RMSE: 0.8296\n",
      "Epoch [161/500], Validation Loss: 2.1935, Validation RMSE: 1.4811, Valid PR: 0.3708\n",
      "Epoch [162/500], Train Loss: 0.6741, Train RMSE: 0.8211\n",
      "Epoch [162/500], Validation Loss: 2.1934, Validation RMSE: 1.4810, Valid PR: 0.3766\n",
      "Epoch [163/500], Train Loss: 0.6894, Train RMSE: 0.8303\n",
      "Epoch [163/500], Validation Loss: 2.1933, Validation RMSE: 1.4810, Valid PR: 0.3809\n",
      "Epoch [164/500], Train Loss: 0.6926, Train RMSE: 0.8322\n",
      "Epoch [164/500], Validation Loss: 2.1932, Validation RMSE: 1.4810, Valid PR: 0.3887\n",
      "Epoch [165/500], Train Loss: 0.9684, Train RMSE: 0.9841\n",
      "Epoch [165/500], Validation Loss: 2.1931, Validation RMSE: 1.4809, Valid PR: 0.3931\n",
      "Epoch [166/500], Train Loss: 0.7521, Train RMSE: 0.8672\n",
      "Epoch [166/500], Validation Loss: 2.1931, Validation RMSE: 1.4809, Valid PR: 0.3973\n",
      "Epoch [167/500], Train Loss: 0.7202, Train RMSE: 0.8487\n",
      "Epoch [167/500], Validation Loss: 2.1929, Validation RMSE: 1.4808, Valid PR: 0.4030\n",
      "Epoch [168/500], Train Loss: 0.7380, Train RMSE: 0.8591\n",
      "Epoch [168/500], Validation Loss: 2.1925, Validation RMSE: 1.4807, Valid PR: 0.4085\n",
      "Epoch [169/500], Train Loss: 0.6962, Train RMSE: 0.8344\n",
      "Epoch [169/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.4115\n",
      "Epoch [170/500], Train Loss: 0.7299, Train RMSE: 0.8544\n",
      "Epoch [170/500], Validation Loss: 2.1919, Validation RMSE: 1.4805, Valid PR: 0.4134\n",
      "Epoch [171/500], Train Loss: 0.6960, Train RMSE: 0.8342\n",
      "Epoch [171/500], Validation Loss: 2.1918, Validation RMSE: 1.4805, Valid PR: 0.4133\n",
      "Epoch [172/500], Train Loss: 0.7571, Train RMSE: 0.8701\n",
      "Epoch [172/500], Validation Loss: 2.1918, Validation RMSE: 1.4805, Valid PR: 0.4129\n",
      "Epoch [173/500], Train Loss: 0.7367, Train RMSE: 0.8583\n",
      "Epoch [173/500], Validation Loss: 2.1919, Validation RMSE: 1.4805, Valid PR: 0.4137\n",
      "Epoch [174/500], Train Loss: 0.8270, Train RMSE: 0.9094\n",
      "Epoch [174/500], Validation Loss: 2.1920, Validation RMSE: 1.4806, Valid PR: 0.4154\n",
      "Epoch [175/500], Train Loss: 0.7590, Train RMSE: 0.8712\n",
      "Epoch [175/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.4170\n",
      "Epoch [176/500], Train Loss: 0.7640, Train RMSE: 0.8741\n",
      "Epoch [176/500], Validation Loss: 2.1920, Validation RMSE: 1.4805, Valid PR: 0.4194\n",
      "Epoch [177/500], Train Loss: 0.7530, Train RMSE: 0.8677\n",
      "Epoch [177/500], Validation Loss: 2.1920, Validation RMSE: 1.4805, Valid PR: 0.4233\n",
      "Epoch [178/500], Train Loss: 0.7818, Train RMSE: 0.8842\n",
      "Epoch [178/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.4282\n",
      "Epoch [179/500], Train Loss: 0.7204, Train RMSE: 0.8488\n",
      "Epoch [179/500], Validation Loss: 2.1919, Validation RMSE: 1.4805, Valid PR: 0.4335\n",
      "Epoch [180/500], Train Loss: 0.6832, Train RMSE: 0.8266\n",
      "Epoch [180/500], Validation Loss: 2.1920, Validation RMSE: 1.4805, Valid PR: 0.4374\n",
      "Epoch [181/500], Train Loss: 0.8429, Train RMSE: 0.9181\n",
      "Epoch [181/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.4393\n",
      "Epoch [182/500], Train Loss: 0.7091, Train RMSE: 0.8421\n",
      "Epoch [182/500], Validation Loss: 2.1924, Validation RMSE: 1.4807, Valid PR: 0.4402\n",
      "Epoch [183/500], Train Loss: 0.7564, Train RMSE: 0.8697\n",
      "Epoch [183/500], Validation Loss: 2.1928, Validation RMSE: 1.4808, Valid PR: 0.4429\n",
      "Epoch [184/500], Train Loss: 0.6893, Train RMSE: 0.8303\n",
      "Epoch [184/500], Validation Loss: 2.1934, Validation RMSE: 1.4810, Valid PR: 0.4453\n",
      "Epoch [185/500], Train Loss: 0.7215, Train RMSE: 0.8494\n",
      "Epoch [185/500], Validation Loss: 2.1939, Validation RMSE: 1.4812, Valid PR: 0.4478\n",
      "Epoch [186/500], Train Loss: 0.7811, Train RMSE: 0.8838\n",
      "Epoch [186/500], Validation Loss: 2.1945, Validation RMSE: 1.4814, Valid PR: 0.4496\n",
      "Epoch [187/500], Train Loss: 0.6303, Train RMSE: 0.7939\n",
      "Epoch [187/500], Validation Loss: 2.1952, Validation RMSE: 1.4816, Valid PR: 0.4512\n",
      "Epoch [188/500], Train Loss: 0.7578, Train RMSE: 0.8705\n",
      "Epoch [188/500], Validation Loss: 2.1959, Validation RMSE: 1.4819, Valid PR: 0.4524\n",
      "Epoch [189/500], Train Loss: 0.7580, Train RMSE: 0.8707\n",
      "Epoch [189/500], Validation Loss: 2.1971, Validation RMSE: 1.4823, Valid PR: 0.4541\n",
      "Epoch [190/500], Train Loss: 0.6782, Train RMSE: 0.8235\n",
      "Epoch [190/500], Validation Loss: 2.1982, Validation RMSE: 1.4826, Valid PR: 0.4554\n",
      "Epoch [191/500], Train Loss: 0.7144, Train RMSE: 0.8452\n",
      "Epoch [191/500], Validation Loss: 2.1989, Validation RMSE: 1.4829, Valid PR: 0.4570\n",
      "Epoch [192/500], Train Loss: 0.7470, Train RMSE: 0.8643\n",
      "Epoch [192/500], Validation Loss: 2.1987, Validation RMSE: 1.4828, Valid PR: 0.4592\n",
      "Epoch [193/500], Train Loss: 0.7527, Train RMSE: 0.8676\n",
      "Epoch [193/500], Validation Loss: 2.1981, Validation RMSE: 1.4826, Valid PR: 0.4606\n",
      "Epoch [194/500], Train Loss: 0.7194, Train RMSE: 0.8482\n",
      "Epoch [194/500], Validation Loss: 2.1976, Validation RMSE: 1.4824, Valid PR: 0.4608\n",
      "Epoch [195/500], Train Loss: 0.7367, Train RMSE: 0.8583\n",
      "Epoch [195/500], Validation Loss: 2.1973, Validation RMSE: 1.4823, Valid PR: 0.4610\n",
      "Epoch [196/500], Train Loss: 0.7426, Train RMSE: 0.8617\n",
      "Epoch [196/500], Validation Loss: 2.1969, Validation RMSE: 1.4822, Valid PR: 0.4611\n",
      "Early stopping triggered.\n",
      "Test Loss: 3.0524, Test RMSE: 1.7471, Test PR: -0.1148\n",
      "Replication 2 for method3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:122: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 9.5509, Train RMSE: 3.0905\n",
      "Epoch [1/500], Validation Loss: 14.3740, Validation RMSE: 3.7913, Valid PR: 0.4244\n",
      "Epoch [2/500], Train Loss: 4.2126, Train RMSE: 2.0525\n",
      "Epoch [2/500], Validation Loss: 10.2709, Validation RMSE: 3.2048, Valid PR: 0.5515\n",
      "Epoch [3/500], Train Loss: 3.1053, Train RMSE: 1.7622\n",
      "Epoch [3/500], Validation Loss: 8.8349, Validation RMSE: 2.9724, Valid PR: 0.4356\n",
      "Epoch [4/500], Train Loss: 2.8104, Train RMSE: 1.6764\n",
      "Epoch [4/500], Validation Loss: 7.9462, Validation RMSE: 2.8189, Valid PR: 0.3699\n",
      "Epoch [5/500], Train Loss: 2.5512, Train RMSE: 1.5972\n",
      "Epoch [5/500], Validation Loss: 7.2989, Validation RMSE: 2.7016, Valid PR: 0.3711\n",
      "Epoch [6/500], Train Loss: 2.3421, Train RMSE: 1.5304\n",
      "Epoch [6/500], Validation Loss: 6.8148, Validation RMSE: 2.6105, Valid PR: 0.4156\n",
      "Epoch [7/500], Train Loss: 2.3078, Train RMSE: 1.5191\n",
      "Epoch [7/500], Validation Loss: 6.4448, Validation RMSE: 2.5387, Valid PR: 0.2997\n",
      "Epoch [8/500], Train Loss: 1.9916, Train RMSE: 1.4113\n",
      "Epoch [8/500], Validation Loss: 6.1750, Validation RMSE: 2.4849, Valid PR: -0.2212\n",
      "Epoch [9/500], Train Loss: 1.8813, Train RMSE: 1.3716\n",
      "Epoch [9/500], Validation Loss: 5.9868, Validation RMSE: 2.4468, Valid PR: -0.4557\n",
      "Epoch [10/500], Train Loss: 1.9610, Train RMSE: 1.4004\n",
      "Epoch [10/500], Validation Loss: 5.8511, Validation RMSE: 2.4189, Valid PR: -0.4097\n",
      "Epoch [11/500], Train Loss: 1.9006, Train RMSE: 1.3786\n",
      "Epoch [11/500], Validation Loss: 5.7512, Validation RMSE: 2.3982, Valid PR: -0.4355\n",
      "Epoch [12/500], Train Loss: 1.9279, Train RMSE: 1.3885\n",
      "Epoch [12/500], Validation Loss: 5.6636, Validation RMSE: 2.3798, Valid PR: -0.4514\n",
      "Epoch [13/500], Train Loss: 1.8521, Train RMSE: 1.3609\n",
      "Epoch [13/500], Validation Loss: 5.5846, Validation RMSE: 2.3632, Valid PR: -0.4290\n",
      "Epoch [14/500], Train Loss: 1.8048, Train RMSE: 1.3434\n",
      "Epoch [14/500], Validation Loss: 5.5064, Validation RMSE: 2.3466, Valid PR: -0.4247\n",
      "Epoch [15/500], Train Loss: 1.7424, Train RMSE: 1.3200\n",
      "Epoch [15/500], Validation Loss: 5.4283, Validation RMSE: 2.3299, Valid PR: -0.4139\n",
      "Epoch [16/500], Train Loss: 1.8278, Train RMSE: 1.3520\n",
      "Epoch [16/500], Validation Loss: 5.3522, Validation RMSE: 2.3135, Valid PR: -0.4196\n",
      "Epoch [17/500], Train Loss: 1.7929, Train RMSE: 1.3390\n",
      "Epoch [17/500], Validation Loss: 5.2782, Validation RMSE: 2.2974, Valid PR: -0.4308\n",
      "Epoch [18/500], Train Loss: 1.7048, Train RMSE: 1.3057\n",
      "Epoch [18/500], Validation Loss: 5.2064, Validation RMSE: 2.2817, Valid PR: -0.4459\n",
      "Epoch [19/500], Train Loss: 1.6875, Train RMSE: 1.2990\n",
      "Epoch [19/500], Validation Loss: 5.1368, Validation RMSE: 2.2665, Valid PR: -0.4578\n",
      "Epoch [20/500], Train Loss: 1.7250, Train RMSE: 1.3134\n",
      "Epoch [20/500], Validation Loss: 5.0697, Validation RMSE: 2.2516, Valid PR: -0.4778\n",
      "Epoch [21/500], Train Loss: 1.6316, Train RMSE: 1.2774\n",
      "Epoch [21/500], Validation Loss: 5.0048, Validation RMSE: 2.2371, Valid PR: -0.4982\n",
      "Epoch [22/500], Train Loss: 1.6376, Train RMSE: 1.2797\n",
      "Epoch [22/500], Validation Loss: 4.9408, Validation RMSE: 2.2228, Valid PR: -0.5136\n",
      "Epoch [23/500], Train Loss: 1.6467, Train RMSE: 1.2832\n",
      "Epoch [23/500], Validation Loss: 4.8770, Validation RMSE: 2.2084, Valid PR: -0.5303\n",
      "Epoch [24/500], Train Loss: 1.6071, Train RMSE: 1.2677\n",
      "Epoch [24/500], Validation Loss: 4.8139, Validation RMSE: 2.1941, Valid PR: -0.5444\n",
      "Epoch [25/500], Train Loss: 1.6157, Train RMSE: 1.2711\n",
      "Epoch [25/500], Validation Loss: 4.7515, Validation RMSE: 2.1798, Valid PR: -0.5572\n",
      "Epoch [26/500], Train Loss: 1.6635, Train RMSE: 1.2898\n",
      "Epoch [26/500], Validation Loss: 4.6904, Validation RMSE: 2.1657, Valid PR: -0.5632\n",
      "Epoch [27/500], Train Loss: 1.5975, Train RMSE: 1.2639\n",
      "Epoch [27/500], Validation Loss: 4.6311, Validation RMSE: 2.1520, Valid PR: -0.5563\n",
      "Epoch [28/500], Train Loss: 1.5604, Train RMSE: 1.2492\n",
      "Epoch [28/500], Validation Loss: 4.5740, Validation RMSE: 2.1387, Valid PR: -0.4708\n",
      "Epoch [29/500], Train Loss: 1.5579, Train RMSE: 1.2482\n",
      "Epoch [29/500], Validation Loss: 4.5192, Validation RMSE: 2.1258, Valid PR: -0.2873\n",
      "Epoch [30/500], Train Loss: 1.4717, Train RMSE: 1.2132\n",
      "Epoch [30/500], Validation Loss: 4.4665, Validation RMSE: 2.1134, Valid PR: -0.0596\n",
      "Epoch [31/500], Train Loss: 1.5629, Train RMSE: 1.2501\n",
      "Epoch [31/500], Validation Loss: 4.4146, Validation RMSE: 2.1011, Valid PR: 0.1219\n",
      "Epoch [32/500], Train Loss: 1.4241, Train RMSE: 1.1934\n",
      "Epoch [32/500], Validation Loss: 4.3632, Validation RMSE: 2.0888, Valid PR: 0.2115\n",
      "Epoch [33/500], Train Loss: 1.4016, Train RMSE: 1.1839\n",
      "Epoch [33/500], Validation Loss: 4.3124, Validation RMSE: 2.0766, Valid PR: 0.2538\n",
      "Epoch [34/500], Train Loss: 1.4014, Train RMSE: 1.1838\n",
      "Epoch [34/500], Validation Loss: 4.2622, Validation RMSE: 2.0645, Valid PR: 0.2610\n",
      "Epoch [35/500], Train Loss: 1.4603, Train RMSE: 1.2084\n",
      "Epoch [35/500], Validation Loss: 4.2125, Validation RMSE: 2.0524, Valid PR: 0.1770\n",
      "Epoch [36/500], Train Loss: 1.4670, Train RMSE: 1.2112\n",
      "Epoch [36/500], Validation Loss: 4.1636, Validation RMSE: 2.0405, Valid PR: -0.0304\n",
      "Epoch [37/500], Train Loss: 1.3785, Train RMSE: 1.1741\n",
      "Epoch [37/500], Validation Loss: 4.1156, Validation RMSE: 2.0287, Valid PR: -0.3164\n",
      "Epoch [38/500], Train Loss: 1.4220, Train RMSE: 1.1925\n",
      "Epoch [38/500], Validation Loss: 4.0683, Validation RMSE: 2.0170, Valid PR: -0.4624\n",
      "Epoch [39/500], Train Loss: 1.4283, Train RMSE: 1.1951\n",
      "Epoch [39/500], Validation Loss: 4.0221, Validation RMSE: 2.0055, Valid PR: -0.4745\n",
      "Epoch [40/500], Train Loss: 1.4037, Train RMSE: 1.1848\n",
      "Epoch [40/500], Validation Loss: 3.9766, Validation RMSE: 1.9941, Valid PR: -0.4414\n",
      "Epoch [41/500], Train Loss: 1.4125, Train RMSE: 1.1885\n",
      "Epoch [41/500], Validation Loss: 3.9326, Validation RMSE: 1.9831, Valid PR: -0.4229\n",
      "Epoch [42/500], Train Loss: 1.3529, Train RMSE: 1.1631\n",
      "Epoch [42/500], Validation Loss: 3.8895, Validation RMSE: 1.9722, Valid PR: -0.4208\n",
      "Epoch [43/500], Train Loss: 1.3034, Train RMSE: 1.1417\n",
      "Epoch [43/500], Validation Loss: 3.8469, Validation RMSE: 1.9614, Valid PR: -0.4290\n",
      "Epoch [44/500], Train Loss: 1.2618, Train RMSE: 1.1233\n",
      "Epoch [44/500], Validation Loss: 3.8048, Validation RMSE: 1.9506, Valid PR: -0.3963\n",
      "Epoch [45/500], Train Loss: 1.3078, Train RMSE: 1.1436\n",
      "Epoch [45/500], Validation Loss: 3.7636, Validation RMSE: 1.9400, Valid PR: -0.3485\n",
      "Epoch [46/500], Train Loss: 1.2110, Train RMSE: 1.1004\n",
      "Epoch [46/500], Validation Loss: 3.7228, Validation RMSE: 1.9295, Valid PR: -0.2601\n",
      "Epoch [47/500], Train Loss: 1.3490, Train RMSE: 1.1615\n",
      "Epoch [47/500], Validation Loss: 3.6828, Validation RMSE: 1.9191, Valid PR: -0.1812\n",
      "Epoch [48/500], Train Loss: 1.2002, Train RMSE: 1.0955\n",
      "Epoch [48/500], Validation Loss: 3.6435, Validation RMSE: 1.9088, Valid PR: -0.0760\n",
      "Epoch [49/500], Train Loss: 1.2984, Train RMSE: 1.1395\n",
      "Epoch [49/500], Validation Loss: 3.6048, Validation RMSE: 1.8986, Valid PR: 0.0584\n",
      "Epoch [50/500], Train Loss: 1.2598, Train RMSE: 1.1224\n",
      "Epoch [50/500], Validation Loss: 3.5672, Validation RMSE: 1.8887, Valid PR: 0.1389\n",
      "Epoch [51/500], Train Loss: 1.2663, Train RMSE: 1.1253\n",
      "Epoch [51/500], Validation Loss: 3.5305, Validation RMSE: 1.8790, Valid PR: 0.1881\n",
      "Epoch [52/500], Train Loss: 1.2739, Train RMSE: 1.1287\n",
      "Epoch [52/500], Validation Loss: 3.4947, Validation RMSE: 1.8694, Valid PR: 0.2036\n",
      "Epoch [53/500], Train Loss: 1.2394, Train RMSE: 1.1133\n",
      "Epoch [53/500], Validation Loss: 3.4596, Validation RMSE: 1.8600, Valid PR: 0.1851\n",
      "Epoch [54/500], Train Loss: 1.2827, Train RMSE: 1.1326\n",
      "Epoch [54/500], Validation Loss: 3.4246, Validation RMSE: 1.8506, Valid PR: 0.1126\n",
      "Epoch [55/500], Train Loss: 1.1915, Train RMSE: 1.0915\n",
      "Epoch [55/500], Validation Loss: 3.3902, Validation RMSE: 1.8412, Valid PR: -0.0177\n",
      "Epoch [56/500], Train Loss: 1.1915, Train RMSE: 1.0916\n",
      "Epoch [56/500], Validation Loss: 3.3564, Validation RMSE: 1.8321, Valid PR: -0.1819\n",
      "Epoch [57/500], Train Loss: 1.1556, Train RMSE: 1.0750\n",
      "Epoch [57/500], Validation Loss: 3.3231, Validation RMSE: 1.8229, Valid PR: -0.3050\n",
      "Epoch [58/500], Train Loss: 1.2191, Train RMSE: 1.1041\n",
      "Epoch [58/500], Validation Loss: 3.2909, Validation RMSE: 1.8141, Valid PR: -0.4188\n",
      "Epoch [59/500], Train Loss: 1.1032, Train RMSE: 1.0503\n",
      "Epoch [59/500], Validation Loss: 3.2587, Validation RMSE: 1.8052, Valid PR: -0.4400\n",
      "Epoch [60/500], Train Loss: 1.0511, Train RMSE: 1.0252\n",
      "Epoch [60/500], Validation Loss: 3.2272, Validation RMSE: 1.7964, Valid PR: -0.4443\n",
      "Epoch [61/500], Train Loss: 1.1413, Train RMSE: 1.0683\n",
      "Epoch [61/500], Validation Loss: 3.1959, Validation RMSE: 1.7877, Valid PR: -0.4373\n",
      "Epoch [62/500], Train Loss: 1.1793, Train RMSE: 1.0860\n",
      "Epoch [62/500], Validation Loss: 3.1650, Validation RMSE: 1.7791, Valid PR: -0.4326\n",
      "Epoch [63/500], Train Loss: 1.2050, Train RMSE: 1.0977\n",
      "Epoch [63/500], Validation Loss: 3.1350, Validation RMSE: 1.7706, Valid PR: -0.4457\n",
      "Epoch [64/500], Train Loss: 1.0838, Train RMSE: 1.0410\n",
      "Epoch [64/500], Validation Loss: 3.1059, Validation RMSE: 1.7624, Valid PR: -0.4572\n",
      "Epoch [65/500], Train Loss: 1.0790, Train RMSE: 1.0387\n",
      "Epoch [65/500], Validation Loss: 3.0778, Validation RMSE: 1.7544, Valid PR: -0.4666\n",
      "Epoch [66/500], Train Loss: 1.0597, Train RMSE: 1.0294\n",
      "Epoch [66/500], Validation Loss: 3.0501, Validation RMSE: 1.7465, Valid PR: -0.4660\n",
      "Epoch [67/500], Train Loss: 1.0465, Train RMSE: 1.0230\n",
      "Epoch [67/500], Validation Loss: 3.0230, Validation RMSE: 1.7387, Valid PR: -0.4796\n",
      "Epoch [68/500], Train Loss: 1.0500, Train RMSE: 1.0247\n",
      "Epoch [68/500], Validation Loss: 2.9967, Validation RMSE: 1.7311, Valid PR: -0.4935\n",
      "Epoch [69/500], Train Loss: 1.1256, Train RMSE: 1.0609\n",
      "Epoch [69/500], Validation Loss: 2.9711, Validation RMSE: 1.7237, Valid PR: -0.5033\n",
      "Epoch [70/500], Train Loss: 1.0314, Train RMSE: 1.0156\n",
      "Epoch [70/500], Validation Loss: 2.9460, Validation RMSE: 1.7164, Valid PR: -0.5260\n",
      "Epoch [71/500], Train Loss: 0.9657, Train RMSE: 0.9827\n",
      "Epoch [71/500], Validation Loss: 2.9216, Validation RMSE: 1.7093, Valid PR: -0.4997\n",
      "Epoch [72/500], Train Loss: 1.0532, Train RMSE: 1.0263\n",
      "Epoch [72/500], Validation Loss: 2.8981, Validation RMSE: 1.7024, Valid PR: -0.4791\n",
      "Epoch [73/500], Train Loss: 0.9479, Train RMSE: 0.9736\n",
      "Epoch [73/500], Validation Loss: 2.8749, Validation RMSE: 1.6956, Valid PR: -0.4850\n",
      "Epoch [74/500], Train Loss: 1.0641, Train RMSE: 1.0316\n",
      "Epoch [74/500], Validation Loss: 2.8523, Validation RMSE: 1.6889, Valid PR: -0.5424\n",
      "Epoch [75/500], Train Loss: 0.9503, Train RMSE: 0.9749\n",
      "Epoch [75/500], Validation Loss: 2.8303, Validation RMSE: 1.6823, Valid PR: -0.6211\n",
      "Epoch [76/500], Train Loss: 0.9053, Train RMSE: 0.9515\n",
      "Epoch [76/500], Validation Loss: 2.8085, Validation RMSE: 1.6759, Valid PR: -0.6771\n",
      "Epoch [77/500], Train Loss: 1.0458, Train RMSE: 1.0226\n",
      "Epoch [77/500], Validation Loss: 2.7873, Validation RMSE: 1.6695, Valid PR: -0.7280\n",
      "Epoch [78/500], Train Loss: 0.9168, Train RMSE: 0.9575\n",
      "Epoch [78/500], Validation Loss: 2.7667, Validation RMSE: 1.6634, Valid PR: -0.7431\n",
      "Epoch [79/500], Train Loss: 0.9789, Train RMSE: 0.9894\n",
      "Epoch [79/500], Validation Loss: 2.7465, Validation RMSE: 1.6572, Valid PR: -0.7392\n",
      "Epoch [80/500], Train Loss: 0.9989, Train RMSE: 0.9995\n",
      "Epoch [80/500], Validation Loss: 2.7269, Validation RMSE: 1.6513, Valid PR: -0.7239\n",
      "Epoch [81/500], Train Loss: 1.0321, Train RMSE: 1.0159\n",
      "Epoch [81/500], Validation Loss: 2.7077, Validation RMSE: 1.6455, Valid PR: -0.7050\n",
      "Epoch [82/500], Train Loss: 0.9652, Train RMSE: 0.9825\n",
      "Epoch [82/500], Validation Loss: 2.6889, Validation RMSE: 1.6398, Valid PR: -0.6818\n",
      "Epoch [83/500], Train Loss: 0.8622, Train RMSE: 0.9285\n",
      "Epoch [83/500], Validation Loss: 2.6704, Validation RMSE: 1.6341, Valid PR: -0.6521\n",
      "Epoch [84/500], Train Loss: 0.9814, Train RMSE: 0.9906\n",
      "Epoch [84/500], Validation Loss: 2.6525, Validation RMSE: 1.6287, Valid PR: -0.6231\n",
      "Epoch [85/500], Train Loss: 0.9568, Train RMSE: 0.9782\n",
      "Epoch [85/500], Validation Loss: 2.6352, Validation RMSE: 1.6233, Valid PR: -0.5970\n",
      "Epoch [86/500], Train Loss: 0.8982, Train RMSE: 0.9477\n",
      "Epoch [86/500], Validation Loss: 2.6182, Validation RMSE: 1.6181, Valid PR: -0.5856\n",
      "Epoch [87/500], Train Loss: 0.9001, Train RMSE: 0.9487\n",
      "Epoch [87/500], Validation Loss: 2.6016, Validation RMSE: 1.6129, Valid PR: -0.5760\n",
      "Epoch [88/500], Train Loss: 0.9390, Train RMSE: 0.9690\n",
      "Epoch [88/500], Validation Loss: 2.5855, Validation RMSE: 1.6079, Valid PR: -0.5682\n",
      "Epoch [89/500], Train Loss: 0.9272, Train RMSE: 0.9629\n",
      "Epoch [89/500], Validation Loss: 2.5701, Validation RMSE: 1.6031, Valid PR: -0.5551\n",
      "Epoch [90/500], Train Loss: 0.8614, Train RMSE: 0.9281\n",
      "Epoch [90/500], Validation Loss: 2.5552, Validation RMSE: 1.5985, Valid PR: -0.5259\n",
      "Epoch [91/500], Train Loss: 0.9626, Train RMSE: 0.9811\n",
      "Epoch [91/500], Validation Loss: 2.5406, Validation RMSE: 1.5939, Valid PR: -0.4739\n",
      "Epoch [92/500], Train Loss: 0.9013, Train RMSE: 0.9494\n",
      "Epoch [92/500], Validation Loss: 2.5268, Validation RMSE: 1.5896, Valid PR: -0.4096\n",
      "Epoch [93/500], Train Loss: 0.8839, Train RMSE: 0.9402\n",
      "Epoch [93/500], Validation Loss: 2.5134, Validation RMSE: 1.5854, Valid PR: -0.3516\n",
      "Epoch [94/500], Train Loss: 0.9693, Train RMSE: 0.9845\n",
      "Epoch [94/500], Validation Loss: 2.5004, Validation RMSE: 1.5813, Valid PR: -0.3209\n",
      "Epoch [95/500], Train Loss: 0.7951, Train RMSE: 0.8917\n",
      "Epoch [95/500], Validation Loss: 2.4877, Validation RMSE: 1.5773, Valid PR: -0.2938\n",
      "Epoch [96/500], Train Loss: 0.8514, Train RMSE: 0.9227\n",
      "Epoch [96/500], Validation Loss: 2.4752, Validation RMSE: 1.5733, Valid PR: -0.3223\n",
      "Epoch [97/500], Train Loss: 0.8985, Train RMSE: 0.9479\n",
      "Epoch [97/500], Validation Loss: 2.4629, Validation RMSE: 1.5694, Valid PR: -0.3134\n",
      "Epoch [98/500], Train Loss: 0.8275, Train RMSE: 0.9097\n",
      "Epoch [98/500], Validation Loss: 2.4508, Validation RMSE: 1.5655, Valid PR: -0.2876\n",
      "Epoch [99/500], Train Loss: 0.8674, Train RMSE: 0.9313\n",
      "Epoch [99/500], Validation Loss: 2.4390, Validation RMSE: 1.5617, Valid PR: -0.2305\n",
      "Epoch [100/500], Train Loss: 0.7912, Train RMSE: 0.8895\n",
      "Epoch [100/500], Validation Loss: 2.4276, Validation RMSE: 1.5581, Valid PR: -0.1393\n",
      "Epoch [101/500], Train Loss: 0.8389, Train RMSE: 0.9159\n",
      "Epoch [101/500], Validation Loss: 2.4167, Validation RMSE: 1.5546, Valid PR: 0.0033\n",
      "Epoch [102/500], Train Loss: 0.8916, Train RMSE: 0.9442\n",
      "Epoch [102/500], Validation Loss: 2.4063, Validation RMSE: 1.5512, Valid PR: 0.1210\n",
      "Epoch [103/500], Train Loss: 0.7896, Train RMSE: 0.8886\n",
      "Epoch [103/500], Validation Loss: 2.3964, Validation RMSE: 1.5480, Valid PR: 0.2015\n",
      "Epoch [104/500], Train Loss: 0.8558, Train RMSE: 0.9251\n",
      "Epoch [104/500], Validation Loss: 2.3867, Validation RMSE: 1.5449, Valid PR: 0.3027\n",
      "Epoch [105/500], Train Loss: 0.8172, Train RMSE: 0.9040\n",
      "Epoch [105/500], Validation Loss: 2.3773, Validation RMSE: 1.5418, Valid PR: 0.3678\n",
      "Epoch [106/500], Train Loss: 0.8366, Train RMSE: 0.9147\n",
      "Epoch [106/500], Validation Loss: 2.3682, Validation RMSE: 1.5389, Valid PR: 0.3709\n",
      "Epoch [107/500], Train Loss: 0.7752, Train RMSE: 0.8805\n",
      "Epoch [107/500], Validation Loss: 2.3596, Validation RMSE: 1.5361, Valid PR: 0.3551\n",
      "Epoch [108/500], Train Loss: 0.8351, Train RMSE: 0.9138\n",
      "Epoch [108/500], Validation Loss: 2.3513, Validation RMSE: 1.5334, Valid PR: 0.3521\n",
      "Epoch [109/500], Train Loss: 0.8632, Train RMSE: 0.9291\n",
      "Epoch [109/500], Validation Loss: 2.3434, Validation RMSE: 1.5308, Valid PR: 0.3450\n",
      "Epoch [110/500], Train Loss: 0.8855, Train RMSE: 0.9410\n",
      "Epoch [110/500], Validation Loss: 2.3359, Validation RMSE: 1.5284, Valid PR: 0.3374\n",
      "Epoch [111/500], Train Loss: 0.8788, Train RMSE: 0.9375\n",
      "Epoch [111/500], Validation Loss: 2.3285, Validation RMSE: 1.5259, Valid PR: 0.3398\n",
      "Epoch [112/500], Train Loss: 0.8060, Train RMSE: 0.8978\n",
      "Epoch [112/500], Validation Loss: 2.3213, Validation RMSE: 1.5236, Valid PR: 0.3478\n",
      "Epoch [113/500], Train Loss: 0.8608, Train RMSE: 0.9278\n",
      "Epoch [113/500], Validation Loss: 2.3144, Validation RMSE: 1.5213, Valid PR: 0.3476\n",
      "Epoch [114/500], Train Loss: 0.8426, Train RMSE: 0.9179\n",
      "Epoch [114/500], Validation Loss: 2.3078, Validation RMSE: 1.5191, Valid PR: 0.3433\n",
      "Epoch [115/500], Train Loss: 0.8101, Train RMSE: 0.9001\n",
      "Epoch [115/500], Validation Loss: 2.3013, Validation RMSE: 1.5170, Valid PR: 0.3416\n",
      "Epoch [116/500], Train Loss: 0.7421, Train RMSE: 0.8615\n",
      "Epoch [116/500], Validation Loss: 2.2950, Validation RMSE: 1.5149, Valid PR: 0.3343\n",
      "Epoch [117/500], Train Loss: 0.8348, Train RMSE: 0.9137\n",
      "Epoch [117/500], Validation Loss: 2.2891, Validation RMSE: 1.5130, Valid PR: 0.3306\n",
      "Epoch [118/500], Train Loss: 0.8000, Train RMSE: 0.8944\n",
      "Epoch [118/500], Validation Loss: 2.2834, Validation RMSE: 1.5111, Valid PR: 0.3315\n",
      "Epoch [119/500], Train Loss: 0.8555, Train RMSE: 0.9249\n",
      "Epoch [119/500], Validation Loss: 2.2779, Validation RMSE: 1.5093, Valid PR: 0.3201\n",
      "Epoch [120/500], Train Loss: 0.7710, Train RMSE: 0.8781\n",
      "Epoch [120/500], Validation Loss: 2.2724, Validation RMSE: 1.5075, Valid PR: 0.3188\n",
      "Epoch [121/500], Train Loss: 0.7838, Train RMSE: 0.8853\n",
      "Epoch [121/500], Validation Loss: 2.2672, Validation RMSE: 1.5057, Valid PR: 0.3335\n",
      "Epoch [122/500], Train Loss: 0.8184, Train RMSE: 0.9047\n",
      "Epoch [122/500], Validation Loss: 2.2624, Validation RMSE: 1.5041, Valid PR: 0.3384\n",
      "Epoch [123/500], Train Loss: 0.7758, Train RMSE: 0.8808\n",
      "Epoch [123/500], Validation Loss: 2.2578, Validation RMSE: 1.5026, Valid PR: 0.3616\n",
      "Epoch [124/500], Train Loss: 0.7009, Train RMSE: 0.8372\n",
      "Epoch [124/500], Validation Loss: 2.2535, Validation RMSE: 1.5012, Valid PR: 0.3844\n",
      "Epoch [125/500], Train Loss: 0.8226, Train RMSE: 0.9070\n",
      "Epoch [125/500], Validation Loss: 2.2494, Validation RMSE: 1.4998, Valid PR: 0.3990\n",
      "Epoch [126/500], Train Loss: 0.8235, Train RMSE: 0.9075\n",
      "Epoch [126/500], Validation Loss: 2.2455, Validation RMSE: 1.4985, Valid PR: 0.4106\n",
      "Epoch [127/500], Train Loss: 0.7940, Train RMSE: 0.8910\n",
      "Epoch [127/500], Validation Loss: 2.2418, Validation RMSE: 1.4973, Valid PR: 0.4301\n",
      "Epoch [128/500], Train Loss: 0.7700, Train RMSE: 0.8775\n",
      "Epoch [128/500], Validation Loss: 2.2382, Validation RMSE: 1.4961, Valid PR: 0.4431\n",
      "Epoch [129/500], Train Loss: 0.8565, Train RMSE: 0.9254\n",
      "Epoch [129/500], Validation Loss: 2.2346, Validation RMSE: 1.4949, Valid PR: 0.4531\n",
      "Epoch [130/500], Train Loss: 0.7807, Train RMSE: 0.8836\n",
      "Epoch [130/500], Validation Loss: 2.2312, Validation RMSE: 1.4937, Valid PR: 0.4466\n",
      "Epoch [131/500], Train Loss: 0.7693, Train RMSE: 0.8771\n",
      "Epoch [131/500], Validation Loss: 2.2279, Validation RMSE: 1.4926, Valid PR: 0.4450\n",
      "Epoch [132/500], Train Loss: 0.8089, Train RMSE: 0.8994\n",
      "Epoch [132/500], Validation Loss: 2.2248, Validation RMSE: 1.4916, Valid PR: 0.4451\n",
      "Epoch [133/500], Train Loss: 0.7459, Train RMSE: 0.8636\n",
      "Epoch [133/500], Validation Loss: 2.2219, Validation RMSE: 1.4906, Valid PR: 0.4447\n",
      "Epoch [134/500], Train Loss: 0.8083, Train RMSE: 0.8991\n",
      "Epoch [134/500], Validation Loss: 2.2193, Validation RMSE: 1.4897, Valid PR: 0.4375\n",
      "Epoch [135/500], Train Loss: 0.7945, Train RMSE: 0.8913\n",
      "Epoch [135/500], Validation Loss: 2.2168, Validation RMSE: 1.4889, Valid PR: 0.4285\n",
      "Epoch [136/500], Train Loss: 0.7807, Train RMSE: 0.8836\n",
      "Epoch [136/500], Validation Loss: 2.2144, Validation RMSE: 1.4881, Valid PR: 0.4216\n",
      "Epoch [137/500], Train Loss: 0.7671, Train RMSE: 0.8759\n",
      "Epoch [137/500], Validation Loss: 2.2121, Validation RMSE: 1.4873, Valid PR: 0.4137\n",
      "Epoch [138/500], Train Loss: 0.7873, Train RMSE: 0.8873\n",
      "Epoch [138/500], Validation Loss: 2.2100, Validation RMSE: 1.4866, Valid PR: 0.4052\n",
      "Epoch [139/500], Train Loss: 0.7079, Train RMSE: 0.8414\n",
      "Epoch [139/500], Validation Loss: 2.2082, Validation RMSE: 1.4860, Valid PR: 0.3969\n",
      "Epoch [140/500], Train Loss: 0.7335, Train RMSE: 0.8564\n",
      "Epoch [140/500], Validation Loss: 2.2064, Validation RMSE: 1.4854, Valid PR: 0.3940\n",
      "Epoch [141/500], Train Loss: 0.7390, Train RMSE: 0.8597\n",
      "Epoch [141/500], Validation Loss: 2.2047, Validation RMSE: 1.4848, Valid PR: 0.3943\n",
      "Epoch [142/500], Train Loss: 0.7927, Train RMSE: 0.8903\n",
      "Epoch [142/500], Validation Loss: 2.2031, Validation RMSE: 1.4843, Valid PR: 0.3979\n",
      "Epoch [143/500], Train Loss: 0.7483, Train RMSE: 0.8650\n",
      "Epoch [143/500], Validation Loss: 2.2015, Validation RMSE: 1.4838, Valid PR: 0.4084\n",
      "Epoch [144/500], Train Loss: 0.7453, Train RMSE: 0.8633\n",
      "Epoch [144/500], Validation Loss: 2.2002, Validation RMSE: 1.4833, Valid PR: 0.4165\n",
      "Epoch [145/500], Train Loss: 0.7198, Train RMSE: 0.8484\n",
      "Epoch [145/500], Validation Loss: 2.1990, Validation RMSE: 1.4829, Valid PR: 0.4231\n",
      "Epoch [146/500], Train Loss: 0.7808, Train RMSE: 0.8836\n",
      "Epoch [146/500], Validation Loss: 2.1979, Validation RMSE: 1.4825, Valid PR: 0.4287\n",
      "Epoch [147/500], Train Loss: 0.8023, Train RMSE: 0.8957\n",
      "Epoch [147/500], Validation Loss: 2.1968, Validation RMSE: 1.4822, Valid PR: 0.4449\n",
      "Epoch [148/500], Train Loss: 0.7763, Train RMSE: 0.8811\n",
      "Epoch [148/500], Validation Loss: 2.1958, Validation RMSE: 1.4818, Valid PR: 0.4597\n",
      "Epoch [149/500], Train Loss: 0.8090, Train RMSE: 0.8994\n",
      "Epoch [149/500], Validation Loss: 2.1948, Validation RMSE: 1.4815, Valid PR: 0.4748\n",
      "Epoch [150/500], Train Loss: 0.6733, Train RMSE: 0.8205\n",
      "Epoch [150/500], Validation Loss: 2.1939, Validation RMSE: 1.4812, Valid PR: 0.4889\n",
      "Epoch [151/500], Train Loss: 0.7482, Train RMSE: 0.8650\n",
      "Epoch [151/500], Validation Loss: 2.1930, Validation RMSE: 1.4809, Valid PR: 0.5005\n",
      "Epoch [152/500], Train Loss: 0.7701, Train RMSE: 0.8776\n",
      "Epoch [152/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.5124\n",
      "Epoch [153/500], Train Loss: 0.8197, Train RMSE: 0.9054\n",
      "Epoch [153/500], Validation Loss: 2.1914, Validation RMSE: 1.4803, Valid PR: 0.5208\n",
      "Epoch [154/500], Train Loss: 0.7796, Train RMSE: 0.8829\n",
      "Epoch [154/500], Validation Loss: 2.1907, Validation RMSE: 1.4801, Valid PR: 0.5262\n",
      "Epoch [155/500], Train Loss: 0.7235, Train RMSE: 0.8506\n",
      "Epoch [155/500], Validation Loss: 2.1901, Validation RMSE: 1.4799, Valid PR: 0.5266\n",
      "Epoch [156/500], Train Loss: 0.7911, Train RMSE: 0.8894\n",
      "Epoch [156/500], Validation Loss: 2.1897, Validation RMSE: 1.4798, Valid PR: 0.5281\n",
      "Epoch [157/500], Train Loss: 0.7507, Train RMSE: 0.8664\n",
      "Epoch [157/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.5302\n",
      "Epoch [158/500], Train Loss: 0.8051, Train RMSE: 0.8972\n",
      "Epoch [158/500], Validation Loss: 2.1892, Validation RMSE: 1.4796, Valid PR: 0.5307\n",
      "Epoch [159/500], Train Loss: 0.7364, Train RMSE: 0.8581\n",
      "Epoch [159/500], Validation Loss: 2.1892, Validation RMSE: 1.4796, Valid PR: 0.5334\n",
      "Epoch [160/500], Train Loss: 0.7982, Train RMSE: 0.8934\n",
      "Epoch [160/500], Validation Loss: 2.1892, Validation RMSE: 1.4796, Valid PR: 0.5351\n",
      "Epoch [161/500], Train Loss: 0.7323, Train RMSE: 0.8557\n",
      "Epoch [161/500], Validation Loss: 2.1893, Validation RMSE: 1.4796, Valid PR: 0.5338\n",
      "Epoch [162/500], Train Loss: 0.7066, Train RMSE: 0.8406\n",
      "Epoch [162/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.5312\n",
      "Epoch [163/500], Train Loss: 0.8190, Train RMSE: 0.9050\n",
      "Epoch [163/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.5289\n",
      "Epoch [164/500], Train Loss: 0.6721, Train RMSE: 0.8198\n",
      "Epoch [164/500], Validation Loss: 2.1895, Validation RMSE: 1.4797, Valid PR: 0.5289\n",
      "Epoch [165/500], Train Loss: 0.7454, Train RMSE: 0.8634\n",
      "Epoch [165/500], Validation Loss: 2.1897, Validation RMSE: 1.4798, Valid PR: 0.5294\n",
      "Epoch [166/500], Train Loss: 0.8004, Train RMSE: 0.8947\n",
      "Epoch [166/500], Validation Loss: 2.1900, Validation RMSE: 1.4798, Valid PR: 0.5310\n",
      "Epoch [167/500], Train Loss: 0.7626, Train RMSE: 0.8733\n",
      "Epoch [167/500], Validation Loss: 2.1902, Validation RMSE: 1.4799, Valid PR: 0.5299\n",
      "Epoch [168/500], Train Loss: 0.7091, Train RMSE: 0.8421\n",
      "Epoch [168/500], Validation Loss: 2.1905, Validation RMSE: 1.4800, Valid PR: 0.5238\n",
      "Epoch [169/500], Train Loss: 0.7570, Train RMSE: 0.8701\n",
      "Epoch [169/500], Validation Loss: 2.1906, Validation RMSE: 1.4801, Valid PR: 0.5188\n",
      "Epoch [170/500], Train Loss: 0.7120, Train RMSE: 0.8438\n",
      "Epoch [170/500], Validation Loss: 2.1906, Validation RMSE: 1.4801, Valid PR: 0.5121\n",
      "Epoch [171/500], Train Loss: 0.7052, Train RMSE: 0.8398\n",
      "Epoch [171/500], Validation Loss: 2.1907, Validation RMSE: 1.4801, Valid PR: 0.5104\n",
      "Epoch [172/500], Train Loss: 0.7311, Train RMSE: 0.8551\n",
      "Epoch [172/500], Validation Loss: 2.1907, Validation RMSE: 1.4801, Valid PR: 0.5091\n",
      "Epoch [173/500], Train Loss: 0.7689, Train RMSE: 0.8769\n",
      "Epoch [173/500], Validation Loss: 2.1907, Validation RMSE: 1.4801, Valid PR: 0.5073\n",
      "Epoch [174/500], Train Loss: 0.7972, Train RMSE: 0.8929\n",
      "Epoch [174/500], Validation Loss: 2.1906, Validation RMSE: 1.4801, Valid PR: 0.5038\n",
      "Epoch [175/500], Train Loss: 0.7228, Train RMSE: 0.8502\n",
      "Epoch [175/500], Validation Loss: 2.1904, Validation RMSE: 1.4800, Valid PR: 0.5003\n",
      "Epoch [176/500], Train Loss: 0.7508, Train RMSE: 0.8665\n",
      "Epoch [176/500], Validation Loss: 2.1903, Validation RMSE: 1.4800, Valid PR: 0.4966\n",
      "Epoch [177/500], Train Loss: 0.7015, Train RMSE: 0.8376\n",
      "Epoch [177/500], Validation Loss: 2.1900, Validation RMSE: 1.4799, Valid PR: 0.4936\n",
      "Epoch [178/500], Train Loss: 0.8470, Train RMSE: 0.9203\n",
      "Epoch [178/500], Validation Loss: 2.1898, Validation RMSE: 1.4798, Valid PR: 0.4854\n",
      "Epoch [179/500], Train Loss: 0.7512, Train RMSE: 0.8667\n",
      "Epoch [179/500], Validation Loss: 2.1896, Validation RMSE: 1.4797, Valid PR: 0.4768\n",
      "Epoch [180/500], Train Loss: 0.6938, Train RMSE: 0.8330\n",
      "Epoch [180/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.4693\n",
      "Epoch [181/500], Train Loss: 0.7554, Train RMSE: 0.8692\n",
      "Epoch [181/500], Validation Loss: 2.1892, Validation RMSE: 1.4796, Valid PR: 0.4636\n",
      "Epoch [182/500], Train Loss: 0.6786, Train RMSE: 0.8237\n",
      "Epoch [182/500], Validation Loss: 2.1890, Validation RMSE: 1.4795, Valid PR: 0.4600\n",
      "Epoch [183/500], Train Loss: 0.6998, Train RMSE: 0.8366\n",
      "Epoch [183/500], Validation Loss: 2.1886, Validation RMSE: 1.4794, Valid PR: 0.4570\n",
      "Epoch [184/500], Train Loss: 0.8461, Train RMSE: 0.9199\n",
      "Epoch [184/500], Validation Loss: 2.1881, Validation RMSE: 1.4792, Valid PR: 0.4567\n",
      "Epoch [185/500], Train Loss: 0.6906, Train RMSE: 0.8310\n",
      "Epoch [185/500], Validation Loss: 2.1878, Validation RMSE: 1.4791, Valid PR: 0.4555\n",
      "Epoch [186/500], Train Loss: 0.7605, Train RMSE: 0.8721\n",
      "Epoch [186/500], Validation Loss: 2.1875, Validation RMSE: 1.4790, Valid PR: 0.4557\n",
      "Epoch [187/500], Train Loss: 0.7586, Train RMSE: 0.8710\n",
      "Epoch [187/500], Validation Loss: 2.1870, Validation RMSE: 1.4788, Valid PR: 0.4573\n",
      "Epoch [188/500], Train Loss: 0.7570, Train RMSE: 0.8701\n",
      "Epoch [188/500], Validation Loss: 2.1866, Validation RMSE: 1.4787, Valid PR: 0.4587\n",
      "Epoch [189/500], Train Loss: 0.6737, Train RMSE: 0.8208\n",
      "Epoch [189/500], Validation Loss: 2.1864, Validation RMSE: 1.4786, Valid PR: 0.4603\n",
      "Epoch [190/500], Train Loss: 0.7814, Train RMSE: 0.8840\n",
      "Epoch [190/500], Validation Loss: 2.1861, Validation RMSE: 1.4785, Valid PR: 0.4604\n",
      "Epoch [191/500], Train Loss: 0.6895, Train RMSE: 0.8304\n",
      "Epoch [191/500], Validation Loss: 2.1862, Validation RMSE: 1.4786, Valid PR: 0.4583\n",
      "Epoch [192/500], Train Loss: 0.6937, Train RMSE: 0.8329\n",
      "Epoch [192/500], Validation Loss: 2.1866, Validation RMSE: 1.4787, Valid PR: 0.4587\n",
      "Epoch [193/500], Train Loss: 0.7130, Train RMSE: 0.8444\n",
      "Epoch [193/500], Validation Loss: 2.1869, Validation RMSE: 1.4788, Valid PR: 0.4597\n",
      "Epoch [194/500], Train Loss: 0.6864, Train RMSE: 0.8285\n",
      "Epoch [194/500], Validation Loss: 2.1874, Validation RMSE: 1.4790, Valid PR: 0.4592\n",
      "Epoch [195/500], Train Loss: 0.7434, Train RMSE: 0.8622\n",
      "Epoch [195/500], Validation Loss: 2.1881, Validation RMSE: 1.4792, Valid PR: 0.4570\n",
      "Epoch [196/500], Train Loss: 0.7012, Train RMSE: 0.8374\n",
      "Epoch [196/500], Validation Loss: 2.1887, Validation RMSE: 1.4794, Valid PR: 0.4564\n",
      "Epoch [197/500], Train Loss: 0.7009, Train RMSE: 0.8372\n",
      "Epoch [197/500], Validation Loss: 2.1897, Validation RMSE: 1.4798, Valid PR: 0.4559\n",
      "Epoch [198/500], Train Loss: 0.7100, Train RMSE: 0.8426\n",
      "Epoch [198/500], Validation Loss: 2.1906, Validation RMSE: 1.4801, Valid PR: 0.4546\n",
      "Epoch [199/500], Train Loss: 0.6740, Train RMSE: 0.8210\n",
      "Epoch [199/500], Validation Loss: 2.1917, Validation RMSE: 1.4804, Valid PR: 0.4540\n",
      "Epoch [200/500], Train Loss: 0.7130, Train RMSE: 0.8444\n",
      "Epoch [200/500], Validation Loss: 2.1929, Validation RMSE: 1.4808, Valid PR: 0.4531\n",
      "Epoch [201/500], Train Loss: 0.7830, Train RMSE: 0.8849\n",
      "Epoch [201/500], Validation Loss: 2.1941, Validation RMSE: 1.4812, Valid PR: 0.4531\n",
      "Epoch [202/500], Train Loss: 0.7789, Train RMSE: 0.8826\n",
      "Epoch [202/500], Validation Loss: 2.1950, Validation RMSE: 1.4816, Valid PR: 0.4533\n",
      "Epoch [203/500], Train Loss: 0.6910, Train RMSE: 0.8313\n",
      "Epoch [203/500], Validation Loss: 2.1966, Validation RMSE: 1.4821, Valid PR: 0.4524\n",
      "Epoch [204/500], Train Loss: 0.7546, Train RMSE: 0.8686\n",
      "Epoch [204/500], Validation Loss: 2.1982, Validation RMSE: 1.4826, Valid PR: 0.4521\n",
      "Epoch [205/500], Train Loss: 0.7201, Train RMSE: 0.8486\n",
      "Epoch [205/500], Validation Loss: 2.1989, Validation RMSE: 1.4829, Valid PR: 0.4537\n",
      "Epoch [206/500], Train Loss: 0.6248, Train RMSE: 0.7904\n",
      "Epoch [206/500], Validation Loss: 2.1992, Validation RMSE: 1.4830, Valid PR: 0.4567\n",
      "Epoch [207/500], Train Loss: 0.7018, Train RMSE: 0.8378\n",
      "Epoch [207/500], Validation Loss: 2.1992, Validation RMSE: 1.4830, Valid PR: 0.4598\n",
      "Epoch [208/500], Train Loss: 0.7292, Train RMSE: 0.8539\n",
      "Epoch [208/500], Validation Loss: 2.1988, Validation RMSE: 1.4828, Valid PR: 0.4619\n",
      "Epoch [209/500], Train Loss: 0.7274, Train RMSE: 0.8529\n",
      "Epoch [209/500], Validation Loss: 2.1984, Validation RMSE: 1.4827, Valid PR: 0.4634\n",
      "Epoch [210/500], Train Loss: 0.7458, Train RMSE: 0.8636\n",
      "Epoch [210/500], Validation Loss: 2.1971, Validation RMSE: 1.4823, Valid PR: 0.4652\n",
      "Epoch [211/500], Train Loss: 0.7446, Train RMSE: 0.8629\n",
      "Epoch [211/500], Validation Loss: 2.1963, Validation RMSE: 1.4820, Valid PR: 0.4663\n",
      "Epoch [212/500], Train Loss: 0.7316, Train RMSE: 0.8553\n",
      "Epoch [212/500], Validation Loss: 2.1953, Validation RMSE: 1.4816, Valid PR: 0.4678\n",
      "Epoch [213/500], Train Loss: 0.7557, Train RMSE: 0.8693\n",
      "Epoch [213/500], Validation Loss: 2.1942, Validation RMSE: 1.4813, Valid PR: 0.4689\n",
      "Epoch [214/500], Train Loss: 0.7554, Train RMSE: 0.8691\n",
      "Epoch [214/500], Validation Loss: 2.1923, Validation RMSE: 1.4807, Valid PR: 0.4705\n",
      "Epoch [215/500], Train Loss: 0.6714, Train RMSE: 0.8194\n",
      "Epoch [215/500], Validation Loss: 2.1907, Validation RMSE: 1.4801, Valid PR: 0.4724\n",
      "Epoch [216/500], Train Loss: 0.7292, Train RMSE: 0.8539\n",
      "Epoch [216/500], Validation Loss: 2.1898, Validation RMSE: 1.4798, Valid PR: 0.4736\n",
      "Epoch [217/500], Train Loss: 0.7235, Train RMSE: 0.8506\n",
      "Epoch [217/500], Validation Loss: 2.1884, Validation RMSE: 1.4793, Valid PR: 0.4749\n",
      "Epoch [218/500], Train Loss: 0.8084, Train RMSE: 0.8991\n",
      "Epoch [218/500], Validation Loss: 2.1868, Validation RMSE: 1.4788, Valid PR: 0.4749\n",
      "Epoch [219/500], Train Loss: 0.7588, Train RMSE: 0.8711\n",
      "Epoch [219/500], Validation Loss: 2.1846, Validation RMSE: 1.4780, Valid PR: 0.4752\n",
      "Epoch [220/500], Train Loss: 0.6753, Train RMSE: 0.8218\n",
      "Epoch [220/500], Validation Loss: 2.1822, Validation RMSE: 1.4772, Valid PR: 0.4755\n",
      "Epoch [221/500], Train Loss: 0.7367, Train RMSE: 0.8583\n",
      "Epoch [221/500], Validation Loss: 2.1793, Validation RMSE: 1.4762, Valid PR: 0.4758\n",
      "Epoch [222/500], Train Loss: 0.6878, Train RMSE: 0.8293\n",
      "Epoch [222/500], Validation Loss: 2.1760, Validation RMSE: 1.4751, Valid PR: 0.4759\n",
      "Epoch [223/500], Train Loss: 0.7527, Train RMSE: 0.8676\n",
      "Epoch [223/500], Validation Loss: 2.1721, Validation RMSE: 1.4738, Valid PR: 0.4763\n",
      "Epoch [224/500], Train Loss: 0.7424, Train RMSE: 0.8616\n",
      "Epoch [224/500], Validation Loss: 2.1676, Validation RMSE: 1.4723, Valid PR: 0.4768\n",
      "Epoch [225/500], Train Loss: 0.7098, Train RMSE: 0.8425\n",
      "Epoch [225/500], Validation Loss: 2.1641, Validation RMSE: 1.4711, Valid PR: 0.4768\n",
      "Epoch [226/500], Train Loss: 0.7254, Train RMSE: 0.8517\n",
      "Epoch [226/500], Validation Loss: 2.1605, Validation RMSE: 1.4699, Valid PR: 0.4765\n",
      "Epoch [227/500], Train Loss: 0.6519, Train RMSE: 0.8074\n",
      "Epoch [227/500], Validation Loss: 2.1576, Validation RMSE: 1.4689, Valid PR: 0.4760\n",
      "Epoch [228/500], Train Loss: 0.7211, Train RMSE: 0.8492\n",
      "Epoch [228/500], Validation Loss: 2.1556, Validation RMSE: 1.4682, Valid PR: 0.4751\n",
      "Epoch [229/500], Train Loss: 0.7792, Train RMSE: 0.8827\n",
      "Epoch [229/500], Validation Loss: 2.1544, Validation RMSE: 1.4678, Valid PR: 0.4740\n",
      "Epoch [230/500], Train Loss: 0.7152, Train RMSE: 0.8457\n",
      "Epoch [230/500], Validation Loss: 2.1522, Validation RMSE: 1.4670, Valid PR: 0.4735\n",
      "Epoch [231/500], Train Loss: 0.7524, Train RMSE: 0.8674\n",
      "Epoch [231/500], Validation Loss: 2.1503, Validation RMSE: 1.4664, Valid PR: 0.4724\n",
      "Epoch [232/500], Train Loss: 0.7469, Train RMSE: 0.8642\n",
      "Epoch [232/500], Validation Loss: 2.1493, Validation RMSE: 1.4660, Valid PR: 0.4710\n",
      "Epoch [233/500], Train Loss: 0.6873, Train RMSE: 0.8291\n",
      "Epoch [233/500], Validation Loss: 2.1483, Validation RMSE: 1.4657, Valid PR: 0.4695\n",
      "Epoch [234/500], Train Loss: 0.6878, Train RMSE: 0.8294\n",
      "Epoch [234/500], Validation Loss: 2.1491, Validation RMSE: 1.4660, Valid PR: 0.4673\n",
      "Epoch [235/500], Train Loss: 0.7358, Train RMSE: 0.8578\n",
      "Epoch [235/500], Validation Loss: 2.1504, Validation RMSE: 1.4664, Valid PR: 0.4652\n",
      "Epoch [236/500], Train Loss: 0.7071, Train RMSE: 0.8409\n",
      "Epoch [236/500], Validation Loss: 2.1516, Validation RMSE: 1.4668, Valid PR: 0.4638\n",
      "Epoch [237/500], Train Loss: 0.6909, Train RMSE: 0.8312\n",
      "Epoch [237/500], Validation Loss: 2.1522, Validation RMSE: 1.4670, Valid PR: 0.4621\n",
      "Epoch [238/500], Train Loss: 0.6127, Train RMSE: 0.7827\n",
      "Epoch [238/500], Validation Loss: 2.1527, Validation RMSE: 1.4672, Valid PR: 0.4604\n",
      "Epoch [239/500], Train Loss: 0.7095, Train RMSE: 0.8423\n",
      "Epoch [239/500], Validation Loss: 2.1510, Validation RMSE: 1.4666, Valid PR: 0.4587\n",
      "Epoch [240/500], Train Loss: 0.7364, Train RMSE: 0.8581\n",
      "Epoch [240/500], Validation Loss: 2.1501, Validation RMSE: 1.4663, Valid PR: 0.4567\n",
      "Epoch [241/500], Train Loss: 0.7567, Train RMSE: 0.8699\n",
      "Epoch [241/500], Validation Loss: 2.1490, Validation RMSE: 1.4660, Valid PR: 0.4552\n",
      "Epoch [242/500], Train Loss: 0.7718, Train RMSE: 0.8785\n",
      "Epoch [242/500], Validation Loss: 2.1478, Validation RMSE: 1.4655, Valid PR: 0.4537\n",
      "Epoch [243/500], Train Loss: 0.7126, Train RMSE: 0.8442\n",
      "Epoch [243/500], Validation Loss: 2.1434, Validation RMSE: 1.4640, Valid PR: 0.4537\n",
      "Epoch [244/500], Train Loss: 0.6295, Train RMSE: 0.7934\n",
      "Epoch [244/500], Validation Loss: 2.1389, Validation RMSE: 1.4625, Valid PR: 0.4533\n",
      "Epoch [245/500], Train Loss: 0.7040, Train RMSE: 0.8390\n",
      "Epoch [245/500], Validation Loss: 2.1301, Validation RMSE: 1.4595, Valid PR: 0.4546\n",
      "Epoch [246/500], Train Loss: 0.6398, Train RMSE: 0.7999\n",
      "Epoch [246/500], Validation Loss: 2.1221, Validation RMSE: 1.4567, Valid PR: 0.4551\n",
      "Epoch [247/500], Train Loss: 0.7605, Train RMSE: 0.8721\n",
      "Epoch [247/500], Validation Loss: 2.1130, Validation RMSE: 1.4536, Valid PR: 0.4555\n",
      "Epoch [248/500], Train Loss: 0.7296, Train RMSE: 0.8542\n",
      "Epoch [248/500], Validation Loss: 2.1040, Validation RMSE: 1.4505, Valid PR: 0.4556\n",
      "Epoch [249/500], Train Loss: 0.7474, Train RMSE: 0.8645\n",
      "Epoch [249/500], Validation Loss: 2.0946, Validation RMSE: 1.4473, Valid PR: 0.4560\n",
      "Epoch [250/500], Train Loss: 0.6932, Train RMSE: 0.8326\n",
      "Epoch [250/500], Validation Loss: 2.0884, Validation RMSE: 1.4451, Valid PR: 0.4555\n",
      "Epoch [251/500], Train Loss: 0.6883, Train RMSE: 0.8296\n",
      "Epoch [251/500], Validation Loss: 2.0846, Validation RMSE: 1.4438, Valid PR: 0.4547\n",
      "Epoch [252/500], Train Loss: 0.6832, Train RMSE: 0.8266\n",
      "Epoch [252/500], Validation Loss: 2.0748, Validation RMSE: 1.4404, Valid PR: 0.4551\n",
      "Epoch [253/500], Train Loss: 0.7530, Train RMSE: 0.8678\n",
      "Epoch [253/500], Validation Loss: 2.0655, Validation RMSE: 1.4372, Valid PR: 0.4549\n",
      "Epoch [254/500], Train Loss: 0.7212, Train RMSE: 0.8493\n",
      "Epoch [254/500], Validation Loss: 2.0544, Validation RMSE: 1.4333, Valid PR: 0.4542\n",
      "Epoch [255/500], Train Loss: 0.6792, Train RMSE: 0.8241\n",
      "Epoch [255/500], Validation Loss: 2.0412, Validation RMSE: 1.4287, Valid PR: 0.4534\n",
      "Epoch [256/500], Train Loss: 0.6614, Train RMSE: 0.8133\n",
      "Epoch [256/500], Validation Loss: 2.0301, Validation RMSE: 1.4248, Valid PR: 0.4522\n",
      "Epoch [257/500], Train Loss: 0.6713, Train RMSE: 0.8193\n",
      "Epoch [257/500], Validation Loss: 2.0268, Validation RMSE: 1.4237, Valid PR: 0.4492\n",
      "Epoch [258/500], Train Loss: 0.6850, Train RMSE: 0.8277\n",
      "Epoch [258/500], Validation Loss: 2.0253, Validation RMSE: 1.4231, Valid PR: 0.4456\n",
      "Epoch [259/500], Train Loss: 0.7912, Train RMSE: 0.8895\n",
      "Epoch [259/500], Validation Loss: 2.0318, Validation RMSE: 1.4254, Valid PR: 0.4403\n",
      "Epoch [260/500], Train Loss: 0.7165, Train RMSE: 0.8465\n",
      "Epoch [260/500], Validation Loss: 2.0390, Validation RMSE: 1.4279, Valid PR: 0.4341\n",
      "Epoch [261/500], Train Loss: 0.6976, Train RMSE: 0.8352\n",
      "Epoch [261/500], Validation Loss: 2.0419, Validation RMSE: 1.4289, Valid PR: 0.4281\n",
      "Epoch [262/500], Train Loss: 0.6799, Train RMSE: 0.8246\n",
      "Epoch [262/500], Validation Loss: 2.0406, Validation RMSE: 1.4285, Valid PR: 0.4235\n",
      "Epoch [263/500], Train Loss: 0.7081, Train RMSE: 0.8415\n",
      "Epoch [263/500], Validation Loss: 2.0355, Validation RMSE: 1.4267, Valid PR: 0.4201\n",
      "Epoch [264/500], Train Loss: 0.7114, Train RMSE: 0.8434\n",
      "Epoch [264/500], Validation Loss: 2.0240, Validation RMSE: 1.4227, Valid PR: 0.4185\n",
      "Epoch [265/500], Train Loss: 0.6597, Train RMSE: 0.8122\n",
      "Epoch [265/500], Validation Loss: 1.9973, Validation RMSE: 1.4132, Valid PR: 0.4218\n",
      "Epoch [266/500], Train Loss: 0.6824, Train RMSE: 0.8261\n",
      "Epoch [266/500], Validation Loss: 1.9603, Validation RMSE: 1.4001, Valid PR: 0.4297\n",
      "Epoch [267/500], Train Loss: 0.7071, Train RMSE: 0.8409\n",
      "Epoch [267/500], Validation Loss: 1.9367, Validation RMSE: 1.3917, Valid PR: 0.4333\n",
      "Epoch [268/500], Train Loss: 0.6644, Train RMSE: 0.8151\n",
      "Epoch [268/500], Validation Loss: 1.9204, Validation RMSE: 1.3858, Valid PR: 0.4347\n",
      "Epoch [269/500], Train Loss: 0.6843, Train RMSE: 0.8272\n",
      "Epoch [269/500], Validation Loss: 1.9252, Validation RMSE: 1.3875, Valid PR: 0.4288\n",
      "Epoch [270/500], Train Loss: 0.7562, Train RMSE: 0.8696\n",
      "Epoch [270/500], Validation Loss: 1.9443, Validation RMSE: 1.3944, Valid PR: 0.4175\n",
      "Epoch [271/500], Train Loss: 0.7644, Train RMSE: 0.8743\n",
      "Epoch [271/500], Validation Loss: 1.9627, Validation RMSE: 1.4010, Valid PR: 0.4062\n",
      "Epoch [272/500], Train Loss: 0.8037, Train RMSE: 0.8965\n",
      "Epoch [272/500], Validation Loss: 1.9836, Validation RMSE: 1.4084, Valid PR: 0.3946\n",
      "Epoch [273/500], Train Loss: 0.7390, Train RMSE: 0.8596\n",
      "Epoch [273/500], Validation Loss: 2.0016, Validation RMSE: 1.4148, Valid PR: 0.3823\n",
      "Epoch [274/500], Train Loss: 0.6948, Train RMSE: 0.8335\n",
      "Epoch [274/500], Validation Loss: 2.0132, Validation RMSE: 1.4189, Valid PR: 0.3735\n",
      "Epoch [275/500], Train Loss: 0.6652, Train RMSE: 0.8156\n",
      "Epoch [275/500], Validation Loss: 2.0146, Validation RMSE: 1.4194, Valid PR: 0.3696\n",
      "Epoch [276/500], Train Loss: 0.6505, Train RMSE: 0.8065\n",
      "Epoch [276/500], Validation Loss: 2.0085, Validation RMSE: 1.4172, Valid PR: 0.3685\n",
      "Epoch [277/500], Train Loss: 0.7091, Train RMSE: 0.8421\n",
      "Epoch [277/500], Validation Loss: 1.9885, Validation RMSE: 1.4101, Valid PR: 0.3726\n",
      "Epoch [278/500], Train Loss: 0.6409, Train RMSE: 0.8005\n",
      "Epoch [278/500], Validation Loss: 1.9581, Validation RMSE: 1.3993, Valid PR: 0.3816\n",
      "Epoch [279/500], Train Loss: 0.6623, Train RMSE: 0.8138\n",
      "Epoch [279/500], Validation Loss: 1.9314, Validation RMSE: 1.3897, Valid PR: 0.3891\n",
      "Epoch [280/500], Train Loss: 0.7057, Train RMSE: 0.8401\n",
      "Epoch [280/500], Validation Loss: 1.9255, Validation RMSE: 1.3876, Valid PR: 0.3886\n",
      "Epoch [281/500], Train Loss: 0.6795, Train RMSE: 0.8243\n",
      "Epoch [281/500], Validation Loss: 1.9363, Validation RMSE: 1.3915, Valid PR: 0.3824\n",
      "Epoch [282/500], Train Loss: 0.7444, Train RMSE: 0.8628\n",
      "Epoch [282/500], Validation Loss: 1.9506, Validation RMSE: 1.3966, Valid PR: 0.3752\n",
      "Epoch [283/500], Train Loss: 0.6604, Train RMSE: 0.8127\n",
      "Epoch [283/500], Validation Loss: 1.9787, Validation RMSE: 1.4067, Valid PR: 0.3620\n",
      "Epoch [284/500], Train Loss: 0.7501, Train RMSE: 0.8661\n",
      "Epoch [284/500], Validation Loss: 2.0167, Validation RMSE: 1.4201, Valid PR: 0.3436\n",
      "Epoch [285/500], Train Loss: 0.7817, Train RMSE: 0.8841\n",
      "Epoch [285/500], Validation Loss: 2.0394, Validation RMSE: 1.4281, Valid PR: 0.3319\n",
      "Epoch [286/500], Train Loss: 0.6697, Train RMSE: 0.8183\n",
      "Epoch [286/500], Validation Loss: 2.0585, Validation RMSE: 1.4348, Valid PR: 0.3208\n",
      "Epoch [287/500], Train Loss: 0.6042, Train RMSE: 0.7773\n",
      "Epoch [287/500], Validation Loss: 2.0631, Validation RMSE: 1.4363, Valid PR: 0.3168\n",
      "Epoch [288/500], Train Loss: 0.6816, Train RMSE: 0.8256\n",
      "Epoch [288/500], Validation Loss: 2.0580, Validation RMSE: 1.4346, Valid PR: 0.3187\n",
      "Epoch [289/500], Train Loss: 0.7040, Train RMSE: 0.8390\n",
      "Epoch [289/500], Validation Loss: 2.0558, Validation RMSE: 1.4338, Valid PR: 0.3175\n",
      "Epoch [290/500], Train Loss: 0.7527, Train RMSE: 0.8676\n",
      "Epoch [290/500], Validation Loss: 2.0426, Validation RMSE: 1.4292, Valid PR: 0.3231\n",
      "Epoch [291/500], Train Loss: 0.6815, Train RMSE: 0.8255\n",
      "Epoch [291/500], Validation Loss: 2.0271, Validation RMSE: 1.4237, Valid PR: 0.3295\n",
      "Epoch [292/500], Train Loss: 0.7634, Train RMSE: 0.8737\n",
      "Epoch [292/500], Validation Loss: 1.9952, Validation RMSE: 1.4125, Valid PR: 0.3423\n",
      "Epoch [293/500], Train Loss: 0.6359, Train RMSE: 0.7974\n",
      "Epoch [293/500], Validation Loss: 1.9665, Validation RMSE: 1.4023, Valid PR: 0.3529\n",
      "Epoch [294/500], Train Loss: 0.6978, Train RMSE: 0.8354\n",
      "Epoch [294/500], Validation Loss: 1.9557, Validation RMSE: 1.3985, Valid PR: 0.3550\n",
      "Epoch [295/500], Train Loss: 0.7289, Train RMSE: 0.8537\n",
      "Epoch [295/500], Validation Loss: 1.9912, Validation RMSE: 1.4111, Valid PR: 0.3369\n",
      "Epoch [296/500], Train Loss: 0.6603, Train RMSE: 0.8126\n",
      "Epoch [296/500], Validation Loss: 2.0364, Validation RMSE: 1.4270, Valid PR: 0.3140\n",
      "Epoch [297/500], Train Loss: 0.6485, Train RMSE: 0.8053\n",
      "Epoch [297/500], Validation Loss: 2.0919, Validation RMSE: 1.4463, Valid PR: 0.2818\n",
      "Epoch [298/500], Train Loss: 0.7592, Train RMSE: 0.8713\n",
      "Epoch [298/500], Validation Loss: 2.1023, Validation RMSE: 1.4499, Valid PR: 0.2737\n",
      "Epoch [299/500], Train Loss: 0.7464, Train RMSE: 0.8639\n",
      "Epoch [299/500], Validation Loss: 2.0923, Validation RMSE: 1.4465, Valid PR: 0.2787\n",
      "Epoch [300/500], Train Loss: 0.6854, Train RMSE: 0.8279\n",
      "Epoch [300/500], Validation Loss: 2.0637, Validation RMSE: 1.4366, Valid PR: 0.2939\n",
      "Epoch [301/500], Train Loss: 0.6933, Train RMSE: 0.8327\n",
      "Epoch [301/500], Validation Loss: 2.0176, Validation RMSE: 1.4204, Valid PR: 0.3156\n",
      "Epoch [302/500], Train Loss: 0.5828, Train RMSE: 0.7634\n",
      "Epoch [302/500], Validation Loss: 1.9867, Validation RMSE: 1.4095, Valid PR: 0.3292\n",
      "Epoch [303/500], Train Loss: 0.7216, Train RMSE: 0.8495\n",
      "Epoch [303/500], Validation Loss: 1.9739, Validation RMSE: 1.4050, Valid PR: 0.3345\n",
      "Epoch [304/500], Train Loss: 0.6341, Train RMSE: 0.7963\n",
      "Epoch [304/500], Validation Loss: 1.9497, Validation RMSE: 1.3963, Valid PR: 0.3378\n",
      "Epoch [305/500], Train Loss: 0.7107, Train RMSE: 0.8430\n",
      "Epoch [305/500], Validation Loss: 1.9389, Validation RMSE: 1.3924, Valid PR: 0.3414\n",
      "Epoch [306/500], Train Loss: 0.6703, Train RMSE: 0.8187\n",
      "Epoch [306/500], Validation Loss: 1.9413, Validation RMSE: 1.3933, Valid PR: 0.3424\n",
      "Epoch [307/500], Train Loss: 0.6876, Train RMSE: 0.8292\n",
      "Epoch [307/500], Validation Loss: 1.9587, Validation RMSE: 1.3995, Valid PR: 0.3322\n",
      "Epoch [308/500], Train Loss: 0.6877, Train RMSE: 0.8293\n",
      "Epoch [308/500], Validation Loss: 1.9951, Validation RMSE: 1.4125, Valid PR: 0.3051\n",
      "Epoch [309/500], Train Loss: 0.7620, Train RMSE: 0.8729\n",
      "Epoch [309/500], Validation Loss: 2.0497, Validation RMSE: 1.4317, Valid PR: 0.2566\n",
      "Epoch [310/500], Train Loss: 0.6637, Train RMSE: 0.8147\n",
      "Epoch [310/500], Validation Loss: 2.1046, Validation RMSE: 1.4507, Valid PR: 0.2038\n",
      "Epoch [311/500], Train Loss: 0.6944, Train RMSE: 0.8333\n",
      "Epoch [311/500], Validation Loss: 2.1444, Validation RMSE: 1.4644, Valid PR: 0.1790\n",
      "Epoch [312/500], Train Loss: 0.6920, Train RMSE: 0.8318\n",
      "Epoch [312/500], Validation Loss: 2.1649, Validation RMSE: 1.4714, Valid PR: 0.1932\n",
      "Epoch [313/500], Train Loss: 0.7083, Train RMSE: 0.8416\n",
      "Epoch [313/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.1953\n",
      "Epoch [314/500], Train Loss: 0.6976, Train RMSE: 0.8352\n",
      "Epoch [314/500], Validation Loss: 2.2053, Validation RMSE: 1.4850, Valid PR: 0.1766\n",
      "Epoch [315/500], Train Loss: 0.6814, Train RMSE: 0.8255\n",
      "Epoch [315/500], Validation Loss: 2.2011, Validation RMSE: 1.4836, Valid PR: 0.1698\n",
      "Epoch [316/500], Train Loss: 0.6380, Train RMSE: 0.7988\n",
      "Epoch [316/500], Validation Loss: 2.1945, Validation RMSE: 1.4814, Valid PR: 0.1520\n",
      "Epoch [317/500], Train Loss: 0.6960, Train RMSE: 0.8343\n",
      "Epoch [317/500], Validation Loss: 2.1875, Validation RMSE: 1.4790, Valid PR: 0.1664\n",
      "Epoch [318/500], Train Loss: 0.6984, Train RMSE: 0.8357\n",
      "Epoch [318/500], Validation Loss: 2.1802, Validation RMSE: 1.4766, Valid PR: 0.1983\n",
      "Early stopping triggered.\n",
      "Test Loss: 3.2224, Test RMSE: 1.7951, Test PR: -0.1745\n",
      "Replication 3 for method3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:122: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 11.3094, Train RMSE: 3.3629\n",
      "Epoch [1/500], Validation Loss: 14.7058, Validation RMSE: 3.8348, Valid PR: 0.3587\n",
      "Epoch [2/500], Train Loss: 4.4556, Train RMSE: 2.1108\n",
      "Epoch [2/500], Validation Loss: 9.9291, Validation RMSE: 3.1510, Valid PR: 0.2585\n",
      "Epoch [3/500], Train Loss: 3.0838, Train RMSE: 1.7561\n",
      "Epoch [3/500], Validation Loss: 8.4251, Validation RMSE: 2.9026, Valid PR: 0.1513\n",
      "Epoch [4/500], Train Loss: 2.5859, Train RMSE: 1.6081\n",
      "Epoch [4/500], Validation Loss: 7.6484, Validation RMSE: 2.7656, Valid PR: 0.0190\n",
      "Epoch [5/500], Train Loss: 2.2583, Train RMSE: 1.5028\n",
      "Epoch [5/500], Validation Loss: 7.1441, Validation RMSE: 2.6729, Valid PR: 0.1646\n",
      "Epoch [6/500], Train Loss: 2.3136, Train RMSE: 1.5210\n",
      "Epoch [6/500], Validation Loss: 6.7650, Validation RMSE: 2.6010, Valid PR: 0.1410\n",
      "Epoch [7/500], Train Loss: 2.2460, Train RMSE: 1.4987\n",
      "Epoch [7/500], Validation Loss: 6.4676, Validation RMSE: 2.5431, Valid PR: -0.0795\n",
      "Epoch [8/500], Train Loss: 2.0826, Train RMSE: 1.4431\n",
      "Epoch [8/500], Validation Loss: 6.2401, Validation RMSE: 2.4980, Valid PR: -0.3476\n",
      "Epoch [9/500], Train Loss: 2.1146, Train RMSE: 1.4542\n",
      "Epoch [9/500], Validation Loss: 6.0418, Validation RMSE: 2.4580, Valid PR: -0.5728\n",
      "Epoch [10/500], Train Loss: 2.0398, Train RMSE: 1.4282\n",
      "Epoch [10/500], Validation Loss: 5.8574, Validation RMSE: 2.4202, Valid PR: -0.5903\n",
      "Epoch [11/500], Train Loss: 1.8445, Train RMSE: 1.3581\n",
      "Epoch [11/500], Validation Loss: 5.6931, Validation RMSE: 2.3860, Valid PR: -0.5518\n",
      "Epoch [12/500], Train Loss: 1.9162, Train RMSE: 1.3843\n",
      "Epoch [12/500], Validation Loss: 5.5510, Validation RMSE: 2.3561, Valid PR: -0.5848\n",
      "Epoch [13/500], Train Loss: 1.8803, Train RMSE: 1.3712\n",
      "Epoch [13/500], Validation Loss: 5.4295, Validation RMSE: 2.3301, Valid PR: -0.5796\n",
      "Epoch [14/500], Train Loss: 1.8234, Train RMSE: 1.3503\n",
      "Epoch [14/500], Validation Loss: 5.3239, Validation RMSE: 2.3074, Valid PR: -0.5691\n",
      "Epoch [15/500], Train Loss: 1.7154, Train RMSE: 1.3097\n",
      "Epoch [15/500], Validation Loss: 5.2286, Validation RMSE: 2.2866, Valid PR: -0.5833\n",
      "Epoch [16/500], Train Loss: 1.8118, Train RMSE: 1.3460\n",
      "Epoch [16/500], Validation Loss: 5.1396, Validation RMSE: 2.2671, Valid PR: -0.5183\n",
      "Epoch [17/500], Train Loss: 1.6915, Train RMSE: 1.3006\n",
      "Epoch [17/500], Validation Loss: 5.0547, Validation RMSE: 2.2483, Valid PR: -0.4905\n",
      "Epoch [18/500], Train Loss: 1.7076, Train RMSE: 1.3068\n",
      "Epoch [18/500], Validation Loss: 4.9744, Validation RMSE: 2.2303, Valid PR: -0.4400\n",
      "Epoch [19/500], Train Loss: 1.5838, Train RMSE: 1.2585\n",
      "Epoch [19/500], Validation Loss: 4.8990, Validation RMSE: 2.2134, Valid PR: -0.4116\n",
      "Epoch [20/500], Train Loss: 1.5906, Train RMSE: 1.2612\n",
      "Epoch [20/500], Validation Loss: 4.8283, Validation RMSE: 2.1973, Valid PR: -0.3922\n",
      "Epoch [21/500], Train Loss: 1.5684, Train RMSE: 1.2524\n",
      "Epoch [21/500], Validation Loss: 4.7613, Validation RMSE: 2.1820, Valid PR: -0.3752\n",
      "Epoch [22/500], Train Loss: 1.7261, Train RMSE: 1.3138\n",
      "Epoch [22/500], Validation Loss: 4.6961, Validation RMSE: 2.1671, Valid PR: -0.3588\n",
      "Epoch [23/500], Train Loss: 1.5243, Train RMSE: 1.2346\n",
      "Epoch [23/500], Validation Loss: 4.6325, Validation RMSE: 2.1523, Valid PR: -0.3382\n",
      "Epoch [24/500], Train Loss: 1.5452, Train RMSE: 1.2431\n",
      "Epoch [24/500], Validation Loss: 4.5709, Validation RMSE: 2.1380, Valid PR: -0.3249\n",
      "Epoch [25/500], Train Loss: 1.6123, Train RMSE: 1.2698\n",
      "Epoch [25/500], Validation Loss: 4.5120, Validation RMSE: 2.1241, Valid PR: -0.3293\n",
      "Epoch [26/500], Train Loss: 1.5539, Train RMSE: 1.2465\n",
      "Epoch [26/500], Validation Loss: 4.4552, Validation RMSE: 2.1107, Valid PR: -0.3522\n",
      "Epoch [27/500], Train Loss: 1.4258, Train RMSE: 1.1941\n",
      "Epoch [27/500], Validation Loss: 4.4008, Validation RMSE: 2.0978, Valid PR: -0.3718\n",
      "Epoch [28/500], Train Loss: 1.4465, Train RMSE: 1.2027\n",
      "Epoch [28/500], Validation Loss: 4.3470, Validation RMSE: 2.0849, Valid PR: -0.3917\n",
      "Epoch [29/500], Train Loss: 1.4400, Train RMSE: 1.2000\n",
      "Epoch [29/500], Validation Loss: 4.2945, Validation RMSE: 2.0723, Valid PR: -0.4146\n",
      "Epoch [30/500], Train Loss: 1.3370, Train RMSE: 1.1563\n",
      "Epoch [30/500], Validation Loss: 4.2432, Validation RMSE: 2.0599, Valid PR: -0.4357\n",
      "Epoch [31/500], Train Loss: 1.3987, Train RMSE: 1.1827\n",
      "Epoch [31/500], Validation Loss: 4.1933, Validation RMSE: 2.0478, Valid PR: -0.4510\n",
      "Epoch [32/500], Train Loss: 1.4099, Train RMSE: 1.1874\n",
      "Epoch [32/500], Validation Loss: 4.1446, Validation RMSE: 2.0358, Valid PR: -0.4647\n",
      "Epoch [33/500], Train Loss: 1.3713, Train RMSE: 1.1710\n",
      "Epoch [33/500], Validation Loss: 4.0966, Validation RMSE: 2.0240, Valid PR: -0.4756\n",
      "Epoch [34/500], Train Loss: 1.3447, Train RMSE: 1.1596\n",
      "Epoch [34/500], Validation Loss: 4.0492, Validation RMSE: 2.0123, Valid PR: -0.4849\n",
      "Epoch [35/500], Train Loss: 1.4652, Train RMSE: 1.2104\n",
      "Epoch [35/500], Validation Loss: 4.0026, Validation RMSE: 2.0006, Valid PR: -0.4898\n",
      "Epoch [36/500], Train Loss: 1.3879, Train RMSE: 1.1781\n",
      "Epoch [36/500], Validation Loss: 3.9572, Validation RMSE: 1.9893, Valid PR: -0.4941\n",
      "Epoch [37/500], Train Loss: 1.3862, Train RMSE: 1.1774\n",
      "Epoch [37/500], Validation Loss: 3.9127, Validation RMSE: 1.9781, Valid PR: -0.4882\n",
      "Epoch [38/500], Train Loss: 1.3566, Train RMSE: 1.1647\n",
      "Epoch [38/500], Validation Loss: 3.8693, Validation RMSE: 1.9670, Valid PR: -0.4739\n",
      "Epoch [39/500], Train Loss: 1.2684, Train RMSE: 1.1262\n",
      "Epoch [39/500], Validation Loss: 3.8266, Validation RMSE: 1.9562, Valid PR: -0.4210\n",
      "Epoch [40/500], Train Loss: 1.2855, Train RMSE: 1.1338\n",
      "Epoch [40/500], Validation Loss: 3.7843, Validation RMSE: 1.9453, Valid PR: -0.2222\n",
      "Epoch [41/500], Train Loss: 1.3214, Train RMSE: 1.1495\n",
      "Epoch [41/500], Validation Loss: 3.7427, Validation RMSE: 1.9346, Valid PR: 0.1052\n",
      "Epoch [42/500], Train Loss: 1.3297, Train RMSE: 1.1531\n",
      "Epoch [42/500], Validation Loss: 3.7017, Validation RMSE: 1.9240, Valid PR: 0.2823\n",
      "Epoch [43/500], Train Loss: 1.3194, Train RMSE: 1.1486\n",
      "Epoch [43/500], Validation Loss: 3.6615, Validation RMSE: 1.9135, Valid PR: 0.3777\n",
      "Epoch [44/500], Train Loss: 1.2922, Train RMSE: 1.1367\n",
      "Epoch [44/500], Validation Loss: 3.6223, Validation RMSE: 1.9032, Valid PR: 0.4060\n",
      "Epoch [45/500], Train Loss: 1.1835, Train RMSE: 1.0879\n",
      "Epoch [45/500], Validation Loss: 3.5840, Validation RMSE: 1.8931, Valid PR: 0.4068\n",
      "Epoch [46/500], Train Loss: 1.2215, Train RMSE: 1.1052\n",
      "Epoch [46/500], Validation Loss: 3.5469, Validation RMSE: 1.8833, Valid PR: 0.4139\n",
      "Epoch [47/500], Train Loss: 1.2556, Train RMSE: 1.1205\n",
      "Epoch [47/500], Validation Loss: 3.5108, Validation RMSE: 1.8737, Valid PR: 0.4194\n",
      "Epoch [48/500], Train Loss: 1.3110, Train RMSE: 1.1450\n",
      "Epoch [48/500], Validation Loss: 3.4756, Validation RMSE: 1.8643, Valid PR: 0.4176\n",
      "Epoch [49/500], Train Loss: 1.2298, Train RMSE: 1.1090\n",
      "Epoch [49/500], Validation Loss: 3.4410, Validation RMSE: 1.8550, Valid PR: 0.4231\n",
      "Epoch [50/500], Train Loss: 1.2159, Train RMSE: 1.1027\n",
      "Epoch [50/500], Validation Loss: 3.4066, Validation RMSE: 1.8457, Valid PR: 0.4264\n",
      "Epoch [51/500], Train Loss: 1.1624, Train RMSE: 1.0782\n",
      "Epoch [51/500], Validation Loss: 3.3727, Validation RMSE: 1.8365, Valid PR: 0.4312\n",
      "Epoch [52/500], Train Loss: 1.2017, Train RMSE: 1.0962\n",
      "Epoch [52/500], Validation Loss: 3.3389, Validation RMSE: 1.8273, Valid PR: 0.4309\n",
      "Epoch [53/500], Train Loss: 1.1612, Train RMSE: 1.0776\n",
      "Epoch [53/500], Validation Loss: 3.3057, Validation RMSE: 1.8182, Valid PR: 0.4341\n",
      "Epoch [54/500], Train Loss: 1.0997, Train RMSE: 1.0487\n",
      "Epoch [54/500], Validation Loss: 3.2730, Validation RMSE: 1.8091, Valid PR: 0.4374\n",
      "Epoch [55/500], Train Loss: 1.1742, Train RMSE: 1.0836\n",
      "Epoch [55/500], Validation Loss: 3.2412, Validation RMSE: 1.8003, Valid PR: 0.4520\n",
      "Epoch [56/500], Train Loss: 1.1692, Train RMSE: 1.0813\n",
      "Epoch [56/500], Validation Loss: 3.2100, Validation RMSE: 1.7917, Valid PR: 0.4774\n",
      "Epoch [57/500], Train Loss: 1.1807, Train RMSE: 1.0866\n",
      "Epoch [57/500], Validation Loss: 3.1797, Validation RMSE: 1.7832, Valid PR: 0.4831\n",
      "Epoch [58/500], Train Loss: 1.1218, Train RMSE: 1.0591\n",
      "Epoch [58/500], Validation Loss: 3.1504, Validation RMSE: 1.7749, Valid PR: 0.5017\n",
      "Epoch [59/500], Train Loss: 1.2028, Train RMSE: 1.0967\n",
      "Epoch [59/500], Validation Loss: 3.1218, Validation RMSE: 1.7669, Valid PR: 0.4709\n",
      "Epoch [60/500], Train Loss: 1.0582, Train RMSE: 1.0287\n",
      "Epoch [60/500], Validation Loss: 3.0938, Validation RMSE: 1.7589, Valid PR: 0.4459\n",
      "Epoch [61/500], Train Loss: 1.1212, Train RMSE: 1.0589\n",
      "Epoch [61/500], Validation Loss: 3.0664, Validation RMSE: 1.7511, Valid PR: 0.3880\n",
      "Epoch [62/500], Train Loss: 1.1043, Train RMSE: 1.0509\n",
      "Epoch [62/500], Validation Loss: 3.0394, Validation RMSE: 1.7434, Valid PR: 0.3261\n",
      "Epoch [63/500], Train Loss: 1.1342, Train RMSE: 1.0650\n",
      "Epoch [63/500], Validation Loss: 3.0130, Validation RMSE: 1.7358, Valid PR: 0.2311\n",
      "Epoch [64/500], Train Loss: 1.1107, Train RMSE: 1.0539\n",
      "Epoch [64/500], Validation Loss: 2.9869, Validation RMSE: 1.7283, Valid PR: 0.1020\n",
      "Epoch [65/500], Train Loss: 1.0969, Train RMSE: 1.0473\n",
      "Epoch [65/500], Validation Loss: 2.9615, Validation RMSE: 1.7209, Valid PR: -0.0879\n",
      "Epoch [66/500], Train Loss: 1.1684, Train RMSE: 1.0809\n",
      "Epoch [66/500], Validation Loss: 2.9367, Validation RMSE: 1.7137, Valid PR: -0.1115\n",
      "Epoch [67/500], Train Loss: 1.1375, Train RMSE: 1.0665\n",
      "Epoch [67/500], Validation Loss: 2.9127, Validation RMSE: 1.7067, Valid PR: -0.0096\n",
      "Epoch [68/500], Train Loss: 1.1221, Train RMSE: 1.0593\n",
      "Epoch [68/500], Validation Loss: 2.8892, Validation RMSE: 1.6998, Valid PR: 0.0691\n",
      "Epoch [69/500], Train Loss: 1.0012, Train RMSE: 1.0006\n",
      "Epoch [69/500], Validation Loss: 2.8660, Validation RMSE: 1.6929, Valid PR: 0.0683\n",
      "Epoch [70/500], Train Loss: 1.1202, Train RMSE: 1.0584\n",
      "Epoch [70/500], Validation Loss: 2.8431, Validation RMSE: 1.6862, Valid PR: 0.0665\n",
      "Epoch [71/500], Train Loss: 1.0196, Train RMSE: 1.0097\n",
      "Epoch [71/500], Validation Loss: 2.8207, Validation RMSE: 1.6795, Valid PR: 0.0926\n",
      "Epoch [72/500], Train Loss: 1.0059, Train RMSE: 1.0030\n",
      "Epoch [72/500], Validation Loss: 2.7986, Validation RMSE: 1.6729, Valid PR: 0.1364\n",
      "Epoch [73/500], Train Loss: 1.0252, Train RMSE: 1.0125\n",
      "Epoch [73/500], Validation Loss: 2.7771, Validation RMSE: 1.6665, Valid PR: 0.1777\n",
      "Epoch [74/500], Train Loss: 0.9984, Train RMSE: 0.9992\n",
      "Epoch [74/500], Validation Loss: 2.7561, Validation RMSE: 1.6601, Valid PR: 0.2044\n",
      "Epoch [75/500], Train Loss: 1.0027, Train RMSE: 1.0013\n",
      "Epoch [75/500], Validation Loss: 2.7354, Validation RMSE: 1.6539, Valid PR: 0.2409\n",
      "Epoch [76/500], Train Loss: 1.0011, Train RMSE: 1.0005\n",
      "Epoch [76/500], Validation Loss: 2.7155, Validation RMSE: 1.6479, Valid PR: 0.2441\n",
      "Epoch [77/500], Train Loss: 0.9322, Train RMSE: 0.9655\n",
      "Epoch [77/500], Validation Loss: 2.6960, Validation RMSE: 1.6419, Valid PR: 0.2273\n",
      "Epoch [78/500], Train Loss: 1.0135, Train RMSE: 1.0067\n",
      "Epoch [78/500], Validation Loss: 2.6770, Validation RMSE: 1.6362, Valid PR: 0.2535\n",
      "Epoch [79/500], Train Loss: 1.0797, Train RMSE: 1.0391\n",
      "Epoch [79/500], Validation Loss: 2.6586, Validation RMSE: 1.6305, Valid PR: 0.2663\n",
      "Epoch [80/500], Train Loss: 0.9639, Train RMSE: 0.9818\n",
      "Epoch [80/500], Validation Loss: 2.6406, Validation RMSE: 1.6250, Valid PR: 0.3041\n",
      "Epoch [81/500], Train Loss: 0.9666, Train RMSE: 0.9832\n",
      "Epoch [81/500], Validation Loss: 2.6234, Validation RMSE: 1.6197, Valid PR: 0.3510\n",
      "Epoch [82/500], Train Loss: 1.0060, Train RMSE: 1.0030\n",
      "Epoch [82/500], Validation Loss: 2.6066, Validation RMSE: 1.6145, Valid PR: 0.3819\n",
      "Epoch [83/500], Train Loss: 0.9285, Train RMSE: 0.9636\n",
      "Epoch [83/500], Validation Loss: 2.5902, Validation RMSE: 1.6094, Valid PR: 0.4159\n",
      "Epoch [84/500], Train Loss: 0.9188, Train RMSE: 0.9585\n",
      "Epoch [84/500], Validation Loss: 2.5743, Validation RMSE: 1.6045, Valid PR: 0.4369\n",
      "Epoch [85/500], Train Loss: 0.9903, Train RMSE: 0.9952\n",
      "Epoch [85/500], Validation Loss: 2.5590, Validation RMSE: 1.5997, Valid PR: 0.4491\n",
      "Epoch [86/500], Train Loss: 0.8468, Train RMSE: 0.9202\n",
      "Epoch [86/500], Validation Loss: 2.5442, Validation RMSE: 1.5950, Valid PR: 0.4395\n",
      "Epoch [87/500], Train Loss: 0.8348, Train RMSE: 0.9137\n",
      "Epoch [87/500], Validation Loss: 2.5298, Validation RMSE: 1.5905, Valid PR: 0.4407\n",
      "Epoch [88/500], Train Loss: 0.9074, Train RMSE: 0.9526\n",
      "Epoch [88/500], Validation Loss: 2.5159, Validation RMSE: 1.5862, Valid PR: 0.4577\n",
      "Epoch [89/500], Train Loss: 0.8808, Train RMSE: 0.9385\n",
      "Epoch [89/500], Validation Loss: 2.5025, Validation RMSE: 1.5819, Valid PR: 0.4619\n",
      "Epoch [90/500], Train Loss: 0.9075, Train RMSE: 0.9527\n",
      "Epoch [90/500], Validation Loss: 2.4894, Validation RMSE: 1.5778, Valid PR: 0.4903\n",
      "Epoch [91/500], Train Loss: 0.9391, Train RMSE: 0.9691\n",
      "Epoch [91/500], Validation Loss: 2.4766, Validation RMSE: 1.5737, Valid PR: 0.5349\n",
      "Epoch [92/500], Train Loss: 0.7979, Train RMSE: 0.8933\n",
      "Epoch [92/500], Validation Loss: 2.4643, Validation RMSE: 1.5698, Valid PR: 0.5389\n",
      "Epoch [93/500], Train Loss: 0.8178, Train RMSE: 0.9043\n",
      "Epoch [93/500], Validation Loss: 2.4521, Validation RMSE: 1.5659, Valid PR: 0.5346\n",
      "Epoch [94/500], Train Loss: 0.9005, Train RMSE: 0.9489\n",
      "Epoch [94/500], Validation Loss: 2.4403, Validation RMSE: 1.5621, Valid PR: 0.5214\n",
      "Epoch [95/500], Train Loss: 0.8653, Train RMSE: 0.9302\n",
      "Epoch [95/500], Validation Loss: 2.4288, Validation RMSE: 1.5585, Valid PR: 0.5092\n",
      "Epoch [96/500], Train Loss: 0.8214, Train RMSE: 0.9063\n",
      "Epoch [96/500], Validation Loss: 2.4177, Validation RMSE: 1.5549, Valid PR: 0.4994\n",
      "Epoch [97/500], Train Loss: 0.8822, Train RMSE: 0.9393\n",
      "Epoch [97/500], Validation Loss: 2.4071, Validation RMSE: 1.5515, Valid PR: 0.4922\n",
      "Epoch [98/500], Train Loss: 0.8032, Train RMSE: 0.8962\n",
      "Epoch [98/500], Validation Loss: 2.3968, Validation RMSE: 1.5482, Valid PR: 0.4873\n",
      "Epoch [99/500], Train Loss: 0.7777, Train RMSE: 0.8819\n",
      "Epoch [99/500], Validation Loss: 2.3869, Validation RMSE: 1.5450, Valid PR: 0.4818\n",
      "Epoch [100/500], Train Loss: 0.8509, Train RMSE: 0.9225\n",
      "Epoch [100/500], Validation Loss: 2.3774, Validation RMSE: 1.5419, Valid PR: 0.4840\n",
      "Epoch [101/500], Train Loss: 0.9049, Train RMSE: 0.9512\n",
      "Epoch [101/500], Validation Loss: 2.3681, Validation RMSE: 1.5389, Valid PR: 0.4911\n",
      "Epoch [102/500], Train Loss: 0.8168, Train RMSE: 0.9038\n",
      "Epoch [102/500], Validation Loss: 2.3590, Validation RMSE: 1.5359, Valid PR: 0.4901\n",
      "Epoch [103/500], Train Loss: 0.8098, Train RMSE: 0.8999\n",
      "Epoch [103/500], Validation Loss: 2.3503, Validation RMSE: 1.5331, Valid PR: 0.4923\n",
      "Epoch [104/500], Train Loss: 0.7971, Train RMSE: 0.8928\n",
      "Epoch [104/500], Validation Loss: 2.3420, Validation RMSE: 1.5304, Valid PR: 0.4931\n",
      "Epoch [105/500], Train Loss: 0.8439, Train RMSE: 0.9186\n",
      "Epoch [105/500], Validation Loss: 2.3341, Validation RMSE: 1.5278, Valid PR: 0.4967\n",
      "Epoch [106/500], Train Loss: 0.8751, Train RMSE: 0.9355\n",
      "Epoch [106/500], Validation Loss: 2.3265, Validation RMSE: 1.5253, Valid PR: 0.4953\n",
      "Epoch [107/500], Train Loss: 0.7986, Train RMSE: 0.8936\n",
      "Epoch [107/500], Validation Loss: 2.3191, Validation RMSE: 1.5229, Valid PR: 0.4935\n",
      "Epoch [108/500], Train Loss: 0.8378, Train RMSE: 0.9153\n",
      "Epoch [108/500], Validation Loss: 2.3119, Validation RMSE: 1.5205, Valid PR: 0.4940\n",
      "Epoch [109/500], Train Loss: 0.7626, Train RMSE: 0.8733\n",
      "Epoch [109/500], Validation Loss: 2.3051, Validation RMSE: 1.5182, Valid PR: 0.4967\n",
      "Epoch [110/500], Train Loss: 0.8235, Train RMSE: 0.9075\n",
      "Epoch [110/500], Validation Loss: 2.2985, Validation RMSE: 1.5161, Valid PR: 0.4985\n",
      "Epoch [111/500], Train Loss: 0.7717, Train RMSE: 0.8784\n",
      "Epoch [111/500], Validation Loss: 2.2923, Validation RMSE: 1.5140, Valid PR: 0.4941\n",
      "Epoch [112/500], Train Loss: 0.8444, Train RMSE: 0.9189\n",
      "Epoch [112/500], Validation Loss: 2.2861, Validation RMSE: 1.5120, Valid PR: 0.4898\n",
      "Epoch [113/500], Train Loss: 0.7830, Train RMSE: 0.8849\n",
      "Epoch [113/500], Validation Loss: 2.2803, Validation RMSE: 1.5101, Valid PR: 0.4862\n",
      "Epoch [114/500], Train Loss: 0.7901, Train RMSE: 0.8889\n",
      "Epoch [114/500], Validation Loss: 2.2747, Validation RMSE: 1.5082, Valid PR: 0.4811\n",
      "Epoch [115/500], Train Loss: 0.8643, Train RMSE: 0.9297\n",
      "Epoch [115/500], Validation Loss: 2.2694, Validation RMSE: 1.5065, Valid PR: 0.4766\n",
      "Epoch [116/500], Train Loss: 0.7805, Train RMSE: 0.8835\n",
      "Epoch [116/500], Validation Loss: 2.2644, Validation RMSE: 1.5048, Valid PR: 0.4702\n",
      "Epoch [117/500], Train Loss: 0.7508, Train RMSE: 0.8665\n",
      "Epoch [117/500], Validation Loss: 2.2596, Validation RMSE: 1.5032, Valid PR: 0.4700\n",
      "Epoch [118/500], Train Loss: 0.7554, Train RMSE: 0.8692\n",
      "Epoch [118/500], Validation Loss: 2.2551, Validation RMSE: 1.5017, Valid PR: 0.4752\n",
      "Epoch [119/500], Train Loss: 0.7764, Train RMSE: 0.8811\n",
      "Epoch [119/500], Validation Loss: 2.2507, Validation RMSE: 1.5002, Valid PR: 0.4845\n",
      "Epoch [120/500], Train Loss: 0.8105, Train RMSE: 0.9003\n",
      "Epoch [120/500], Validation Loss: 2.2467, Validation RMSE: 1.4989, Valid PR: 0.4772\n",
      "Epoch [121/500], Train Loss: 0.8989, Train RMSE: 0.9481\n",
      "Epoch [121/500], Validation Loss: 2.2431, Validation RMSE: 1.4977, Valid PR: 0.4540\n",
      "Epoch [122/500], Train Loss: 0.8400, Train RMSE: 0.9165\n",
      "Epoch [122/500], Validation Loss: 2.2396, Validation RMSE: 1.4965, Valid PR: 0.4282\n",
      "Epoch [123/500], Train Loss: 0.6799, Train RMSE: 0.8245\n",
      "Epoch [123/500], Validation Loss: 2.2363, Validation RMSE: 1.4954, Valid PR: 0.3932\n",
      "Epoch [124/500], Train Loss: 0.7625, Train RMSE: 0.8732\n",
      "Epoch [124/500], Validation Loss: 2.2331, Validation RMSE: 1.4944, Valid PR: 0.3626\n",
      "Epoch [125/500], Train Loss: 0.7581, Train RMSE: 0.8707\n",
      "Epoch [125/500], Validation Loss: 2.2300, Validation RMSE: 1.4933, Valid PR: 0.3384\n",
      "Epoch [126/500], Train Loss: 0.7947, Train RMSE: 0.8914\n",
      "Epoch [126/500], Validation Loss: 2.2270, Validation RMSE: 1.4923, Valid PR: 0.3010\n",
      "Epoch [127/500], Train Loss: 0.7822, Train RMSE: 0.8844\n",
      "Epoch [127/500], Validation Loss: 2.2242, Validation RMSE: 1.4914, Valid PR: 0.2850\n",
      "Epoch [128/500], Train Loss: 0.8230, Train RMSE: 0.9072\n",
      "Epoch [128/500], Validation Loss: 2.2216, Validation RMSE: 1.4905, Valid PR: 0.3092\n",
      "Epoch [129/500], Train Loss: 0.7607, Train RMSE: 0.8722\n",
      "Epoch [129/500], Validation Loss: 2.2190, Validation RMSE: 1.4896, Valid PR: 0.3342\n",
      "Epoch [130/500], Train Loss: 0.7263, Train RMSE: 0.8522\n",
      "Epoch [130/500], Validation Loss: 2.2166, Validation RMSE: 1.4888, Valid PR: 0.3532\n",
      "Epoch [131/500], Train Loss: 0.7580, Train RMSE: 0.8707\n",
      "Epoch [131/500], Validation Loss: 2.2144, Validation RMSE: 1.4881, Valid PR: 0.3696\n",
      "Epoch [132/500], Train Loss: 0.7645, Train RMSE: 0.8743\n",
      "Epoch [132/500], Validation Loss: 2.2123, Validation RMSE: 1.4874, Valid PR: 0.3859\n",
      "Epoch [133/500], Train Loss: 0.7519, Train RMSE: 0.8671\n",
      "Epoch [133/500], Validation Loss: 2.2100, Validation RMSE: 1.4866, Valid PR: 0.4076\n",
      "Epoch [134/500], Train Loss: 0.7641, Train RMSE: 0.8741\n",
      "Epoch [134/500], Validation Loss: 2.2078, Validation RMSE: 1.4859, Valid PR: 0.4271\n",
      "Epoch [135/500], Train Loss: 0.7354, Train RMSE: 0.8575\n",
      "Epoch [135/500], Validation Loss: 2.2058, Validation RMSE: 1.4852, Valid PR: 0.4351\n",
      "Epoch [136/500], Train Loss: 0.8032, Train RMSE: 0.8962\n",
      "Epoch [136/500], Validation Loss: 2.2039, Validation RMSE: 1.4846, Valid PR: 0.4514\n",
      "Epoch [137/500], Train Loss: 0.7583, Train RMSE: 0.8708\n",
      "Epoch [137/500], Validation Loss: 2.2021, Validation RMSE: 1.4839, Valid PR: 0.4624\n",
      "Epoch [138/500], Train Loss: 0.7382, Train RMSE: 0.8592\n",
      "Epoch [138/500], Validation Loss: 2.2004, Validation RMSE: 1.4834, Valid PR: 0.4689\n",
      "Epoch [139/500], Train Loss: 0.7334, Train RMSE: 0.8564\n",
      "Epoch [139/500], Validation Loss: 2.1988, Validation RMSE: 1.4828, Valid PR: 0.4740\n",
      "Epoch [140/500], Train Loss: 0.7241, Train RMSE: 0.8510\n",
      "Epoch [140/500], Validation Loss: 2.1974, Validation RMSE: 1.4824, Valid PR: 0.4772\n",
      "Epoch [141/500], Train Loss: 0.7461, Train RMSE: 0.8638\n",
      "Epoch [141/500], Validation Loss: 2.1962, Validation RMSE: 1.4819, Valid PR: 0.4776\n",
      "Epoch [142/500], Train Loss: 0.7173, Train RMSE: 0.8469\n",
      "Epoch [142/500], Validation Loss: 2.1950, Validation RMSE: 1.4816, Valid PR: 0.4795\n",
      "Epoch [143/500], Train Loss: 0.7495, Train RMSE: 0.8657\n",
      "Epoch [143/500], Validation Loss: 2.1940, Validation RMSE: 1.4812, Valid PR: 0.4810\n",
      "Epoch [144/500], Train Loss: 0.8379, Train RMSE: 0.9154\n",
      "Epoch [144/500], Validation Loss: 2.1930, Validation RMSE: 1.4809, Valid PR: 0.4813\n",
      "Epoch [145/500], Train Loss: 0.7760, Train RMSE: 0.8809\n",
      "Epoch [145/500], Validation Loss: 2.1922, Validation RMSE: 1.4806, Valid PR: 0.4818\n",
      "Epoch [146/500], Train Loss: 0.7383, Train RMSE: 0.8592\n",
      "Epoch [146/500], Validation Loss: 2.1914, Validation RMSE: 1.4803, Valid PR: 0.4837\n",
      "Epoch [147/500], Train Loss: 0.7505, Train RMSE: 0.8663\n",
      "Epoch [147/500], Validation Loss: 2.1908, Validation RMSE: 1.4801, Valid PR: 0.4837\n",
      "Epoch [148/500], Train Loss: 0.7245, Train RMSE: 0.8512\n",
      "Epoch [148/500], Validation Loss: 2.1902, Validation RMSE: 1.4799, Valid PR: 0.4812\n",
      "Epoch [149/500], Train Loss: 0.6831, Train RMSE: 0.8265\n",
      "Epoch [149/500], Validation Loss: 2.1898, Validation RMSE: 1.4798, Valid PR: 0.4762\n",
      "Epoch [150/500], Train Loss: 0.6978, Train RMSE: 0.8354\n",
      "Epoch [150/500], Validation Loss: 2.1895, Validation RMSE: 1.4797, Valid PR: 0.4706\n",
      "Epoch [151/500], Train Loss: 0.6804, Train RMSE: 0.8248\n",
      "Epoch [151/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.4632\n",
      "Epoch [152/500], Train Loss: 0.7720, Train RMSE: 0.8786\n",
      "Epoch [152/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.4533\n",
      "Epoch [153/500], Train Loss: 0.7189, Train RMSE: 0.8479\n",
      "Epoch [153/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.4442\n",
      "Epoch [154/500], Train Loss: 0.7347, Train RMSE: 0.8571\n",
      "Epoch [154/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.4372\n",
      "Epoch [155/500], Train Loss: 0.7288, Train RMSE: 0.8537\n",
      "Epoch [155/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.4344\n",
      "Epoch [156/500], Train Loss: 0.7430, Train RMSE: 0.8620\n",
      "Epoch [156/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.4327\n",
      "Epoch [157/500], Train Loss: 0.6968, Train RMSE: 0.8348\n",
      "Epoch [157/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.4316\n",
      "Epoch [158/500], Train Loss: 0.6842, Train RMSE: 0.8271\n",
      "Epoch [158/500], Validation Loss: 2.1894, Validation RMSE: 1.4797, Valid PR: 0.4323\n",
      "Epoch [159/500], Train Loss: 0.6588, Train RMSE: 0.8117\n",
      "Epoch [159/500], Validation Loss: 2.1895, Validation RMSE: 1.4797, Valid PR: 0.4355\n",
      "Epoch [160/500], Train Loss: 0.6835, Train RMSE: 0.8267\n",
      "Epoch [160/500], Validation Loss: 2.1897, Validation RMSE: 1.4798, Valid PR: 0.4369\n",
      "Epoch [161/500], Train Loss: 0.7287, Train RMSE: 0.8536\n",
      "Epoch [161/500], Validation Loss: 2.1900, Validation RMSE: 1.4799, Valid PR: 0.4385\n",
      "Epoch [162/500], Train Loss: 0.7206, Train RMSE: 0.8489\n",
      "Epoch [162/500], Validation Loss: 2.1904, Validation RMSE: 1.4800, Valid PR: 0.4390\n",
      "Epoch [163/500], Train Loss: 0.5961, Train RMSE: 0.7721\n",
      "Epoch [163/500], Validation Loss: 2.1909, Validation RMSE: 1.4802, Valid PR: 0.4381\n",
      "Epoch [164/500], Train Loss: 0.7457, Train RMSE: 0.8635\n",
      "Epoch [164/500], Validation Loss: 2.1913, Validation RMSE: 1.4803, Valid PR: 0.4364\n",
      "Epoch [165/500], Train Loss: 0.7409, Train RMSE: 0.8608\n",
      "Epoch [165/500], Validation Loss: 2.1917, Validation RMSE: 1.4804, Valid PR: 0.4375\n",
      "Epoch [166/500], Train Loss: 0.7183, Train RMSE: 0.8475\n",
      "Epoch [166/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.4373\n",
      "Epoch [167/500], Train Loss: 0.8420, Train RMSE: 0.9176\n",
      "Epoch [167/500], Validation Loss: 2.1925, Validation RMSE: 1.4807, Valid PR: 0.4348\n",
      "Epoch [168/500], Train Loss: 0.6457, Train RMSE: 0.8036\n",
      "Epoch [168/500], Validation Loss: 2.1929, Validation RMSE: 1.4809, Valid PR: 0.4314\n",
      "Epoch [169/500], Train Loss: 0.7374, Train RMSE: 0.8587\n",
      "Epoch [169/500], Validation Loss: 2.1935, Validation RMSE: 1.4810, Valid PR: 0.4280\n",
      "Epoch [170/500], Train Loss: 0.7520, Train RMSE: 0.8672\n",
      "Epoch [170/500], Validation Loss: 2.1938, Validation RMSE: 1.4811, Valid PR: 0.4268\n",
      "Epoch [171/500], Train Loss: 0.7566, Train RMSE: 0.8698\n",
      "Epoch [171/500], Validation Loss: 2.1941, Validation RMSE: 1.4813, Valid PR: 0.4242\n",
      "Epoch [172/500], Train Loss: 0.7530, Train RMSE: 0.8678\n",
      "Epoch [172/500], Validation Loss: 2.1943, Validation RMSE: 1.4813, Valid PR: 0.4242\n",
      "Epoch [173/500], Train Loss: 0.7765, Train RMSE: 0.8812\n",
      "Epoch [173/500], Validation Loss: 2.1946, Validation RMSE: 1.4814, Valid PR: 0.4224\n",
      "Epoch [174/500], Train Loss: 0.7230, Train RMSE: 0.8503\n",
      "Epoch [174/500], Validation Loss: 2.1950, Validation RMSE: 1.4816, Valid PR: 0.4207\n",
      "Epoch [175/500], Train Loss: 0.7203, Train RMSE: 0.8487\n",
      "Epoch [175/500], Validation Loss: 2.1953, Validation RMSE: 1.4817, Valid PR: 0.4207\n",
      "Epoch [176/500], Train Loss: 0.6910, Train RMSE: 0.8312\n",
      "Epoch [176/500], Validation Loss: 2.1954, Validation RMSE: 1.4817, Valid PR: 0.4207\n",
      "Epoch [177/500], Train Loss: 0.7073, Train RMSE: 0.8410\n",
      "Epoch [177/500], Validation Loss: 2.1957, Validation RMSE: 1.4818, Valid PR: 0.4189\n",
      "Epoch [178/500], Train Loss: 0.7181, Train RMSE: 0.8474\n",
      "Epoch [178/500], Validation Loss: 2.1961, Validation RMSE: 1.4819, Valid PR: 0.4158\n",
      "Epoch [179/500], Train Loss: 0.6626, Train RMSE: 0.8140\n",
      "Epoch [179/500], Validation Loss: 2.1968, Validation RMSE: 1.4822, Valid PR: 0.4086\n",
      "Epoch [180/500], Train Loss: 0.6798, Train RMSE: 0.8245\n",
      "Epoch [180/500], Validation Loss: 2.1975, Validation RMSE: 1.4824, Valid PR: 0.4021\n",
      "Epoch [181/500], Train Loss: 0.7118, Train RMSE: 0.8437\n",
      "Epoch [181/500], Validation Loss: 2.1982, Validation RMSE: 1.4826, Valid PR: 0.3950\n",
      "Epoch [182/500], Train Loss: 0.6606, Train RMSE: 0.8128\n",
      "Epoch [182/500], Validation Loss: 2.1988, Validation RMSE: 1.4828, Valid PR: 0.3885\n",
      "Epoch [183/500], Train Loss: 0.6722, Train RMSE: 0.8199\n",
      "Epoch [183/500], Validation Loss: 2.1995, Validation RMSE: 1.4831, Valid PR: 0.3834\n",
      "Epoch [184/500], Train Loss: 0.6969, Train RMSE: 0.8348\n",
      "Epoch [184/500], Validation Loss: 2.1999, Validation RMSE: 1.4832, Valid PR: 0.3778\n",
      "Epoch [185/500], Train Loss: 0.7334, Train RMSE: 0.8564\n",
      "Epoch [185/500], Validation Loss: 2.2004, Validation RMSE: 1.4834, Valid PR: 0.3709\n",
      "Epoch [186/500], Train Loss: 0.8026, Train RMSE: 0.8959\n",
      "Epoch [186/500], Validation Loss: 2.2007, Validation RMSE: 1.4835, Valid PR: 0.3722\n",
      "Epoch [187/500], Train Loss: 0.7028, Train RMSE: 0.8383\n",
      "Epoch [187/500], Validation Loss: 2.2009, Validation RMSE: 1.4835, Valid PR: 0.3740\n",
      "Epoch [188/500], Train Loss: 0.7326, Train RMSE: 0.8559\n",
      "Epoch [188/500], Validation Loss: 2.2012, Validation RMSE: 1.4836, Valid PR: 0.3759\n",
      "Epoch [189/500], Train Loss: 0.7505, Train RMSE: 0.8663\n",
      "Epoch [189/500], Validation Loss: 2.2014, Validation RMSE: 1.4837, Valid PR: 0.3782\n",
      "Epoch [190/500], Train Loss: 0.7332, Train RMSE: 0.8563\n",
      "Epoch [190/500], Validation Loss: 2.2015, Validation RMSE: 1.4837, Valid PR: 0.3804\n",
      "Epoch [191/500], Train Loss: 0.7143, Train RMSE: 0.8452\n",
      "Epoch [191/500], Validation Loss: 2.2015, Validation RMSE: 1.4838, Valid PR: 0.3875\n",
      "Epoch [192/500], Train Loss: 0.7146, Train RMSE: 0.8453\n",
      "Epoch [192/500], Validation Loss: 2.2014, Validation RMSE: 1.4837, Valid PR: 0.3945\n",
      "Epoch [193/500], Train Loss: 0.7024, Train RMSE: 0.8381\n",
      "Epoch [193/500], Validation Loss: 2.2009, Validation RMSE: 1.4835, Valid PR: 0.4023\n",
      "Epoch [194/500], Train Loss: 0.7051, Train RMSE: 0.8397\n",
      "Epoch [194/500], Validation Loss: 2.2001, Validation RMSE: 1.4833, Valid PR: 0.4083\n",
      "Epoch [195/500], Train Loss: 0.7582, Train RMSE: 0.8707\n",
      "Epoch [195/500], Validation Loss: 2.1991, Validation RMSE: 1.4829, Valid PR: 0.4128\n",
      "Epoch [196/500], Train Loss: 0.7335, Train RMSE: 0.8564\n",
      "Epoch [196/500], Validation Loss: 2.1981, Validation RMSE: 1.4826, Valid PR: 0.4166\n",
      "Epoch [197/500], Train Loss: 0.7737, Train RMSE: 0.8796\n",
      "Epoch [197/500], Validation Loss: 2.1968, Validation RMSE: 1.4822, Valid PR: 0.4206\n",
      "Epoch [198/500], Train Loss: 0.6851, Train RMSE: 0.8277\n",
      "Epoch [198/500], Validation Loss: 2.1960, Validation RMSE: 1.4819, Valid PR: 0.4228\n",
      "Epoch [199/500], Train Loss: 0.7225, Train RMSE: 0.8500\n",
      "Epoch [199/500], Validation Loss: 2.1949, Validation RMSE: 1.4815, Valid PR: 0.4254\n",
      "Epoch [200/500], Train Loss: 0.7556, Train RMSE: 0.8692\n",
      "Epoch [200/500], Validation Loss: 2.1939, Validation RMSE: 1.4812, Valid PR: 0.4267\n",
      "Epoch [201/500], Train Loss: 0.7411, Train RMSE: 0.8609\n",
      "Epoch [201/500], Validation Loss: 2.1928, Validation RMSE: 1.4808, Valid PR: 0.4271\n",
      "Epoch [202/500], Train Loss: 0.6711, Train RMSE: 0.8192\n",
      "Epoch [202/500], Validation Loss: 2.1921, Validation RMSE: 1.4806, Valid PR: 0.4274\n",
      "Epoch [203/500], Train Loss: 0.8130, Train RMSE: 0.9016\n",
      "Epoch [203/500], Validation Loss: 2.1916, Validation RMSE: 1.4804, Valid PR: 0.4271\n",
      "Epoch [204/500], Train Loss: 0.7351, Train RMSE: 0.8574\n",
      "Epoch [204/500], Validation Loss: 2.1910, Validation RMSE: 1.4802, Valid PR: 0.4269\n",
      "Epoch [205/500], Train Loss: 0.7221, Train RMSE: 0.8498\n",
      "Epoch [205/500], Validation Loss: 2.1905, Validation RMSE: 1.4800, Valid PR: 0.4264\n",
      "Epoch [206/500], Train Loss: 0.7699, Train RMSE: 0.8774\n",
      "Epoch [206/500], Validation Loss: 2.1902, Validation RMSE: 1.4799, Valid PR: 0.4250\n",
      "Early stopping triggered.\n",
      "Test Loss: 3.0747, Test RMSE: 1.7535, Test PR: -0.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51712327/ipykernel_500297/3586863157.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set seed before every training run\n",
    "set_seed(42)\n",
    "\n",
    "# Define transformer-based neural network class\n",
    "class TransformerNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, output_dim):\n",
    "        super(TransformerNN, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)  # Adding sequence length dimension\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.squeeze(1)  # Removing sequence length dimension\n",
    "        return self.fc(x)\n",
    "\n",
    "# Train transformer-based neural network to predict labels and record metrics\n",
    "def train_transformer_nn(train_matrix_encodings, train_vector_encodings, y_train, val_matrix_encodings, val_vector_encodings, y_val, hidden_dim=256, num_heads=2, num_layers=1, learning_rate=3e-4, num_epochs=500, batch_size=512, early_stop_patience=50):\n",
    "    # Combine matrix and vector encodings\n",
    "    train_features = torch.cat((train_matrix_encodings, train_vector_encodings), dim=1)\n",
    "    val_features = torch.cat((val_matrix_encodings, val_vector_encodings), dim=1)\n",
    "    \n",
    "    # Create training and validation datasets\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_features, torch.tensor(y_train, dtype=torch.float32))\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_features, torch.tensor(y_val, dtype=torch.float32))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    input_dim = train_features.size(1)\n",
    "    output_dim = 1  # Assuming regression task\n",
    "    model = TransformerNN(input_dim, hidden_dim, num_heads, num_layers, output_dim).to(device)\n",
    "    criterion = nn.MSELoss() if output_dim == 1 else nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=75, verbose=True)\n",
    "\n",
    "    # DataFrame to store metrics\n",
    "    metrics_df = pd.DataFrame(columns=[\"Epoch\", \"Train Loss\", \"Train RMSE\", \"Valid RMSE\", \"Valid PR\"])\n",
    "\n",
    "    # Variables to track best model\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    accumulation_steps = 4\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for i, (features, labels) in enumerate(train_loader):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass\n",
    "            loss = loss / accumulation_steps\n",
    "            loss.backward()\n",
    "            # Gradient accumulation\n",
    "            if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_rmse = torch.sqrt(torch.tensor(avg_train_loss)).item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_outputs_list = []\n",
    "        val_labels_list = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(features).squeeze()\n",
    "                val_loss = criterion(outputs, labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "                val_outputs_list.append(outputs.cpu())\n",
    "                val_labels_list.append(labels.cpu())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_rmse = torch.sqrt(torch.tensor(avg_val_loss)).item()\n",
    "        val_outputs = torch.cat(val_outputs_list, dim=0)\n",
    "        val_labels = torch.cat(val_labels_list, dim=0)\n",
    "        valid_pr = torch.corrcoef(torch.stack([val_outputs, val_labels]))[0, 1].item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation RMSE: {val_rmse:.4f}, Valid PR: {valid_pr:.4f}\")\n",
    "\n",
    "        # Record metrics\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([{\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": avg_train_loss,\n",
    "            \"Train RMSE\": train_rmse,\n",
    "            \"Valid RMSE\": val_rmse,\n",
    "            \"Valid PR\": valid_pr\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "        # Update best model if validation loss improves\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({'model_state_dict': model.state_dict(), 'hidden_dim': hidden_dim, 'num_heads': num_heads, 'num_layers': num_layers}, f\"best_model_state_{method}_rep_{rep + 1}.pth\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        # Early stopping check\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        # Learning rate decay\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "# Load and test the final model and record metrics\n",
    "def test_transformer_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path, hidden_dim=256, num_heads=4, num_layers=2, batch_size=64):\n",
    "    # Combine matrix and vector encodings\n",
    "    test_features = torch.cat((test_matrix_encodings, test_vector_encodings), dim=1)\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_features, torch.tensor(y_test, dtype=torch.float32))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    input_dim = test_features.size(1)\n",
    "    output_dim = 1  # Assuming regression task\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    hidden_dim = checkpoint['hidden_dim']\n",
    "    num_heads = checkpoint['num_heads']\n",
    "    num_layers = checkpoint['num_layers']\n",
    "    model = TransformerNN(input_dim, hidden_dim, num_heads, num_layers, output_dim).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Define loss function\n",
    "    criterion = nn.MSELoss() if output_dim == 1 else nn.BCEWithLogitsLoss()\n",
    "    total_test_loss = 0\n",
    "    test_outputs_list = []\n",
    "    test_labels_list = []\n",
    "    \n",
    "    # Testing loop\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_test_loss += loss.item()\n",
    "            test_outputs_list.append(outputs.cpu())\n",
    "            test_labels_list.append(labels.cpu())\n",
    "    \n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_rmse = torch.sqrt(torch.tensor(avg_test_loss)).item()\n",
    "    test_outputs = torch.cat(test_outputs_list, dim=0)\n",
    "    test_labels = torch.cat(test_labels_list, dim=0)\n",
    "    test_pr = torch.corrcoef(torch.stack([test_outputs, test_labels]))[0, 1].item()\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test RMSE: {test_rmse:.4f}, Test PR: {test_pr:.4f}\")\n",
    "    \n",
    "    return test_rmse, test_pr\n",
    "\n",
    "# Refactor to test three encoding methods\n",
    "encoding_methods = [\n",
    "    \"method1\",\n",
    "    \"method2\",\n",
    "    \"method3\"\n",
    "]\n",
    "\n",
    "metrics_summary = pd.DataFrame(columns=[\"Method\", \"Epoch\", \"Model Type\", \"Train Loss\", \"Train RMSE\", \"Valid RMSE\", \"Valid PR\", \"Test RMSE\", \"Test PR\"])\n",
    "\n",
    "for method in encoding_methods:\n",
    "    print(f\"Testing {method}...\")\n",
    "    for rep in range(3):\n",
    "        print(f\"Replication {rep + 1} for {method}...\")\n",
    "        \n",
    "        # Define different get_encodings functions for each method\n",
    "        if method == \"method1\":\n",
    "            def get_encodings(model, data_loader, device):\n",
    "                matrix_encodings = []\n",
    "                vector_encodings = []\n",
    "                with torch.no_grad():\n",
    "                    for matrix, vector in data_loader:\n",
    "                        matrix, vector = matrix.to(device), vector.to(device)\n",
    "                        matrix_features, vector_features = model(matrix, vector)\n",
    "                        matrix_encodings.append(matrix_features.cpu())\n",
    "                        vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "                matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "                vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "                return matrix_encodings, vector_encodings\n",
    "        elif method == \"method2\":\n",
    "            def get_encodings(model, data_loader, device):\n",
    "                matrix_encoder, vector_encoder = model.matrix_encoder, model.vector_encoder\n",
    "                matrix_encodings = []\n",
    "                vector_encodings = []\n",
    "                with torch.no_grad():\n",
    "                    for matrix, vector in data_loader:\n",
    "                        matrix, vector = matrix.to(device), vector.to(device)\n",
    "                        matrix_features_encoder = model.matrix_encoder(matrix)\n",
    "                        vector_features_encoder = model.vector_encoder(vector)\n",
    "                        matrix_features, vector_features = model(matrix, vector)\n",
    "                        # Concatenate both outputs\n",
    "                        matrix_features = torch.cat((matrix_features, matrix_features_encoder), dim=-1)\n",
    "                        vector_features = torch.cat((vector_features, vector_features_encoder), dim=-1)\n",
    "                        matrix_encodings.append(matrix_features.cpu())\n",
    "                        vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "                matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "                vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "                return matrix_encodings, vector_encodings\n",
    "        elif method == \"method3\":\n",
    "            def get_encodings(model, data_loader, device):\n",
    "                matrix_encodings = []\n",
    "                vector_encodings = []\n",
    "                with torch.no_grad():\n",
    "                    for matrix, vector in data_loader:\n",
    "                        matrix, vector = matrix.to(device), vector.to(device)\n",
    "                        matrix_features = model.matrix_encoder(matrix)\n",
    "                        vector_features = model.vector_encoder(vector)\n",
    "                        matrix_encodings.append(matrix_features.cpu())\n",
    "                        vector_encodings.append(vector_features.cpu())\n",
    "\n",
    "                matrix_encodings = torch.cat(matrix_encodings, dim=0)\n",
    "                vector_encodings = torch.cat(vector_encodings, dim=0)\n",
    "                return matrix_encodings, vector_encodings\n",
    "        \n",
    "        # Get encodings\n",
    "        train_matrix_encodings, train_vector_encodings = get_encodings(model, train_loader, device)\n",
    "        val_matrix_encodings, val_vector_encodings = get_encodings(model, val_loader, device)\n",
    "        test_matrix_encodings, test_vector_encodings = get_encodings(model, test_loader, device)\n",
    "\n",
    "        # Train transformer-based neural network to predict labels\n",
    "        metrics_df = train_transformer_nn(\n",
    "            train_matrix_encodings, train_vector_encodings, y_train,\n",
    "            val_matrix_encodings, val_vector_encodings, y_val\n",
    "        )\n",
    "\n",
    "        # Test the best model\n",
    "        best_test_rmse, best_test_pr = test_transformer_nn(test_matrix_encodings, test_vector_encodings, y_test, model_path=f\"best_model_state_{method}_rep_{rep + 1}.pth\")\n",
    "\n",
    "        # Store metrics for best model\n",
    "        best_metrics = metrics_df[metrics_df['Valid RMSE'] == metrics_df['Valid RMSE'].min()].copy()\n",
    "        best_metrics[\"Method\"] = method\n",
    "        best_metrics[\"Replication\"] = rep + 1\n",
    "        best_metrics[\"Model Type\"] = \"Best\"\n",
    "        best_metrics[\"Test RMSE\"] = best_test_rmse\n",
    "        best_metrics[\"Test PR\"] = best_test_pr\n",
    "        metrics_summary = pd.concat([metrics_summary, best_metrics], ignore_index=True)\n",
    "\n",
    "# Save summary metrics to CSV\n",
    "metrics_summary.to_csv(\"encoding_methods_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b9f12dd4-b1b5-4577-927a-6dfeddae0934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Valid RMSE</th>\n",
       "      <th>Valid PR</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test PR</th>\n",
       "      <th>Replication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>method1</td>\n",
       "      <td>198</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.499530</td>\n",
       "      <td>0.706775</td>\n",
       "      <td>0.655467</td>\n",
       "      <td>0.922382</td>\n",
       "      <td>1.859185</td>\n",
       "      <td>0.122103</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>method1</td>\n",
       "      <td>266</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.427360</td>\n",
       "      <td>0.653728</td>\n",
       "      <td>0.717947</td>\n",
       "      <td>0.929559</td>\n",
       "      <td>1.798706</td>\n",
       "      <td>0.087363</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>method1</td>\n",
       "      <td>259</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.550690</td>\n",
       "      <td>0.742085</td>\n",
       "      <td>0.618312</td>\n",
       "      <td>0.935124</td>\n",
       "      <td>1.782357</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>method2</td>\n",
       "      <td>254</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.641414</td>\n",
       "      <td>0.800883</td>\n",
       "      <td>1.362149</td>\n",
       "      <td>0.484742</td>\n",
       "      <td>1.759069</td>\n",
       "      <td>-0.150561</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>method2</td>\n",
       "      <td>352</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.623433</td>\n",
       "      <td>0.789578</td>\n",
       "      <td>1.374100</td>\n",
       "      <td>0.381237</td>\n",
       "      <td>1.858708</td>\n",
       "      <td>-0.114307</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>method2</td>\n",
       "      <td>379</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.657787</td>\n",
       "      <td>0.811041</td>\n",
       "      <td>1.362216</td>\n",
       "      <td>0.407839</td>\n",
       "      <td>1.889383</td>\n",
       "      <td>-0.162566</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>method3</td>\n",
       "      <td>146</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.693114</td>\n",
       "      <td>0.832534</td>\n",
       "      <td>1.480243</td>\n",
       "      <td>0.391878</td>\n",
       "      <td>1.747118</td>\n",
       "      <td>-0.114832</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>method3</td>\n",
       "      <td>268</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.664402</td>\n",
       "      <td>0.815109</td>\n",
       "      <td>1.385777</td>\n",
       "      <td>0.434656</td>\n",
       "      <td>1.795099</td>\n",
       "      <td>-0.174513</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>method3</td>\n",
       "      <td>156</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.742992</td>\n",
       "      <td>0.861970</td>\n",
       "      <td>1.479654</td>\n",
       "      <td>0.432712</td>\n",
       "      <td>1.753488</td>\n",
       "      <td>-0.117452</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Method Epoch Model Type  Train Loss  Train RMSE  Valid RMSE  Valid PR  \\\n",
       "0  method1   198       Best    0.499530    0.706775    0.655467  0.922382   \n",
       "1  method1   266       Best    0.427360    0.653728    0.717947  0.929559   \n",
       "2  method1   259       Best    0.550690    0.742085    0.618312  0.935124   \n",
       "3  method2   254       Best    0.641414    0.800883    1.362149  0.484742   \n",
       "4  method2   352       Best    0.623433    0.789578    1.374100  0.381237   \n",
       "5  method2   379       Best    0.657787    0.811041    1.362216  0.407839   \n",
       "6  method3   146       Best    0.693114    0.832534    1.480243  0.391878   \n",
       "7  method3   268       Best    0.664402    0.815109    1.385777  0.434656   \n",
       "8  method3   156       Best    0.742992    0.861970    1.479654  0.432712   \n",
       "\n",
       "   Test RMSE   Test PR  Replication  \n",
       "0   1.859185  0.122103          1.0  \n",
       "1   1.798706  0.087363          2.0  \n",
       "2   1.782357  0.125660          3.0  \n",
       "3   1.759069 -0.150561          1.0  \n",
       "4   1.858708 -0.114307          2.0  \n",
       "5   1.889383 -0.162566          3.0  \n",
       "6   1.747118 -0.114832          1.0  \n",
       "7   1.795099 -0.174513          2.0  \n",
       "8   1.753488 -0.117452          3.0  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc88c9-ca42-4ac9-9dc0-ca6ce1dcecda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce5ab0-129c-432a-9848-9b1e6e6ff8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copra",
   "language": "python",
   "name": "copra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
