{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import parse_yaml\n",
    "dataset_args = parse_yaml('./config/datasets/biolip.yml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_type': 'biolip_dataset',\n",
       " 'df_path': '/home/HR/PIXberts/datasets/BioLiP2/pretrain_length_750_clean.csv',\n",
       " 'batch_size': 20,\n",
       " 'data_root': '/home/HR/PIXberts/datasets/BioLiP2/PDBs',\n",
       " 'num_workers': 0,\n",
       " 'col_prot_name': 'PDB',\n",
       " 'col_prot_chain': 'Protein chains',\n",
       " 'col_na_chain': 'RNA chains',\n",
       " 'col_binding_site': 'Binding site renumbered merged',\n",
       " 'col_ligand': 'Binding ligands',\n",
       " 'pin_memory': True,\n",
       " 'cache_dir': './cache/biolip',\n",
       " 'loss_type': 'regression',\n",
       " 'strategy': 'separate',\n",
       " 'transform': [{'type': 'select_atom', 'resolution': 'backbone'},\n",
       "  {'type': 'selected_region_with_distmap', 'patch_size': 256},\n",
       "  {'type': 'subtract_center_of_mass'}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_modules import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cls = get_dataset(dataset_args)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data.biolip_dataset.BioLiPDataset at 0x14e8ed2a18a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cls(df_train,**dataset_args,diskcache=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('fake_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['fold_0'].isin(['train'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fold_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id fold_0  feature_1  feature_2  feature_3  label\n",
       "0   1  train        0.1        0.2        0.3      0\n",
       "1   2  train        0.4        0.5        0.6      1\n",
       "2   3  train        0.7        0.8        0.9      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.structure_dataset import StructureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('fake_data.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['fold_0'].isin(['train'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB</th>\n",
       "      <th>Protein chains</th>\n",
       "      <th>RNA chains</th>\n",
       "      <th>Binding site renumbered merged</th>\n",
       "      <th>Binding ligands</th>\n",
       "      <th>fold_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1abc</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>ligand1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PDB Protein chains RNA chains Binding site renumbered merged  \\\n",
       "0  1abc              A          B                        1,2,3,4   \n",
       "\n",
       "  Binding ligands fold_0  \n",
       "0         ligand1  train  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from easydict import EasyDict\n",
    "with open('config/datasets/pdbbind_struct.yml', 'r') as f:\n",
    "    content = f.read()\n",
    "    config_dict = EasyDict(yaml.load(content, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_type': 'structure_dataset',\n",
       " 'df_path': '/home/HR/PIXberts/datasets/PNA350/splits_corrected/merge_filtered_5_fold_dG_restrict_resplit_remove.csv',\n",
       " 'batch_size': 16,\n",
       " 'data_root': '/home/HR/PIXberts/datasets/PNA350/PDBs_filtered',\n",
       " 'num_workers': 2,\n",
       " 'col_prot_chain': 'Protein chains',\n",
       " 'col_na_chain': 'RNA chains',\n",
       " 'col_prot': 'Protein sequences',\n",
       " 'col_na': 'RNA sequences',\n",
       " 'col_label': '△G(kcal/mol)',\n",
       " 'pin_memory': True,\n",
       " 'cache_dir': './cache/pdbbind_struct',\n",
       " 'loss_type': 'regression',\n",
       " 'strategy': 'separate',\n",
       " 'transform': [{'type': 'select_atom', 'resolution': 'backbone'},\n",
       "  {'type': 'selected_region_with_distmap', 'patch_size': 256},\n",
       "  {'type': 'subtract_center_of_mass'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "from data.structure_dataset import StructureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tzutang.lin/blue_ufhpc/CoPRA/test.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhpg/home/tzutang.lin/blue_ufhpc/CoPRA/test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m StructureDataset(df_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig_dict, diskcache\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "StructureDataset(df_train, **config_dict, diskcache=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'PDB': ['fake1', 'fake2'],  # Fake PDB IDs\n",
    "    'Protein chains': ['A', 'B'],  # Fake protein chain identifiers\n",
    "    'RNA chains': ['X', 'Y'],  # Fake RNA chain identifiers\n",
    "    'Protein sequences': ['MVLSPADKTNVKAAWGKVGAHAGEYGAEALERMFLSFPTTKTYFPHF','MVLSPADKTNVKAAWGKVGAHAGEYGAEALERMFLSFPTTKTYFPHF'],  # Fake protein sequences\n",
    "    'RNA sequences': ['AUGGCCAUGGCGCCCAGAACUGGGUAA','AUGGCCAUGGCGCCCAGAACUGGGUAA'],  # Fake RNA sequences\n",
    "    '△G(kcal/mol)': [-7.5, -8.2],  # Fake binding affinity values\n",
    "    'fold_0': ['train', 'train'],  # Fake fold assignment\n",
    "    'MUTATION': ['', ''],  # Optional mutation info\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tzutang.lin/blue_ufhpc/CoPRA/test.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhpg/home/tzutang.lin/blue_ufhpc/CoPRA/test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m fake_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "fake_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StructureDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tzutang.lin/blue_ufhpc/CoPRA/test.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhpg/home/tzutang.lin/blue_ufhpc/CoPRA/test.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m StructureDataset(fake_df, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig_dict, diskcache\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StructureDataset' is not defined"
     ]
    }
   ],
   "source": [
    "StructureDataset(fake_df, **config_dict, diskcache=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "from models import ModelRegister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_args:dict=None):\n",
    "    register = ModelRegister()\n",
    "    model_args_ori = {}\n",
    "    model_args_ori.update(model_args)\n",
    "    model_cls = register[model_args['model_type']]\n",
    "    model = model_cls(**model_args_ori)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from easydict import EasyDict\n",
    "with open('config/models/esm2_650M_rinalmo_struct.yml', 'r') as f:\n",
    "    content = f.read()\n",
    "    config_dict = EasyDict(yaml.load(content, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'esm2_rinalmo_struct',\n",
       " 'esm_type': '650M',\n",
       " 'pooling': 'token',\n",
       " 'output_dim': 1,\n",
       " 'fix_lms': True,\n",
       " 'lora_tune': False,\n",
       " 'lora_rank': 16,\n",
       " 'lora_alpha': 32,\n",
       " 'pair_dim': 40,\n",
       " 'dist_dim': 40,\n",
       " 'representation_layer': 33,\n",
       " 'cformer': {'embed_dim': 320,\n",
       "  'pair_dim': 40,\n",
       "  'num_blocks': 6,\n",
       "  'num_heads': 20,\n",
       "  'use_rot_emb': True,\n",
       "  'attn_qkv_bias': False,\n",
       "  'attention_dropout': 0.1,\n",
       "  'transition_dropout': 0.0,\n",
       "  'residual_dropout': 0.1,\n",
       "  'transition_factor': 4,\n",
       "  'use_flash_attn': False}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling Strategy: token\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ESM2RiNALMo(\n",
       "  (esm): ESM2(\n",
       "    (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-32): 33 x TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (rot_emb): RotaryEmbedding()\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (contact_head): ContactPredictionHead(\n",
       "      (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): RobertaLMHead(\n",
       "      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (rinalmo): RiNALMo(\n",
       "    (embedding): Embedding(22, 1280, padding_idx=1)\n",
       "    (transformer): Transformer(\n",
       "      (blocks): ModuleList(\n",
       "        (0-32): 33 x TransformerBlock(\n",
       "          (mh_attn): FlashMultiHeadSelfAttention(\n",
       "            (rotary_emb): RotaryEmbedding()\n",
       "            (flash_self_attn): FlashAttention()\n",
       "            (Wqkv): Linear(in_features=1280, out_features=3840, bias=False)\n",
       "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          )\n",
       "          (attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (transition): Sequential(\n",
       "            (0): SwiGLU(\n",
       "              (linear): Linear(in_features=1280, out_features=3413, bias=True)\n",
       "              (linear_gate): Linear(in_features=1280, out_features=3413, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Linear(in_features=3413, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (residual_dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (residual_dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_mask_head): MaskedLanguageModelHead(\n",
       "      (linear1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear2): Linear(in_features=1280, out_features=22, bias=True)\n",
       "    )\n",
       "    (token_dropout): TokenDropout()\n",
       "  )\n",
       "  (pair_encoder): ResiduePairEncoder(\n",
       "    (aa_pair_embed): Embedding(900, 40)\n",
       "    (relpos_embed): Embedding(65, 40)\n",
       "    (aapair_to_distcoef): Embedding(900, 16)\n",
       "    (distance_embed): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=40, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=40, out_features=40, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (dihedral_embed): AngularEncoding()\n",
       "    (out_mlp): Sequential(\n",
       "      (0): Linear(in_features=146, out_features=40, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=40, out_features=40, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=40, out_features=40, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (c_former): CFormer(\n",
       "    (blocks): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (mh_attn): MultiHeadSelfAttention(\n",
       "          (mh_attn): MultiHeadAttention(\n",
       "            (rotary_emb): RotaryPositionEmbedding()\n",
       "            (struct_bias): Linear(in_features=40, out_features=20, bias=False)\n",
       "            (outer_linear): Linear(in_features=64, out_features=40, bias=True)\n",
       "            (outer_squeeze): Linear(in_features=320, out_features=8, bias=True)\n",
       "            (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "            (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "            (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "            (struct_out_proj): Linear(in_features=40, out_features=40, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (attn_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (transition): Sequential(\n",
       "          (0): SwiGLU(\n",
       "            (linear): Linear(in_features=320, out_features=853, bias=True)\n",
       "            (linear_gate): Linear(in_features=320, out_features=853, bias=True)\n",
       "          )\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "          (2): Linear(in_features=853, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (pair_layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (residual_dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (residual_dropout_2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (pair_final_layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (proj_cplx): Linear(in_features=1280, out_features=320, bias=True)\n",
       "  (z_proj): Linear(in_features=40, out_features=320, bias=True)\n",
       "  (pred_head): Sequential(\n",
       "    (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1280, out_features=1, bias=True)\n",
       "  )\n",
       "  (dist_head): Sequential(\n",
       "    (0): Linear(in_features=40, out_features=1280, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1280, out_features=40, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model(config_dict.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.complex import ComplexInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_pdb_path = '1rpu.pdb'\n",
    "comp = ComplexInput.from_path(fake_pdb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protein-RNA Complex(\n",
       "  seq: NDTREQANGERWDGGSGGITSPFKLPDESPSWTEWRLYNDENPLGFKESWGFGKVVFKRYLRYDRTEASLHRVLGSWTGDSVNYAASRFLGANQVGCTYSIRFRGVSVTISGGSRTLQHLCEMAIRSKQELLQLTPVEVNDTREQANGERWDGGSGGITSPFKLPDESPSWTEWRLYNDENPLGFKESWGFGKVVFKRYLRYDRTEASLHRVLGSWTGDSVNYAASRFLGANQVGCTYSIRFRGVSVTISGGSRTLQHLCEMAIRSKQELLQLTPCGUACGCGUCACGCGUACGUUCGUACGCGUCACGCGUACGUU, \n",
       "  length: 317, \n",
       "  mask: 01111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111, \n",
       "  chainid: 00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111222222222222222222222333333333333333333333, \n",
       "  identifier: 00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000111111111111111111111111111111111111111111, \n",
       "  restype: (317,), \n",
       "  atom_mask: (317, 64), \n",
       "  atom_positions: (317, 64, 3)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from easydict import EasyDict\n",
    "with open('config/datasets/biolip.yml', 'r') as f:\n",
    "    content = f.read()\n",
    "    config_dict = EasyDict(yaml.load(content, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_type': 'biolip_dataset',\n",
       " 'df_path': 'fake_data.csv',\n",
       " 'batch_size': 20,\n",
       " 'data_root': '/home/HR/PIXberts/datasets/BioLiP2/PDBs',\n",
       " 'num_workers': 0,\n",
       " 'col_prot_name': 'PDB',\n",
       " 'col_prot_chain': 'Protein chains',\n",
       " 'col_na_chain': 'RNA chains',\n",
       " 'col_binding_site': 'Binding site renumbered merged',\n",
       " 'col_ligand': 'Binding ligands',\n",
       " 'pin_memory': True,\n",
       " 'cache_dir': './cache/biolip',\n",
       " 'loss_type': 'regression',\n",
       " 'strategy': 'separate',\n",
       " 'transform': [{'type': 'select_atom', 'resolution': 'backbone'},\n",
       "  {'type': 'selected_region_with_distmap', 'patch_size': 256},\n",
       "  {'type': 'subtract_center_of_mass'}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.biolip_dataset import BioLiPDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataModule.train_dataloader of <pl_modules.data_module.DataModule object at 0x1458a508d660>>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataModule(config_dict).train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BioLiPDataset(df_train, **config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1rpu.pdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/tzutang.lin/blue_ufhpc/CoPRA/test.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhpg/home/tzutang.lin/blue_ufhpc/CoPRA/test.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_dataset\u001b[39m.\u001b[39;49mload_data(\u001b[39m'\u001b[39;49m\u001b[39m1rpu.pdb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/blue/yanjun.li/tzutang.lin/CoPRA/data/biolip_dataset.py:66\u001b[0m, in \u001b[0;36mBioLiPDataset.load_data\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> 66\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49mloc[idx]\n\u001b[1;32m     67\u001b[0m     structure_id \u001b[39m=\u001b[39m row[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_prot_name]\n\u001b[1;32m     68\u001b[0m     prot_chains \u001b[39m=\u001b[39m [row[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_prot_chain]]\n",
      "File \u001b[0;32m/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/pandas/core/indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1431\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/pandas/core/indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1380\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1381\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/pandas/core/generic.py:4301\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4299\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[1;32m   4300\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4301\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4303\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   4304\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[0;32m/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '1rpu.pdb'"
     ]
    }
   ],
   "source": [
    "train_dataset.load_data('1rpu.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /blue/yanjun.li/tzutang.lin/.conda/envs/copra/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from data.biolip_dataset import BioLiPStructCollate, BioLiPDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import diskcache\n",
    "import os\n",
    "from data.transforms import get_transform\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "from typing import Optional, Dict\n",
    "from easydict import EasyDict\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "def get_collate(dataset_type):\n",
    "    collate_dict = {'biolip_dataset': BioLiPStructCollate}\n",
    "    return collate_dict[dataset_type]\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 df_path='', \n",
    "                 batch_size=32, \n",
    "                 num_workers=0, \n",
    "                 pin_memory=True, \n",
    "                 cache_dir=None, \n",
    "                 strategy='separate',\n",
    "                 dataset_args=None, \n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.df_path = df_path\n",
    "        self.batch_size=batch_size\n",
    "        self.num_workers=num_workers\n",
    "        self.pin_memory=pin_memory\n",
    "        self.cache_dir=cache_dir\n",
    "        self.strategy=strategy\n",
    "        self.dataset_args=dataset_args\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        if self.cache_dir is None:\n",
    "            cache = None\n",
    "        else:\n",
    "            print(\"Using diskcache at {}.\".format(self.cache_dir))\n",
    "            cache = diskcache.Cache(directory=self.cache_dir, eviction_policy='none')\n",
    "        \n",
    "        df = pd.read_csv(self.df_path)\n",
    "        df_train = df[df['fold_0'].isin(['train'])]\n",
    "        df_val = df[df['fold_0'].isin(['val'])]\n",
    "        df_test = df[df['fold_0'].isin(['test'])]\n",
    "        self.train_dataset = BioLiPDataset(df_train, **self.dataset_args, diskcache=cache)\n",
    "        self.val_dataset = BioLiPDataset(df_val, **self.dataset_args, diskcache=cache)\n",
    "\n",
    "        if len(df_test) > 0 :\n",
    "            print(f\"Using Test Fold to test the model!\")\n",
    "            self.test_dataset = BioLiPDataset(df_test, **self.dataset_args, diskcache=cache)\n",
    "        else:\n",
    "            print(f\"Using Validation Fold fold_0 to test the model!\")\n",
    "            self.test_dataset = BioLiPDataset(df_val, **self.dataset_args, diskcache=cache)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        collate = get_collate(self.dataset_args.dataset_type)\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            persistent_workers=self.num_workers > 0,\n",
    "            collate_fn=collate(strategy=self.strategy),\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        collate = get_collate(self.dataset_args.dataset_type)\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            persistent_workers=self.num_workers > 0,\n",
    "            collate_fn=collate(strategy=self.strategy),\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        collate = get_collate(self.dataset_args.dataset_type)\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            persistent_workers=self.num_workers > 0,\n",
    "            collate_fn=collate(strategy=self.strategy),\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using diskcache at ./cache/biolip.\n",
      "Using Test Fold to test the model!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_args = {\n",
    "    'dataset_type': 'biolip_dataset',\n",
    "    'df_path': 'fake_data.csv',\n",
    "    'batch_size': 20,\n",
    "    'data_root': '/home/HR/PIXberts/datasets/BioLiP2/PDBs',\n",
    "    'num_workers': 0,\n",
    "    'col_prot_name': 'PDB',\n",
    "    'col_prot_chain': 'Protein chains',\n",
    "    'col_na_chain': 'RNA chains',\n",
    "    'col_binding_site': 'Binding site renumbered merged',\n",
    "    'col_ligand': 'Binding ligands',\n",
    "    'pin_memory': True,\n",
    "    'cache_dir': './cache/biolip',\n",
    "    'strategy': 'separate',\n",
    "    'transform': [\n",
    "        {'type': 'select_atom', 'resolution': 'backbone'},\n",
    "        {'type': 'selected_region_with_distmap', 'patch_size': 256},\n",
    "        {'type': 'subtract_center_of_mass'}\n",
    "    ]}\n",
    "\n",
    "datamodule = DataModule(df_path=data_args['df_path'], batch_size=data_args['batch_size'], num_workers=data_args['num_workers'], pin_memory=data_args['pin_memory'], cache_dir=data_args['cache_dir'], strategy=data_args['strategy'], dataset_args=data_args)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate = get_collate('biolip_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data.biolip_dataset.BioLiPStructCollate"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
